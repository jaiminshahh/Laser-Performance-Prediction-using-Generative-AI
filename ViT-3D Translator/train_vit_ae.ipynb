{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f81a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "from models import MaskedAutoencoderViT\n",
    "from dataloader import SpatioTemporalDataset, get_loader\n",
    "from main import getpaths\n",
    "from torch import optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ed0ad1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir_path = 'Results'\n",
    "run_name = 'first_pulse_only'\n",
    "save_path = os.path.join(save_dir_path, run_name)\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2515ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MaskedAutoencoderViT(img_size = 256,\n",
    "                           patch_size = 16,\n",
    "                           in_chans = 600,\n",
    "                           depth = 2,\n",
    "                           num_heads = 2,\n",
    "                           decoder_depth = 2,\n",
    "                           decoder_num_heads = 2,\n",
    "                           mlp_ratio = 4,\n",
    "                           embed_dim = 128,\n",
    "                           decoder_embed_dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f890f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train_dataset: 920\n",
      "length of train_loader: 230\n",
      "\n",
      "\n",
      "length of val_dataset: 240\n",
      "length of val_loader: 60\n",
      "\n",
      "\n",
      "length of test_dataset: 200\n",
      "length of test_loader: 200\n",
      "\n",
      "\n",
      "Shape of input video: torch.Size([4, 1, 600, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "config_path = 'config.yaml'\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "trainfol_path, valfol_path = getpaths(config, mode='train')\n",
    "testfol_path = getpaths(config, mode='test')\n",
    "\n",
    "# Get the dataloader for each of the train valid and test sets\n",
    "train_dataset, train_loader = get_loader(config, trainfol_path, mode='train')\n",
    "val_dataset, val_loader = get_loader(config, valfol_path, mode='valid')\n",
    "test_dataset, test_loader = get_loader(config, testfol_path, mode='test')\n",
    "\n",
    "print(f\"length of train_dataset: {len(train_dataset)}\")\n",
    "print(f\"length of train_loader: {len(train_loader)}\")\n",
    "print(\"\\n\")\n",
    "print(f\"length of val_dataset: {len(val_dataset)}\")\n",
    "print(f\"length of val_loader: {len(val_loader)}\")\n",
    "print(\"\\n\")\n",
    "print(f\"length of test_dataset: {len(test_dataset)}\")\n",
    "print(f\"length of test_loader: {len(test_loader)}\")\n",
    "print(\"\\n\")\n",
    "train_iter = iter(train_loader)\n",
    "inp_vid, tar_img, tar_pls = next(train_iter)\n",
    "print(f\"Shape of input video: {inp_vid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fcc5e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20689655172413793"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "240/(920+240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7bcb1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "criterion = nn.L1Loss()\n",
    "lr = config['training_parameters']['learning_rate']\n",
    "#num_epochs = config['training_parameters']['epochs']\n",
    "num_epochs = 100\n",
    "batch_size = config['training_parameters']['batch_size']\n",
    "optimizer = optim.Adam(net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e956bb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "36d0aef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 1, batch train loss: 104.89038848876953\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 2, batch train loss: 202.65823364257812\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 3, batch train loss: 169.46939086914062\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 4, batch train loss: 82.0373306274414\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 5, batch train loss: 114.58906555175781\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 6, batch train loss: 115.80059814453125\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 7, batch train loss: 108.786376953125\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 8, batch train loss: 82.09578704833984\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 9, batch train loss: 75.38178253173828\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 10, batch train loss: 126.95855712890625\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 11, batch train loss: 74.158935546875\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 12, batch train loss: 91.63133239746094\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 13, batch train loss: 69.26919555664062\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 14, batch train loss: 102.65746307373047\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 15, batch train loss: 75.29608154296875\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 16, batch train loss: 58.589881896972656\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 17, batch train loss: 79.701904296875\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 18, batch train loss: 63.7734375\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 19, batch train loss: 70.7358627319336\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 20, batch train loss: 80.54983520507812\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 21, batch train loss: 72.39411163330078\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 22, batch train loss: 70.57711791992188\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 23, batch train loss: 127.50932312011719\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 24, batch train loss: 66.15125274658203\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 25, batch train loss: 71.88472747802734\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 26, batch train loss: 45.403018951416016\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 27, batch train loss: 88.16635131835938\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 28, batch train loss: 66.7500991821289\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 29, batch train loss: 76.5901870727539\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 30, batch train loss: 57.14278030395508\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 31, batch train loss: 53.07954788208008\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 32, batch train loss: 50.312255859375\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 33, batch train loss: 74.5023193359375\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 34, batch train loss: 60.856666564941406\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 35, batch train loss: 104.85110473632812\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 36, batch train loss: 56.51747512817383\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 37, batch train loss: 83.59750366210938\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 38, batch train loss: 46.037208557128906\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 39, batch train loss: 73.01985931396484\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 40, batch train loss: 38.68094253540039\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 41, batch train loss: 61.336483001708984\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 42, batch train loss: 77.08586883544922\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 43, batch train loss: 51.78340148925781\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 44, batch train loss: 42.878170013427734\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 45, batch train loss: 43.77183151245117\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 46, batch train loss: 40.75107955932617\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 47, batch train loss: 49.20122528076172\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 48, batch train loss: 43.40449905395508\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 49, batch train loss: 44.600730895996094\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 50, batch train loss: 45.24666213989258\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 51, batch train loss: 54.47617721557617\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 52, batch train loss: 39.724552154541016\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 53, batch train loss: 45.641014099121094\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 54, batch train loss: 56.99553298950195\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 55, batch train loss: 46.263004302978516\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 56, batch train loss: 49.28248977661133\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 57, batch train loss: 65.6421127319336\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 58, batch train loss: 39.03901672363281\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 59, batch train loss: 46.62052917480469\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 60, batch train loss: 35.59720230102539\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 61, batch train loss: 45.35813903808594\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 62, batch train loss: 42.53760528564453\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 63, batch train loss: 34.49932098388672\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 64, batch train loss: 38.03402328491211\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 65, batch train loss: 32.829891204833984\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 66, batch train loss: 37.5894889831543\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 67, batch train loss: 36.606361389160156\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 68, batch train loss: 27.624351501464844\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 69, batch train loss: 30.55451774597168\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 70, batch train loss: 34.697811126708984\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 71, batch train loss: 33.373355865478516\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 72, batch train loss: 30.040250778198242\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 73, batch train loss: 27.240842819213867\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 74, batch train loss: 26.739065170288086\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 75, batch train loss: 30.3032169342041\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 76, batch train loss: 28.394638061523438\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 77, batch train loss: 29.010404586791992\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 78, batch train loss: 23.720163345336914\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 79, batch train loss: 28.825057983398438\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 80, batch train loss: 27.78434181213379\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 81, batch train loss: 23.7571964263916\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 82, batch train loss: 28.42056655883789\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 83, batch train loss: 27.94548797607422\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 84, batch train loss: 28.8743839263916\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 85, batch train loss: 27.723804473876953\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 86, batch train loss: 24.306751251220703\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 87, batch train loss: 26.374799728393555\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 88, batch train loss: 25.235355377197266\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 89, batch train loss: 26.524307250976562\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 90, batch train loss: 28.305591583251953\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 91, batch train loss: 27.831275939941406\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 92, batch train loss: 28.76858139038086\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 93, batch train loss: 25.26003646850586\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 94, batch train loss: 33.18217849731445\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 95, batch train loss: 32.058204650878906\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 96, batch train loss: 35.912357330322266\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 97, batch train loss: 34.74043655395508\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 98, batch train loss: 26.563549041748047\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 99, batch train loss: 29.656875610351562\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 100, batch train loss: 27.70659828186035\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 101, batch train loss: 22.2885799407959\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 102, batch train loss: 27.078519821166992\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 103, batch train loss: 20.80071449279785\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 104, batch train loss: 20.98664093017578\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 105, batch train loss: 27.98968505859375\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 106, batch train loss: 22.978103637695312\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 107, batch train loss: 22.459470748901367\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 108, batch train loss: 31.7897891998291\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 109, batch train loss: 26.84898567199707\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 110, batch train loss: 27.690895080566406\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 111, batch train loss: 32.56382751464844\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 112, batch train loss: 21.815271377563477\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 113, batch train loss: 34.062442779541016\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 114, batch train loss: 22.30055046081543\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 115, batch train loss: 27.471094131469727\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 116, batch train loss: 27.26582145690918\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 117, batch train loss: 21.260848999023438\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 118, batch train loss: 38.96639633178711\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 119, batch train loss: 31.803659439086914\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 120, batch train loss: 37.031185150146484\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 121, batch train loss: 33.49545669555664\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 122, batch train loss: 25.985103607177734\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 123, batch train loss: 33.715728759765625\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 124, batch train loss: 32.06717300415039\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 125, batch train loss: 26.171985626220703\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 126, batch train loss: 30.488576889038086\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 127, batch train loss: 41.601829528808594\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 128, batch train loss: 29.933433532714844\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 129, batch train loss: 25.27964210510254\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 130, batch train loss: 22.936431884765625\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 131, batch train loss: 37.5067253112793\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 132, batch train loss: 22.409914016723633\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch_id: 133, batch train loss: 28.306589126586914\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 134, batch train loss: 25.883506774902344\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 135, batch train loss: 29.050643920898438\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 136, batch train loss: 22.886396408081055\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 137, batch train loss: 23.169294357299805\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 138, batch train loss: 26.915855407714844\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 139, batch train loss: 23.03285789489746\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 140, batch train loss: 19.81321907043457\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 141, batch train loss: 19.823848724365234\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 142, batch train loss: 23.57306671142578\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 143, batch train loss: 24.698192596435547\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 144, batch train loss: 21.55986976623535\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 145, batch train loss: 19.375383377075195\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 146, batch train loss: 20.31365966796875\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 147, batch train loss: 20.16812515258789\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 148, batch train loss: 19.562131881713867\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 149, batch train loss: 21.687156677246094\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 150, batch train loss: 20.6283016204834\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 151, batch train loss: 29.741086959838867\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 152, batch train loss: 24.010414123535156\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 153, batch train loss: 26.365461349487305\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 154, batch train loss: 31.323223114013672\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 155, batch train loss: 23.248239517211914\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 156, batch train loss: 24.33289337158203\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 157, batch train loss: 27.034313201904297\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 158, batch train loss: 22.135608673095703\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 159, batch train loss: 28.20123291015625\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 160, batch train loss: 22.185791015625\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 161, batch train loss: 23.554292678833008\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 162, batch train loss: 20.151010513305664\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 163, batch train loss: 22.08327865600586\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 164, batch train loss: 19.195072174072266\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 165, batch train loss: 17.282398223876953\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 166, batch train loss: 15.587627410888672\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 167, batch train loss: 17.96445655822754\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 168, batch train loss: 22.879619598388672\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 169, batch train loss: 21.965913772583008\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 170, batch train loss: 17.072282791137695\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 171, batch train loss: 21.31878662109375\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 172, batch train loss: 19.783926010131836\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 173, batch train loss: 23.01858139038086\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 174, batch train loss: 17.665437698364258\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 175, batch train loss: 17.35687255859375\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 176, batch train loss: 24.554826736450195\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 177, batch train loss: 24.069082260131836\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 178, batch train loss: 24.310260772705078\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 179, batch train loss: 21.576610565185547\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 180, batch train loss: 20.14797592163086\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 181, batch train loss: 21.585594177246094\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 182, batch train loss: 22.973772048950195\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 183, batch train loss: 21.46295166015625\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 184, batch train loss: 19.64743423461914\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 185, batch train loss: 18.79434585571289\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 186, batch train loss: 18.19074821472168\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 187, batch train loss: 16.78517723083496\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 188, batch train loss: 16.73942756652832\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 189, batch train loss: 18.39151382446289\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 190, batch train loss: 19.617090225219727\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 191, batch train loss: 17.057350158691406\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 192, batch train loss: 18.507688522338867\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 193, batch train loss: 15.641617774963379\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 194, batch train loss: 18.458457946777344\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 195, batch train loss: 17.29559326171875\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 196, batch train loss: 16.181062698364258\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 197, batch train loss: 15.269521713256836\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 198, batch train loss: 13.277055740356445\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 199, batch train loss: 13.963215827941895\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 200, batch train loss: 19.13751983642578\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 201, batch train loss: 18.0155086517334\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 202, batch train loss: 22.055387496948242\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 203, batch train loss: 14.643925666809082\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 204, batch train loss: 15.79293155670166\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 205, batch train loss: 18.04694938659668\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 206, batch train loss: 17.768823623657227\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 207, batch train loss: 17.147628784179688\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 208, batch train loss: 18.916276931762695\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 209, batch train loss: 17.52438735961914\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 210, batch train loss: 15.780686378479004\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 211, batch train loss: 17.220365524291992\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 212, batch train loss: 17.525896072387695\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 213, batch train loss: 16.235862731933594\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 214, batch train loss: 20.958187103271484\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 215, batch train loss: 13.9716157913208\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 216, batch train loss: 21.061216354370117\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 217, batch train loss: 18.61948585510254\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 218, batch train loss: 18.187761306762695\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 219, batch train loss: 19.610933303833008\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 220, batch train loss: 14.903014183044434\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 221, batch train loss: 21.594863891601562\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 222, batch train loss: 15.030409812927246\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 223, batch train loss: 22.99777603149414\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 224, batch train loss: 16.38880157470703\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 225, batch train loss: 24.02849578857422\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 226, batch train loss: 23.248018264770508\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 227, batch train loss: 17.793670654296875\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 228, batch train loss: 29.95638656616211\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 229, batch train loss: 17.606096267700195\n",
      "\n",
      "\n",
      "Epoch: 1, batch_id: 230, batch train loss: 25.98225975036621\n",
      "\n",
      "\n",
      "Epoch: 1/ 100, Loss: 36.70655645287555\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Validation Loss: 17.599203888575236\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 2, batch_id: 1, batch train loss: 18.50062370300293\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 2, batch train loss: 16.80335235595703\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 3, batch train loss: 19.435453414916992\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 4, batch train loss: 19.247953414916992\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 5, batch train loss: 19.67225456237793\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 6, batch train loss: 15.629253387451172\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 7, batch train loss: 14.064713478088379\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 8, batch train loss: 15.421529769897461\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 9, batch train loss: 13.8352632522583\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 10, batch train loss: 15.193504333496094\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 11, batch train loss: 13.967073440551758\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 12, batch train loss: 13.685245513916016\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 13, batch train loss: 14.551739692687988\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 14, batch train loss: 22.25029182434082\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 15, batch train loss: 20.128082275390625\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 16, batch train loss: 31.759557723999023\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 17, batch train loss: 22.979949951171875\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 18, batch train loss: 18.027841567993164\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 19, batch train loss: 21.3592586517334\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 20, batch train loss: 17.6545467376709\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 21, batch train loss: 24.097558975219727\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 22, batch train loss: 19.176280975341797\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 23, batch train loss: 20.72495460510254\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 24, batch train loss: 27.777135848999023\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 25, batch train loss: 15.41334342956543\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 26, batch train loss: 24.091594696044922\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 27, batch train loss: 17.492530822753906\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 28, batch train loss: 20.24394416809082\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 29, batch train loss: 22.479591369628906\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 30, batch train loss: 19.600261688232422\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 31, batch train loss: 19.155109405517578\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 32, batch train loss: 14.70474624633789\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 33, batch train loss: 15.579111099243164\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 34, batch train loss: 13.068180084228516\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 35, batch train loss: 16.375137329101562\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 36, batch train loss: 14.223997116088867\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 37, batch train loss: 14.662602424621582\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 38, batch train loss: 18.855018615722656\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 39, batch train loss: 13.489516258239746\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 40, batch train loss: 18.243330001831055\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 41, batch train loss: 16.203428268432617\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 42, batch train loss: 15.70064926147461\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 43, batch train loss: 14.471956253051758\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 44, batch train loss: 16.16712188720703\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 45, batch train loss: 12.447145462036133\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 46, batch train loss: 12.591197967529297\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 47, batch train loss: 13.943326950073242\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 48, batch train loss: 16.40363311767578\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 49, batch train loss: 12.960501670837402\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 50, batch train loss: 14.399015426635742\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 51, batch train loss: 13.827256202697754\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 52, batch train loss: 17.428661346435547\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 53, batch train loss: 15.840522766113281\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 54, batch train loss: 17.7482852935791\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 55, batch train loss: 16.006744384765625\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 56, batch train loss: 14.527358055114746\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 57, batch train loss: 15.615135192871094\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 58, batch train loss: 14.680960655212402\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 59, batch train loss: 14.143881797790527\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 60, batch train loss: 14.88471508026123\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 61, batch train loss: 14.16163444519043\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 62, batch train loss: 15.995580673217773\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 63, batch train loss: 15.534334182739258\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 64, batch train loss: 15.530634880065918\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 65, batch train loss: 13.675640106201172\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 66, batch train loss: 14.990538597106934\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 67, batch train loss: 15.50926399230957\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 68, batch train loss: 19.527271270751953\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 69, batch train loss: 16.959964752197266\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 70, batch train loss: 17.329439163208008\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 71, batch train loss: 13.563260078430176\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 72, batch train loss: 18.1495304107666\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 73, batch train loss: 19.505901336669922\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 74, batch train loss: 16.364961624145508\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 75, batch train loss: 25.82574462890625\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 76, batch train loss: 13.404946327209473\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 77, batch train loss: 16.34649658203125\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 78, batch train loss: 14.262158393859863\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 79, batch train loss: 19.098974227905273\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 80, batch train loss: 14.442753791809082\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 81, batch train loss: 15.891940116882324\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 82, batch train loss: 15.062509536743164\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 83, batch train loss: 16.418664932250977\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 84, batch train loss: 18.687850952148438\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 85, batch train loss: 17.861574172973633\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 86, batch train loss: 23.01689910888672\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 87, batch train loss: 15.612218856811523\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 88, batch train loss: 26.935367584228516\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 89, batch train loss: 16.899513244628906\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 90, batch train loss: 22.70945930480957\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 91, batch train loss: 30.362350463867188\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 92, batch train loss: 22.26148796081543\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 93, batch train loss: 16.498525619506836\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 94, batch train loss: 19.228275299072266\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 95, batch train loss: 17.951066970825195\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 96, batch train loss: 14.971938133239746\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 97, batch train loss: 19.926607131958008\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 98, batch train loss: 14.793790817260742\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 99, batch train loss: 23.272714614868164\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 100, batch train loss: 16.338424682617188\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 101, batch train loss: 16.932703018188477\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 102, batch train loss: 19.369701385498047\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 103, batch train loss: 18.417503356933594\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 104, batch train loss: 15.798185348510742\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 105, batch train loss: 14.378131866455078\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 106, batch train loss: 15.089705467224121\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 107, batch train loss: 16.219202041625977\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 108, batch train loss: 17.76710319519043\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 109, batch train loss: 14.816095352172852\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 110, batch train loss: 14.216045379638672\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 111, batch train loss: 14.235492706298828\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 112, batch train loss: 15.498699188232422\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 113, batch train loss: 14.018702507019043\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 114, batch train loss: 13.091200828552246\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 115, batch train loss: 12.033561706542969\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 116, batch train loss: 16.539154052734375\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 117, batch train loss: 15.196332931518555\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 118, batch train loss: 15.6239013671875\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 119, batch train loss: 14.980820655822754\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 120, batch train loss: 14.960907936096191\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 121, batch train loss: 12.818157196044922\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 122, batch train loss: 15.616676330566406\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 123, batch train loss: 15.946484565734863\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 124, batch train loss: 12.852057456970215\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 125, batch train loss: 14.697737693786621\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 126, batch train loss: 13.06521987915039\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 127, batch train loss: 13.679728507995605\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 128, batch train loss: 15.12728214263916\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 129, batch train loss: 12.741846084594727\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, batch_id: 130, batch train loss: 15.1689453125\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 131, batch train loss: 17.35284996032715\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 132, batch train loss: 17.86240005493164\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 133, batch train loss: 17.053739547729492\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 134, batch train loss: 17.037025451660156\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 135, batch train loss: 12.954758644104004\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 136, batch train loss: 15.726191520690918\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 137, batch train loss: 15.490630149841309\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 138, batch train loss: 17.18354034423828\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 139, batch train loss: 17.986433029174805\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 140, batch train loss: 16.04725456237793\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 141, batch train loss: 24.12300682067871\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 142, batch train loss: 16.648962020874023\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 143, batch train loss: 18.496723175048828\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 144, batch train loss: 19.98267936706543\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 145, batch train loss: 15.966651916503906\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 146, batch train loss: 18.627042770385742\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 147, batch train loss: 16.898590087890625\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 148, batch train loss: 17.96861457824707\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 149, batch train loss: 20.65056610107422\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 150, batch train loss: 18.891204833984375\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 151, batch train loss: 20.717588424682617\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 152, batch train loss: 25.86998748779297\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 153, batch train loss: 17.669391632080078\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 154, batch train loss: 18.84520149230957\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 155, batch train loss: 19.522045135498047\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 156, batch train loss: 15.267642974853516\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 157, batch train loss: 17.784879684448242\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 158, batch train loss: 19.281688690185547\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 159, batch train loss: 22.41676902770996\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 160, batch train loss: 18.46219825744629\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 161, batch train loss: 17.341432571411133\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 162, batch train loss: 18.824281692504883\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 163, batch train loss: 12.836165428161621\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 164, batch train loss: 13.197966575622559\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 165, batch train loss: 15.970107078552246\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 166, batch train loss: 16.862197875976562\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 167, batch train loss: 17.125377655029297\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 168, batch train loss: 15.936521530151367\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 169, batch train loss: 16.863052368164062\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 170, batch train loss: 16.746627807617188\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 171, batch train loss: 17.158748626708984\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 172, batch train loss: 16.391830444335938\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 173, batch train loss: 16.07427978515625\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 174, batch train loss: 11.945770263671875\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 175, batch train loss: 14.352859497070312\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 176, batch train loss: 13.268516540527344\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 177, batch train loss: 13.11015510559082\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 178, batch train loss: 20.144065856933594\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 179, batch train loss: 18.698678970336914\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 180, batch train loss: 15.946121215820312\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 181, batch train loss: 15.339516639709473\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 182, batch train loss: 15.444965362548828\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 183, batch train loss: 17.534303665161133\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 184, batch train loss: 16.266380310058594\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 185, batch train loss: 14.10697078704834\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 186, batch train loss: 18.748062133789062\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 187, batch train loss: 15.536240577697754\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 188, batch train loss: 16.1816463470459\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 189, batch train loss: 16.23373031616211\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 190, batch train loss: 21.0187931060791\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 191, batch train loss: 14.947656631469727\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 192, batch train loss: 18.593826293945312\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 193, batch train loss: 19.554420471191406\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 194, batch train loss: 14.310362815856934\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 195, batch train loss: 21.763334274291992\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 196, batch train loss: 15.593567848205566\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 197, batch train loss: 16.806550979614258\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 198, batch train loss: 18.037845611572266\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 199, batch train loss: 14.791191101074219\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 200, batch train loss: 21.0004825592041\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 201, batch train loss: 13.381580352783203\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 202, batch train loss: 16.83700180053711\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 203, batch train loss: 14.439962387084961\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 204, batch train loss: 13.369933128356934\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 205, batch train loss: 15.361507415771484\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 206, batch train loss: 13.464137077331543\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 207, batch train loss: 12.558545112609863\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 208, batch train loss: 12.21899127960205\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 209, batch train loss: 12.709257125854492\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 210, batch train loss: 12.876395225524902\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 211, batch train loss: 14.216232299804688\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 212, batch train loss: 14.584930419921875\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 213, batch train loss: 15.349112510681152\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 214, batch train loss: 12.974678993225098\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 215, batch train loss: 15.166321754455566\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 216, batch train loss: 12.965604782104492\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 217, batch train loss: 12.88134479522705\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 218, batch train loss: 14.143842697143555\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 219, batch train loss: 12.169059753417969\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 220, batch train loss: 12.84421443939209\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 221, batch train loss: 14.120722770690918\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 222, batch train loss: 16.067291259765625\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 223, batch train loss: 12.318413734436035\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 224, batch train loss: 13.056292533874512\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 225, batch train loss: 12.060908317565918\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 226, batch train loss: 13.363478660583496\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 227, batch train loss: 12.063326835632324\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 228, batch train loss: 14.405729293823242\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 229, batch train loss: 13.115604400634766\n",
      "\n",
      "\n",
      "Epoch: 2, batch_id: 230, batch train loss: 15.479287147521973\n",
      "\n",
      "\n",
      "Epoch: 2/ 100, Loss: 16.60584781066231\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:08<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Validation Loss: 14.344892835617065\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 3, batch_id: 1, batch train loss: 13.9579496383667\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 2, batch train loss: 12.574519157409668\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 3, batch train loss: 16.54865074157715\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 4, batch train loss: 15.57947063446045\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 5, batch train loss: 14.233428001403809\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 6, batch train loss: 15.426046371459961\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 7, batch train loss: 12.521978378295898\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 8, batch train loss: 14.404775619506836\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 9, batch train loss: 16.92864990234375\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 10, batch train loss: 16.170515060424805\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 11, batch train loss: 16.1837100982666\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 12, batch train loss: 13.014446258544922\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 13, batch train loss: 16.539121627807617\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 14, batch train loss: 14.78126335144043\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 15, batch train loss: 13.209858894348145\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 16, batch train loss: 19.31502342224121\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 17, batch train loss: 15.204630851745605\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 18, batch train loss: 15.934646606445312\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 19, batch train loss: 19.250307083129883\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 20, batch train loss: 14.809202194213867\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 21, batch train loss: 15.166411399841309\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 22, batch train loss: 15.693605422973633\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 23, batch train loss: 12.06240177154541\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 24, batch train loss: 13.643308639526367\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 25, batch train loss: 12.468708038330078\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 26, batch train loss: 13.509685516357422\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 27, batch train loss: 12.468832015991211\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 28, batch train loss: 13.51898193359375\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 29, batch train loss: 15.467747688293457\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 30, batch train loss: 12.515241622924805\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 31, batch train loss: 11.88077163696289\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 32, batch train loss: 12.721292495727539\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 33, batch train loss: 12.173582077026367\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 34, batch train loss: 12.352785110473633\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 35, batch train loss: 10.4044828414917\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 36, batch train loss: 12.814123153686523\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 37, batch train loss: 11.80151081085205\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 38, batch train loss: 12.846846580505371\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 39, batch train loss: 11.143324851989746\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 40, batch train loss: 12.84145736694336\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 41, batch train loss: 11.376282691955566\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 42, batch train loss: 15.168021202087402\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 43, batch train loss: 13.995080947875977\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 44, batch train loss: 20.56032943725586\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 45, batch train loss: 13.407944679260254\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 46, batch train loss: 17.337509155273438\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 47, batch train loss: 18.931028366088867\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 48, batch train loss: 15.200701713562012\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 49, batch train loss: 21.335283279418945\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 50, batch train loss: 13.637343406677246\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 51, batch train loss: 18.690765380859375\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 52, batch train loss: 18.498462677001953\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 53, batch train loss: 14.408431053161621\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 54, batch train loss: 18.65927505493164\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 55, batch train loss: 22.60334014892578\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 56, batch train loss: 15.111185073852539\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 57, batch train loss: 19.047483444213867\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 58, batch train loss: 22.997177124023438\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 59, batch train loss: 23.037878036499023\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 60, batch train loss: 21.74492835998535\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 61, batch train loss: 23.843677520751953\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 62, batch train loss: 36.72279357910156\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 63, batch train loss: 16.464679718017578\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 64, batch train loss: 20.59174156188965\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 65, batch train loss: 20.266685485839844\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 66, batch train loss: 18.978796005249023\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 67, batch train loss: 17.305566787719727\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 68, batch train loss: 17.809362411499023\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 69, batch train loss: 15.470587730407715\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 70, batch train loss: 15.2947359085083\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 71, batch train loss: 16.739377975463867\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 72, batch train loss: 17.6177978515625\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 73, batch train loss: 17.899564743041992\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 74, batch train loss: 14.90994644165039\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 75, batch train loss: 13.1218843460083\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 76, batch train loss: 12.37961483001709\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 77, batch train loss: 13.468600273132324\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 78, batch train loss: 12.738265037536621\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 79, batch train loss: 18.331087112426758\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 80, batch train loss: 11.51876449584961\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 81, batch train loss: 14.2193021774292\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 82, batch train loss: 11.487292289733887\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 83, batch train loss: 12.870397567749023\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 84, batch train loss: 12.918319702148438\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 85, batch train loss: 11.541378021240234\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 86, batch train loss: 11.640053749084473\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 87, batch train loss: 12.300742149353027\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 88, batch train loss: 12.831738471984863\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 89, batch train loss: 11.513994216918945\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 90, batch train loss: 12.940235137939453\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 91, batch train loss: 11.640730857849121\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 92, batch train loss: 12.766759872436523\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 93, batch train loss: 12.680928230285645\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 94, batch train loss: 11.199409484863281\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 95, batch train loss: 11.79645824432373\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 96, batch train loss: 11.39663028717041\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 97, batch train loss: 13.580951690673828\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 98, batch train loss: 12.995230674743652\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 99, batch train loss: 13.565698623657227\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 100, batch train loss: 13.961101531982422\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 101, batch train loss: 15.319293975830078\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 102, batch train loss: 12.774615287780762\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 103, batch train loss: 17.100982666015625\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 104, batch train loss: 14.319755554199219\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 105, batch train loss: 18.24070167541504\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 106, batch train loss: 20.027578353881836\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 107, batch train loss: 15.597454071044922\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 108, batch train loss: 18.28225326538086\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 109, batch train loss: 15.382960319519043\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 110, batch train loss: 15.805889129638672\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 111, batch train loss: 14.606682777404785\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 112, batch train loss: 14.215500831604004\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 113, batch train loss: 13.748201370239258\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 114, batch train loss: 11.221141815185547\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 115, batch train loss: 10.29112434387207\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 116, batch train loss: 13.76640796661377\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 117, batch train loss: 12.919002532958984\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 118, batch train loss: 12.214559555053711\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 119, batch train loss: 11.050952911376953\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 120, batch train loss: 11.540902137756348\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 121, batch train loss: 11.307202339172363\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 122, batch train loss: 11.045084953308105\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 123, batch train loss: 12.55264663696289\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 124, batch train loss: 15.086158752441406\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 125, batch train loss: 15.413620948791504\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 126, batch train loss: 15.971142768859863\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 127, batch train loss: 14.866479873657227\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 128, batch train loss: 13.68266773223877\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 129, batch train loss: 11.127655982971191\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, batch_id: 130, batch train loss: 12.69702434539795\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 131, batch train loss: 14.403122901916504\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 132, batch train loss: 15.06684398651123\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 133, batch train loss: 13.901076316833496\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 134, batch train loss: 11.798056602478027\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 135, batch train loss: 12.334857940673828\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 136, batch train loss: 15.915660858154297\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 137, batch train loss: 13.714735984802246\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 138, batch train loss: 14.705582618713379\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 139, batch train loss: 13.558640480041504\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 140, batch train loss: 16.79550552368164\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 141, batch train loss: 14.868380546569824\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 142, batch train loss: 15.277228355407715\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 143, batch train loss: 12.488822937011719\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 144, batch train loss: 12.61082649230957\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 145, batch train loss: 16.664424896240234\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 146, batch train loss: 12.267545700073242\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 147, batch train loss: 16.808488845825195\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 148, batch train loss: 10.695319175720215\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 149, batch train loss: 12.710371017456055\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 150, batch train loss: 10.901782035827637\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 151, batch train loss: 14.21207332611084\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 152, batch train loss: 12.32248592376709\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 153, batch train loss: 11.47795581817627\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 154, batch train loss: 11.42236328125\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 155, batch train loss: 13.333236694335938\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 156, batch train loss: 11.046064376831055\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 157, batch train loss: 14.055359840393066\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 158, batch train loss: 12.560269355773926\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 159, batch train loss: 10.829565048217773\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 160, batch train loss: 11.22321891784668\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 161, batch train loss: 11.268269538879395\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 162, batch train loss: 9.51517105102539\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 163, batch train loss: 13.818693161010742\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 164, batch train loss: 11.523751258850098\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 165, batch train loss: 12.982274055480957\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 166, batch train loss: 12.322589874267578\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 167, batch train loss: 8.917388916015625\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 168, batch train loss: 11.371111869812012\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 169, batch train loss: 12.077594757080078\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 170, batch train loss: 12.59150505065918\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 171, batch train loss: 14.162750244140625\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 172, batch train loss: 17.78424835205078\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 173, batch train loss: 15.18896198272705\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 174, batch train loss: 13.200824737548828\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 175, batch train loss: 11.079324722290039\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 176, batch train loss: 11.587510108947754\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 177, batch train loss: 13.813333511352539\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 178, batch train loss: 15.342703819274902\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 179, batch train loss: 18.920654296875\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 180, batch train loss: 12.306952476501465\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 181, batch train loss: 16.733497619628906\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 182, batch train loss: 12.544445991516113\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 183, batch train loss: 14.807662963867188\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 184, batch train loss: 17.2563419342041\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 185, batch train loss: 14.87208366394043\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 186, batch train loss: 15.945618629455566\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 187, batch train loss: 11.516892433166504\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 188, batch train loss: 18.93721580505371\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 189, batch train loss: 14.789767265319824\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 190, batch train loss: 15.118456840515137\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 191, batch train loss: 17.027006149291992\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 192, batch train loss: 15.266477584838867\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 193, batch train loss: 18.067644119262695\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 194, batch train loss: 12.837754249572754\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 195, batch train loss: 16.809871673583984\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 196, batch train loss: 12.328156471252441\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 197, batch train loss: 12.926000595092773\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 198, batch train loss: 18.0788516998291\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 199, batch train loss: 13.083998680114746\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 200, batch train loss: 16.04391098022461\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 201, batch train loss: 10.71014404296875\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 202, batch train loss: 14.098052024841309\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 203, batch train loss: 12.567809104919434\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 204, batch train loss: 16.071636199951172\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 205, batch train loss: 15.812552452087402\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 206, batch train loss: 13.888273239135742\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 207, batch train loss: 12.533674240112305\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 208, batch train loss: 13.722900390625\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 209, batch train loss: 13.586518287658691\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 210, batch train loss: 12.70987606048584\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 211, batch train loss: 12.763072967529297\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 212, batch train loss: 11.897631645202637\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 213, batch train loss: 11.938774108886719\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 214, batch train loss: 12.717582702636719\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 215, batch train loss: 16.062599182128906\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 216, batch train loss: 17.266197204589844\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 217, batch train loss: 14.93823528289795\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 218, batch train loss: 14.780538558959961\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 219, batch train loss: 18.467037200927734\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 220, batch train loss: 15.816326141357422\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 221, batch train loss: 16.314062118530273\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 222, batch train loss: 13.386592864990234\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 223, batch train loss: 21.36248779296875\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 224, batch train loss: 16.750621795654297\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 225, batch train loss: 13.735862731933594\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 226, batch train loss: 18.499208450317383\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 227, batch train loss: 14.013128280639648\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 228, batch train loss: 19.1069278717041\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 229, batch train loss: 18.773954391479492\n",
      "\n",
      "\n",
      "Epoch: 3, batch_id: 230, batch train loss: 13.176599502563477\n",
      "\n",
      "\n",
      "Epoch: 3/ 100, Loss: 14.589279502371083\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:07<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Validation Loss: 17.8206778049469\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, batch_id: 1, batch train loss: 16.540794372558594\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 2, batch train loss: 13.991341590881348\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 3, batch train loss: 12.954111099243164\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 4, batch train loss: 15.67642593383789\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 5, batch train loss: 10.656128883361816\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 6, batch train loss: 17.980562210083008\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 7, batch train loss: 17.6519718170166\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 8, batch train loss: 15.59237289428711\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 9, batch train loss: 19.54058837890625\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 10, batch train loss: 9.750265121459961\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 11, batch train loss: 16.84865379333496\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 12, batch train loss: 17.199247360229492\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 13, batch train loss: 14.705169677734375\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 14, batch train loss: 15.296826362609863\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 15, batch train loss: 14.09737491607666\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 16, batch train loss: 12.93443489074707\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 17, batch train loss: 13.421156883239746\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 18, batch train loss: 11.277515411376953\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 19, batch train loss: 13.017595291137695\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 20, batch train loss: 13.609683990478516\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 21, batch train loss: 12.178332328796387\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 22, batch train loss: 11.255345344543457\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 23, batch train loss: 13.172099113464355\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 24, batch train loss: 10.845684051513672\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 25, batch train loss: 15.07335090637207\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 26, batch train loss: 13.156920433044434\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 27, batch train loss: 10.772725105285645\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 28, batch train loss: 13.18093490600586\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 29, batch train loss: 10.2367525100708\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 30, batch train loss: 11.103678703308105\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 31, batch train loss: 11.120311737060547\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 32, batch train loss: 13.077583312988281\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 33, batch train loss: 12.738956451416016\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 34, batch train loss: 11.197929382324219\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 35, batch train loss: 10.889627456665039\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 36, batch train loss: 13.004241943359375\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 37, batch train loss: 11.700165748596191\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 38, batch train loss: 14.624065399169922\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 39, batch train loss: 10.528863906860352\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 40, batch train loss: 10.728123664855957\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 41, batch train loss: 9.322466850280762\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 42, batch train loss: 9.767109870910645\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 43, batch train loss: 11.334113121032715\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 44, batch train loss: 13.255099296569824\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 45, batch train loss: 13.500146865844727\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 46, batch train loss: 11.436993598937988\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 47, batch train loss: 12.427438735961914\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 48, batch train loss: 10.955925941467285\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 49, batch train loss: 10.66097354888916\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 50, batch train loss: 12.367744445800781\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 51, batch train loss: 14.258834838867188\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 52, batch train loss: 13.616724967956543\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 53, batch train loss: 14.128653526306152\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 54, batch train loss: 13.096783638000488\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 55, batch train loss: 12.930861473083496\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 56, batch train loss: 14.009288787841797\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 57, batch train loss: 13.61720085144043\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 58, batch train loss: 12.107845306396484\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 59, batch train loss: 14.436339378356934\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 60, batch train loss: 15.050633430480957\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 61, batch train loss: 12.889357566833496\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 62, batch train loss: 14.215191841125488\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 63, batch train loss: 10.655245780944824\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 64, batch train loss: 11.475571632385254\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 65, batch train loss: 11.306184768676758\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 66, batch train loss: 13.612181663513184\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 67, batch train loss: 10.783973693847656\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 68, batch train loss: 11.585102081298828\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 69, batch train loss: 11.97201156616211\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 70, batch train loss: 13.03282356262207\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 71, batch train loss: 13.796690940856934\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 72, batch train loss: 14.451370239257812\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 73, batch train loss: 13.161703109741211\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 74, batch train loss: 15.296289443969727\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 75, batch train loss: 16.298297882080078\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 76, batch train loss: 11.470039367675781\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 77, batch train loss: 12.802713394165039\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 78, batch train loss: 9.614766120910645\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 79, batch train loss: 10.266544342041016\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 80, batch train loss: 9.2935209274292\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 81, batch train loss: 10.328906059265137\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 82, batch train loss: 13.3502779006958\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 83, batch train loss: 13.010103225708008\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 84, batch train loss: 11.746966361999512\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 85, batch train loss: 11.608716011047363\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 86, batch train loss: 11.748457908630371\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 87, batch train loss: 12.166463851928711\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 88, batch train loss: 13.1714506149292\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 89, batch train loss: 10.630334854125977\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 90, batch train loss: 10.963911056518555\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 91, batch train loss: 12.385725975036621\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 92, batch train loss: 9.931831359863281\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 93, batch train loss: 10.465378761291504\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 94, batch train loss: 10.98542594909668\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 95, batch train loss: 10.512890815734863\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 96, batch train loss: 12.343843460083008\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 97, batch train loss: 11.240035057067871\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 98, batch train loss: 10.640499114990234\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 99, batch train loss: 10.4677095413208\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 100, batch train loss: 15.046340942382812\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 101, batch train loss: 13.549703598022461\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 102, batch train loss: 12.454202651977539\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 103, batch train loss: 12.465224266052246\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 104, batch train loss: 12.278045654296875\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 105, batch train loss: 12.449297904968262\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 106, batch train loss: 9.338088035583496\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 107, batch train loss: 9.369709968566895\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 108, batch train loss: 13.531737327575684\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 109, batch train loss: 11.940635681152344\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 110, batch train loss: 10.857728958129883\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 111, batch train loss: 11.089935302734375\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 112, batch train loss: 11.819497108459473\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 113, batch train loss: 11.394515991210938\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 114, batch train loss: 11.190926551818848\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 115, batch train loss: 17.02420997619629\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 116, batch train loss: 16.5527400970459\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 117, batch train loss: 14.698253631591797\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 118, batch train loss: 15.239534378051758\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 119, batch train loss: 12.471240997314453\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 120, batch train loss: 12.734902381896973\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 121, batch train loss: 11.761265754699707\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 122, batch train loss: 10.443495750427246\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 123, batch train loss: 12.48071575164795\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 124, batch train loss: 10.586137771606445\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 125, batch train loss: 12.483094215393066\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 126, batch train loss: 10.42644214630127\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 127, batch train loss: 11.701362609863281\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 128, batch train loss: 13.237773895263672\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 129, batch train loss: 11.872672080993652\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 130, batch train loss: 9.677724838256836\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 131, batch train loss: 10.502281188964844\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, batch_id: 132, batch train loss: 10.350976943969727\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 133, batch train loss: 12.74935245513916\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 134, batch train loss: 12.573467254638672\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 135, batch train loss: 15.702153205871582\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 136, batch train loss: 12.060161590576172\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 137, batch train loss: 14.277579307556152\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 138, batch train loss: 12.690190315246582\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 139, batch train loss: 12.140525817871094\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 140, batch train loss: 12.869121551513672\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 141, batch train loss: 12.416086196899414\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 142, batch train loss: 13.345954895019531\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 143, batch train loss: 12.79466438293457\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 144, batch train loss: 12.78193187713623\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 145, batch train loss: 16.374183654785156\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 146, batch train loss: 13.039444923400879\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 147, batch train loss: 13.017820358276367\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 148, batch train loss: 11.76281452178955\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 149, batch train loss: 11.910772323608398\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 150, batch train loss: 13.359994888305664\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 151, batch train loss: 12.81930923461914\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 152, batch train loss: 13.37745475769043\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 153, batch train loss: 14.051027297973633\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 154, batch train loss: 12.902356147766113\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 155, batch train loss: 12.424266815185547\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 156, batch train loss: 12.436187744140625\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 157, batch train loss: 12.147969245910645\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 158, batch train loss: 12.345711708068848\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 159, batch train loss: 12.023197174072266\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 160, batch train loss: 11.77945613861084\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 161, batch train loss: 10.849128723144531\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 162, batch train loss: 10.95901107788086\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 163, batch train loss: 10.327463150024414\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 164, batch train loss: 10.969735145568848\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 165, batch train loss: 11.222858428955078\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 166, batch train loss: 13.767980575561523\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 167, batch train loss: 11.429734230041504\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 168, batch train loss: 11.104894638061523\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 169, batch train loss: 11.572537422180176\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 170, batch train loss: 10.533116340637207\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 171, batch train loss: 10.583832740783691\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 172, batch train loss: 9.289841651916504\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 173, batch train loss: 10.649858474731445\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 174, batch train loss: 14.117180824279785\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 175, batch train loss: 12.209237098693848\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 176, batch train loss: 12.93818187713623\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 177, batch train loss: 11.707343101501465\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 178, batch train loss: 14.896419525146484\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 179, batch train loss: 12.543109893798828\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 180, batch train loss: 10.913714408874512\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 181, batch train loss: 11.579571723937988\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 182, batch train loss: 12.578202247619629\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 183, batch train loss: 11.428051948547363\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 184, batch train loss: 12.1275634765625\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 185, batch train loss: 9.448429107666016\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 186, batch train loss: 11.067909240722656\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 187, batch train loss: 11.238884925842285\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 188, batch train loss: 11.768057823181152\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 189, batch train loss: 11.960745811462402\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 190, batch train loss: 10.462409019470215\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 191, batch train loss: 9.14564323425293\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 192, batch train loss: 12.520458221435547\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 193, batch train loss: 10.759703636169434\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 194, batch train loss: 12.155180931091309\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 195, batch train loss: 11.664984703063965\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 196, batch train loss: 9.810510635375977\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 197, batch train loss: 10.109197616577148\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 198, batch train loss: 10.385578155517578\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 199, batch train loss: 13.550671577453613\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 200, batch train loss: 10.988815307617188\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 201, batch train loss: 10.737707138061523\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 202, batch train loss: 14.852564811706543\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 203, batch train loss: 14.41390609741211\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 204, batch train loss: 18.70102882385254\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 205, batch train loss: 17.449026107788086\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 206, batch train loss: 14.791557312011719\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 207, batch train loss: 15.306684494018555\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 208, batch train loss: 12.411700248718262\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 209, batch train loss: 11.836713790893555\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 210, batch train loss: 14.315305709838867\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 211, batch train loss: 12.721964836120605\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 212, batch train loss: 16.463661193847656\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 213, batch train loss: 13.814510345458984\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 214, batch train loss: 15.988064765930176\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 215, batch train loss: 13.445781707763672\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 216, batch train loss: 12.513408660888672\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 217, batch train loss: 16.071439743041992\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 218, batch train loss: 14.030879020690918\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 219, batch train loss: 24.224536895751953\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 220, batch train loss: 15.317543983459473\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 221, batch train loss: 16.210554122924805\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 222, batch train loss: 13.28991985321045\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 223, batch train loss: 11.632923126220703\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 224, batch train loss: 15.261528015136719\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 225, batch train loss: 12.587729454040527\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 226, batch train loss: 11.444841384887695\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 227, batch train loss: 14.170525550842285\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 228, batch train loss: 17.086639404296875\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 229, batch train loss: 19.277172088623047\n",
      "\n",
      "\n",
      "Epoch: 4, batch_id: 230, batch train loss: 22.10016441345215\n",
      "\n",
      "\n",
      "Epoch: 4/ 100, Loss: 12.722986528147821\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:20<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Validation Loss: 14.682053836186727\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, batch_id: 1, batch train loss: 14.314596176147461\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 2, batch train loss: 16.03667449951172\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 3, batch train loss: 13.533051490783691\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 4, batch train loss: 15.491671562194824\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 5, batch train loss: 15.668813705444336\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 6, batch train loss: 14.679397583007812\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 7, batch train loss: 14.93045711517334\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 8, batch train loss: 11.965827941894531\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 9, batch train loss: 10.414770126342773\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 10, batch train loss: 10.798517227172852\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 11, batch train loss: 11.476304054260254\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 12, batch train loss: 11.411646842956543\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 13, batch train loss: 10.867806434631348\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 14, batch train loss: 11.841907501220703\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 15, batch train loss: 11.536568641662598\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 16, batch train loss: 12.476910591125488\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 17, batch train loss: 13.173013687133789\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 18, batch train loss: 12.032615661621094\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 19, batch train loss: 13.47036075592041\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 20, batch train loss: 11.554295539855957\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 21, batch train loss: 10.645648956298828\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 22, batch train loss: 14.194109916687012\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 23, batch train loss: 12.08043384552002\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 24, batch train loss: 14.240273475646973\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 25, batch train loss: 10.339035034179688\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 26, batch train loss: 10.739526748657227\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 27, batch train loss: 13.650084495544434\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 28, batch train loss: 12.926850318908691\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 29, batch train loss: 12.875460624694824\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 30, batch train loss: 10.705429077148438\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 31, batch train loss: 14.780670166015625\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 32, batch train loss: 12.8358793258667\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 33, batch train loss: 14.491689682006836\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 34, batch train loss: 14.072762489318848\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 35, batch train loss: 12.413411140441895\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 36, batch train loss: 13.036738395690918\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 37, batch train loss: 12.94261646270752\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 38, batch train loss: 15.673069953918457\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 39, batch train loss: 12.466204643249512\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 40, batch train loss: 16.288312911987305\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 41, batch train loss: 18.603654861450195\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 42, batch train loss: 12.176433563232422\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 43, batch train loss: 17.697450637817383\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 44, batch train loss: 10.248260498046875\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 45, batch train loss: 15.264883041381836\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 46, batch train loss: 11.908307075500488\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 47, batch train loss: 11.86571979522705\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 48, batch train loss: 14.663595199584961\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 49, batch train loss: 13.047526359558105\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 50, batch train loss: 12.7791748046875\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 51, batch train loss: 11.118603706359863\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 52, batch train loss: 10.6278715133667\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 53, batch train loss: 11.569235801696777\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 54, batch train loss: 10.954063415527344\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 55, batch train loss: 15.154587745666504\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 56, batch train loss: 12.699748992919922\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 57, batch train loss: 11.320931434631348\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 58, batch train loss: 12.628819465637207\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 59, batch train loss: 11.853363037109375\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 60, batch train loss: 11.804068565368652\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 61, batch train loss: 11.17003345489502\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 62, batch train loss: 12.266973495483398\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 63, batch train loss: 13.359816551208496\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 64, batch train loss: 12.061514854431152\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 65, batch train loss: 13.030404090881348\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 66, batch train loss: 14.74433422088623\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 67, batch train loss: 15.086383819580078\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 68, batch train loss: 12.267851829528809\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 69, batch train loss: 11.197199821472168\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 70, batch train loss: 10.237149238586426\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 71, batch train loss: 11.004369735717773\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 72, batch train loss: 11.506621360778809\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 73, batch train loss: 9.611586570739746\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 74, batch train loss: 11.867168426513672\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 75, batch train loss: 14.53885555267334\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 76, batch train loss: 13.80182933807373\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 77, batch train loss: 12.769678115844727\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 78, batch train loss: 13.277909278869629\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 79, batch train loss: 10.555134773254395\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 80, batch train loss: 12.678698539733887\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 81, batch train loss: 11.131160736083984\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 82, batch train loss: 13.690885543823242\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 83, batch train loss: 12.235891342163086\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 84, batch train loss: 11.82421588897705\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 85, batch train loss: 14.693408012390137\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 86, batch train loss: 10.965784072875977\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 87, batch train loss: 15.99000358581543\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 88, batch train loss: 10.7286958694458\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 89, batch train loss: 9.954188346862793\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 90, batch train loss: 11.076116561889648\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 91, batch train loss: 9.118361473083496\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 92, batch train loss: 10.230981826782227\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 93, batch train loss: 10.290492057800293\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 94, batch train loss: 14.679800987243652\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 95, batch train loss: 10.450508117675781\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 96, batch train loss: 14.668737411499023\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 97, batch train loss: 11.126441955566406\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 98, batch train loss: 11.272759437561035\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 99, batch train loss: 9.194610595703125\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 100, batch train loss: 9.733246803283691\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 101, batch train loss: 10.809723854064941\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 102, batch train loss: 12.929533004760742\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 103, batch train loss: 17.825302124023438\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 104, batch train loss: 14.070616722106934\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 105, batch train loss: 13.054839134216309\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 106, batch train loss: 13.59406852722168\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 107, batch train loss: 11.11678409576416\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 108, batch train loss: 13.664721488952637\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 109, batch train loss: 11.8420991897583\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 110, batch train loss: 13.212716102600098\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 111, batch train loss: 15.77905559539795\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 112, batch train loss: 13.059447288513184\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 113, batch train loss: 12.84665298461914\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 114, batch train loss: 12.439664840698242\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 115, batch train loss: 12.774821281433105\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 116, batch train loss: 10.548659324645996\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 117, batch train loss: 11.11484146118164\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 118, batch train loss: 9.656472206115723\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 119, batch train loss: 14.948522567749023\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 120, batch train loss: 12.248802185058594\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 121, batch train loss: 11.00149154663086\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 122, batch train loss: 9.64709758758545\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 123, batch train loss: 9.706001281738281\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 124, batch train loss: 11.108041763305664\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 125, batch train loss: 10.784737586975098\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 126, batch train loss: 10.380860328674316\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 127, batch train loss: 11.350744247436523\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 128, batch train loss: 11.871024131774902\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 129, batch train loss: 10.764019012451172\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 130, batch train loss: 9.92755126953125\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 131, batch train loss: 11.887492179870605\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, batch_id: 132, batch train loss: 10.066192626953125\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 133, batch train loss: 12.257230758666992\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 134, batch train loss: 9.782296180725098\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 135, batch train loss: 11.759052276611328\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 136, batch train loss: 9.221814155578613\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 137, batch train loss: 8.53514575958252\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 138, batch train loss: 9.124364852905273\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 139, batch train loss: 9.423257827758789\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 140, batch train loss: 9.598196983337402\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 141, batch train loss: 9.32651424407959\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 142, batch train loss: 10.049163818359375\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 143, batch train loss: 9.96646499633789\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 144, batch train loss: 9.942809104919434\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 145, batch train loss: 11.419808387756348\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 146, batch train loss: 10.916814804077148\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 147, batch train loss: 10.534512519836426\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 148, batch train loss: 10.193431854248047\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 149, batch train loss: 10.380268096923828\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 150, batch train loss: 11.319619178771973\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 151, batch train loss: 13.700286865234375\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 152, batch train loss: 10.314502716064453\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 153, batch train loss: 9.893506050109863\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 154, batch train loss: 12.069809913635254\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 155, batch train loss: 10.127948760986328\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 156, batch train loss: 14.715652465820312\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 157, batch train loss: 11.375688552856445\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 158, batch train loss: 12.473155975341797\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 159, batch train loss: 9.193814277648926\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 160, batch train loss: 13.101264953613281\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 161, batch train loss: 11.332250595092773\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 162, batch train loss: 11.209047317504883\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 163, batch train loss: 11.330924034118652\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 164, batch train loss: 11.210600852966309\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 165, batch train loss: 11.057432174682617\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 166, batch train loss: 13.573984146118164\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 167, batch train loss: 10.37291145324707\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 168, batch train loss: 14.409573554992676\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 169, batch train loss: 10.737292289733887\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 170, batch train loss: 15.337639808654785\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 171, batch train loss: 11.51962661743164\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 172, batch train loss: 10.881946563720703\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 173, batch train loss: 13.256020545959473\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 174, batch train loss: 11.417428016662598\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 175, batch train loss: 10.478409767150879\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 176, batch train loss: 10.021947860717773\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 177, batch train loss: 12.416329383850098\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 178, batch train loss: 11.017118453979492\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 179, batch train loss: 12.68138599395752\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 180, batch train loss: 11.61019229888916\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 181, batch train loss: 13.392422676086426\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 182, batch train loss: 13.486359596252441\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 183, batch train loss: 12.99474811553955\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 184, batch train loss: 10.974395751953125\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 185, batch train loss: 13.871973991394043\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 186, batch train loss: 11.844587326049805\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 187, batch train loss: 11.790244102478027\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 188, batch train loss: 11.741981506347656\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 189, batch train loss: 11.913387298583984\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 190, batch train loss: 12.146212577819824\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 191, batch train loss: 12.907583236694336\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 192, batch train loss: 9.833817481994629\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 193, batch train loss: 10.531332969665527\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 194, batch train loss: 10.696246147155762\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 195, batch train loss: 11.294031143188477\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 196, batch train loss: 13.166898727416992\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 197, batch train loss: 13.616147994995117\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 198, batch train loss: 12.06219482421875\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 199, batch train loss: 15.008708000183105\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 200, batch train loss: 14.580522537231445\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 201, batch train loss: 12.345846176147461\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 202, batch train loss: 18.489574432373047\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 203, batch train loss: 13.580403327941895\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 204, batch train loss: 15.001733779907227\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 205, batch train loss: 12.045551300048828\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 206, batch train loss: 15.42431926727295\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 207, batch train loss: 15.29908561706543\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 208, batch train loss: 13.855475425720215\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 209, batch train loss: 14.683856010437012\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 210, batch train loss: 16.077232360839844\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 211, batch train loss: 14.330439567565918\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 212, batch train loss: 12.822087287902832\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 213, batch train loss: 12.723860740661621\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 214, batch train loss: 14.24809741973877\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 215, batch train loss: 13.777631759643555\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 216, batch train loss: 13.747841835021973\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 217, batch train loss: 12.63797664642334\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 218, batch train loss: 11.872426986694336\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 219, batch train loss: 12.940572738647461\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 220, batch train loss: 14.48261547088623\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 221, batch train loss: 18.903146743774414\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 222, batch train loss: 12.614249229431152\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 223, batch train loss: 16.698278427124023\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 224, batch train loss: 15.751593589782715\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 225, batch train loss: 13.273773193359375\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 226, batch train loss: 17.887144088745117\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 227, batch train loss: 16.60091209411621\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 228, batch train loss: 18.323883056640625\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 229, batch train loss: 15.837568283081055\n",
      "\n",
      "\n",
      "Epoch: 5, batch_id: 230, batch train loss: 12.872069358825684\n",
      "\n",
      "\n",
      "Epoch: 5/ 100, Loss: 12.464233112335204\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:20<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Validation Loss: 13.361890681584676\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 6, batch_id: 1, batch train loss: 13.842171669006348\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 2, batch train loss: 12.201163291931152\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 3, batch train loss: 10.711570739746094\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 4, batch train loss: 15.600177764892578\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 5, batch train loss: 12.92720890045166\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 6, batch train loss: 13.669576644897461\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 7, batch train loss: 11.288217544555664\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 8, batch train loss: 10.91179084777832\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 9, batch train loss: 10.841554641723633\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 10, batch train loss: 12.321725845336914\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 11, batch train loss: 10.709238052368164\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 12, batch train loss: 11.314872741699219\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 13, batch train loss: 11.450203895568848\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 14, batch train loss: 9.658965110778809\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 15, batch train loss: 10.120734214782715\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 16, batch train loss: 12.279658317565918\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 17, batch train loss: 11.46911334991455\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 18, batch train loss: 12.683862686157227\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 19, batch train loss: 9.864570617675781\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 20, batch train loss: 9.527791023254395\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 21, batch train loss: 12.546590805053711\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 22, batch train loss: 11.6021089553833\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 23, batch train loss: 13.552600860595703\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 24, batch train loss: 10.3523588180542\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 25, batch train loss: 12.031004905700684\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 26, batch train loss: 9.497581481933594\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 27, batch train loss: 10.784515380859375\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 28, batch train loss: 10.325765609741211\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 29, batch train loss: 11.137908935546875\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 30, batch train loss: 13.815669059753418\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 31, batch train loss: 10.336193084716797\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 32, batch train loss: 10.696022987365723\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 33, batch train loss: 12.210481643676758\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 34, batch train loss: 11.580370903015137\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 35, batch train loss: 11.968927383422852\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 36, batch train loss: 11.018102645874023\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 37, batch train loss: 10.233201026916504\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 38, batch train loss: 13.37203311920166\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 39, batch train loss: 12.942110061645508\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 40, batch train loss: 13.281590461730957\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 41, batch train loss: 11.284521102905273\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 42, batch train loss: 12.627750396728516\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 43, batch train loss: 12.143280029296875\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 44, batch train loss: 12.696035385131836\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 45, batch train loss: 11.58516788482666\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 46, batch train loss: 13.92525863647461\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 47, batch train loss: 12.11130428314209\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 48, batch train loss: 11.136625289916992\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 49, batch train loss: 11.849233627319336\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 50, batch train loss: 12.696855545043945\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 51, batch train loss: 11.142230987548828\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 52, batch train loss: 13.996575355529785\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 53, batch train loss: 13.27560806274414\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 54, batch train loss: 11.202348709106445\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 55, batch train loss: 9.481369018554688\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 56, batch train loss: 8.832328796386719\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 57, batch train loss: 8.49828815460205\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 58, batch train loss: 12.651127815246582\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 59, batch train loss: 10.640871047973633\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 60, batch train loss: 13.126188278198242\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 61, batch train loss: 10.611475944519043\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 62, batch train loss: 12.05766487121582\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 63, batch train loss: 10.717141151428223\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 64, batch train loss: 10.314477920532227\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 65, batch train loss: 11.62740421295166\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 66, batch train loss: 11.128523826599121\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 67, batch train loss: 11.724770545959473\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 68, batch train loss: 9.508132934570312\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 69, batch train loss: 9.685259819030762\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 70, batch train loss: 11.206409454345703\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 71, batch train loss: 13.534192085266113\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 72, batch train loss: 12.477619171142578\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 73, batch train loss: 11.47179889678955\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 74, batch train loss: 9.814457893371582\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 75, batch train loss: 12.543347358703613\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 76, batch train loss: 10.982484817504883\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 77, batch train loss: 10.29825210571289\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 78, batch train loss: 9.253630638122559\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 79, batch train loss: 9.838744163513184\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 80, batch train loss: 10.731613159179688\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 81, batch train loss: 10.1803560256958\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 82, batch train loss: 9.952484130859375\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 83, batch train loss: 9.068092346191406\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 84, batch train loss: 10.651175498962402\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 85, batch train loss: 11.541888236999512\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 86, batch train loss: 10.088939666748047\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 87, batch train loss: 12.946824073791504\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 88, batch train loss: 11.454416275024414\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 89, batch train loss: 10.947324752807617\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 90, batch train loss: 21.24396324157715\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 91, batch train loss: 15.829815864562988\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 92, batch train loss: 15.580446243286133\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 93, batch train loss: 14.77542495727539\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 94, batch train loss: 11.434000015258789\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 95, batch train loss: 13.388352394104004\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 96, batch train loss: 13.5347261428833\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 97, batch train loss: 11.99698543548584\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 98, batch train loss: 12.435615539550781\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 99, batch train loss: 12.432231903076172\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 100, batch train loss: 13.19811725616455\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 101, batch train loss: 12.927702903747559\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 102, batch train loss: 12.484345436096191\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 103, batch train loss: 10.18467903137207\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 104, batch train loss: 12.506242752075195\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 105, batch train loss: 11.111151695251465\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 106, batch train loss: 11.459200859069824\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 107, batch train loss: 11.299551010131836\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 108, batch train loss: 11.426309585571289\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 109, batch train loss: 11.097794532775879\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 110, batch train loss: 10.704385757446289\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 111, batch train loss: 12.240259170532227\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 112, batch train loss: 12.570773124694824\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 113, batch train loss: 13.255279541015625\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 114, batch train loss: 10.720481872558594\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 115, batch train loss: 10.979034423828125\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 116, batch train loss: 12.136687278747559\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 117, batch train loss: 11.050422668457031\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 118, batch train loss: 15.943617820739746\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 119, batch train loss: 15.165979385375977\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 120, batch train loss: 12.669458389282227\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 121, batch train loss: 12.965163230895996\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 122, batch train loss: 10.742463111877441\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 123, batch train loss: 14.266521453857422\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 124, batch train loss: 13.939508438110352\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 125, batch train loss: 12.071866035461426\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 126, batch train loss: 10.839143753051758\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 127, batch train loss: 11.471696853637695\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 128, batch train loss: 9.618422508239746\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 129, batch train loss: 10.466444969177246\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, batch_id: 130, batch train loss: 11.615589141845703\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 131, batch train loss: 10.80146312713623\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 132, batch train loss: 11.729435920715332\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 133, batch train loss: 10.16845989227295\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 134, batch train loss: 9.182235717773438\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 135, batch train loss: 8.378554344177246\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 136, batch train loss: 8.221359252929688\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 137, batch train loss: 8.998390197753906\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 138, batch train loss: 11.273768424987793\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 139, batch train loss: 8.995859146118164\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 140, batch train loss: 11.194902420043945\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 141, batch train loss: 9.92624568939209\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 142, batch train loss: 10.151052474975586\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 143, batch train loss: 10.174970626831055\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 144, batch train loss: 10.538946151733398\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 145, batch train loss: 10.54156494140625\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 146, batch train loss: 13.547303199768066\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 147, batch train loss: 11.235671043395996\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 148, batch train loss: 10.100072860717773\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 149, batch train loss: 10.145231246948242\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 150, batch train loss: 9.958285331726074\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 151, batch train loss: 11.878751754760742\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 152, batch train loss: 10.215856552124023\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 153, batch train loss: 9.305989265441895\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 154, batch train loss: 10.757843971252441\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 155, batch train loss: 9.934447288513184\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 156, batch train loss: 13.362776756286621\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 157, batch train loss: 11.599287033081055\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 158, batch train loss: 11.414493560791016\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 159, batch train loss: 12.159062385559082\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 160, batch train loss: 11.902517318725586\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 161, batch train loss: 9.982991218566895\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 162, batch train loss: 8.563003540039062\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 163, batch train loss: 11.06164264678955\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 164, batch train loss: 12.139537811279297\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 165, batch train loss: 10.227520942687988\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 166, batch train loss: 13.381390571594238\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 167, batch train loss: 12.626336097717285\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 168, batch train loss: 13.092757225036621\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 169, batch train loss: 12.027594566345215\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 170, batch train loss: 10.191113471984863\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 171, batch train loss: 12.496068954467773\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 172, batch train loss: 12.220216751098633\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 173, batch train loss: 13.983016014099121\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 174, batch train loss: 13.638840675354004\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 175, batch train loss: 12.403916358947754\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 176, batch train loss: 12.098489761352539\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 177, batch train loss: 11.628607749938965\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 178, batch train loss: 13.903704643249512\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 179, batch train loss: 11.381562232971191\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 180, batch train loss: 11.526963233947754\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 181, batch train loss: 9.747489929199219\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 182, batch train loss: 11.069210052490234\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 183, batch train loss: 11.527562141418457\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 184, batch train loss: 13.532559394836426\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 185, batch train loss: 16.30193519592285\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 186, batch train loss: 12.072137832641602\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 187, batch train loss: 11.71141529083252\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 188, batch train loss: 11.17831039428711\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 189, batch train loss: 11.072420120239258\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 190, batch train loss: 12.123611450195312\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 191, batch train loss: 11.194416046142578\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 192, batch train loss: 10.840563774108887\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 193, batch train loss: 11.66894817352295\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 194, batch train loss: 10.396098136901855\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 195, batch train loss: 10.680461883544922\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 196, batch train loss: 9.78831958770752\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 197, batch train loss: 9.76342487335205\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 198, batch train loss: 10.28777027130127\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 199, batch train loss: 9.309301376342773\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 200, batch train loss: 9.966575622558594\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 201, batch train loss: 9.734992027282715\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 202, batch train loss: 8.493438720703125\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 203, batch train loss: 9.480798721313477\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 204, batch train loss: 8.24658203125\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 205, batch train loss: 10.12614631652832\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 206, batch train loss: 10.063803672790527\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 207, batch train loss: 11.698534965515137\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 208, batch train loss: 10.655742645263672\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 209, batch train loss: 9.625113487243652\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 210, batch train loss: 8.240960121154785\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 211, batch train loss: 9.387613296508789\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 212, batch train loss: 9.799595832824707\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 213, batch train loss: 12.14842700958252\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 214, batch train loss: 10.265146255493164\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 215, batch train loss: 12.13940715789795\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 216, batch train loss: 13.724885940551758\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 217, batch train loss: 11.397377014160156\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 218, batch train loss: 13.01463794708252\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 219, batch train loss: 9.894224166870117\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 220, batch train loss: 10.120023727416992\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 221, batch train loss: 8.54782772064209\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 222, batch train loss: 9.759520530700684\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 223, batch train loss: 8.703843116760254\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 224, batch train loss: 12.171150207519531\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 225, batch train loss: 9.379345893859863\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 226, batch train loss: 11.305130958557129\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 227, batch train loss: 9.776098251342773\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 228, batch train loss: 11.77612590789795\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 229, batch train loss: 9.858621597290039\n",
      "\n",
      "\n",
      "Epoch: 6, batch_id: 230, batch train loss: 10.710464477539062\n",
      "\n",
      "\n",
      "Epoch: 6/ 100, Loss: 11.411170503367549\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:24<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Validation Loss: 9.812534189224243\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 7, batch_id: 1, batch train loss: 9.76582145690918\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 2, batch train loss: 9.054445266723633\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 3, batch train loss: 10.52541732788086\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 4, batch train loss: 11.221182823181152\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 5, batch train loss: 12.834033966064453\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 6, batch train loss: 11.582621574401855\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 7, batch train loss: 9.144611358642578\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 8, batch train loss: 9.75191879272461\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 9, batch train loss: 11.864744186401367\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 10, batch train loss: 10.646404266357422\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 11, batch train loss: 10.218894958496094\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 12, batch train loss: 10.241374969482422\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 13, batch train loss: 10.298981666564941\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 14, batch train loss: 10.435171127319336\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 15, batch train loss: 9.522374153137207\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 16, batch train loss: 8.530980110168457\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 17, batch train loss: 9.806093215942383\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 18, batch train loss: 11.064772605895996\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 19, batch train loss: 8.646150588989258\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 20, batch train loss: 9.576745986938477\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 21, batch train loss: 12.615924835205078\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 22, batch train loss: 10.640766143798828\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 23, batch train loss: 10.93005084991455\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 24, batch train loss: 10.86180305480957\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 25, batch train loss: 11.28930950164795\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 26, batch train loss: 12.384532928466797\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 27, batch train loss: 10.418859481811523\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 28, batch train loss: 10.56088638305664\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 29, batch train loss: 9.700512886047363\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 30, batch train loss: 10.384161949157715\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 31, batch train loss: 9.565864562988281\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 32, batch train loss: 8.394128799438477\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 33, batch train loss: 9.727648735046387\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 34, batch train loss: 11.085807800292969\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 35, batch train loss: 14.458398818969727\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 36, batch train loss: 14.335774421691895\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 37, batch train loss: 14.5324068069458\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 38, batch train loss: 10.307345390319824\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 39, batch train loss: 12.009603500366211\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 40, batch train loss: 10.334516525268555\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 41, batch train loss: 19.577655792236328\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 42, batch train loss: 15.738751411437988\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 43, batch train loss: 13.880806922912598\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 44, batch train loss: 12.377017974853516\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 45, batch train loss: 14.377342224121094\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 46, batch train loss: 13.053829193115234\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 47, batch train loss: 12.045787811279297\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 48, batch train loss: 12.398571014404297\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 49, batch train loss: 13.141131401062012\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 50, batch train loss: 11.512995719909668\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 51, batch train loss: 17.047929763793945\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 52, batch train loss: 13.719013214111328\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 53, batch train loss: 13.387964248657227\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 54, batch train loss: 13.897041320800781\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 55, batch train loss: 10.476956367492676\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 56, batch train loss: 10.446512222290039\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 57, batch train loss: 9.987646102905273\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 58, batch train loss: 9.098470687866211\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 59, batch train loss: 9.580469131469727\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 60, batch train loss: 9.190112113952637\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 61, batch train loss: 11.377266883850098\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 62, batch train loss: 9.741425514221191\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 63, batch train loss: 11.216109275817871\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 64, batch train loss: 10.357076644897461\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 65, batch train loss: 9.874307632446289\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 66, batch train loss: 8.361186981201172\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 67, batch train loss: 9.561331748962402\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 68, batch train loss: 9.919095039367676\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 69, batch train loss: 8.870752334594727\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 70, batch train loss: 8.70510196685791\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 71, batch train loss: 8.813102722167969\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 72, batch train loss: 9.58874225616455\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 73, batch train loss: 8.131555557250977\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 74, batch train loss: 10.118855476379395\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 75, batch train loss: 9.870147705078125\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 76, batch train loss: 11.156268119812012\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 77, batch train loss: 11.460277557373047\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 78, batch train loss: 9.714093208312988\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 79, batch train loss: 15.260488510131836\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 80, batch train loss: 12.945186614990234\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 81, batch train loss: 13.378019332885742\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 82, batch train loss: 13.186837196350098\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 83, batch train loss: 11.294388771057129\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 84, batch train loss: 12.294161796569824\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 85, batch train loss: 8.4566011428833\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 86, batch train loss: 11.282632827758789\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 87, batch train loss: 12.547138214111328\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 88, batch train loss: 11.321100234985352\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 89, batch train loss: 10.570659637451172\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 90, batch train loss: 13.357275009155273\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 91, batch train loss: 9.387293815612793\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 92, batch train loss: 16.23057746887207\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 93, batch train loss: 11.404936790466309\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 94, batch train loss: 11.497800827026367\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 95, batch train loss: 13.585262298583984\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 96, batch train loss: 11.660571098327637\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 97, batch train loss: 11.89380931854248\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 98, batch train loss: 9.974501609802246\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 99, batch train loss: 11.497611045837402\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 100, batch train loss: 12.705937385559082\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 101, batch train loss: 11.963273048400879\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 102, batch train loss: 12.322895050048828\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 103, batch train loss: 10.552878379821777\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 104, batch train loss: 11.31740951538086\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 105, batch train loss: 11.06837272644043\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 106, batch train loss: 10.287300109863281\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 107, batch train loss: 9.440629959106445\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 108, batch train loss: 9.699301719665527\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 109, batch train loss: 9.722695350646973\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 110, batch train loss: 9.963293075561523\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 111, batch train loss: 9.292548179626465\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 112, batch train loss: 10.737873077392578\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 113, batch train loss: 8.574353218078613\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 114, batch train loss: 8.876733779907227\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 115, batch train loss: 9.74290943145752\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 116, batch train loss: 11.023573875427246\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 117, batch train loss: 11.917997360229492\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 118, batch train loss: 10.972768783569336\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 119, batch train loss: 11.250441551208496\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 120, batch train loss: 9.677104949951172\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 121, batch train loss: 10.14713191986084\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 122, batch train loss: 9.104425430297852\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 123, batch train loss: 9.08690071105957\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 124, batch train loss: 11.752699851989746\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 125, batch train loss: 10.177664756774902\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 126, batch train loss: 10.316739082336426\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 127, batch train loss: 10.533147811889648\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 128, batch train loss: 11.549286842346191\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 129, batch train loss: 8.270172119140625\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, batch_id: 130, batch train loss: 12.535110473632812\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 131, batch train loss: 9.937536239624023\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 132, batch train loss: 10.179368019104004\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 133, batch train loss: 10.21071720123291\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 134, batch train loss: 11.171727180480957\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 135, batch train loss: 11.129510879516602\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 136, batch train loss: 9.86097526550293\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 137, batch train loss: 10.089547157287598\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 138, batch train loss: 9.726431846618652\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 139, batch train loss: 9.119462013244629\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 140, batch train loss: 9.802051544189453\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 141, batch train loss: 8.927298545837402\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 142, batch train loss: 11.326200485229492\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 143, batch train loss: 9.097707748413086\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 144, batch train loss: 11.132262229919434\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 145, batch train loss: 10.365289688110352\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 146, batch train loss: 11.081123352050781\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 147, batch train loss: 9.367222785949707\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 148, batch train loss: 9.251465797424316\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 149, batch train loss: 9.84525203704834\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 150, batch train loss: 9.559276580810547\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 151, batch train loss: 9.97590160369873\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 152, batch train loss: 9.154865264892578\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 153, batch train loss: 8.222580909729004\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 154, batch train loss: 9.573370933532715\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 155, batch train loss: 8.499399185180664\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 156, batch train loss: 7.993478775024414\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 157, batch train loss: 9.251825332641602\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 158, batch train loss: 10.195134162902832\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 159, batch train loss: 9.504730224609375\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 160, batch train loss: 10.767457962036133\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 161, batch train loss: 11.198352813720703\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 162, batch train loss: 9.557181358337402\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 163, batch train loss: 9.309407234191895\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 164, batch train loss: 10.662081718444824\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 165, batch train loss: 11.330147743225098\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 166, batch train loss: 9.284887313842773\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 167, batch train loss: 9.03952407836914\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 168, batch train loss: 8.750506401062012\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 169, batch train loss: 8.425246238708496\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 170, batch train loss: 8.704527854919434\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 171, batch train loss: 9.484301567077637\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 172, batch train loss: 10.893951416015625\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 173, batch train loss: 9.4931058883667\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 174, batch train loss: 10.277018547058105\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 175, batch train loss: 9.137812614440918\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 176, batch train loss: 8.548563957214355\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 177, batch train loss: 10.477814674377441\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 178, batch train loss: 10.157445907592773\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 179, batch train loss: 11.271003723144531\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 180, batch train loss: 10.218369483947754\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 181, batch train loss: 9.371479988098145\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 182, batch train loss: 7.226677894592285\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 183, batch train loss: 8.548478126525879\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 184, batch train loss: 8.804004669189453\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 185, batch train loss: 8.660888671875\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 186, batch train loss: 9.783830642700195\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 187, batch train loss: 10.209016799926758\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 188, batch train loss: 11.629462242126465\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 189, batch train loss: 9.759592056274414\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 190, batch train loss: 12.114699363708496\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 191, batch train loss: 8.842300415039062\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 192, batch train loss: 8.75499439239502\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 193, batch train loss: 10.225615501403809\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 194, batch train loss: 9.16475772857666\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 195, batch train loss: 12.887483596801758\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 196, batch train loss: 9.604815483093262\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 197, batch train loss: 13.441205024719238\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 198, batch train loss: 8.751079559326172\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 199, batch train loss: 9.707942008972168\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 200, batch train loss: 7.399576187133789\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 201, batch train loss: 9.736669540405273\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 202, batch train loss: 9.620122909545898\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 203, batch train loss: 14.562569618225098\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 204, batch train loss: 8.788935661315918\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 205, batch train loss: 9.322856903076172\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 206, batch train loss: 9.478890419006348\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 207, batch train loss: 11.666473388671875\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 208, batch train loss: 9.583441734313965\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 209, batch train loss: 9.540709495544434\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 210, batch train loss: 9.665517807006836\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 211, batch train loss: 8.417776107788086\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 212, batch train loss: 8.266127586364746\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 213, batch train loss: 7.678356170654297\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 214, batch train loss: 7.544720649719238\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 215, batch train loss: 9.789654731750488\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 216, batch train loss: 8.440756797790527\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 217, batch train loss: 7.241163730621338\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 218, batch train loss: 6.891136646270752\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 219, batch train loss: 8.25500774383545\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 220, batch train loss: 9.555777549743652\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 221, batch train loss: 8.485108375549316\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 222, batch train loss: 7.748297691345215\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 223, batch train loss: 8.621162414550781\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 224, batch train loss: 8.483863830566406\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 225, batch train loss: 9.630796432495117\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 226, batch train loss: 9.527544021606445\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 227, batch train loss: 10.630487442016602\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 228, batch train loss: 7.995573043823242\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 229, batch train loss: 9.944189071655273\n",
      "\n",
      "\n",
      "Epoch: 7, batch_id: 230, batch train loss: 9.652728080749512\n",
      "\n",
      "\n",
      "Epoch: 7/ 100, Loss: 10.429777850275455\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:11<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Validation Loss: 8.753355503082275\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 8, batch_id: 1, batch train loss: 8.328721046447754\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 2, batch train loss: 8.657286643981934\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 3, batch train loss: 7.567065238952637\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 4, batch train loss: 7.346222400665283\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 5, batch train loss: 9.742795944213867\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 6, batch train loss: 9.18380355834961\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 7, batch train loss: 9.15117359161377\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 8, batch train loss: 9.112744331359863\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 9, batch train loss: 8.903450965881348\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 10, batch train loss: 11.205381393432617\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 11, batch train loss: 8.013955116271973\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 12, batch train loss: 10.00457763671875\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 13, batch train loss: 10.206933975219727\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 14, batch train loss: 9.370221138000488\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 15, batch train loss: 9.199084281921387\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 16, batch train loss: 10.75076961517334\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 17, batch train loss: 9.096320152282715\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 18, batch train loss: 11.575299263000488\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 19, batch train loss: 9.564128875732422\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 20, batch train loss: 8.823308944702148\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 21, batch train loss: 8.400354385375977\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 22, batch train loss: 8.248848915100098\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 23, batch train loss: 9.210741996765137\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 24, batch train loss: 9.389639854431152\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 25, batch train loss: 7.308712482452393\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 26, batch train loss: 6.680375099182129\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 27, batch train loss: 10.399266242980957\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 28, batch train loss: 8.611212730407715\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 29, batch train loss: 8.04028034210205\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 30, batch train loss: 7.202928066253662\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 31, batch train loss: 8.032444953918457\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 32, batch train loss: 7.229100704193115\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 33, batch train loss: 7.003408908843994\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 34, batch train loss: 7.762599468231201\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 35, batch train loss: 7.909346580505371\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 36, batch train loss: 10.585821151733398\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 37, batch train loss: 8.474614143371582\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 38, batch train loss: 10.7808256149292\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 39, batch train loss: 9.592954635620117\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 40, batch train loss: 10.2959566116333\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 41, batch train loss: 10.405440330505371\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 42, batch train loss: 11.714795112609863\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 43, batch train loss: 9.956827163696289\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 44, batch train loss: 8.751311302185059\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 45, batch train loss: 9.171794891357422\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 46, batch train loss: 8.412579536437988\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 47, batch train loss: 10.3108491897583\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 48, batch train loss: 9.375080108642578\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 49, batch train loss: 10.444584846496582\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 50, batch train loss: 9.229787826538086\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 51, batch train loss: 11.225327491760254\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 52, batch train loss: 13.896790504455566\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 53, batch train loss: 16.234825134277344\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 54, batch train loss: 10.243277549743652\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 55, batch train loss: 10.764047622680664\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 56, batch train loss: 11.314413070678711\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 57, batch train loss: 10.029123306274414\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 58, batch train loss: 9.553738594055176\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 59, batch train loss: 10.5344820022583\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 60, batch train loss: 8.027847290039062\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 61, batch train loss: 12.052931785583496\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 62, batch train loss: 11.752602577209473\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 63, batch train loss: 8.250914573669434\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 64, batch train loss: 8.962895393371582\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 65, batch train loss: 7.795064926147461\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 66, batch train loss: 7.859325408935547\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 67, batch train loss: 9.377050399780273\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 68, batch train loss: 10.874286651611328\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 69, batch train loss: 11.273987770080566\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 70, batch train loss: 10.39253044128418\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 71, batch train loss: 8.256156921386719\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 72, batch train loss: 8.422353744506836\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 73, batch train loss: 8.92665958404541\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 74, batch train loss: 7.686484336853027\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 75, batch train loss: 8.642465591430664\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 76, batch train loss: 9.290047645568848\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 77, batch train loss: 7.498201370239258\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 78, batch train loss: 9.995651245117188\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 79, batch train loss: 8.85231876373291\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 80, batch train loss: 10.125073432922363\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 81, batch train loss: 9.302217483520508\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 82, batch train loss: 10.431909561157227\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 83, batch train loss: 8.84156608581543\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 84, batch train loss: 9.7903413772583\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 85, batch train loss: 8.691742897033691\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 86, batch train loss: 7.607367992401123\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 87, batch train loss: 9.018061637878418\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 88, batch train loss: 9.355891227722168\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 89, batch train loss: 8.774393081665039\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 90, batch train loss: 10.532316207885742\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 91, batch train loss: 13.568808555603027\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 92, batch train loss: 14.747783660888672\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 93, batch train loss: 14.464919090270996\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 94, batch train loss: 11.137411117553711\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 95, batch train loss: 15.956432342529297\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 96, batch train loss: 14.415924072265625\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 97, batch train loss: 9.347716331481934\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 98, batch train loss: 16.60894775390625\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 99, batch train loss: 11.588753700256348\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 100, batch train loss: 10.439861297607422\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 101, batch train loss: 13.799671173095703\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 102, batch train loss: 11.51207447052002\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 103, batch train loss: 11.222160339355469\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 104, batch train loss: 10.085555076599121\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 105, batch train loss: 11.685976028442383\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 106, batch train loss: 12.87644100189209\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 107, batch train loss: 12.909645080566406\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 108, batch train loss: 10.024534225463867\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 109, batch train loss: 10.031329154968262\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 110, batch train loss: 8.544534683227539\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 111, batch train loss: 6.770017623901367\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 112, batch train loss: 9.553553581237793\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 113, batch train loss: 13.510163307189941\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 114, batch train loss: 9.819425582885742\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 115, batch train loss: 9.760038375854492\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 116, batch train loss: 7.793790817260742\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 117, batch train loss: 8.156481742858887\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 118, batch train loss: 8.618566513061523\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 119, batch train loss: 8.47913932800293\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 120, batch train loss: 10.030658721923828\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 121, batch train loss: 8.519221305847168\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 122, batch train loss: 7.819141387939453\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 123, batch train loss: 7.759727954864502\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 124, batch train loss: 7.1137237548828125\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 125, batch train loss: 7.676435470581055\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 126, batch train loss: 7.753098011016846\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 127, batch train loss: 9.52495288848877\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 128, batch train loss: 8.39345932006836\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 129, batch train loss: 9.095928192138672\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 130, batch train loss: 10.109521865844727\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, batch_id: 131, batch train loss: 7.6654582023620605\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 132, batch train loss: 6.832054138183594\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 133, batch train loss: 6.373126029968262\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 134, batch train loss: 7.166228771209717\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 135, batch train loss: 7.269094944000244\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 136, batch train loss: 7.474576950073242\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 137, batch train loss: 7.2413411140441895\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 138, batch train loss: 9.9292631149292\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 139, batch train loss: 8.091533660888672\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 140, batch train loss: 8.723265647888184\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 141, batch train loss: 7.842491149902344\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 142, batch train loss: 8.585479736328125\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 143, batch train loss: 8.001412391662598\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 144, batch train loss: 7.631066799163818\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 145, batch train loss: 9.34191608428955\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 146, batch train loss: 7.027609825134277\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 147, batch train loss: 8.15805435180664\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 148, batch train loss: 7.823870658874512\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 149, batch train loss: 7.4371795654296875\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 150, batch train loss: 8.178067207336426\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 151, batch train loss: 5.909132957458496\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 152, batch train loss: 6.441999435424805\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 153, batch train loss: 5.446695327758789\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 154, batch train loss: 6.00745153427124\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 155, batch train loss: 6.110403060913086\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 156, batch train loss: 8.30990219116211\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 157, batch train loss: 7.046377658843994\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 158, batch train loss: 8.13394546508789\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 159, batch train loss: 6.944537162780762\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 160, batch train loss: 5.653085231781006\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 161, batch train loss: 7.386138439178467\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 162, batch train loss: 4.375617504119873\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 163, batch train loss: 5.2231903076171875\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 164, batch train loss: 5.019684791564941\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 165, batch train loss: 5.169334888458252\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 166, batch train loss: 4.949193477630615\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 167, batch train loss: 6.765681743621826\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 168, batch train loss: 5.538426399230957\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 169, batch train loss: 5.5089497566223145\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 170, batch train loss: 9.123376846313477\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 171, batch train loss: 9.624251365661621\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 172, batch train loss: 6.084681034088135\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 173, batch train loss: 7.6229376792907715\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 174, batch train loss: 5.344081401824951\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 175, batch train loss: 5.491681098937988\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 176, batch train loss: 7.845731735229492\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 177, batch train loss: 7.080443382263184\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 178, batch train loss: 6.525148868560791\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 179, batch train loss: 5.859545707702637\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 180, batch train loss: 6.4558892250061035\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 181, batch train loss: 6.974698066711426\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 182, batch train loss: 9.397906303405762\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 183, batch train loss: 8.313024520874023\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 184, batch train loss: 6.3617634773254395\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 185, batch train loss: 6.990752696990967\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 186, batch train loss: 7.395927906036377\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 187, batch train loss: 5.341581344604492\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 188, batch train loss: 7.950064182281494\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 189, batch train loss: 7.399343967437744\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 190, batch train loss: 5.766483783721924\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 191, batch train loss: 9.419452667236328\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 192, batch train loss: 8.541637420654297\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 193, batch train loss: 9.197232246398926\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 194, batch train loss: 10.138273239135742\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 195, batch train loss: 7.452925682067871\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 196, batch train loss: 14.096258163452148\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 197, batch train loss: 9.538959503173828\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 198, batch train loss: 8.005760192871094\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 199, batch train loss: 6.6480937004089355\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 200, batch train loss: 5.070910453796387\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 201, batch train loss: 5.744692802429199\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 202, batch train loss: 6.586265563964844\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 203, batch train loss: 6.727881908416748\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 204, batch train loss: 5.005871295928955\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 205, batch train loss: 4.923427104949951\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 206, batch train loss: 7.608973026275635\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 207, batch train loss: 8.854522705078125\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 208, batch train loss: 10.221881866455078\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 209, batch train loss: 11.551546096801758\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 210, batch train loss: 9.404217720031738\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 211, batch train loss: 12.198541641235352\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 212, batch train loss: 7.715141773223877\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 213, batch train loss: 8.184243202209473\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 214, batch train loss: 8.123970985412598\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 215, batch train loss: 5.834092617034912\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 216, batch train loss: 10.737671852111816\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 217, batch train loss: 5.5238938331604\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 218, batch train loss: 5.919319152832031\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 219, batch train loss: 6.6331095695495605\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 220, batch train loss: 6.112281322479248\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 221, batch train loss: 6.889463901519775\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 222, batch train loss: 6.865395545959473\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 223, batch train loss: 7.023992538452148\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 224, batch train loss: 6.554619312286377\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 225, batch train loss: 7.814659118652344\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 226, batch train loss: 5.9532880783081055\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 227, batch train loss: 8.069504737854004\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 228, batch train loss: 5.9377264976501465\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 229, batch train loss: 9.594030380249023\n",
      "\n",
      "\n",
      "Epoch: 8, batch_id: 230, batch train loss: 9.991781234741211\n",
      "\n",
      "\n",
      "Epoch: 8/ 100, Loss: 8.715285207914269\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:09<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Validation Loss: 6.705915959676107\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 9, batch_id: 1, batch train loss: 6.1224470138549805\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 2, batch train loss: 9.958592414855957\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 3, batch train loss: 10.567307472229004\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 4, batch train loss: 6.8518385887146\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 5, batch train loss: 12.829977035522461\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 6, batch train loss: 8.784649848937988\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 7, batch train loss: 8.455814361572266\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 8, batch train loss: 13.564248085021973\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 9, batch train loss: 11.0780029296875\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 10, batch train loss: 12.744144439697266\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 11, batch train loss: 15.14136028289795\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 12, batch train loss: 11.071267127990723\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 13, batch train loss: 9.318779945373535\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 14, batch train loss: 11.989032745361328\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 15, batch train loss: 5.766770839691162\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 16, batch train loss: 8.014445304870605\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 17, batch train loss: 11.538619041442871\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 18, batch train loss: 5.884634017944336\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 19, batch train loss: 6.302702903747559\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 20, batch train loss: 5.045921802520752\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 21, batch train loss: 4.170232772827148\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 22, batch train loss: 5.331361293792725\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 23, batch train loss: 5.864135265350342\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 24, batch train loss: 4.574825763702393\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 25, batch train loss: 9.651203155517578\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 26, batch train loss: 5.468177318572998\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 27, batch train loss: 7.099093437194824\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 28, batch train loss: 5.993870258331299\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 29, batch train loss: 6.514875411987305\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 30, batch train loss: 5.480991840362549\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 31, batch train loss: 6.956674575805664\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 32, batch train loss: 7.9910359382629395\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 33, batch train loss: 8.773456573486328\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 34, batch train loss: 7.072518825531006\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 35, batch train loss: 6.291070938110352\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 36, batch train loss: 7.418034076690674\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 37, batch train loss: 8.301508903503418\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 38, batch train loss: 5.040158748626709\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 39, batch train loss: 5.774839878082275\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 40, batch train loss: 10.342577934265137\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 41, batch train loss: 4.789802074432373\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 42, batch train loss: 6.0775980949401855\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 43, batch train loss: 5.347509860992432\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 44, batch train loss: 6.57211446762085\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 45, batch train loss: 5.526336193084717\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 46, batch train loss: 7.248603343963623\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 47, batch train loss: 6.652087211608887\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 48, batch train loss: 8.166135787963867\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 49, batch train loss: 7.0758056640625\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 50, batch train loss: 5.602410316467285\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 51, batch train loss: 9.254134178161621\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 52, batch train loss: 6.740879535675049\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 53, batch train loss: 8.246201515197754\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 54, batch train loss: 7.160553455352783\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 55, batch train loss: 5.764822959899902\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 56, batch train loss: 6.544861793518066\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 57, batch train loss: 6.635968208312988\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 58, batch train loss: 4.302045822143555\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 59, batch train loss: 9.311387062072754\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 60, batch train loss: 8.376482009887695\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 61, batch train loss: 5.42770528793335\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 62, batch train loss: 8.036174774169922\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 63, batch train loss: 6.164076805114746\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 64, batch train loss: 6.375375270843506\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 65, batch train loss: 6.671205043792725\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 66, batch train loss: 10.86965560913086\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 67, batch train loss: 5.465230941772461\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 68, batch train loss: 5.396543979644775\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 69, batch train loss: 7.364297866821289\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 70, batch train loss: 5.906484603881836\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 71, batch train loss: 5.99862003326416\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 72, batch train loss: 5.238465785980225\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 73, batch train loss: 5.775944709777832\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 74, batch train loss: 5.201993465423584\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 75, batch train loss: 4.86558198928833\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 76, batch train loss: 4.140056610107422\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 77, batch train loss: 4.67325496673584\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 78, batch train loss: 5.776819229125977\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 79, batch train loss: 10.017748832702637\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 80, batch train loss: 8.32718563079834\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 81, batch train loss: 7.524097442626953\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 82, batch train loss: 7.978499412536621\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 83, batch train loss: 11.438950538635254\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 84, batch train loss: 7.7921271324157715\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 85, batch train loss: 9.650089263916016\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 86, batch train loss: 14.29662799835205\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 87, batch train loss: 9.964614868164062\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 88, batch train loss: 12.93655014038086\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 89, batch train loss: 15.53577995300293\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 90, batch train loss: 12.996016502380371\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 91, batch train loss: 7.899592399597168\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 92, batch train loss: 11.042070388793945\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 93, batch train loss: 6.157066822052002\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 94, batch train loss: 7.8491926193237305\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 95, batch train loss: 7.760429859161377\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 96, batch train loss: 5.714090347290039\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 97, batch train loss: 8.732379913330078\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 98, batch train loss: 7.5633625984191895\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 99, batch train loss: 6.27598237991333\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 100, batch train loss: 7.297877788543701\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 101, batch train loss: 5.455864429473877\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 102, batch train loss: 7.193080425262451\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 103, batch train loss: 4.63332462310791\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 104, batch train loss: 4.940817356109619\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 105, batch train loss: 5.595968246459961\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 106, batch train loss: 5.953054904937744\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 107, batch train loss: 5.561790943145752\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 108, batch train loss: 4.547492504119873\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 109, batch train loss: 4.458644390106201\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 110, batch train loss: 6.0469651222229\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 111, batch train loss: 5.05091667175293\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 112, batch train loss: 4.849482536315918\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 113, batch train loss: 5.381004333496094\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 114, batch train loss: 4.571224212646484\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 115, batch train loss: 4.706204414367676\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 116, batch train loss: 3.4642460346221924\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 117, batch train loss: 4.48352575302124\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 118, batch train loss: 4.325860977172852\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 119, batch train loss: 4.173166275024414\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 120, batch train loss: 3.6098103523254395\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 121, batch train loss: 5.205465793609619\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 122, batch train loss: 4.954685211181641\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 123, batch train loss: 5.419656276702881\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 124, batch train loss: 4.0857672691345215\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 125, batch train loss: 4.791938781738281\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 126, batch train loss: 5.924149036407471\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 127, batch train loss: 5.929669380187988\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 128, batch train loss: 7.813015937805176\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 129, batch train loss: 3.7659974098205566\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 130, batch train loss: 6.415353775024414\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, batch_id: 131, batch train loss: 9.426057815551758\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 132, batch train loss: 5.961423873901367\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 133, batch train loss: 10.826396942138672\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 134, batch train loss: 14.250235557556152\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 135, batch train loss: 10.068415641784668\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 136, batch train loss: 9.791580200195312\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 137, batch train loss: 12.048093795776367\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 138, batch train loss: 12.436766624450684\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 139, batch train loss: 8.477807998657227\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 140, batch train loss: 11.412707328796387\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 141, batch train loss: 7.394426345825195\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 142, batch train loss: 5.0996222496032715\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 143, batch train loss: 8.246685981750488\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 144, batch train loss: 5.760314464569092\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 145, batch train loss: 6.380195140838623\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 146, batch train loss: 7.064764022827148\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 147, batch train loss: 6.392831325531006\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 148, batch train loss: 8.455348014831543\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 149, batch train loss: 4.39040994644165\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 150, batch train loss: 6.758984565734863\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 151, batch train loss: 8.292784690856934\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 152, batch train loss: 6.872114181518555\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 153, batch train loss: 9.988234519958496\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 154, batch train loss: 7.079100608825684\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 155, batch train loss: 7.108362674713135\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 156, batch train loss: 5.877292633056641\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 157, batch train loss: 6.157324314117432\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 158, batch train loss: 6.7358269691467285\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 159, batch train loss: 6.134450435638428\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 160, batch train loss: 5.304111957550049\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 161, batch train loss: 6.3794145584106445\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 162, batch train loss: 7.423917770385742\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 163, batch train loss: 5.225118160247803\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 164, batch train loss: 8.63440227508545\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 165, batch train loss: 5.029916286468506\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 166, batch train loss: 4.567117691040039\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 167, batch train loss: 5.059347152709961\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 168, batch train loss: 3.915820837020874\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 169, batch train loss: 5.549527645111084\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 170, batch train loss: 4.165361404418945\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 171, batch train loss: 6.029592990875244\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 172, batch train loss: 4.663708209991455\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 173, batch train loss: 3.6033859252929688\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 174, batch train loss: 3.6765739917755127\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 175, batch train loss: 8.26379108428955\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 176, batch train loss: 5.389050483703613\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 177, batch train loss: 5.827401638031006\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 178, batch train loss: 5.584612846374512\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 179, batch train loss: 6.55620002746582\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 180, batch train loss: 4.471868515014648\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 181, batch train loss: 3.6411125659942627\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 182, batch train loss: 3.6893465518951416\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 183, batch train loss: 3.3646116256713867\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 184, batch train loss: 4.94562292098999\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 185, batch train loss: 4.267740249633789\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 186, batch train loss: 4.290274143218994\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 187, batch train loss: 4.299392223358154\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 188, batch train loss: 3.5953845977783203\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 189, batch train loss: 5.339670181274414\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 190, batch train loss: 4.279283046722412\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 191, batch train loss: 4.7144012451171875\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 192, batch train loss: 3.8982303142547607\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 193, batch train loss: 5.793414115905762\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 194, batch train loss: 5.264370441436768\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 195, batch train loss: 3.6383142471313477\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 196, batch train loss: 6.919886112213135\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 197, batch train loss: 4.8600239753723145\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 198, batch train loss: 4.651373863220215\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 199, batch train loss: 3.9155099391937256\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 200, batch train loss: 5.349119663238525\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 201, batch train loss: 4.948612213134766\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 202, batch train loss: 4.954217910766602\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 203, batch train loss: 5.039862632751465\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 204, batch train loss: 4.74520206451416\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 205, batch train loss: 4.029240131378174\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 206, batch train loss: 6.15795373916626\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 207, batch train loss: 4.832775115966797\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 208, batch train loss: 5.676534175872803\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 209, batch train loss: 3.8294241428375244\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 210, batch train loss: 4.422275543212891\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 211, batch train loss: 4.501330375671387\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 212, batch train loss: 3.3073995113372803\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 213, batch train loss: 3.4230077266693115\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 214, batch train loss: 5.794093608856201\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 215, batch train loss: 5.177648544311523\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 216, batch train loss: 4.773629188537598\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 217, batch train loss: 5.817636489868164\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 218, batch train loss: 3.611154794692993\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 219, batch train loss: 7.2757649421691895\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 220, batch train loss: 6.25344705581665\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 221, batch train loss: 4.605630397796631\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 222, batch train loss: 4.963308811187744\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 223, batch train loss: 5.80031681060791\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 224, batch train loss: 3.8190503120422363\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 225, batch train loss: 5.273153781890869\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 226, batch train loss: 4.999072074890137\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 227, batch train loss: 5.041104316711426\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 228, batch train loss: 5.158566474914551\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 229, batch train loss: 5.101095199584961\n",
      "\n",
      "\n",
      "Epoch: 9, batch_id: 230, batch train loss: 6.285301685333252\n",
      "\n",
      "\n",
      "Epoch: 9/ 100, Loss: 6.602115625920503\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:22<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Validation Loss: 5.612189320723216\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 10, batch_id: 1, batch train loss: 5.922604084014893\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 2, batch train loss: 6.12603759765625\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 3, batch train loss: 8.988187789916992\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 4, batch train loss: 5.4202728271484375\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 5, batch train loss: 6.294537544250488\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 6, batch train loss: 6.100890159606934\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 7, batch train loss: 3.840594530105591\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 8, batch train loss: 4.895994663238525\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 9, batch train loss: 4.451368808746338\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 10, batch train loss: 3.594289541244507\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 11, batch train loss: 7.0105485916137695\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 12, batch train loss: 3.4069929122924805\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 13, batch train loss: 6.95414400100708\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 14, batch train loss: 3.6881885528564453\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 15, batch train loss: 7.741906642913818\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 16, batch train loss: 7.559726715087891\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 17, batch train loss: 6.305771350860596\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 18, batch train loss: 6.192610263824463\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 19, batch train loss: 5.016927719116211\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 20, batch train loss: 6.694728851318359\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 21, batch train loss: 7.35281229019165\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 22, batch train loss: 4.182315349578857\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 23, batch train loss: 6.125073432922363\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 24, batch train loss: 6.719844341278076\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 25, batch train loss: 3.434558629989624\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 26, batch train loss: 4.446617126464844\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 27, batch train loss: 4.239455699920654\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 28, batch train loss: 4.845102310180664\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 29, batch train loss: 4.650390625\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 30, batch train loss: 4.400864601135254\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 31, batch train loss: 3.8696208000183105\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 32, batch train loss: 6.201557636260986\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 33, batch train loss: 10.285807609558105\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 34, batch train loss: 5.261530876159668\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 35, batch train loss: 6.177366733551025\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 36, batch train loss: 6.265187740325928\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 37, batch train loss: 4.065406322479248\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 38, batch train loss: 5.4446868896484375\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 39, batch train loss: 3.6808369159698486\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 40, batch train loss: 3.908386707305908\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 41, batch train loss: 3.104275941848755\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 42, batch train loss: 4.095865249633789\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 43, batch train loss: 3.689610242843628\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 44, batch train loss: 2.8855693340301514\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 45, batch train loss: 4.120743274688721\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 46, batch train loss: 4.826612949371338\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 47, batch train loss: 5.280264377593994\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 48, batch train loss: 4.729874134063721\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 49, batch train loss: 5.746279239654541\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 50, batch train loss: 5.326993942260742\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 51, batch train loss: 7.290884494781494\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 52, batch train loss: 4.393858909606934\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 53, batch train loss: 6.182083606719971\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 54, batch train loss: 4.598639011383057\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 55, batch train loss: 5.562648296356201\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 56, batch train loss: 4.404521465301514\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 57, batch train loss: 9.515140533447266\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 58, batch train loss: 5.018086910247803\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 59, batch train loss: 5.980322360992432\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 60, batch train loss: 8.410728454589844\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 61, batch train loss: 15.879286766052246\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 62, batch train loss: 9.211979866027832\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 63, batch train loss: 9.187898635864258\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 64, batch train loss: 8.057209968566895\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 65, batch train loss: 10.6183500289917\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 66, batch train loss: 10.405739784240723\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 67, batch train loss: 7.067017555236816\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 68, batch train loss: 12.665214538574219\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 69, batch train loss: 12.267375946044922\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 70, batch train loss: 9.285760879516602\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 71, batch train loss: 3.0258495807647705\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 72, batch train loss: 6.399903297424316\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 73, batch train loss: 10.72202205657959\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 74, batch train loss: 6.385056018829346\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 75, batch train loss: 5.577517032623291\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 76, batch train loss: 6.4885573387146\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 77, batch train loss: 6.497697830200195\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 78, batch train loss: 5.825956344604492\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 79, batch train loss: 12.074016571044922\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 80, batch train loss: 6.417123794555664\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 81, batch train loss: 6.056765556335449\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 82, batch train loss: 7.309648513793945\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 83, batch train loss: 5.666729927062988\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 84, batch train loss: 10.33619499206543\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 85, batch train loss: 9.515768051147461\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 86, batch train loss: 8.027019500732422\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 87, batch train loss: 5.610655784606934\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 88, batch train loss: 12.1152925491333\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 89, batch train loss: 9.094359397888184\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 90, batch train loss: 8.2597074508667\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 91, batch train loss: 8.7263822555542\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 92, batch train loss: 9.887279510498047\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 93, batch train loss: 5.242964744567871\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 94, batch train loss: 7.353150367736816\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 95, batch train loss: 7.845333576202393\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 96, batch train loss: 7.356893539428711\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 97, batch train loss: 10.979867935180664\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 98, batch train loss: 8.172016143798828\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 99, batch train loss: 6.283360481262207\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 100, batch train loss: 7.498948574066162\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 101, batch train loss: 8.933926582336426\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 102, batch train loss: 7.264898300170898\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 103, batch train loss: 7.1105475425720215\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 104, batch train loss: 4.304257392883301\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 105, batch train loss: 5.798836708068848\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 106, batch train loss: 4.928837776184082\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 107, batch train loss: 5.821499347686768\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 108, batch train loss: 6.2800374031066895\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 109, batch train loss: 3.8876090049743652\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 110, batch train loss: 8.171467781066895\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 111, batch train loss: 3.727074384689331\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 112, batch train loss: 5.194269180297852\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 113, batch train loss: 4.680180072784424\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 114, batch train loss: 5.564615249633789\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 115, batch train loss: 5.107539176940918\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 116, batch train loss: 6.59779167175293\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 117, batch train loss: 4.133983612060547\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 118, batch train loss: 5.6074419021606445\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 119, batch train loss: 7.56504487991333\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 120, batch train loss: 3.4744608402252197\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 121, batch train loss: 5.334475517272949\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 122, batch train loss: 4.7053751945495605\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 123, batch train loss: 3.8936963081359863\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 124, batch train loss: 4.36396598815918\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 125, batch train loss: 3.2910001277923584\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 126, batch train loss: 3.298617124557495\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 127, batch train loss: 2.581557035446167\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 128, batch train loss: 2.981318473815918\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, batch_id: 129, batch train loss: 2.184415340423584\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 130, batch train loss: 5.189210414886475\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 131, batch train loss: 3.9873721599578857\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 132, batch train loss: 3.9479737281799316\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 133, batch train loss: 3.1194355487823486\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 134, batch train loss: 3.479494333267212\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 135, batch train loss: 3.901698350906372\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 136, batch train loss: 6.012761116027832\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 137, batch train loss: 5.117268085479736\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 138, batch train loss: 5.481321811676025\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 139, batch train loss: 7.356706619262695\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 140, batch train loss: 4.033085346221924\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 141, batch train loss: 6.4187469482421875\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 142, batch train loss: 8.935813903808594\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 143, batch train loss: 3.751617908477783\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 144, batch train loss: 5.9447855949401855\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 145, batch train loss: 7.833650588989258\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 146, batch train loss: 4.888920307159424\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 147, batch train loss: 5.0282368659973145\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 148, batch train loss: 5.236657619476318\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 149, batch train loss: 5.23506498336792\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 150, batch train loss: 5.244014263153076\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 151, batch train loss: 7.100362300872803\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 152, batch train loss: 4.595416069030762\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 153, batch train loss: 4.047126293182373\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 154, batch train loss: 3.174992561340332\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 155, batch train loss: 3.708620548248291\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 156, batch train loss: 4.0493950843811035\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 157, batch train loss: 4.347008228302002\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 158, batch train loss: 4.030393600463867\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 159, batch train loss: 5.704308986663818\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 160, batch train loss: 3.103762626647949\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 161, batch train loss: 4.129800796508789\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 162, batch train loss: 3.1271374225616455\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 163, batch train loss: 4.116659164428711\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 164, batch train loss: 4.942031383514404\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 165, batch train loss: 3.003215789794922\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 166, batch train loss: 5.540793418884277\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 167, batch train loss: 3.2173726558685303\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 168, batch train loss: 3.6668269634246826\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 169, batch train loss: 3.8360021114349365\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 170, batch train loss: 3.774340867996216\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 171, batch train loss: 3.7850918769836426\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 172, batch train loss: 4.868959903717041\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 173, batch train loss: 3.227943181991577\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 174, batch train loss: 5.953301906585693\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 175, batch train loss: 5.364687442779541\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 176, batch train loss: 5.798063278198242\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 177, batch train loss: 3.620908498764038\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 178, batch train loss: 4.113328456878662\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 179, batch train loss: 3.080538034439087\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 180, batch train loss: 2.9151201248168945\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 181, batch train loss: 2.262568950653076\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 182, batch train loss: 4.295351505279541\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 183, batch train loss: 4.389501571655273\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 184, batch train loss: 2.6052682399749756\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 185, batch train loss: 4.08306884765625\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 186, batch train loss: 3.4432713985443115\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 187, batch train loss: 7.6732025146484375\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 188, batch train loss: 5.049854278564453\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 189, batch train loss: 4.964714527130127\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 190, batch train loss: 2.95043683052063\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 191, batch train loss: 5.872085094451904\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 192, batch train loss: 5.531889915466309\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 193, batch train loss: 4.435309886932373\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 194, batch train loss: 6.928706169128418\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 195, batch train loss: 5.110132217407227\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 196, batch train loss: 4.8522233963012695\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 197, batch train loss: 3.807110071182251\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 198, batch train loss: 4.261292934417725\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 199, batch train loss: 8.113332748413086\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 200, batch train loss: 7.4488844871521\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 201, batch train loss: 5.04377555847168\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 202, batch train loss: 8.27245044708252\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 203, batch train loss: 5.165503025054932\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 204, batch train loss: 5.311831474304199\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 205, batch train loss: 6.498636245727539\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 206, batch train loss: 4.722477436065674\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 207, batch train loss: 4.058477878570557\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 208, batch train loss: 8.609853744506836\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 209, batch train loss: 3.060593366622925\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 210, batch train loss: 4.360201835632324\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 211, batch train loss: 3.2982921600341797\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 212, batch train loss: 6.521528244018555\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 213, batch train loss: 8.251035690307617\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 214, batch train loss: 10.210005760192871\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 215, batch train loss: 5.18610143661499\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 216, batch train loss: 5.229498863220215\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 217, batch train loss: 4.875464916229248\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 218, batch train loss: 4.501735210418701\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 219, batch train loss: 3.215974807739258\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 220, batch train loss: 7.419884204864502\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 221, batch train loss: 4.73922061920166\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 222, batch train loss: 4.379297733306885\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 223, batch train loss: 3.180051326751709\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 224, batch train loss: 4.635831832885742\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 225, batch train loss: 3.271568536758423\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 226, batch train loss: 4.195556163787842\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 227, batch train loss: 4.294893264770508\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 228, batch train loss: 3.5907235145568848\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 229, batch train loss: 5.725571155548096\n",
      "\n",
      "\n",
      "Epoch: 10, batch_id: 230, batch train loss: 4.297440528869629\n",
      "\n",
      "\n",
      "Epoch: 10/ 100, Loss: 5.649575607672982\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:10<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Validation Loss: 4.348496870199839\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 11, batch_id: 1, batch train loss: 5.570269584655762\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 2, batch train loss: 3.4926257133483887\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 3, batch train loss: 3.7084925174713135\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 4, batch train loss: 3.4919092655181885\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 5, batch train loss: 2.941817283630371\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 6, batch train loss: 3.1021571159362793\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 7, batch train loss: 3.429577589035034\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 8, batch train loss: 2.7070631980895996\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 9, batch train loss: 2.6202828884124756\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 10, batch train loss: 4.27875280380249\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 11, batch train loss: 5.851746559143066\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 12, batch train loss: 5.170464992523193\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 13, batch train loss: 4.9231486320495605\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 14, batch train loss: 6.528799057006836\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 15, batch train loss: 5.484319686889648\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 16, batch train loss: 7.393726348876953\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 17, batch train loss: 6.092819690704346\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 18, batch train loss: 3.450918436050415\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 19, batch train loss: 4.0486907958984375\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 20, batch train loss: 5.374078750610352\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 21, batch train loss: 4.41217565536499\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 22, batch train loss: 6.052768230438232\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 23, batch train loss: 5.167192459106445\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 24, batch train loss: 5.258932113647461\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 25, batch train loss: 4.63857889175415\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 26, batch train loss: 4.441735744476318\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 27, batch train loss: 4.994118690490723\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 28, batch train loss: 5.066364288330078\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 29, batch train loss: 3.513568162918091\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 30, batch train loss: 4.089983940124512\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 31, batch train loss: 8.455185890197754\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 32, batch train loss: 4.508339881896973\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 33, batch train loss: 5.618236064910889\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 34, batch train loss: 3.704728603363037\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 35, batch train loss: 2.748572587966919\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 36, batch train loss: 4.539982318878174\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 37, batch train loss: 3.8706021308898926\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 38, batch train loss: 5.650470733642578\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 39, batch train loss: 6.105739116668701\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 40, batch train loss: 4.626206398010254\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 41, batch train loss: 3.651501417160034\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 42, batch train loss: 4.503170013427734\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 43, batch train loss: 3.2560834884643555\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 44, batch train loss: 2.7543423175811768\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 45, batch train loss: 3.6411352157592773\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 46, batch train loss: 4.070431232452393\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 47, batch train loss: 5.112283706665039\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 48, batch train loss: 3.8034870624542236\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 49, batch train loss: 3.6139423847198486\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 50, batch train loss: 4.130178451538086\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 51, batch train loss: 5.368222713470459\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 52, batch train loss: 4.567926406860352\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 53, batch train loss: 4.2719221115112305\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 54, batch train loss: 3.0563199520111084\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 55, batch train loss: 3.6248092651367188\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 56, batch train loss: 6.815556049346924\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 57, batch train loss: 4.589337348937988\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 58, batch train loss: 3.2054059505462646\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 59, batch train loss: 5.956235408782959\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 60, batch train loss: 5.42233419418335\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 61, batch train loss: 3.7139759063720703\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 62, batch train loss: 7.2012200355529785\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 63, batch train loss: 5.40385103225708\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 64, batch train loss: 3.2745957374572754\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 65, batch train loss: 6.183648109436035\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 66, batch train loss: 4.336673259735107\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 67, batch train loss: 3.6186795234680176\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 68, batch train loss: 3.0857717990875244\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 69, batch train loss: 3.2454938888549805\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 70, batch train loss: 4.949088096618652\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 71, batch train loss: 3.2064995765686035\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 72, batch train loss: 3.3525607585906982\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 73, batch train loss: 4.7814531326293945\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 74, batch train loss: 5.223606586456299\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 75, batch train loss: 4.093732833862305\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 76, batch train loss: 2.90578293800354\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 77, batch train loss: 3.9340980052948\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 78, batch train loss: 4.318458557128906\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 79, batch train loss: 4.712210178375244\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 80, batch train loss: 5.301219463348389\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 81, batch train loss: 4.453354835510254\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 82, batch train loss: 4.761256694793701\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 83, batch train loss: 2.9308700561523438\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 84, batch train loss: 3.961906671524048\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 85, batch train loss: 3.2907936573028564\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 86, batch train loss: 5.393901824951172\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 87, batch train loss: 4.07390832901001\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 88, batch train loss: 4.490245342254639\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 89, batch train loss: 3.339491367340088\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 90, batch train loss: 4.090206146240234\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 91, batch train loss: 2.70725417137146\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 92, batch train loss: 3.3784945011138916\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 93, batch train loss: 3.8924567699432373\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 94, batch train loss: 2.542330503463745\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 95, batch train loss: 3.7891108989715576\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 96, batch train loss: 3.4577741622924805\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 97, batch train loss: 4.2108073234558105\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 98, batch train loss: 4.255068778991699\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 99, batch train loss: 4.613201141357422\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 100, batch train loss: 7.680422306060791\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 101, batch train loss: 4.216421127319336\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 102, batch train loss: 6.5575175285339355\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 103, batch train loss: 5.153562545776367\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 104, batch train loss: 4.447262287139893\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 105, batch train loss: 6.681021213531494\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 106, batch train loss: 5.4694719314575195\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 107, batch train loss: 3.025357723236084\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 108, batch train loss: 5.262236595153809\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 109, batch train loss: 5.2029829025268555\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 110, batch train loss: 4.416680335998535\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 111, batch train loss: 3.7763419151306152\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 112, batch train loss: 5.0868239402771\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 113, batch train loss: 4.611573219299316\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 114, batch train loss: 3.3678228855133057\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 115, batch train loss: 3.0661861896514893\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 116, batch train loss: 3.2840702533721924\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 117, batch train loss: 4.958006381988525\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 118, batch train loss: 3.086353063583374\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 119, batch train loss: 3.2989397048950195\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 120, batch train loss: 3.5785257816314697\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 121, batch train loss: 2.4455771446228027\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 122, batch train loss: 3.158841371536255\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 123, batch train loss: 3.760352849960327\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 124, batch train loss: 3.6001179218292236\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 125, batch train loss: 2.7574727535247803\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 126, batch train loss: 3.339877128601074\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 127, batch train loss: 3.300577402114868\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 128, batch train loss: 5.099780082702637\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, batch_id: 129, batch train loss: 3.6759676933288574\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 130, batch train loss: 3.7916581630706787\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 131, batch train loss: 4.518655300140381\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 132, batch train loss: 4.130573749542236\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 133, batch train loss: 4.510629653930664\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 134, batch train loss: 3.6502938270568848\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 135, batch train loss: 3.5170552730560303\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 136, batch train loss: 6.1289215087890625\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 137, batch train loss: 4.5503830909729\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 138, batch train loss: 5.301898002624512\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 139, batch train loss: 7.047236919403076\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 140, batch train loss: 4.820252895355225\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 141, batch train loss: 4.729126453399658\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 142, batch train loss: 5.0441789627075195\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 143, batch train loss: 3.260253667831421\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 144, batch train loss: 4.643667697906494\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 145, batch train loss: 6.167882442474365\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 146, batch train loss: 5.8232879638671875\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 147, batch train loss: 7.194227695465088\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 148, batch train loss: 7.109904766082764\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 149, batch train loss: 3.844326972961426\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 150, batch train loss: 4.227136135101318\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 151, batch train loss: 5.430764675140381\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 152, batch train loss: 3.582686424255371\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 153, batch train loss: 3.2065582275390625\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 154, batch train loss: 3.6490304470062256\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 155, batch train loss: 3.8940048217773438\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 156, batch train loss: 3.7487690448760986\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 157, batch train loss: 4.402931213378906\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 158, batch train loss: 4.773947715759277\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 159, batch train loss: 3.185417890548706\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 160, batch train loss: 3.572742223739624\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 161, batch train loss: 2.7575716972351074\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 162, batch train loss: 3.931868076324463\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 163, batch train loss: 5.0590410232543945\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 164, batch train loss: 3.6622347831726074\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 165, batch train loss: 4.675344467163086\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 166, batch train loss: 4.0436110496521\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 167, batch train loss: 3.239651918411255\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 168, batch train loss: 4.915152072906494\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 169, batch train loss: 3.382559061050415\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 170, batch train loss: 3.6105992794036865\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 171, batch train loss: 4.513492584228516\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 172, batch train loss: 3.2694029808044434\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 173, batch train loss: 4.9993743896484375\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 174, batch train loss: 3.7716479301452637\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 175, batch train loss: 4.8856611251831055\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 176, batch train loss: 7.228201389312744\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 177, batch train loss: 8.90454387664795\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 178, batch train loss: 5.824418544769287\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 179, batch train loss: 5.107256889343262\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 180, batch train loss: 7.195610523223877\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 181, batch train loss: 6.127354145050049\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 182, batch train loss: 3.7829647064208984\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 183, batch train loss: 6.50516414642334\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 184, batch train loss: 10.554374694824219\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 185, batch train loss: 8.168248176574707\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 186, batch train loss: 4.014299392700195\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 187, batch train loss: 7.443215370178223\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 188, batch train loss: 13.259079933166504\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 189, batch train loss: 7.694573402404785\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 190, batch train loss: 4.477409839630127\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 191, batch train loss: 8.126219749450684\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 192, batch train loss: 5.540062427520752\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 193, batch train loss: 3.460456609725952\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 194, batch train loss: 5.395681858062744\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 195, batch train loss: 5.848411560058594\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 196, batch train loss: 4.578720569610596\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 197, batch train loss: 12.448963165283203\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 198, batch train loss: 6.952372074127197\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 199, batch train loss: 4.540377140045166\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 200, batch train loss: 4.212958335876465\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 201, batch train loss: 6.268154144287109\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 202, batch train loss: 4.944861888885498\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 203, batch train loss: 8.382434844970703\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 204, batch train loss: 6.348811626434326\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 205, batch train loss: 7.017636775970459\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 206, batch train loss: 3.4247782230377197\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 207, batch train loss: 4.98500919342041\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 208, batch train loss: 6.427162170410156\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 209, batch train loss: 4.49503755569458\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 210, batch train loss: 5.456206321716309\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 211, batch train loss: 6.626614093780518\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 212, batch train loss: 4.443848609924316\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 213, batch train loss: 5.297548294067383\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 214, batch train loss: 6.27761173248291\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 215, batch train loss: 3.966165065765381\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 216, batch train loss: 3.6967906951904297\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 217, batch train loss: 4.8186211585998535\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 218, batch train loss: 4.932043075561523\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 219, batch train loss: 2.9522337913513184\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 220, batch train loss: 7.384812831878662\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 221, batch train loss: 10.953161239624023\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 222, batch train loss: 4.963526725769043\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 223, batch train loss: 4.849917888641357\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 224, batch train loss: 6.819087505340576\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 225, batch train loss: 9.23324203491211\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 226, batch train loss: 5.839781761169434\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 227, batch train loss: 3.941420555114746\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 228, batch train loss: 5.080465316772461\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 229, batch train loss: 3.495378017425537\n",
      "\n",
      "\n",
      "Epoch: 11, batch_id: 230, batch train loss: 2.6746952533721924\n",
      "\n",
      "\n",
      "Epoch: 11/ 100, Loss: 4.773672075893568\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Validation Loss: 3.9580071171124778\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 12, batch_id: 1, batch train loss: 5.13341760635376\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 2, batch train loss: 3.11124849319458\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 3, batch train loss: 3.1264657974243164\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 4, batch train loss: 4.79305362701416\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 5, batch train loss: 4.102834701538086\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 6, batch train loss: 3.981771945953369\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 7, batch train loss: 5.059957504272461\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 8, batch train loss: 3.4908320903778076\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 9, batch train loss: 4.009424686431885\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 10, batch train loss: 3.8432397842407227\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 11, batch train loss: 4.4713592529296875\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 12, batch train loss: 5.258094310760498\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 13, batch train loss: 3.0652830600738525\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 14, batch train loss: 3.0501341819763184\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 15, batch train loss: 3.3019747734069824\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 16, batch train loss: 2.5838301181793213\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 17, batch train loss: 5.0110883712768555\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 18, batch train loss: 3.3813695907592773\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 19, batch train loss: 3.6875667572021484\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 20, batch train loss: 4.437918663024902\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 21, batch train loss: 3.5617127418518066\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 22, batch train loss: 4.462771415710449\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 23, batch train loss: 3.9277384281158447\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 24, batch train loss: 4.150918960571289\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 25, batch train loss: 4.180525779724121\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 26, batch train loss: 3.636098623275757\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 27, batch train loss: 4.086248397827148\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 28, batch train loss: 3.6344754695892334\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 29, batch train loss: 3.8589985370635986\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 30, batch train loss: 3.308077335357666\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 31, batch train loss: 3.180795192718506\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 32, batch train loss: 2.7175934314727783\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 33, batch train loss: 2.847550392150879\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 34, batch train loss: 3.0693914890289307\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 35, batch train loss: 3.771376132965088\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 36, batch train loss: 2.993438720703125\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 37, batch train loss: 2.917102813720703\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 38, batch train loss: 3.3682918548583984\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 39, batch train loss: 2.3554813861846924\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 40, batch train loss: 3.561387062072754\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 41, batch train loss: 3.060788869857788\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 42, batch train loss: 2.9246232509613037\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 43, batch train loss: 3.493391513824463\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 44, batch train loss: 4.184960842132568\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 45, batch train loss: 2.637758731842041\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 46, batch train loss: 3.630303144454956\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 47, batch train loss: 2.6902341842651367\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 48, batch train loss: 4.330758094787598\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 49, batch train loss: 4.259859085083008\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 50, batch train loss: 3.684863805770874\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 51, batch train loss: 5.639852046966553\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 52, batch train loss: 4.844181537628174\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 53, batch train loss: 5.695013523101807\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 54, batch train loss: 6.475164413452148\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 55, batch train loss: 3.1707189083099365\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 56, batch train loss: 3.486894130706787\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 57, batch train loss: 6.932945728302002\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 58, batch train loss: 5.407140254974365\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 59, batch train loss: 6.059083461761475\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 60, batch train loss: 5.2042236328125\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 61, batch train loss: 5.554969787597656\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 62, batch train loss: 4.9863176345825195\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 63, batch train loss: 3.899897813796997\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 64, batch train loss: 3.765255928039551\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 65, batch train loss: 4.39061164855957\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 66, batch train loss: 4.262951850891113\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 67, batch train loss: 4.250594139099121\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 68, batch train loss: 3.3069331645965576\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 69, batch train loss: 3.0798821449279785\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 70, batch train loss: 2.8890068531036377\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 71, batch train loss: 3.071040391921997\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 72, batch train loss: 3.065964460372925\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 73, batch train loss: 2.763063430786133\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 74, batch train loss: 3.6456644535064697\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 75, batch train loss: 5.049517631530762\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 76, batch train loss: 3.340641975402832\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 77, batch train loss: 4.038168907165527\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 78, batch train loss: 3.9356584548950195\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 79, batch train loss: 2.6009018421173096\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 80, batch train loss: 3.0899672508239746\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 81, batch train loss: 3.365785837173462\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 82, batch train loss: 2.586165428161621\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 83, batch train loss: 3.801464796066284\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 84, batch train loss: 5.866034030914307\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 85, batch train loss: 4.843946933746338\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 86, batch train loss: 2.7288424968719482\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 87, batch train loss: 4.112798690795898\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 88, batch train loss: 3.7957756519317627\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 89, batch train loss: 3.4955437183380127\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 90, batch train loss: 4.573956489562988\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 91, batch train loss: 3.544888496398926\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 92, batch train loss: 5.387025833129883\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 93, batch train loss: 5.433566093444824\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 94, batch train loss: 3.48130202293396\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 95, batch train loss: 5.05250883102417\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 96, batch train loss: 2.9861364364624023\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 97, batch train loss: 5.067120552062988\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 98, batch train loss: 3.9073681831359863\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 99, batch train loss: 3.0468246936798096\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 100, batch train loss: 5.254125118255615\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 101, batch train loss: 3.407233953475952\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 102, batch train loss: 9.040332794189453\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 103, batch train loss: 10.253786087036133\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 104, batch train loss: 7.779629707336426\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 105, batch train loss: 4.136516094207764\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 106, batch train loss: 6.834028244018555\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 107, batch train loss: 11.222399711608887\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 108, batch train loss: 8.23592472076416\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 109, batch train loss: 5.807708740234375\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 110, batch train loss: 3.694038152694702\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 111, batch train loss: 10.291476249694824\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 112, batch train loss: 10.461139678955078\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 113, batch train loss: 3.9387476444244385\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 114, batch train loss: 4.049704551696777\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 115, batch train loss: 6.902557849884033\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 116, batch train loss: 10.392536163330078\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 117, batch train loss: 6.860464096069336\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 118, batch train loss: 3.5201363563537598\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 119, batch train loss: 7.340008735656738\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 120, batch train loss: 8.654641151428223\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 121, batch train loss: 5.2067694664001465\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 122, batch train loss: 4.037107944488525\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 123, batch train loss: 6.045958995819092\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 124, batch train loss: 4.988204479217529\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 125, batch train loss: 4.54900598526001\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 126, batch train loss: 3.702989101409912\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 127, batch train loss: 4.9771809577941895\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 128, batch train loss: 7.616937637329102\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, batch_id: 129, batch train loss: 3.775566816329956\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 130, batch train loss: 4.6294708251953125\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 131, batch train loss: 3.013702869415283\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 132, batch train loss: 2.943655490875244\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 133, batch train loss: 5.374241352081299\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 134, batch train loss: 5.259706020355225\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 135, batch train loss: 2.6224868297576904\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 136, batch train loss: 5.362480640411377\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 137, batch train loss: 5.859752655029297\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 138, batch train loss: 7.373481273651123\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 139, batch train loss: 3.4457600116729736\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 140, batch train loss: 5.265567302703857\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 141, batch train loss: 5.044616222381592\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 142, batch train loss: 3.049919366836548\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 143, batch train loss: 4.134979248046875\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 144, batch train loss: 5.520748615264893\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 145, batch train loss: 3.8875882625579834\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 146, batch train loss: 4.508796215057373\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 147, batch train loss: 3.275294542312622\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 148, batch train loss: 3.366663932800293\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 149, batch train loss: 4.539402961730957\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 150, batch train loss: 2.678560495376587\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 151, batch train loss: 5.07650089263916\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 152, batch train loss: 5.15212869644165\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 153, batch train loss: 3.4825611114501953\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 154, batch train loss: 3.4662580490112305\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 155, batch train loss: 4.277137279510498\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 156, batch train loss: 3.746884822845459\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 157, batch train loss: 4.19327449798584\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 158, batch train loss: 5.031565189361572\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 159, batch train loss: 4.506932735443115\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 160, batch train loss: 2.9296212196350098\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 161, batch train loss: 4.755148410797119\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 162, batch train loss: 4.968254089355469\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 163, batch train loss: 3.162365198135376\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 164, batch train loss: 4.005547523498535\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 165, batch train loss: 3.205561399459839\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 166, batch train loss: 2.2108423709869385\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 167, batch train loss: 4.703528881072998\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 168, batch train loss: 3.5065083503723145\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 169, batch train loss: 4.307938098907471\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 170, batch train loss: 4.276182651519775\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 171, batch train loss: 3.2317984104156494\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 172, batch train loss: 3.065124273300171\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 173, batch train loss: 4.868556022644043\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 174, batch train loss: 4.010340213775635\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 175, batch train loss: 5.020380020141602\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 176, batch train loss: 3.8395931720733643\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 177, batch train loss: 6.081535816192627\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 178, batch train loss: 4.0373663902282715\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 179, batch train loss: 3.402721643447876\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 180, batch train loss: 3.457697868347168\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 181, batch train loss: 2.826690196990967\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 182, batch train loss: 3.085341691970825\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 183, batch train loss: 3.290709972381592\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 184, batch train loss: 2.4123170375823975\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 185, batch train loss: 3.6130738258361816\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 186, batch train loss: 2.6483609676361084\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 187, batch train loss: 3.967135429382324\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 188, batch train loss: 2.7231576442718506\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 189, batch train loss: 5.163949966430664\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 190, batch train loss: 2.803725242614746\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 191, batch train loss: 4.324028491973877\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 192, batch train loss: 3.110408067703247\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 193, batch train loss: 3.811984062194824\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 194, batch train loss: 2.879417657852173\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 195, batch train loss: 2.344271421432495\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 196, batch train loss: 2.415478229522705\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 197, batch train loss: 3.718214511871338\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 198, batch train loss: 1.6094613075256348\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 199, batch train loss: 2.847259759902954\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 200, batch train loss: 2.581674814224243\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 201, batch train loss: 2.819505214691162\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 202, batch train loss: 2.7789623737335205\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 203, batch train loss: 3.1270158290863037\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 204, batch train loss: 3.2013020515441895\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 205, batch train loss: 2.2520785331726074\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 206, batch train loss: 3.796365261077881\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 207, batch train loss: 3.6253275871276855\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 208, batch train loss: 3.591289520263672\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 209, batch train loss: 3.6870076656341553\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 210, batch train loss: 3.534139394760132\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 211, batch train loss: 2.137230157852173\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 212, batch train loss: 3.726223945617676\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 213, batch train loss: 2.817371368408203\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 214, batch train loss: 2.176760196685791\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 215, batch train loss: 2.304276466369629\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 216, batch train loss: 2.4949069023132324\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 217, batch train loss: 2.347083568572998\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 218, batch train loss: 3.351945638656616\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 219, batch train loss: 2.3974385261535645\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 220, batch train loss: 3.807077646255493\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 221, batch train loss: 2.6254799365997314\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 222, batch train loss: 2.482757329940796\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 223, batch train loss: 3.7514798641204834\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 224, batch train loss: 2.5132646560668945\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 225, batch train loss: 2.663050413131714\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 226, batch train loss: 2.856318235397339\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 227, batch train loss: 4.027493000030518\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 228, batch train loss: 2.7044548988342285\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 229, batch train loss: 3.392867088317871\n",
      "\n",
      "\n",
      "Epoch: 12, batch_id: 230, batch train loss: 2.7626781463623047\n",
      "\n",
      "\n",
      "Epoch: 12/ 100, Loss: 4.114830708503723\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Validation Loss: 3.2271383961041766\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 13, batch_id: 1, batch train loss: 3.1471025943756104\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 2, batch train loss: 2.801227331161499\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 3, batch train loss: 1.985225796699524\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 4, batch train loss: 2.5276663303375244\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 5, batch train loss: 3.1071252822875977\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 6, batch train loss: 2.7378287315368652\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 7, batch train loss: 3.3228085041046143\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 8, batch train loss: 2.769381046295166\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 9, batch train loss: 2.502716064453125\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 10, batch train loss: 2.5027549266815186\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 11, batch train loss: 2.277475595474243\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 12, batch train loss: 3.0889854431152344\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 13, batch train loss: 4.517601490020752\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 14, batch train loss: 3.352667808532715\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 15, batch train loss: 4.038637638092041\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 16, batch train loss: 2.6862618923187256\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 17, batch train loss: 2.87617564201355\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 18, batch train loss: 5.345398426055908\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 19, batch train loss: 2.9865851402282715\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 20, batch train loss: 3.929098606109619\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 21, batch train loss: 3.341874599456787\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 22, batch train loss: 2.8363475799560547\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 23, batch train loss: 3.1582651138305664\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 24, batch train loss: 3.0233206748962402\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 25, batch train loss: 2.5365872383117676\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 26, batch train loss: 2.3292815685272217\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 27, batch train loss: 2.721341371536255\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 28, batch train loss: 2.1559829711914062\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 29, batch train loss: 3.5462653636932373\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 30, batch train loss: 2.2051455974578857\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 31, batch train loss: 3.1148858070373535\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 32, batch train loss: 3.282510995864868\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 33, batch train loss: 2.4007251262664795\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 34, batch train loss: 3.5580830574035645\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 35, batch train loss: 4.834057331085205\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 36, batch train loss: 4.781157970428467\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 37, batch train loss: 4.134200572967529\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 38, batch train loss: 4.702691078186035\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 39, batch train loss: 2.506213665008545\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 40, batch train loss: 4.733715534210205\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 41, batch train loss: 3.3157660961151123\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 42, batch train loss: 4.370782852172852\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 43, batch train loss: 4.6622772216796875\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 44, batch train loss: 3.3145453929901123\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 45, batch train loss: 3.5519542694091797\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 46, batch train loss: 3.247917890548706\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 47, batch train loss: 2.7959229946136475\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 48, batch train loss: 3.3434009552001953\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 49, batch train loss: 2.3356149196624756\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 50, batch train loss: 2.0992908477783203\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 51, batch train loss: 3.8543567657470703\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 52, batch train loss: 2.695418357849121\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 53, batch train loss: 2.782160520553589\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 54, batch train loss: 4.233129024505615\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 55, batch train loss: 2.751504898071289\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 56, batch train loss: 5.489774227142334\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 57, batch train loss: 3.336968421936035\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 58, batch train loss: 3.4940526485443115\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 59, batch train loss: 3.6015682220458984\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 60, batch train loss: 4.03402853012085\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 61, batch train loss: 3.1348791122436523\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 62, batch train loss: 3.0011494159698486\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 63, batch train loss: 3.9331071376800537\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 64, batch train loss: 4.19761848449707\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 65, batch train loss: 2.9955227375030518\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 66, batch train loss: 3.3932440280914307\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 67, batch train loss: 2.315770149230957\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 68, batch train loss: 2.4637722969055176\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 69, batch train loss: 2.9504284858703613\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 70, batch train loss: 3.956059217453003\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 71, batch train loss: 2.6573567390441895\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 72, batch train loss: 3.3712363243103027\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 73, batch train loss: 2.562201738357544\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 74, batch train loss: 3.173642873764038\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 75, batch train loss: 2.967256784439087\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 76, batch train loss: 2.3816311359405518\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 77, batch train loss: 3.9875195026397705\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 78, batch train loss: 2.3595807552337646\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 79, batch train loss: 2.550386667251587\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 80, batch train loss: 3.639622688293457\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 81, batch train loss: 2.983543634414673\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 82, batch train loss: 2.1828157901763916\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 83, batch train loss: 3.638406991958618\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 84, batch train loss: 3.4380977153778076\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 85, batch train loss: 2.400231122970581\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 86, batch train loss: 2.7419378757476807\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 87, batch train loss: 3.452816963195801\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 88, batch train loss: 3.7157034873962402\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 89, batch train loss: 2.5192339420318604\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 90, batch train loss: 4.165484428405762\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 91, batch train loss: 3.261349678039551\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 92, batch train loss: 4.035145282745361\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 93, batch train loss: 3.223193883895874\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 94, batch train loss: 2.694589138031006\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 95, batch train loss: 4.725500106811523\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 96, batch train loss: 3.454989433288574\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 97, batch train loss: 4.306257247924805\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 98, batch train loss: 3.391240119934082\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 99, batch train loss: 3.3404369354248047\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 100, batch train loss: 4.711000442504883\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 101, batch train loss: 4.030574321746826\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 102, batch train loss: 3.350095510482788\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 103, batch train loss: 2.8354110717773438\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 104, batch train loss: 2.485058546066284\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 105, batch train loss: 3.123318910598755\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 106, batch train loss: 1.8509639501571655\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 107, batch train loss: 2.726191759109497\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 108, batch train loss: 2.0245025157928467\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 109, batch train loss: 2.5383822917938232\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 110, batch train loss: 2.1397159099578857\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 111, batch train loss: 2.5782365798950195\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 112, batch train loss: 2.2281055450439453\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 113, batch train loss: 2.6170926094055176\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 114, batch train loss: 2.437919855117798\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 115, batch train loss: 3.0045790672302246\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 116, batch train loss: 2.3768179416656494\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 117, batch train loss: 3.1286585330963135\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 118, batch train loss: 4.38721227645874\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 119, batch train loss: 2.4029343128204346\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 120, batch train loss: 2.364576578140259\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 121, batch train loss: 2.457512617111206\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 122, batch train loss: 5.138208866119385\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 123, batch train loss: 4.027614116668701\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 124, batch train loss: 3.117856025695801\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 125, batch train loss: 4.707169532775879\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 126, batch train loss: 4.529566764831543\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 127, batch train loss: 2.538062810897827\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 128, batch train loss: 5.175836086273193\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, batch_id: 129, batch train loss: 2.8731272220611572\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 130, batch train loss: 3.549069404602051\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 131, batch train loss: 4.188683032989502\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 132, batch train loss: 3.32181453704834\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 133, batch train loss: 3.742927312850952\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 134, batch train loss: 2.8329031467437744\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 135, batch train loss: 3.914318799972534\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 136, batch train loss: 4.960427761077881\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 137, batch train loss: 2.8594448566436768\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 138, batch train loss: 2.4580957889556885\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 139, batch train loss: 2.9014647006988525\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 140, batch train loss: 3.7084851264953613\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 141, batch train loss: 2.572604179382324\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 142, batch train loss: 4.668200492858887\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 143, batch train loss: 4.281877517700195\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 144, batch train loss: 3.8935179710388184\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 145, batch train loss: 2.808506965637207\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 146, batch train loss: 5.73947811126709\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 147, batch train loss: 3.655055284500122\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 148, batch train loss: 4.216559886932373\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 149, batch train loss: 2.664828300476074\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 150, batch train loss: 2.6663637161254883\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 151, batch train loss: 4.217238426208496\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 152, batch train loss: 3.071627616882324\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 153, batch train loss: 2.939319372177124\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 154, batch train loss: 3.434368848800659\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 155, batch train loss: 2.735130548477173\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 156, batch train loss: 4.340439319610596\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 157, batch train loss: 3.0129401683807373\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 158, batch train loss: 5.120219707489014\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 159, batch train loss: 4.488193988800049\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 160, batch train loss: 3.386558771133423\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 161, batch train loss: 3.345050573348999\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 162, batch train loss: 3.186492919921875\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 163, batch train loss: 3.2371444702148438\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 164, batch train loss: 2.7251548767089844\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 165, batch train loss: 3.118030309677124\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 166, batch train loss: 2.756531238555908\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 167, batch train loss: 2.813638210296631\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 168, batch train loss: 3.40175461769104\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 169, batch train loss: 3.042675018310547\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 170, batch train loss: 3.802485704421997\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 171, batch train loss: 4.485670566558838\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 172, batch train loss: 2.873631238937378\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 173, batch train loss: 6.388986587524414\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 174, batch train loss: 3.306584358215332\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 175, batch train loss: 2.8760440349578857\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 176, batch train loss: 5.184405326843262\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 177, batch train loss: 4.717185974121094\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 178, batch train loss: 4.0313334465026855\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 179, batch train loss: 5.588768482208252\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 180, batch train loss: 4.308438301086426\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 181, batch train loss: 3.5492069721221924\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 182, batch train loss: 4.291053771972656\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 183, batch train loss: 3.4733283519744873\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 184, batch train loss: 3.2642390727996826\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 185, batch train loss: 3.406562089920044\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 186, batch train loss: 4.793441295623779\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 187, batch train loss: 4.172578811645508\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 188, batch train loss: 4.0328240394592285\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 189, batch train loss: 4.702646255493164\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 190, batch train loss: 2.7985470294952393\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 191, batch train loss: 3.4948794841766357\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 192, batch train loss: 3.29060435295105\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 193, batch train loss: 3.190871477127075\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 194, batch train loss: 3.370603322982788\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 195, batch train loss: 2.26989483833313\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 196, batch train loss: 3.1459996700286865\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 197, batch train loss: 2.5739033222198486\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 198, batch train loss: 3.7650504112243652\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 199, batch train loss: 2.8055975437164307\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 200, batch train loss: 2.8000895977020264\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 201, batch train loss: 2.4384233951568604\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 202, batch train loss: 2.1782114505767822\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 203, batch train loss: 3.509571075439453\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 204, batch train loss: 3.899461269378662\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 205, batch train loss: 3.489093542098999\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 206, batch train loss: 2.1770262718200684\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 207, batch train loss: 2.1396429538726807\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 208, batch train loss: 3.729712724685669\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 209, batch train loss: 2.5885539054870605\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 210, batch train loss: 3.4744033813476562\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 211, batch train loss: 3.668449640274048\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 212, batch train loss: 3.6322762966156006\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 213, batch train loss: 5.087413787841797\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 214, batch train loss: 2.096708297729492\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 215, batch train loss: 3.987736463546753\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 216, batch train loss: 3.270249366760254\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 217, batch train loss: 3.736315965652466\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 218, batch train loss: 3.6462674140930176\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 219, batch train loss: 4.7372918128967285\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 220, batch train loss: 3.2076468467712402\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 221, batch train loss: 3.618450403213501\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 222, batch train loss: 3.473459482192993\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 223, batch train loss: 2.2535488605499268\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 224, batch train loss: 2.7448952198028564\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 225, batch train loss: 2.6385016441345215\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 226, batch train loss: 4.333563327789307\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 227, batch train loss: 8.314920425415039\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 228, batch train loss: 5.019428730010986\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 229, batch train loss: 5.267405033111572\n",
      "\n",
      "\n",
      "Epoch: 13, batch_id: 230, batch train loss: 4.628011703491211\n",
      "\n",
      "\n",
      "Epoch: 13/ 100, Loss: 3.404366554384646\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:08<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Validation Loss: 3.7172409693400064\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, batch_id: 1, batch train loss: 3.969792127609253\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 2, batch train loss: 4.200296401977539\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 3, batch train loss: 5.832326412200928\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 4, batch train loss: 7.770968437194824\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 5, batch train loss: 6.874797344207764\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 6, batch train loss: 2.954511880874634\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 7, batch train loss: 2.01332950592041\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 8, batch train loss: 4.546313762664795\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 9, batch train loss: 2.960552453994751\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 10, batch train loss: 3.3703155517578125\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 11, batch train loss: 3.8964781761169434\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 12, batch train loss: 2.637962579727173\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 13, batch train loss: 2.6631994247436523\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 14, batch train loss: 4.083061695098877\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 15, batch train loss: 3.1330199241638184\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 16, batch train loss: 2.7986249923706055\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 17, batch train loss: 3.3616931438446045\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 18, batch train loss: 3.1697323322296143\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 19, batch train loss: 2.405233860015869\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 20, batch train loss: 3.3418469429016113\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 21, batch train loss: 3.2247111797332764\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 22, batch train loss: 3.4177889823913574\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 23, batch train loss: 8.547867774963379\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 24, batch train loss: 4.449281692504883\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 25, batch train loss: 4.826475620269775\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 26, batch train loss: 5.703128337860107\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 27, batch train loss: 3.800546407699585\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 28, batch train loss: 3.739149570465088\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 29, batch train loss: 5.472925186157227\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 30, batch train loss: 4.687276840209961\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 31, batch train loss: 4.016921043395996\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 32, batch train loss: 2.730457305908203\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 33, batch train loss: 2.4363625049591064\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 34, batch train loss: 2.034276247024536\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 35, batch train loss: 3.6958301067352295\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 36, batch train loss: 1.9533939361572266\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 37, batch train loss: 1.6265698671340942\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 38, batch train loss: 2.421903371810913\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 39, batch train loss: 1.8884761333465576\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 40, batch train loss: 3.538881778717041\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 41, batch train loss: 2.8223915100097656\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 42, batch train loss: 3.3151445388793945\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 43, batch train loss: 2.94933819770813\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 44, batch train loss: 2.2271230220794678\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 45, batch train loss: 3.8382694721221924\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 46, batch train loss: 2.1589581966400146\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 47, batch train loss: 4.065372943878174\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 48, batch train loss: 2.976126194000244\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 49, batch train loss: 2.7157626152038574\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 50, batch train loss: 3.1788103580474854\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 51, batch train loss: 2.2470316886901855\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 52, batch train loss: 2.544255256652832\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 53, batch train loss: 3.655238151550293\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 54, batch train loss: 2.8345470428466797\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 55, batch train loss: 3.8224785327911377\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 56, batch train loss: 3.2424559593200684\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 57, batch train loss: 5.064165115356445\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 58, batch train loss: 4.121987819671631\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 59, batch train loss: 2.9247798919677734\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 60, batch train loss: 3.5645833015441895\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 61, batch train loss: 2.772042989730835\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 62, batch train loss: 2.651134490966797\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 63, batch train loss: 3.1255645751953125\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 64, batch train loss: 3.063732385635376\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 65, batch train loss: 3.134577512741089\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 66, batch train loss: 3.696887969970703\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 67, batch train loss: 2.814148187637329\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 68, batch train loss: 2.467252492904663\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 69, batch train loss: 3.0501151084899902\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 70, batch train loss: 3.1990625858306885\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 71, batch train loss: 3.1678194999694824\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 72, batch train loss: 3.915342092514038\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 73, batch train loss: 3.023691415786743\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 74, batch train loss: 5.421473979949951\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 75, batch train loss: 4.665589332580566\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 76, batch train loss: 3.582139492034912\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 77, batch train loss: 2.982100009918213\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 78, batch train loss: 3.945765733718872\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 79, batch train loss: 3.6943001747131348\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 80, batch train loss: 3.1883597373962402\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 81, batch train loss: 4.3903093338012695\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 82, batch train loss: 3.4489212036132812\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 83, batch train loss: 6.6507039070129395\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 84, batch train loss: 4.847398281097412\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 85, batch train loss: 2.036330461502075\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 86, batch train loss: 5.265987396240234\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 87, batch train loss: 3.65675950050354\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 88, batch train loss: 2.5444133281707764\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 89, batch train loss: 3.951801061630249\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 90, batch train loss: 4.434899806976318\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 91, batch train loss: 3.4453186988830566\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 92, batch train loss: 4.623614311218262\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 93, batch train loss: 4.674835681915283\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 94, batch train loss: 2.7431278228759766\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 95, batch train loss: 2.75544810295105\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 96, batch train loss: 3.363482713699341\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 97, batch train loss: 3.454984188079834\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 98, batch train loss: 3.894512891769409\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 99, batch train loss: 4.666703701019287\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 100, batch train loss: 3.990175485610962\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 101, batch train loss: 3.6012704372406006\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 102, batch train loss: 8.14455509185791\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 103, batch train loss: 8.02881145477295\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 104, batch train loss: 5.14727258682251\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 105, batch train loss: 4.251762866973877\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 106, batch train loss: 7.008190155029297\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 107, batch train loss: 5.606266021728516\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 108, batch train loss: 3.7220091819763184\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 109, batch train loss: 6.70097017288208\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 110, batch train loss: 4.619850158691406\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 111, batch train loss: 5.779030799865723\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 112, batch train loss: 3.2901039123535156\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 113, batch train loss: 8.746257781982422\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 114, batch train loss: 4.250266075134277\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 115, batch train loss: 3.891237497329712\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 116, batch train loss: 4.714656352996826\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 117, batch train loss: 6.362339019775391\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 118, batch train loss: 3.1312332153320312\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 119, batch train loss: 5.8599324226379395\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 120, batch train loss: 6.689207553863525\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 121, batch train loss: 2.5104947090148926\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 122, batch train loss: 5.524528980255127\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 123, batch train loss: 4.428277492523193\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 124, batch train loss: 2.731769323348999\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 125, batch train loss: 3.384117364883423\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 126, batch train loss: 2.7396624088287354\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 127, batch train loss: 2.416309118270874\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 128, batch train loss: 3.372103214263916\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 129, batch train loss: 4.052460670471191\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 130, batch train loss: 4.200729846954346\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, batch_id: 131, batch train loss: 5.1401166915893555\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 132, batch train loss: 3.6204304695129395\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 133, batch train loss: 3.867079973220825\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 134, batch train loss: 2.791055202484131\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 135, batch train loss: 3.1226792335510254\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 136, batch train loss: 3.968981981277466\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 137, batch train loss: 2.936495542526245\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 138, batch train loss: 3.878037929534912\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 139, batch train loss: 3.6825666427612305\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 140, batch train loss: 3.357590436935425\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 141, batch train loss: 6.187985420227051\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 142, batch train loss: 6.585515022277832\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 143, batch train loss: 4.383633613586426\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 144, batch train loss: 5.3630146980285645\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 145, batch train loss: 7.415513515472412\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 146, batch train loss: 5.868956089019775\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 147, batch train loss: 5.587282180786133\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 148, batch train loss: 7.052380561828613\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 149, batch train loss: 6.528867721557617\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 150, batch train loss: 3.404266595840454\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 151, batch train loss: 4.205804347991943\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 152, batch train loss: 5.6172776222229\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 153, batch train loss: 3.936729669570923\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 154, batch train loss: 3.214205026626587\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 155, batch train loss: 5.5238447189331055\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 156, batch train loss: 4.633525371551514\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 157, batch train loss: 3.8109655380249023\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 158, batch train loss: 4.058225631713867\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 159, batch train loss: 2.669335126876831\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 160, batch train loss: 3.694741725921631\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 161, batch train loss: 3.75640869140625\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 162, batch train loss: 3.509476661682129\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 163, batch train loss: 3.154411554336548\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 164, batch train loss: 4.99102783203125\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 165, batch train loss: 4.216450214385986\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 166, batch train loss: 3.443363904953003\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 167, batch train loss: 4.420828819274902\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 168, batch train loss: 3.3012359142303467\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 169, batch train loss: 2.9525513648986816\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 170, batch train loss: 3.9626073837280273\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 171, batch train loss: 2.4353325366973877\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 172, batch train loss: 4.146945953369141\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 173, batch train loss: 4.908609390258789\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 174, batch train loss: 3.7990481853485107\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 175, batch train loss: 5.094339370727539\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 176, batch train loss: 5.073589324951172\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 177, batch train loss: 3.985198497772217\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 178, batch train loss: 4.761740684509277\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 179, batch train loss: 3.787404775619507\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 180, batch train loss: 3.0281026363372803\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 181, batch train loss: 3.998562812805176\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 182, batch train loss: 3.2034997940063477\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 183, batch train loss: 2.020803928375244\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 184, batch train loss: 3.168790102005005\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 185, batch train loss: 3.3745229244232178\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 186, batch train loss: 3.8260498046875\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 187, batch train loss: 2.7009849548339844\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 188, batch train loss: 3.8474419116973877\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 189, batch train loss: 3.3977413177490234\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 190, batch train loss: 3.8230302333831787\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 191, batch train loss: 3.1477298736572266\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 192, batch train loss: 3.3400919437408447\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 193, batch train loss: 3.4909415245056152\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 194, batch train loss: 2.9430465698242188\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 195, batch train loss: 3.1964974403381348\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 196, batch train loss: 2.5967414379119873\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 197, batch train loss: 4.187843322753906\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 198, batch train loss: 3.477252244949341\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 199, batch train loss: 2.2463014125823975\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 200, batch train loss: 2.673813819885254\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 201, batch train loss: 4.174899578094482\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 202, batch train loss: 3.2232577800750732\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 203, batch train loss: 4.314423561096191\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 204, batch train loss: 4.4318742752075195\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 205, batch train loss: 3.052727699279785\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 206, batch train loss: 3.632736921310425\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 207, batch train loss: 4.113739490509033\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 208, batch train loss: 2.4748318195343018\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 209, batch train loss: 4.540726661682129\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 210, batch train loss: 3.8741812705993652\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 211, batch train loss: 3.068016767501831\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 212, batch train loss: 2.298473596572876\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 213, batch train loss: 4.972606182098389\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 214, batch train loss: 1.9455269575119019\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 215, batch train loss: 3.3026506900787354\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 216, batch train loss: 2.4165871143341064\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 217, batch train loss: 4.37910270690918\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 218, batch train loss: 4.199306011199951\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 219, batch train loss: 1.979254126548767\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 220, batch train loss: 3.789660692214966\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 221, batch train loss: 2.0970144271850586\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 222, batch train loss: 2.7187228202819824\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 223, batch train loss: 2.3290834426879883\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 224, batch train loss: 2.3779244422912598\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 225, batch train loss: 2.380012273788452\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 226, batch train loss: 2.5660669803619385\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 227, batch train loss: 2.755000352859497\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 228, batch train loss: 2.6059486865997314\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 229, batch train loss: 2.9050004482269287\n",
      "\n",
      "\n",
      "Epoch: 14, batch_id: 230, batch train loss: 2.7672030925750732\n",
      "\n",
      "\n",
      "Epoch: 14/ 100, Loss: 3.830241871398428\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:08<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Validation Loss: 2.729197108745575\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 15, batch_id: 1, batch train loss: 2.7759194374084473\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 2, batch train loss: 2.1235618591308594\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 3, batch train loss: 2.593287706375122\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 4, batch train loss: 2.6705055236816406\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 5, batch train loss: 3.2541604042053223\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 6, batch train loss: 3.5921623706817627\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 7, batch train loss: 2.5641236305236816\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 8, batch train loss: 3.2316179275512695\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 9, batch train loss: 2.530048131942749\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 10, batch train loss: 2.833421468734741\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 11, batch train loss: 2.43534255027771\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 12, batch train loss: 3.702047824859619\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 13, batch train loss: 2.3103890419006348\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 14, batch train loss: 2.7821381092071533\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 15, batch train loss: 2.3867921829223633\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 16, batch train loss: 2.9153213500976562\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 17, batch train loss: 3.186673641204834\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 18, batch train loss: 3.6709139347076416\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 19, batch train loss: 2.481959342956543\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 20, batch train loss: 2.28240704536438\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 21, batch train loss: 2.435565710067749\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 22, batch train loss: 3.390852689743042\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 23, batch train loss: 2.6057660579681396\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 24, batch train loss: 2.082700490951538\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 25, batch train loss: 2.297863245010376\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 26, batch train loss: 2.6825809478759766\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 27, batch train loss: 4.9876837730407715\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 28, batch train loss: 3.8014726638793945\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 29, batch train loss: 2.265242576599121\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 30, batch train loss: 2.218918800354004\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 31, batch train loss: 2.289177656173706\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 32, batch train loss: 2.1276280879974365\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 33, batch train loss: 5.599742412567139\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 34, batch train loss: 2.3162622451782227\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 35, batch train loss: 2.717735528945923\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 36, batch train loss: 2.5004026889801025\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 37, batch train loss: 2.0086796283721924\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 38, batch train loss: 3.4042980670928955\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 39, batch train loss: 2.1173765659332275\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 40, batch train loss: 3.326300859451294\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 41, batch train loss: 4.7124924659729\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 42, batch train loss: 2.716909170150757\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 43, batch train loss: 3.9021048545837402\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 44, batch train loss: 2.752354145050049\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 45, batch train loss: 2.3179943561553955\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 46, batch train loss: 2.601083517074585\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 47, batch train loss: 3.121675729751587\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 48, batch train loss: 2.818563461303711\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 49, batch train loss: 2.6425700187683105\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 50, batch train loss: 2.3011467456817627\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 51, batch train loss: 2.1512856483459473\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 52, batch train loss: 3.1698668003082275\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 53, batch train loss: 2.4627530574798584\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 54, batch train loss: 2.288646936416626\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 55, batch train loss: 3.85795521736145\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 56, batch train loss: 3.6538305282592773\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 57, batch train loss: 2.2185447216033936\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 58, batch train loss: 3.3208134174346924\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 59, batch train loss: 3.0411269664764404\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 60, batch train loss: 3.940584421157837\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 61, batch train loss: 2.7711405754089355\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 62, batch train loss: 3.9223995208740234\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 63, batch train loss: 4.5663299560546875\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 64, batch train loss: 2.6797969341278076\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 65, batch train loss: 3.8431694507598877\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 66, batch train loss: 4.55430269241333\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 67, batch train loss: 2.905001640319824\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 68, batch train loss: 3.193286657333374\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 69, batch train loss: 5.964038372039795\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 70, batch train loss: 4.491213321685791\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 71, batch train loss: 3.7174413204193115\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 72, batch train loss: 4.8588337898254395\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 73, batch train loss: 4.117877960205078\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 74, batch train loss: 3.8496029376983643\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 75, batch train loss: 3.2342302799224854\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 76, batch train loss: 2.4479126930236816\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 77, batch train loss: 2.896501064300537\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 78, batch train loss: 1.5590248107910156\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 79, batch train loss: 3.1092066764831543\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 80, batch train loss: 2.326352834701538\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 81, batch train loss: 3.051232099533081\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 82, batch train loss: 2.298535108566284\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 83, batch train loss: 2.613126516342163\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 84, batch train loss: 3.2339842319488525\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 85, batch train loss: 2.560380220413208\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 86, batch train loss: 3.0501272678375244\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 87, batch train loss: 2.44128155708313\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 88, batch train loss: 2.0985682010650635\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 89, batch train loss: 4.072418689727783\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 90, batch train loss: 3.036978244781494\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 91, batch train loss: 3.5278429985046387\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 92, batch train loss: 2.2417359352111816\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 93, batch train loss: 3.193415641784668\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 94, batch train loss: 3.278813123703003\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 95, batch train loss: 2.3247575759887695\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 96, batch train loss: 4.360330104827881\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 97, batch train loss: 2.325561046600342\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 98, batch train loss: 3.4826717376708984\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 99, batch train loss: 3.3682994842529297\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 100, batch train loss: 2.7413268089294434\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 101, batch train loss: 4.094212055206299\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 102, batch train loss: 2.819965362548828\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 103, batch train loss: 2.5068910121917725\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 104, batch train loss: 3.874004364013672\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 105, batch train loss: 3.890226125717163\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 106, batch train loss: 3.751985788345337\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 107, batch train loss: 4.844566822052002\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 108, batch train loss: 2.927398443222046\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 109, batch train loss: 4.200234413146973\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 110, batch train loss: 3.527902841567993\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 111, batch train loss: 2.366292715072632\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 112, batch train loss: 3.9688472747802734\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 113, batch train loss: 4.105299472808838\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 114, batch train loss: 5.462094783782959\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 115, batch train loss: 4.197413444519043\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 116, batch train loss: 3.765918016433716\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 117, batch train loss: 3.326186180114746\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 118, batch train loss: 3.2806246280670166\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 119, batch train loss: 4.097150802612305\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 120, batch train loss: 2.8335869312286377\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 121, batch train loss: 2.4577200412750244\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 122, batch train loss: 3.291142463684082\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 123, batch train loss: 4.082300662994385\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 124, batch train loss: 3.6044986248016357\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 125, batch train loss: 3.5763399600982666\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 126, batch train loss: 3.1729562282562256\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 127, batch train loss: 3.3054428100585938\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 128, batch train loss: 3.0031485557556152\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, batch_id: 129, batch train loss: 4.165029525756836\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 130, batch train loss: 2.2356131076812744\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 131, batch train loss: 3.515831708908081\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 132, batch train loss: 2.9311397075653076\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 133, batch train loss: 2.9695334434509277\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 134, batch train loss: 3.138355016708374\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 135, batch train loss: 1.965492606163025\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 136, batch train loss: 3.5639867782592773\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 137, batch train loss: 2.831486701965332\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 138, batch train loss: 3.3852739334106445\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 139, batch train loss: 2.954543113708496\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 140, batch train loss: 3.5502803325653076\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 141, batch train loss: 3.198444128036499\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 142, batch train loss: 3.680905342102051\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 143, batch train loss: 3.996607780456543\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 144, batch train loss: 4.822428226470947\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 145, batch train loss: 5.568999767303467\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 146, batch train loss: 3.699408769607544\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 147, batch train loss: 4.361016273498535\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 148, batch train loss: 4.473621368408203\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 149, batch train loss: 2.9946024417877197\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 150, batch train loss: 5.1262311935424805\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 151, batch train loss: 2.9711034297943115\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 152, batch train loss: 5.878084182739258\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 153, batch train loss: 4.789365291595459\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 154, batch train loss: 2.7226765155792236\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 155, batch train loss: 3.732424020767212\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 156, batch train loss: 3.712850332260132\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 157, batch train loss: 5.257126331329346\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 158, batch train loss: 5.283559322357178\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 159, batch train loss: 2.4486162662506104\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 160, batch train loss: 2.2239701747894287\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 161, batch train loss: 5.168603420257568\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 162, batch train loss: 2.6414339542388916\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 163, batch train loss: 3.493281364440918\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 164, batch train loss: 3.13033127784729\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 165, batch train loss: 4.01827335357666\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 166, batch train loss: 3.525374412536621\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 167, batch train loss: 3.404024124145508\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 168, batch train loss: 3.1851439476013184\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 169, batch train loss: 2.326232433319092\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 170, batch train loss: 2.6589999198913574\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 171, batch train loss: 2.8507041931152344\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 172, batch train loss: 2.3206417560577393\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 173, batch train loss: 2.7559075355529785\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 174, batch train loss: 2.40671706199646\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 175, batch train loss: 2.835325002670288\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 176, batch train loss: 2.572094678878784\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 177, batch train loss: 2.914896249771118\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 178, batch train loss: 3.5506930351257324\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 179, batch train loss: 4.655157089233398\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 180, batch train loss: 3.547757625579834\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 181, batch train loss: 2.3077406883239746\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 182, batch train loss: 2.528620719909668\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 183, batch train loss: 1.78411865234375\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 184, batch train loss: 1.9324473142623901\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 185, batch train loss: 2.578496217727661\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 186, batch train loss: 2.488776683807373\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 187, batch train loss: 2.7213048934936523\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 188, batch train loss: 3.869910478591919\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 189, batch train loss: 2.419571876525879\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 190, batch train loss: 3.321267604827881\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 191, batch train loss: 2.340867519378662\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 192, batch train loss: 4.385071754455566\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 193, batch train loss: 3.865126609802246\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 194, batch train loss: 2.4821884632110596\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 195, batch train loss: 2.731282949447632\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 196, batch train loss: 2.593672275543213\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 197, batch train loss: 2.253704309463501\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 198, batch train loss: 2.700779676437378\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 199, batch train loss: 2.474944829940796\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 200, batch train loss: 1.9723368883132935\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 201, batch train loss: 2.694511651992798\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 202, batch train loss: 2.01383900642395\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 203, batch train loss: 2.1799516677856445\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 204, batch train loss: 2.012935161590576\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 205, batch train loss: 2.216824769973755\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 206, batch train loss: 2.3475918769836426\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 207, batch train loss: 1.913126826286316\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 208, batch train loss: 2.2510204315185547\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 209, batch train loss: 1.830501675605774\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 210, batch train loss: 2.816434144973755\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 211, batch train loss: 2.0394515991210938\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 212, batch train loss: 1.8771878480911255\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 213, batch train loss: 2.6859774589538574\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 214, batch train loss: 4.125850200653076\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 215, batch train loss: 2.5229763984680176\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 216, batch train loss: 3.38213849067688\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 217, batch train loss: 2.5297248363494873\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 218, batch train loss: 2.6032674312591553\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 219, batch train loss: 2.916428327560425\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 220, batch train loss: 3.5642125606536865\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 221, batch train loss: 2.6751046180725098\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 222, batch train loss: 2.485121965408325\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 223, batch train loss: 2.353898048400879\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 224, batch train loss: 3.0700509548187256\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 225, batch train loss: 3.6615853309631348\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 226, batch train loss: 4.618051528930664\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 227, batch train loss: 4.569474220275879\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 228, batch train loss: 2.9055027961730957\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 229, batch train loss: 3.9470767974853516\n",
      "\n",
      "\n",
      "Epoch: 15, batch_id: 230, batch train loss: 6.415266036987305\n",
      "\n",
      "\n",
      "Epoch: 15/ 100, Loss: 3.1618359213290006\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:08<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Validation Loss: 3.4356536050637563\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, batch_id: 1, batch train loss: 2.3229739665985107\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 2, batch train loss: 3.0948281288146973\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 3, batch train loss: 6.3228912353515625\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 4, batch train loss: 3.0437088012695312\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 5, batch train loss: 3.8353707790374756\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 6, batch train loss: 2.886505603790283\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 7, batch train loss: 2.855360984802246\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 8, batch train loss: 3.671184778213501\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 9, batch train loss: 2.4724044799804688\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 10, batch train loss: 2.8891663551330566\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 11, batch train loss: 2.7196426391601562\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 12, batch train loss: 2.8302721977233887\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 13, batch train loss: 2.849461555480957\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 14, batch train loss: 2.7067642211914062\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 15, batch train loss: 2.7893595695495605\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 16, batch train loss: 2.8345940113067627\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 17, batch train loss: 2.283247470855713\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 18, batch train loss: 2.9929351806640625\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 19, batch train loss: 3.1166701316833496\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 20, batch train loss: 2.087451934814453\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 21, batch train loss: 2.871320962905884\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 22, batch train loss: 2.4110376834869385\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 23, batch train loss: 2.435443162918091\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 24, batch train loss: 2.224001884460449\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 25, batch train loss: 2.194343090057373\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 26, batch train loss: 2.0347039699554443\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 27, batch train loss: 2.5250906944274902\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 28, batch train loss: 2.268285036087036\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 29, batch train loss: 3.8926327228546143\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 30, batch train loss: 2.7595596313476562\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 31, batch train loss: 2.629019021987915\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 32, batch train loss: 2.805727958679199\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 33, batch train loss: 5.871930122375488\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 34, batch train loss: 2.9212048053741455\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 35, batch train loss: 3.004411220550537\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 36, batch train loss: 2.1815531253814697\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 37, batch train loss: 2.593571662902832\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 38, batch train loss: 3.2430481910705566\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 39, batch train loss: 3.667003631591797\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 40, batch train loss: 2.8135054111480713\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 41, batch train loss: 3.5075786113739014\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 42, batch train loss: 3.718062400817871\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 43, batch train loss: 3.2078588008880615\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 44, batch train loss: 6.4594316482543945\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 45, batch train loss: 3.126913070678711\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 46, batch train loss: 3.7325634956359863\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 47, batch train loss: 4.315572738647461\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 48, batch train loss: 3.199521064758301\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 49, batch train loss: 4.200116157531738\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 50, batch train loss: 4.142055511474609\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 51, batch train loss: 2.962756395339966\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 52, batch train loss: 10.24035358428955\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 53, batch train loss: 3.103048801422119\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 54, batch train loss: 3.018998384475708\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 55, batch train loss: 4.600065231323242\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 56, batch train loss: 4.067794322967529\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 57, batch train loss: 4.249547481536865\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 58, batch train loss: 3.7699689865112305\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 59, batch train loss: 6.15800666809082\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 60, batch train loss: 3.3054118156433105\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 61, batch train loss: 3.726865530014038\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 62, batch train loss: 2.8908960819244385\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 63, batch train loss: 3.7308509349823\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 64, batch train loss: 3.927020788192749\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 65, batch train loss: 3.2326724529266357\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 66, batch train loss: 4.6368207931518555\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 67, batch train loss: 3.9039783477783203\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 68, batch train loss: 3.239102602005005\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 69, batch train loss: 3.258643388748169\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 70, batch train loss: 2.7429885864257812\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 71, batch train loss: 2.442681074142456\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 72, batch train loss: 3.2957825660705566\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 73, batch train loss: 3.8780765533447266\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 74, batch train loss: 3.817107677459717\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 75, batch train loss: 3.0255627632141113\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 76, batch train loss: 2.7757043838500977\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 77, batch train loss: 2.8737893104553223\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 78, batch train loss: 3.06718373298645\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 79, batch train loss: 3.6230220794677734\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 80, batch train loss: 2.988558530807495\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 81, batch train loss: 3.120147228240967\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 82, batch train loss: 3.6507515907287598\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 83, batch train loss: 2.6802945137023926\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 84, batch train loss: 4.3524017333984375\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 85, batch train loss: 2.444664478302002\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 86, batch train loss: 2.5199673175811768\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 87, batch train loss: 3.226229429244995\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 88, batch train loss: 2.831082820892334\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 89, batch train loss: 2.213423252105713\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 90, batch train loss: 2.6329033374786377\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 91, batch train loss: 3.2716660499572754\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 92, batch train loss: 2.383028030395508\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 93, batch train loss: 2.441466808319092\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 94, batch train loss: 2.80442476272583\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 95, batch train loss: 3.300354480743408\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 96, batch train loss: 3.652756452560425\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 97, batch train loss: 3.999558210372925\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 98, batch train loss: 4.626014709472656\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 99, batch train loss: 3.4446048736572266\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 100, batch train loss: 5.298321723937988\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 101, batch train loss: 5.2243123054504395\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 102, batch train loss: 3.458911895751953\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 103, batch train loss: 3.121025800704956\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 104, batch train loss: 3.4098570346832275\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 105, batch train loss: 1.9141114950180054\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 106, batch train loss: 3.835787296295166\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 107, batch train loss: 3.636474609375\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 108, batch train loss: 2.7098894119262695\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 109, batch train loss: 4.015021324157715\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 110, batch train loss: 2.6501073837280273\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 111, batch train loss: 3.158200263977051\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 112, batch train loss: 2.5766773223876953\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 113, batch train loss: 1.8484508991241455\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 114, batch train loss: 2.5215492248535156\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 115, batch train loss: 3.556691884994507\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 116, batch train loss: 2.3236632347106934\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 117, batch train loss: 2.87896728515625\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 118, batch train loss: 2.2405288219451904\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 119, batch train loss: 2.0159101486206055\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 120, batch train loss: 4.931991100311279\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 121, batch train loss: 3.638388156890869\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 122, batch train loss: 3.6226260662078857\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 123, batch train loss: 6.6209564208984375\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 124, batch train loss: 6.405486583709717\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 125, batch train loss: 4.040249347686768\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 126, batch train loss: 5.3956990242004395\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 127, batch train loss: 6.616767406463623\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 128, batch train loss: 3.9137930870056152\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 129, batch train loss: 7.061355113983154\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, batch_id: 130, batch train loss: 5.821873188018799\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 131, batch train loss: 4.332984447479248\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 132, batch train loss: 4.307353973388672\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 133, batch train loss: 6.879479885101318\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 134, batch train loss: 3.831247568130493\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 135, batch train loss: 3.7325692176818848\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 136, batch train loss: 5.5204315185546875\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 137, batch train loss: 4.331664085388184\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 138, batch train loss: 3.468914747238159\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 139, batch train loss: 4.414973258972168\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 140, batch train loss: 2.2487680912017822\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 141, batch train loss: 3.598567008972168\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 142, batch train loss: 3.277104377746582\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 143, batch train loss: 3.2577409744262695\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 144, batch train loss: 2.6932075023651123\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 145, batch train loss: 2.2549376487731934\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 146, batch train loss: 2.2786285877227783\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 147, batch train loss: 2.8566129207611084\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 148, batch train loss: 2.8844668865203857\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 149, batch train loss: 1.9080255031585693\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 150, batch train loss: 2.2434122562408447\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 151, batch train loss: 2.421919345855713\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 152, batch train loss: 2.807565927505493\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 153, batch train loss: 1.4387578964233398\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 154, batch train loss: 2.781850576400757\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 155, batch train loss: 1.7616652250289917\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 156, batch train loss: 2.8584909439086914\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 157, batch train loss: 2.341423273086548\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 158, batch train loss: 3.0923011302948\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 159, batch train loss: 2.674232244491577\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 160, batch train loss: 2.278527021408081\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 161, batch train loss: 1.9507299661636353\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 162, batch train loss: 4.63350772857666\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 163, batch train loss: 3.635861396789551\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 164, batch train loss: 3.4528398513793945\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 165, batch train loss: 3.236703395843506\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 166, batch train loss: 2.6752376556396484\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 167, batch train loss: 3.8911304473876953\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 168, batch train loss: 2.5428059101104736\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 169, batch train loss: 2.4451794624328613\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 170, batch train loss: 2.3188624382019043\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 171, batch train loss: 2.9149329662323\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 172, batch train loss: 5.444991111755371\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 173, batch train loss: 6.050027847290039\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 174, batch train loss: 3.2220027446746826\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 175, batch train loss: 5.0283522605896\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 176, batch train loss: 6.146450996398926\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 177, batch train loss: 3.28232741355896\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 178, batch train loss: 4.27538537979126\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 179, batch train loss: 4.917903900146484\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 180, batch train loss: 3.977658271789551\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 181, batch train loss: 4.886905193328857\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 182, batch train loss: 4.519603729248047\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 183, batch train loss: 5.616994857788086\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 184, batch train loss: 4.061535358428955\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 185, batch train loss: 5.2181525230407715\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 186, batch train loss: 4.988834381103516\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 187, batch train loss: 2.8372914791107178\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 188, batch train loss: 3.257047414779663\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 189, batch train loss: 4.1111016273498535\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 190, batch train loss: 5.026815414428711\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 191, batch train loss: 4.639704704284668\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 192, batch train loss: 4.234596252441406\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 193, batch train loss: 3.353790044784546\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 194, batch train loss: 3.3804996013641357\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 195, batch train loss: 5.014299392700195\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 196, batch train loss: 3.518817663192749\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 197, batch train loss: 3.5239009857177734\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 198, batch train loss: 2.8759005069732666\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 199, batch train loss: 2.2695152759552\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 200, batch train loss: 3.3166027069091797\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 201, batch train loss: 4.130801200866699\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 202, batch train loss: 5.270171642303467\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 203, batch train loss: 6.3969950675964355\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 204, batch train loss: 3.222604513168335\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 205, batch train loss: 3.7968339920043945\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 206, batch train loss: 2.366471529006958\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 207, batch train loss: 2.3503317832946777\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 208, batch train loss: 2.0926225185394287\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 209, batch train loss: 2.073621988296509\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 210, batch train loss: 3.731402635574341\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 211, batch train loss: 3.1041932106018066\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 212, batch train loss: 2.6616125106811523\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 213, batch train loss: 4.108271598815918\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 214, batch train loss: 4.27554178237915\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 215, batch train loss: 2.34842586517334\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 216, batch train loss: 4.6001129150390625\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 217, batch train loss: 2.0478479862213135\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 218, batch train loss: 3.129260301589966\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 219, batch train loss: 3.6489083766937256\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 220, batch train loss: 4.27509880065918\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 221, batch train loss: 4.872053623199463\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 222, batch train loss: 2.918351650238037\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 223, batch train loss: 4.828180313110352\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 224, batch train loss: 4.2082438468933105\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 225, batch train loss: 2.4944193363189697\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 226, batch train loss: 4.38077974319458\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 227, batch train loss: 4.9290995597839355\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 228, batch train loss: 5.859156608581543\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 229, batch train loss: 5.326560974121094\n",
      "\n",
      "\n",
      "Epoch: 16, batch_id: 230, batch train loss: 6.3904314041137695\n",
      "\n",
      "\n",
      "Epoch: 16/ 100, Loss: 3.5542849473331284\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:10<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 Validation Loss: 3.983133296171824\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, batch_id: 1, batch train loss: 4.865224838256836\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 2, batch train loss: 3.5249691009521484\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 3, batch train loss: 4.784583568572998\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 4, batch train loss: 4.3647942543029785\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 5, batch train loss: 2.7942097187042236\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 6, batch train loss: 4.176015853881836\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 7, batch train loss: 4.226599216461182\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 8, batch train loss: 2.20378041267395\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 9, batch train loss: 2.2968153953552246\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 10, batch train loss: 2.831245183944702\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 11, batch train loss: 4.731849193572998\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 12, batch train loss: 2.684161901473999\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 13, batch train loss: 2.5134918689727783\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 14, batch train loss: 2.617142677307129\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 15, batch train loss: 2.353696346282959\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 16, batch train loss: 2.938817024230957\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 17, batch train loss: 1.985669732093811\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 18, batch train loss: 2.701490879058838\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 19, batch train loss: 2.69368052482605\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 20, batch train loss: 2.1209263801574707\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 21, batch train loss: 4.04654598236084\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 22, batch train loss: 3.259768486022949\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 23, batch train loss: 4.090600490570068\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 24, batch train loss: 3.742704153060913\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 25, batch train loss: 2.052274227142334\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 26, batch train loss: 3.4777042865753174\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 27, batch train loss: 3.0868403911590576\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 28, batch train loss: 2.5210742950439453\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 29, batch train loss: 2.455775499343872\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 30, batch train loss: 3.7868456840515137\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 31, batch train loss: 2.0590105056762695\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 32, batch train loss: 2.828829765319824\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 33, batch train loss: 3.0023393630981445\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 34, batch train loss: 2.7922916412353516\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 35, batch train loss: 2.3099846839904785\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 36, batch train loss: 2.9498534202575684\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 37, batch train loss: 3.134821891784668\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 38, batch train loss: 2.619724988937378\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 39, batch train loss: 3.7071053981781006\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 40, batch train loss: 2.7763073444366455\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 41, batch train loss: 2.959118604660034\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 42, batch train loss: 2.284235954284668\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 43, batch train loss: 2.268251419067383\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 44, batch train loss: 1.7055209875106812\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 45, batch train loss: 2.6275429725646973\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 46, batch train loss: 2.370738983154297\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 47, batch train loss: 4.343628406524658\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 48, batch train loss: 3.076953649520874\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 49, batch train loss: 2.8813936710357666\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 50, batch train loss: 4.722813606262207\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 51, batch train loss: 2.214421510696411\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 52, batch train loss: 4.1013922691345215\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 53, batch train loss: 4.259045600891113\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 54, batch train loss: 2.9660496711730957\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 55, batch train loss: 4.449167251586914\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 56, batch train loss: 2.772557497024536\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 57, batch train loss: 2.8820364475250244\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 58, batch train loss: 2.5759875774383545\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 59, batch train loss: 2.875354528427124\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 60, batch train loss: 2.442755937576294\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 61, batch train loss: 3.5933947563171387\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 62, batch train loss: 3.0196378231048584\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 63, batch train loss: 3.333866834640503\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 64, batch train loss: 3.4787344932556152\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 65, batch train loss: 2.4276413917541504\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 66, batch train loss: 2.944338083267212\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 67, batch train loss: 2.2103073596954346\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 68, batch train loss: 1.6152344942092896\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 69, batch train loss: 2.6064555644989014\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 70, batch train loss: 2.2584948539733887\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 71, batch train loss: 3.1763644218444824\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 72, batch train loss: 2.4069859981536865\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 73, batch train loss: 2.294964075088501\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 74, batch train loss: 2.4673354625701904\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 75, batch train loss: 2.250856637954712\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 76, batch train loss: 2.607405185699463\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 77, batch train loss: 1.8336780071258545\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 78, batch train loss: 2.8907651901245117\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 79, batch train loss: 3.3803727626800537\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 80, batch train loss: 2.4055705070495605\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 81, batch train loss: 2.516042470932007\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 82, batch train loss: 2.7907209396362305\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 83, batch train loss: 2.5034196376800537\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 84, batch train loss: 3.441890001296997\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 85, batch train loss: 2.899512529373169\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 86, batch train loss: 2.2719945907592773\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 87, batch train loss: 2.9335813522338867\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 88, batch train loss: 1.7310227155685425\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 89, batch train loss: 3.5884945392608643\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 90, batch train loss: 2.2576181888580322\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 91, batch train loss: 3.3333826065063477\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 92, batch train loss: 2.8784987926483154\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 93, batch train loss: 2.141439914703369\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 94, batch train loss: 3.3801612854003906\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 95, batch train loss: 1.7714250087738037\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 96, batch train loss: 2.63594913482666\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 97, batch train loss: 2.379758596420288\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 98, batch train loss: 3.45951247215271\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 99, batch train loss: 2.541599988937378\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 100, batch train loss: 3.2430107593536377\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 101, batch train loss: 3.3757853507995605\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 102, batch train loss: 2.4129858016967773\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 103, batch train loss: 2.184523820877075\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 104, batch train loss: 1.9907499551773071\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 105, batch train loss: 2.334397077560425\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 106, batch train loss: 2.550901174545288\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 107, batch train loss: 2.5989990234375\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 108, batch train loss: 4.1195387840271\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 109, batch train loss: 2.29551100730896\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 110, batch train loss: 3.8967981338500977\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 111, batch train loss: 3.378612756729126\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 112, batch train loss: 3.1000945568084717\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 113, batch train loss: 4.9527363777160645\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 114, batch train loss: 3.544449806213379\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 115, batch train loss: 3.107574462890625\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 116, batch train loss: 5.103818893432617\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 117, batch train loss: 2.8089816570281982\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 118, batch train loss: 2.3606228828430176\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 119, batch train loss: 4.942790985107422\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 120, batch train loss: 3.162245988845825\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 121, batch train loss: 3.3015921115875244\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 122, batch train loss: 4.627635478973389\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 123, batch train loss: 2.958425998687744\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 124, batch train loss: 5.342172622680664\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 125, batch train loss: 7.033625602722168\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 126, batch train loss: 4.223934650421143\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 127, batch train loss: 3.09831166267395\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 128, batch train loss: 5.523977279663086\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 129, batch train loss: 4.031618595123291\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, batch_id: 130, batch train loss: 3.0356132984161377\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 131, batch train loss: 4.199850082397461\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 132, batch train loss: 2.270470142364502\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 133, batch train loss: 4.581705570220947\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 134, batch train loss: 4.321075916290283\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 135, batch train loss: 2.605677604675293\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 136, batch train loss: 4.484565734863281\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 137, batch train loss: 6.338757514953613\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 138, batch train loss: 1.8769718408584595\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 139, batch train loss: 3.3786916732788086\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 140, batch train loss: 5.248526573181152\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 141, batch train loss: 3.000206470489502\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 142, batch train loss: 3.346672773361206\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 143, batch train loss: 2.442608594894409\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 144, batch train loss: 1.8772413730621338\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 145, batch train loss: 2.267613649368286\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 146, batch train loss: 2.418429374694824\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 147, batch train loss: 2.063555955886841\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 148, batch train loss: 1.6204026937484741\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 149, batch train loss: 2.1097044944763184\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 150, batch train loss: 2.348475217819214\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 151, batch train loss: 1.8830119371414185\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 152, batch train loss: 2.1058268547058105\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 153, batch train loss: 3.173563241958618\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 154, batch train loss: 3.8269739151000977\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 155, batch train loss: 4.150569438934326\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 156, batch train loss: 2.238767385482788\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 157, batch train loss: 2.0786213874816895\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 158, batch train loss: 2.234109878540039\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 159, batch train loss: 2.526982307434082\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 160, batch train loss: 1.8889713287353516\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 161, batch train loss: 2.1951889991760254\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 162, batch train loss: 1.7778944969177246\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 163, batch train loss: 2.4774293899536133\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 164, batch train loss: 3.3017308712005615\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 165, batch train loss: 2.765465021133423\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 166, batch train loss: 2.147247076034546\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 167, batch train loss: 3.1993541717529297\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 168, batch train loss: 2.417996406555176\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 169, batch train loss: 2.425633430480957\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 170, batch train loss: 2.2198400497436523\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 171, batch train loss: 1.732130527496338\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 172, batch train loss: 1.9833321571350098\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 173, batch train loss: 2.5665385723114014\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 174, batch train loss: 2.3129777908325195\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 175, batch train loss: 2.196207046508789\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 176, batch train loss: 2.1675126552581787\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 177, batch train loss: 2.081374406814575\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 178, batch train loss: 2.160292148590088\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 179, batch train loss: 1.672019600868225\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 180, batch train loss: 3.1144649982452393\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 181, batch train loss: 2.4260966777801514\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 182, batch train loss: 1.9992802143096924\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 183, batch train loss: 2.512091875076294\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 184, batch train loss: 3.19677734375\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 185, batch train loss: 3.2931020259857178\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 186, batch train loss: 3.083083152770996\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 187, batch train loss: 4.116955757141113\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 188, batch train loss: 6.558487415313721\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 189, batch train loss: 2.8213109970092773\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 190, batch train loss: 3.5233256816864014\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 191, batch train loss: 2.0774431228637695\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 192, batch train loss: 3.4028425216674805\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 193, batch train loss: 1.9064290523529053\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 194, batch train loss: 2.6858792304992676\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 195, batch train loss: 2.9282429218292236\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 196, batch train loss: 2.8404769897460938\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 197, batch train loss: 3.900435447692871\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 198, batch train loss: 3.498213291168213\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 199, batch train loss: 2.146193742752075\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 200, batch train loss: 2.7822957038879395\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 201, batch train loss: 1.7875630855560303\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 202, batch train loss: 3.0276315212249756\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 203, batch train loss: 1.99951171875\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 204, batch train loss: 1.9597721099853516\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 205, batch train loss: 2.448035717010498\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 206, batch train loss: 1.7088401317596436\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 207, batch train loss: 2.0674221515655518\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 208, batch train loss: 2.6422667503356934\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 209, batch train loss: 2.3903920650482178\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 210, batch train loss: 2.311776638031006\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 211, batch train loss: 2.4248387813568115\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 212, batch train loss: 3.1428401470184326\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 213, batch train loss: 2.6967101097106934\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 214, batch train loss: 2.6061575412750244\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 215, batch train loss: 2.3945865631103516\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 216, batch train loss: 2.542797327041626\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 217, batch train loss: 2.488184928894043\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 218, batch train loss: 2.884906768798828\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 219, batch train loss: 2.3515188694000244\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 220, batch train loss: 2.0375783443450928\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 221, batch train loss: 2.8079187870025635\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 222, batch train loss: 3.017528533935547\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 223, batch train loss: 2.9659922122955322\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 224, batch train loss: 2.1908488273620605\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 225, batch train loss: 2.5791096687316895\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 226, batch train loss: 2.3690311908721924\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 227, batch train loss: 2.1976468563079834\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 228, batch train loss: 1.9469051361083984\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 229, batch train loss: 2.677551746368408\n",
      "\n",
      "\n",
      "Epoch: 17, batch_id: 230, batch train loss: 2.7826766967773438\n",
      "\n",
      "\n",
      "Epoch: 17/ 100, Loss: 2.9180857964183975\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:09<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 Validation Loss: 2.818667697906494\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, batch_id: 1, batch train loss: 2.7976834774017334\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 2, batch train loss: 2.4595773220062256\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 3, batch train loss: 2.617309331893921\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 4, batch train loss: 2.446594476699829\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 5, batch train loss: 2.3081648349761963\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 6, batch train loss: 3.345397472381592\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 7, batch train loss: 2.3956711292266846\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 8, batch train loss: 3.1350228786468506\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 9, batch train loss: 2.8234121799468994\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 10, batch train loss: 2.8713021278381348\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 11, batch train loss: 2.2205045223236084\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 12, batch train loss: 1.8795307874679565\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 13, batch train loss: 2.60674786567688\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 14, batch train loss: 2.51975417137146\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 15, batch train loss: 3.190850019454956\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 16, batch train loss: 2.8010427951812744\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 17, batch train loss: 2.939124345779419\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 18, batch train loss: 2.5411152839660645\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 19, batch train loss: 2.656355857849121\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 20, batch train loss: 2.130033493041992\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 21, batch train loss: 3.7183377742767334\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 22, batch train loss: 3.4608097076416016\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 23, batch train loss: 3.0835390090942383\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 24, batch train loss: 2.794964075088501\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 25, batch train loss: 4.430210590362549\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 26, batch train loss: 3.074115514755249\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 27, batch train loss: 3.3777196407318115\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 28, batch train loss: 3.2154672145843506\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 29, batch train loss: 2.817615270614624\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 30, batch train loss: 3.6045451164245605\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 31, batch train loss: 2.187592029571533\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 32, batch train loss: 2.0439789295196533\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 33, batch train loss: 2.7408382892608643\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 34, batch train loss: 2.6274847984313965\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 35, batch train loss: 2.5787389278411865\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 36, batch train loss: 3.410102128982544\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 37, batch train loss: 3.9960038661956787\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 38, batch train loss: 3.6502811908721924\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 39, batch train loss: 3.1038999557495117\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 40, batch train loss: 3.668848991394043\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 41, batch train loss: 4.387218952178955\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 42, batch train loss: 3.0385444164276123\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 43, batch train loss: 5.000370502471924\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 44, batch train loss: 3.6945571899414062\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 45, batch train loss: 3.4601786136627197\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 46, batch train loss: 6.271007537841797\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 47, batch train loss: 3.802197217941284\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 48, batch train loss: 4.420658588409424\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 49, batch train loss: 3.3583598136901855\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 50, batch train loss: 4.773303508758545\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 51, batch train loss: 3.9287281036376953\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 52, batch train loss: 3.886418342590332\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 53, batch train loss: 4.9179534912109375\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 54, batch train loss: 4.7046732902526855\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 55, batch train loss: 3.3194921016693115\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 56, batch train loss: 4.118436813354492\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 57, batch train loss: 3.335566282272339\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 58, batch train loss: 3.612995147705078\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 59, batch train loss: 3.020479440689087\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 60, batch train loss: 2.917583703994751\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 61, batch train loss: 3.269818067550659\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 62, batch train loss: 3.3584601879119873\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 63, batch train loss: 2.7625350952148438\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 64, batch train loss: 3.731062889099121\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 65, batch train loss: 3.1934468746185303\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 66, batch train loss: 3.439891815185547\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 67, batch train loss: 2.5983991622924805\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 68, batch train loss: 2.498075246810913\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 69, batch train loss: 3.6581621170043945\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 70, batch train loss: 1.965186595916748\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 71, batch train loss: 2.717910051345825\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 72, batch train loss: 2.858276844024658\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 73, batch train loss: 2.085940361022949\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 74, batch train loss: 2.7757186889648438\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 75, batch train loss: 2.7718207836151123\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 76, batch train loss: 2.8533408641815186\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 77, batch train loss: 2.404221296310425\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 78, batch train loss: 2.1044702529907227\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 79, batch train loss: 1.6006351709365845\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 80, batch train loss: 2.1637589931488037\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 81, batch train loss: 1.2849339246749878\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 82, batch train loss: 2.4446194171905518\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 83, batch train loss: 5.027646541595459\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 84, batch train loss: 3.815837860107422\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 85, batch train loss: 4.285456657409668\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 86, batch train loss: 3.2553892135620117\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 87, batch train loss: 4.2074103355407715\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 88, batch train loss: 3.376595973968506\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 89, batch train loss: 5.0261616706848145\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 90, batch train loss: 4.1919755935668945\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 91, batch train loss: 2.603402853012085\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 92, batch train loss: 4.536782741546631\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 93, batch train loss: 3.1628189086914062\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 94, batch train loss: 3.2692601680755615\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 95, batch train loss: 4.4138641357421875\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 96, batch train loss: 1.797061562538147\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 97, batch train loss: 2.630634307861328\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 98, batch train loss: 2.0547754764556885\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 99, batch train loss: 2.1483232975006104\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 100, batch train loss: 1.9438458681106567\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 101, batch train loss: 2.818662166595459\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 102, batch train loss: 2.028315544128418\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 103, batch train loss: 2.077369213104248\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 104, batch train loss: 2.620586395263672\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 105, batch train loss: 3.543488025665283\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 106, batch train loss: 2.2860090732574463\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 107, batch train loss: 2.382935047149658\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 108, batch train loss: 4.632986068725586\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 109, batch train loss: 4.066559314727783\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 110, batch train loss: 3.335846424102783\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 111, batch train loss: 1.9802660942077637\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 112, batch train loss: 2.0688586235046387\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 113, batch train loss: 1.9272961616516113\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 114, batch train loss: 1.8285760879516602\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 115, batch train loss: 2.883105993270874\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 116, batch train loss: 2.046564817428589\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 117, batch train loss: 1.86357581615448\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 118, batch train loss: 2.108222723007202\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 119, batch train loss: 1.5167250633239746\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 120, batch train loss: 1.9052832126617432\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 121, batch train loss: 2.004281997680664\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 122, batch train loss: 2.2893307209014893\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 123, batch train loss: 2.080280065536499\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 124, batch train loss: 2.2528765201568604\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 125, batch train loss: 2.497523307800293\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 126, batch train loss: 2.48176646232605\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 127, batch train loss: 2.245497465133667\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 128, batch train loss: 2.3245203495025635\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 129, batch train loss: 2.261242151260376\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, batch_id: 130, batch train loss: 2.594038486480713\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 131, batch train loss: 1.8945589065551758\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 132, batch train loss: 2.368705987930298\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 133, batch train loss: 2.5893094539642334\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 134, batch train loss: 2.4424333572387695\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 135, batch train loss: 2.7360846996307373\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 136, batch train loss: 2.3276305198669434\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 137, batch train loss: 2.3443291187286377\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 138, batch train loss: 2.027808427810669\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 139, batch train loss: 2.596967935562134\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 140, batch train loss: 2.1669914722442627\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 141, batch train loss: 2.246898651123047\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 142, batch train loss: 1.5475693941116333\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 143, batch train loss: 2.7203195095062256\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 144, batch train loss: 2.232219696044922\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 145, batch train loss: 1.7516928911209106\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 146, batch train loss: 4.436476230621338\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 147, batch train loss: 2.579188346862793\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 148, batch train loss: 4.310168743133545\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 149, batch train loss: 2.537905693054199\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 150, batch train loss: 2.458315134048462\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 151, batch train loss: 3.1433112621307373\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 152, batch train loss: 2.08496356010437\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 153, batch train loss: 2.215830087661743\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 154, batch train loss: 2.80401873588562\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 155, batch train loss: 2.5776283740997314\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 156, batch train loss: 2.534289836883545\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 157, batch train loss: 3.068527936935425\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 158, batch train loss: 1.683248519897461\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 159, batch train loss: 2.063900947570801\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 160, batch train loss: 2.680673122406006\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 161, batch train loss: 3.229008436203003\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 162, batch train loss: 3.0419139862060547\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 163, batch train loss: 3.8145711421966553\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 164, batch train loss: 2.5705525875091553\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 165, batch train loss: 2.1667163372039795\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 166, batch train loss: 2.341893196105957\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 167, batch train loss: 2.3039567470550537\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 168, batch train loss: 2.7171947956085205\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 169, batch train loss: 1.624537467956543\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 170, batch train loss: 2.0335230827331543\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 171, batch train loss: 3.0295357704162598\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 172, batch train loss: 3.7410175800323486\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 173, batch train loss: 2.2254390716552734\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 174, batch train loss: 2.6417429447174072\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 175, batch train loss: 2.393867254257202\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 176, batch train loss: 2.029258966445923\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 177, batch train loss: 2.3306543827056885\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 178, batch train loss: 2.274729013442993\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 179, batch train loss: 2.777104377746582\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 180, batch train loss: 3.3110439777374268\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 181, batch train loss: 2.3672468662261963\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 182, batch train loss: 2.838013172149658\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 183, batch train loss: 3.383662223815918\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 184, batch train loss: 1.9719592332839966\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 185, batch train loss: 2.745903730392456\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 186, batch train loss: 1.8467274904251099\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 187, batch train loss: 3.6265628337860107\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 188, batch train loss: 3.6742358207702637\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 189, batch train loss: 2.465770959854126\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 190, batch train loss: 3.258500099182129\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 191, batch train loss: 2.783573865890503\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 192, batch train loss: 2.5611658096313477\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 193, batch train loss: 4.063067436218262\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 194, batch train loss: 2.211796522140503\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 195, batch train loss: 2.838791608810425\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 196, batch train loss: 2.5395779609680176\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 197, batch train loss: 2.692967414855957\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 198, batch train loss: 2.4209673404693604\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 199, batch train loss: 1.8841049671173096\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 200, batch train loss: 3.9749341011047363\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 201, batch train loss: 2.2945010662078857\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 202, batch train loss: 4.256110191345215\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 203, batch train loss: 2.4089691638946533\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 204, batch train loss: 2.689209461212158\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 205, batch train loss: 2.5062942504882812\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 206, batch train loss: 1.766401767730713\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 207, batch train loss: 1.8260085582733154\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 208, batch train loss: 3.894784688949585\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 209, batch train loss: 3.7662360668182373\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 210, batch train loss: 3.656628370285034\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 211, batch train loss: 2.732977867126465\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 212, batch train loss: 3.423114061355591\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 213, batch train loss: 3.581685781478882\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 214, batch train loss: 3.387634754180908\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 215, batch train loss: 2.7466635704040527\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 216, batch train loss: 2.2055394649505615\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 217, batch train loss: 2.3579530715942383\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 218, batch train loss: 2.6565659046173096\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 219, batch train loss: 2.5838239192962646\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 220, batch train loss: 2.670659065246582\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 221, batch train loss: 2.8445773124694824\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 222, batch train loss: 2.9531009197235107\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 223, batch train loss: 2.6553475856781006\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 224, batch train loss: 2.3681211471557617\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 225, batch train loss: 3.5895864963531494\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 226, batch train loss: 2.6407523155212402\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 227, batch train loss: 3.5715575218200684\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 228, batch train loss: 2.3172006607055664\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 229, batch train loss: 3.1292366981506348\n",
      "\n",
      "\n",
      "Epoch: 18, batch_id: 230, batch train loss: 2.5653202533721924\n",
      "\n",
      "\n",
      "Epoch: 18/ 100, Loss: 2.867155855634938\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:11<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 Validation Loss: 2.840086501836777\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, batch_id: 1, batch train loss: 2.1476051807403564\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 2, batch train loss: 3.949505567550659\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 3, batch train loss: 2.663696050643921\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 4, batch train loss: 3.948923349380493\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 5, batch train loss: 2.360487222671509\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 6, batch train loss: 4.028155326843262\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 7, batch train loss: 2.7966814041137695\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 8, batch train loss: 3.737004041671753\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 9, batch train loss: 2.0628793239593506\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 10, batch train loss: 1.881974697113037\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 11, batch train loss: 2.565666437149048\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 12, batch train loss: 4.589169025421143\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 13, batch train loss: 4.815322399139404\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 14, batch train loss: 5.4069294929504395\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 15, batch train loss: 3.8775105476379395\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 16, batch train loss: 3.199416399002075\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 17, batch train loss: 4.573719501495361\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 18, batch train loss: 5.496106147766113\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 19, batch train loss: 3.687002658843994\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 20, batch train loss: 4.373622894287109\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 21, batch train loss: 3.22465443611145\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 22, batch train loss: 3.5189368724823\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 23, batch train loss: 2.9212372303009033\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 24, batch train loss: 2.691206455230713\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 25, batch train loss: 4.027622699737549\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 26, batch train loss: 3.983295440673828\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 27, batch train loss: 4.124713897705078\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 28, batch train loss: 5.211888313293457\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 29, batch train loss: 2.5635933876037598\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 30, batch train loss: 4.127567768096924\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 31, batch train loss: 4.206367492675781\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 32, batch train loss: 3.7917847633361816\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 33, batch train loss: 3.224015474319458\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 34, batch train loss: 5.25117301940918\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 35, batch train loss: 3.8405704498291016\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 36, batch train loss: 2.986706256866455\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 37, batch train loss: 2.933398962020874\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 38, batch train loss: 2.5295417308807373\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 39, batch train loss: 2.8811721801757812\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 40, batch train loss: 3.9888575077056885\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 41, batch train loss: 2.278799057006836\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 42, batch train loss: 2.8898987770080566\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 43, batch train loss: 2.853930711746216\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 44, batch train loss: 2.812535524368286\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 45, batch train loss: 2.528674840927124\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 46, batch train loss: 2.6253535747528076\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 47, batch train loss: 3.6082770824432373\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 48, batch train loss: 2.7701964378356934\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 49, batch train loss: 3.4154117107391357\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 50, batch train loss: 2.0772459506988525\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 51, batch train loss: 1.7480151653289795\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 52, batch train loss: 2.1444787979125977\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 53, batch train loss: 2.5260562896728516\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 54, batch train loss: 2.0680229663848877\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 55, batch train loss: 1.849813461303711\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 56, batch train loss: 2.116565465927124\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 57, batch train loss: 2.015829563140869\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 58, batch train loss: 2.0633704662323\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 59, batch train loss: 2.1122801303863525\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 60, batch train loss: 2.0318593978881836\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 61, batch train loss: 1.9387691020965576\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 62, batch train loss: 1.6989223957061768\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 63, batch train loss: 1.7226539850234985\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 64, batch train loss: 2.405376434326172\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 65, batch train loss: 3.1973507404327393\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 66, batch train loss: 3.279252052307129\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 67, batch train loss: 3.022214651107788\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 68, batch train loss: 2.6853344440460205\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 69, batch train loss: 2.572711229324341\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 70, batch train loss: 3.00490140914917\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 71, batch train loss: 2.5335187911987305\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 72, batch train loss: 1.7616888284683228\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 73, batch train loss: 2.3970532417297363\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 74, batch train loss: 3.723555564880371\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 75, batch train loss: 3.4977285861968994\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 76, batch train loss: 3.030688762664795\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 77, batch train loss: 2.5068461894989014\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 78, batch train loss: 1.9640555381774902\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 79, batch train loss: 2.182093858718872\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 80, batch train loss: 2.6760573387145996\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 81, batch train loss: 2.25283145904541\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 82, batch train loss: 2.618683338165283\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 83, batch train loss: 2.03102445602417\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 84, batch train loss: 2.2995100021362305\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 85, batch train loss: 2.15057373046875\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 86, batch train loss: 1.531300663948059\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 87, batch train loss: 2.146686553955078\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 88, batch train loss: 1.6909301280975342\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 89, batch train loss: 2.6080870628356934\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 90, batch train loss: 2.209176540374756\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 91, batch train loss: 2.495697498321533\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 92, batch train loss: 2.237630844116211\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 93, batch train loss: 1.9947054386138916\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 94, batch train loss: 2.468374252319336\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 95, batch train loss: 2.1925418376922607\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 96, batch train loss: 1.4959144592285156\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 97, batch train loss: 1.9182263612747192\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 98, batch train loss: 1.568426251411438\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 99, batch train loss: 1.5953586101531982\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 100, batch train loss: 1.752218246459961\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 101, batch train loss: 1.7414131164550781\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 102, batch train loss: 3.3500516414642334\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 103, batch train loss: 2.939244270324707\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 104, batch train loss: 2.861758232116699\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 105, batch train loss: 1.8597831726074219\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 106, batch train loss: 4.346153736114502\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 107, batch train loss: 3.58567214012146\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 108, batch train loss: 3.2561750411987305\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 109, batch train loss: 3.5297067165374756\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 110, batch train loss: 2.7779104709625244\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 111, batch train loss: 2.7858781814575195\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 112, batch train loss: 2.283066749572754\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 113, batch train loss: 2.5246729850769043\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 114, batch train loss: 2.2777183055877686\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 115, batch train loss: 2.267876148223877\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 116, batch train loss: 1.998765230178833\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 117, batch train loss: 2.8126778602600098\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 118, batch train loss: 2.0361785888671875\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 119, batch train loss: 4.45397424697876\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 120, batch train loss: 2.209958076477051\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 121, batch train loss: 4.359228610992432\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 122, batch train loss: 2.528254985809326\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 123, batch train loss: 2.176382303237915\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 124, batch train loss: 1.8347737789154053\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 125, batch train loss: 1.9621189832687378\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 126, batch train loss: 2.230816125869751\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 127, batch train loss: 2.985990285873413\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 128, batch train loss: 2.1873457431793213\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 129, batch train loss: 3.0151495933532715\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, batch_id: 130, batch train loss: 3.3884127140045166\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 131, batch train loss: 4.273383617401123\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 132, batch train loss: 2.0745747089385986\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 133, batch train loss: 3.2777786254882812\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 134, batch train loss: 1.8920644521713257\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 135, batch train loss: 3.387024402618408\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 136, batch train loss: 2.8755741119384766\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 137, batch train loss: 4.588693141937256\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 138, batch train loss: 5.77431058883667\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 139, batch train loss: 3.821154832839966\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 140, batch train loss: 2.7404112815856934\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 141, batch train loss: 3.053109645843506\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 142, batch train loss: 3.9465463161468506\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 143, batch train loss: 1.9999611377716064\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 144, batch train loss: 6.683586597442627\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 145, batch train loss: 3.1807756423950195\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 146, batch train loss: 3.846099853515625\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 147, batch train loss: 10.560640335083008\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 148, batch train loss: 4.235408306121826\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 149, batch train loss: 4.043417930603027\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 150, batch train loss: 5.558668613433838\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 151, batch train loss: 4.295443534851074\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 152, batch train loss: 3.7129390239715576\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 153, batch train loss: 5.822957515716553\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 154, batch train loss: 4.122540473937988\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 155, batch train loss: 3.0191409587860107\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 156, batch train loss: 4.9308624267578125\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 157, batch train loss: 2.7641448974609375\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 158, batch train loss: 2.7734715938568115\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 159, batch train loss: 2.7557997703552246\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 160, batch train loss: 2.414552927017212\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 161, batch train loss: 2.378653049468994\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 162, batch train loss: 3.2549703121185303\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 163, batch train loss: 3.2140705585479736\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 164, batch train loss: 2.825538158416748\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 165, batch train loss: 2.5153653621673584\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 166, batch train loss: 2.450491189956665\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 167, batch train loss: 2.486624002456665\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 168, batch train loss: 2.7470176219940186\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 169, batch train loss: 3.040985584259033\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 170, batch train loss: 3.5992281436920166\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 171, batch train loss: 3.106794834136963\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 172, batch train loss: 2.934070587158203\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 173, batch train loss: 3.3347463607788086\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 174, batch train loss: 2.8857126235961914\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 175, batch train loss: 3.508058786392212\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 176, batch train loss: 2.2174878120422363\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 177, batch train loss: 3.5463263988494873\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 178, batch train loss: 2.922480583190918\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 179, batch train loss: 2.2338614463806152\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 180, batch train loss: 1.7826062440872192\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 181, batch train loss: 2.4395735263824463\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 182, batch train loss: 1.8041205406188965\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 183, batch train loss: 2.4940900802612305\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 184, batch train loss: 2.5783329010009766\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 185, batch train loss: 2.838041067123413\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 186, batch train loss: 2.6704373359680176\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 187, batch train loss: 2.4161267280578613\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 188, batch train loss: 2.2553133964538574\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 189, batch train loss: 2.7491261959075928\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 190, batch train loss: 2.3705129623413086\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 191, batch train loss: 2.2091410160064697\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 192, batch train loss: 4.096783638000488\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 193, batch train loss: 2.0911896228790283\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 194, batch train loss: 3.138812780380249\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 195, batch train loss: 2.4106578826904297\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 196, batch train loss: 1.9229477643966675\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 197, batch train loss: 3.532010793685913\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 198, batch train loss: 3.8072733879089355\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 199, batch train loss: 4.1049604415893555\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 200, batch train loss: 3.525198459625244\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 201, batch train loss: 2.596149206161499\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 202, batch train loss: 3.493533134460449\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 203, batch train loss: 2.0509355068206787\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 204, batch train loss: 2.6021175384521484\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 205, batch train loss: 1.8421710729599\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 206, batch train loss: 2.5568647384643555\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 207, batch train loss: 2.38173770904541\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 208, batch train loss: 1.8951821327209473\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 209, batch train loss: 2.7388105392456055\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 210, batch train loss: 1.7121288776397705\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 211, batch train loss: 2.2312545776367188\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 212, batch train loss: 2.2926065921783447\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 213, batch train loss: 2.607365608215332\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 214, batch train loss: 2.8824219703674316\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 215, batch train loss: 1.785828709602356\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 216, batch train loss: 2.014883518218994\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 217, batch train loss: 1.7932747602462769\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 218, batch train loss: 2.728259801864624\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 219, batch train loss: 2.4685161113739014\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 220, batch train loss: 2.5126688480377197\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 221, batch train loss: 2.152308702468872\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 222, batch train loss: 2.9805474281311035\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 223, batch train loss: 2.704772710800171\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 224, batch train loss: 2.956815242767334\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 225, batch train loss: 2.756040573120117\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 226, batch train loss: 3.4477157592773438\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 227, batch train loss: 2.035949468612671\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 228, batch train loss: 2.4083425998687744\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 229, batch train loss: 2.5744311809539795\n",
      "\n",
      "\n",
      "Epoch: 19, batch_id: 230, batch train loss: 2.466017961502075\n",
      "\n",
      "\n",
      "Epoch: 19/ 100, Loss: 2.925593505734983\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Validation Loss: 2.8181517839431764\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, batch_id: 1, batch train loss: 2.6429827213287354\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 2, batch train loss: 5.427192211151123\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 3, batch train loss: 2.8989572525024414\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 4, batch train loss: 3.11942195892334\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 5, batch train loss: 2.334872007369995\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 6, batch train loss: 2.4637882709503174\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 7, batch train loss: 2.6188411712646484\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 8, batch train loss: 2.0825486183166504\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 9, batch train loss: 2.4783220291137695\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 10, batch train loss: 2.1613450050354004\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 11, batch train loss: 2.5489375591278076\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 12, batch train loss: 4.644021987915039\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 13, batch train loss: 2.2243683338165283\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 14, batch train loss: 2.9617691040039062\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 15, batch train loss: 2.256528615951538\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 16, batch train loss: 2.451146125793457\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 17, batch train loss: 2.258058786392212\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 18, batch train loss: 2.5390686988830566\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 19, batch train loss: 2.9368042945861816\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 20, batch train loss: 2.5224978923797607\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 21, batch train loss: 2.941530466079712\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 22, batch train loss: 2.3686094284057617\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 23, batch train loss: 2.7101545333862305\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 24, batch train loss: 2.1614530086517334\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 25, batch train loss: 2.499640941619873\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 26, batch train loss: 2.211008310317993\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 27, batch train loss: 2.5962512493133545\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 28, batch train loss: 2.5273497104644775\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 29, batch train loss: 2.4198358058929443\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 30, batch train loss: 2.223816394805908\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 31, batch train loss: 3.0680811405181885\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 32, batch train loss: 2.4779226779937744\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 33, batch train loss: 2.3047609329223633\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 34, batch train loss: 2.328045606613159\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 35, batch train loss: 2.286198616027832\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 36, batch train loss: 2.970813512802124\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 37, batch train loss: 2.269169807434082\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 38, batch train loss: 2.5426251888275146\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 39, batch train loss: 2.81020188331604\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 40, batch train loss: 2.6257035732269287\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 41, batch train loss: 2.0160610675811768\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 42, batch train loss: 1.8380547761917114\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 43, batch train loss: 1.9214471578598022\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 44, batch train loss: 2.327897071838379\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 45, batch train loss: 2.0297751426696777\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 46, batch train loss: 1.7939225435256958\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 47, batch train loss: 2.231834888458252\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 48, batch train loss: 2.2024519443511963\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 49, batch train loss: 2.2670698165893555\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 50, batch train loss: 1.9659475088119507\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 51, batch train loss: 2.5663397312164307\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 52, batch train loss: 1.8268119096755981\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 53, batch train loss: 2.7489118576049805\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 54, batch train loss: 2.255126953125\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 55, batch train loss: 2.2425649166107178\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 56, batch train loss: 1.9949185848236084\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 57, batch train loss: 2.08076810836792\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 58, batch train loss: 2.103282928466797\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 59, batch train loss: 1.8598874807357788\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 60, batch train loss: 1.7814310789108276\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 61, batch train loss: 1.5442620515823364\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 62, batch train loss: 2.2312088012695312\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 63, batch train loss: 2.329841375350952\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 64, batch train loss: 1.7618117332458496\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 65, batch train loss: 2.7935214042663574\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 66, batch train loss: 1.9471337795257568\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 67, batch train loss: 2.0337460041046143\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 68, batch train loss: 1.8107829093933105\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 69, batch train loss: 2.619751214981079\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 70, batch train loss: 1.9310791492462158\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 71, batch train loss: 3.1062822341918945\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 72, batch train loss: 1.9569710493087769\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 73, batch train loss: 2.002495288848877\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 74, batch train loss: 2.153956413269043\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 75, batch train loss: 2.051569938659668\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 76, batch train loss: 1.5663173198699951\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 77, batch train loss: 2.430267333984375\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 78, batch train loss: 1.851743221282959\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 79, batch train loss: 2.098719596862793\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 80, batch train loss: 1.8657042980194092\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 81, batch train loss: 1.5996685028076172\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 82, batch train loss: 1.7038260698318481\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 83, batch train loss: 1.4874714612960815\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 84, batch train loss: 1.9075438976287842\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 85, batch train loss: 1.7246013879776\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 86, batch train loss: 1.555540680885315\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 87, batch train loss: 1.803019642829895\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 88, batch train loss: 1.7938883304595947\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 89, batch train loss: 2.7246859073638916\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 90, batch train loss: 2.045600414276123\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 91, batch train loss: 1.8948848247528076\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 92, batch train loss: 2.0545854568481445\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 93, batch train loss: 1.576603889465332\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 94, batch train loss: 2.189840078353882\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 95, batch train loss: 1.8362430334091187\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 96, batch train loss: 1.6527851819992065\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 97, batch train loss: 1.3364633321762085\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 98, batch train loss: 1.6128673553466797\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 99, batch train loss: 1.5186742544174194\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 100, batch train loss: 1.772397518157959\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 101, batch train loss: 1.4610286951065063\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 102, batch train loss: 2.0256741046905518\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 103, batch train loss: 2.1933226585388184\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 104, batch train loss: 1.5660258531570435\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 105, batch train loss: 1.7926656007766724\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 106, batch train loss: 2.094489336013794\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 107, batch train loss: 2.0918002128601074\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 108, batch train loss: 1.7098532915115356\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 109, batch train loss: 1.6159396171569824\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 110, batch train loss: 1.9727716445922852\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 111, batch train loss: 2.6795740127563477\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 112, batch train loss: 1.8125858306884766\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 113, batch train loss: 2.018832206726074\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 114, batch train loss: 2.08168363571167\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 115, batch train loss: 2.204380750656128\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 116, batch train loss: 2.7273612022399902\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 117, batch train loss: 1.6927388906478882\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 118, batch train loss: 2.4961905479431152\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 119, batch train loss: 1.6355928182601929\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 120, batch train loss: 1.6599560976028442\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 121, batch train loss: 2.866466760635376\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 122, batch train loss: 2.2219438552856445\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 123, batch train loss: 1.726413607597351\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 124, batch train loss: 2.036093235015869\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 125, batch train loss: 1.4892209768295288\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 126, batch train loss: 2.3341939449310303\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 127, batch train loss: 2.1058850288391113\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 128, batch train loss: 2.0173604488372803\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 129, batch train loss: 1.951171636581421\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, batch_id: 130, batch train loss: 2.7371633052825928\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 131, batch train loss: 1.9183136224746704\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 132, batch train loss: 2.217331886291504\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 133, batch train loss: 1.8549107313156128\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 134, batch train loss: 2.711172580718994\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 135, batch train loss: 3.068134307861328\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 136, batch train loss: 3.1450533866882324\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 137, batch train loss: 2.221163034439087\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 138, batch train loss: 2.5982370376586914\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 139, batch train loss: 2.706183671951294\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 140, batch train loss: 2.5255117416381836\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 141, batch train loss: 3.9532740116119385\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 142, batch train loss: 3.3876349925994873\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 143, batch train loss: 3.466191053390503\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 144, batch train loss: 2.372699022293091\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 145, batch train loss: 3.7369959354400635\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 146, batch train loss: 2.3628978729248047\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 147, batch train loss: 4.88545036315918\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 148, batch train loss: 1.9388867616653442\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 149, batch train loss: 3.0585274696350098\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 150, batch train loss: 2.4263298511505127\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 151, batch train loss: 4.1156463623046875\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 152, batch train loss: 2.56501841545105\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 153, batch train loss: 2.7722911834716797\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 154, batch train loss: 2.4010114669799805\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 155, batch train loss: 2.36714768409729\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 156, batch train loss: 3.1734964847564697\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 157, batch train loss: 2.6694581508636475\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 158, batch train loss: 2.394490957260132\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 159, batch train loss: 2.5465543270111084\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 160, batch train loss: 3.6713027954101562\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 161, batch train loss: 2.4674341678619385\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 162, batch train loss: 2.7028372287750244\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 163, batch train loss: 2.901463508605957\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 164, batch train loss: 3.590195655822754\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 165, batch train loss: 4.450467109680176\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 166, batch train loss: 3.2139291763305664\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 167, batch train loss: 2.703667163848877\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 168, batch train loss: 4.044826030731201\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 169, batch train loss: 3.0124340057373047\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 170, batch train loss: 2.39473557472229\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 171, batch train loss: 3.9249496459960938\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 172, batch train loss: 3.8148629665374756\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 173, batch train loss: 2.60371994972229\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 174, batch train loss: 3.596445322036743\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 175, batch train loss: 3.017982006072998\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 176, batch train loss: 2.9514212608337402\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 177, batch train loss: 2.786637306213379\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 178, batch train loss: 2.2120883464813232\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 179, batch train loss: 2.557978630065918\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 180, batch train loss: 2.412099838256836\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 181, batch train loss: 3.5317814350128174\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 182, batch train loss: 2.917388677597046\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 183, batch train loss: 3.224184274673462\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 184, batch train loss: 3.0983760356903076\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 185, batch train loss: 3.9369137287139893\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 186, batch train loss: 3.2073171138763428\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 187, batch train loss: 3.5689001083374023\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 188, batch train loss: 5.157588481903076\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 189, batch train loss: 3.6153335571289062\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 190, batch train loss: 3.6909186840057373\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 191, batch train loss: 4.746441841125488\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 192, batch train loss: 3.359205722808838\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 193, batch train loss: 4.646843433380127\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 194, batch train loss: 5.246682643890381\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 195, batch train loss: 2.4236788749694824\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 196, batch train loss: 3.653244972229004\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 197, batch train loss: 2.1476504802703857\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 198, batch train loss: 2.6110918521881104\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 199, batch train loss: 3.112149238586426\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 200, batch train loss: 1.914151668548584\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 201, batch train loss: 1.888085126876831\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 202, batch train loss: 2.203495979309082\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 203, batch train loss: 2.305954933166504\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 204, batch train loss: 2.340590715408325\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 205, batch train loss: 3.0658740997314453\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 206, batch train loss: 2.4625041484832764\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 207, batch train loss: 2.4614098072052\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 208, batch train loss: 1.8386837244033813\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 209, batch train loss: 1.7588521242141724\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 210, batch train loss: 2.1531319618225098\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 211, batch train loss: 1.823612928390503\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 212, batch train loss: 1.9494450092315674\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 213, batch train loss: 2.538003444671631\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 214, batch train loss: 2.1905903816223145\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 215, batch train loss: 2.399224281311035\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 216, batch train loss: 2.1311938762664795\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 217, batch train loss: 2.2986204624176025\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 218, batch train loss: 1.977635145187378\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 219, batch train loss: 1.9184455871582031\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 220, batch train loss: 2.1130192279815674\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 221, batch train loss: 1.9904494285583496\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 222, batch train loss: 1.8685451745986938\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 223, batch train loss: 1.897702693939209\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 224, batch train loss: 2.4758388996124268\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 225, batch train loss: 2.5035974979400635\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 226, batch train loss: 2.705298662185669\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 227, batch train loss: 1.7277402877807617\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 228, batch train loss: 3.0989739894866943\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 229, batch train loss: 2.639638662338257\n",
      "\n",
      "\n",
      "Epoch: 20, batch_id: 230, batch train loss: 2.0607213973999023\n",
      "\n",
      "\n",
      "Epoch: 20/ 100, Loss: 2.47849609385366\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:23<00:00,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Validation Loss: 3.7158422589302065\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, batch_id: 1, batch train loss: 4.696646690368652\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 2, batch train loss: 1.8955857753753662\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 3, batch train loss: 3.4620230197906494\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 4, batch train loss: 4.297542095184326\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 5, batch train loss: 2.2831625938415527\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 6, batch train loss: 3.2116730213165283\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 7, batch train loss: 2.3934152126312256\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 8, batch train loss: 4.613897800445557\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 9, batch train loss: 2.7869231700897217\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 10, batch train loss: 4.082498073577881\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 11, batch train loss: 3.9950037002563477\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 12, batch train loss: 4.090285778045654\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 13, batch train loss: 4.511570930480957\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 14, batch train loss: 4.639829635620117\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 15, batch train loss: 2.5250542163848877\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 16, batch train loss: 3.071140766143799\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 17, batch train loss: 4.307586193084717\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 18, batch train loss: 6.710045337677002\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 19, batch train loss: 3.7940096855163574\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 20, batch train loss: 8.977516174316406\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 21, batch train loss: 7.795494079589844\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 22, batch train loss: 4.1714372634887695\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 23, batch train loss: 6.771316051483154\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 24, batch train loss: 6.747976303100586\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 25, batch train loss: 3.7628865242004395\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 26, batch train loss: 2.176969528198242\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 27, batch train loss: 3.0600926876068115\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 28, batch train loss: 4.060455799102783\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 29, batch train loss: 3.6647207736968994\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 30, batch train loss: 3.2586662769317627\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 31, batch train loss: 5.240273475646973\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 32, batch train loss: 3.744293212890625\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 33, batch train loss: 2.954716205596924\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 34, batch train loss: 3.591071844100952\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 35, batch train loss: 3.11881160736084\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 36, batch train loss: 2.580904483795166\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 37, batch train loss: 2.5932705402374268\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 38, batch train loss: 2.280057430267334\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 39, batch train loss: 2.7776575088500977\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 40, batch train loss: 2.3485145568847656\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 41, batch train loss: 2.126580238342285\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 42, batch train loss: 2.124150276184082\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 43, batch train loss: 2.0318620204925537\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 44, batch train loss: 1.8066492080688477\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 45, batch train loss: 1.964258074760437\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 46, batch train loss: 2.982755184173584\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 47, batch train loss: 2.7983880043029785\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 48, batch train loss: 2.422661542892456\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 49, batch train loss: 4.6139678955078125\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 50, batch train loss: 4.282678127288818\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 51, batch train loss: 2.276508092880249\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 52, batch train loss: 3.0560660362243652\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 53, batch train loss: 1.7888911962509155\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 54, batch train loss: 2.2830848693847656\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 55, batch train loss: 1.8677253723144531\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 56, batch train loss: 1.975252628326416\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 57, batch train loss: 2.0939223766326904\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 58, batch train loss: 2.438565731048584\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 59, batch train loss: 1.8968669176101685\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 60, batch train loss: 2.871127128601074\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 61, batch train loss: 1.9562331438064575\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 62, batch train loss: 2.6159963607788086\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 63, batch train loss: 3.030862808227539\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 64, batch train loss: 1.9936777353286743\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 65, batch train loss: 3.2295024394989014\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 66, batch train loss: 2.1973743438720703\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 67, batch train loss: 2.4110100269317627\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 68, batch train loss: 2.9876179695129395\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 69, batch train loss: 2.3867013454437256\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 70, batch train loss: 2.7571630477905273\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 71, batch train loss: 1.9077070951461792\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 72, batch train loss: 2.8347415924072266\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 73, batch train loss: 1.9074786901474\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 74, batch train loss: 2.2446508407592773\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 75, batch train loss: 2.6991333961486816\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 76, batch train loss: 3.5042247772216797\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 77, batch train loss: 3.2295801639556885\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 78, batch train loss: 2.8619115352630615\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 79, batch train loss: 2.4693663120269775\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 80, batch train loss: 2.1122541427612305\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 81, batch train loss: 2.744734525680542\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 82, batch train loss: 2.4167733192443848\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 83, batch train loss: 2.5674972534179688\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 84, batch train loss: 2.0195672512054443\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 85, batch train loss: 2.728501796722412\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 86, batch train loss: 2.0937387943267822\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 87, batch train loss: 2.979727268218994\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 88, batch train loss: 2.2751870155334473\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 89, batch train loss: 2.376643657684326\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 90, batch train loss: 2.189765453338623\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 91, batch train loss: 2.002941846847534\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 92, batch train loss: 2.167511463165283\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 93, batch train loss: 2.3543851375579834\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 94, batch train loss: 2.4542856216430664\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 95, batch train loss: 2.993365526199341\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 96, batch train loss: 2.445838212966919\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 97, batch train loss: 2.3302221298217773\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 98, batch train loss: 3.3162906169891357\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 99, batch train loss: 2.9598703384399414\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 100, batch train loss: 2.7378439903259277\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 101, batch train loss: 2.6908841133117676\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 102, batch train loss: 2.600956678390503\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 103, batch train loss: 3.5700385570526123\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 104, batch train loss: 4.457895278930664\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 105, batch train loss: 2.4724438190460205\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 106, batch train loss: 2.8453357219696045\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 107, batch train loss: 3.689688205718994\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 108, batch train loss: 3.771035671234131\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 109, batch train loss: 3.2278223037719727\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 110, batch train loss: 2.9142379760742188\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 111, batch train loss: 4.001813888549805\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 112, batch train loss: 2.4406440258026123\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 113, batch train loss: 4.331331729888916\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 114, batch train loss: 2.2630815505981445\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 115, batch train loss: 3.374187707901001\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 116, batch train loss: 2.6827120780944824\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 117, batch train loss: 2.616314649581909\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 118, batch train loss: 3.0460965633392334\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 119, batch train loss: 3.0646796226501465\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 120, batch train loss: 2.7275588512420654\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 121, batch train loss: 2.5862295627593994\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 122, batch train loss: 3.6011104583740234\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 123, batch train loss: 2.254889488220215\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 124, batch train loss: 2.920538902282715\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 125, batch train loss: 2.253696918487549\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 126, batch train loss: 2.8386828899383545\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 127, batch train loss: 2.326040744781494\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 128, batch train loss: 1.943402886390686\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 129, batch train loss: 1.4751580953598022\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, batch_id: 130, batch train loss: 2.0630178451538086\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 131, batch train loss: 2.0964252948760986\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 132, batch train loss: 2.3697824478149414\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 133, batch train loss: 1.905096173286438\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 134, batch train loss: 2.140732765197754\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 135, batch train loss: 2.4764435291290283\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 136, batch train loss: 2.8616104125976562\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 137, batch train loss: 3.235675573348999\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 138, batch train loss: 2.0991148948669434\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 139, batch train loss: 2.125931978225708\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 140, batch train loss: 2.987999439239502\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 141, batch train loss: 2.2662594318389893\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 142, batch train loss: 1.9047422409057617\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 143, batch train loss: 2.7871296405792236\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 144, batch train loss: 2.4478752613067627\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 145, batch train loss: 2.6427836418151855\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 146, batch train loss: 2.5799901485443115\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 147, batch train loss: 1.9212905168533325\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 148, batch train loss: 3.711777687072754\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 149, batch train loss: 3.8276264667510986\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 150, batch train loss: 2.1337530612945557\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 151, batch train loss: 2.886380434036255\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 152, batch train loss: 2.5053024291992188\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 153, batch train loss: 2.8953282833099365\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 154, batch train loss: 2.844259738922119\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 155, batch train loss: 2.1674413681030273\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 156, batch train loss: 2.5930306911468506\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 157, batch train loss: 2.1712753772735596\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 158, batch train loss: 2.2163779735565186\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 159, batch train loss: 3.410256862640381\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 160, batch train loss: 2.084146499633789\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 161, batch train loss: 2.266130208969116\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 162, batch train loss: 2.3455893993377686\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 163, batch train loss: 2.8169026374816895\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 164, batch train loss: 3.90446400642395\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 165, batch train loss: 3.2789456844329834\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 166, batch train loss: 5.322932720184326\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 167, batch train loss: 3.3130850791931152\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 168, batch train loss: 2.993595600128174\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 169, batch train loss: 2.963672399520874\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 170, batch train loss: 4.405372142791748\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 171, batch train loss: 1.9085224866867065\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 172, batch train loss: 3.2855496406555176\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 173, batch train loss: 3.0128965377807617\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 174, batch train loss: 3.061511993408203\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 175, batch train loss: 3.801852226257324\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 176, batch train loss: 2.3584656715393066\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 177, batch train loss: 2.8268849849700928\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 178, batch train loss: 2.0282113552093506\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 179, batch train loss: 2.110013008117676\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 180, batch train loss: 2.514458179473877\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 181, batch train loss: 2.1191251277923584\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 182, batch train loss: 2.8773136138916016\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 183, batch train loss: 1.9464831352233887\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 184, batch train loss: 2.523090124130249\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 185, batch train loss: 2.2946131229400635\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 186, batch train loss: 1.9583357572555542\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 187, batch train loss: 2.4767463207244873\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 188, batch train loss: 2.6113288402557373\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 189, batch train loss: 1.985921025276184\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 190, batch train loss: 1.7729817628860474\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 191, batch train loss: 5.723709583282471\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 192, batch train loss: 5.541621685028076\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 193, batch train loss: 3.739109754562378\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 194, batch train loss: 5.426141738891602\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 195, batch train loss: 4.682806968688965\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 196, batch train loss: 2.738654375076294\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 197, batch train loss: 3.126965045928955\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 198, batch train loss: 2.6915900707244873\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 199, batch train loss: 5.485456466674805\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 200, batch train loss: 4.446126461029053\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 201, batch train loss: 5.757866382598877\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 202, batch train loss: 4.156586647033691\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 203, batch train loss: 10.897912979125977\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 204, batch train loss: 8.83774185180664\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 205, batch train loss: 6.585989475250244\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 206, batch train loss: 5.451241970062256\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 207, batch train loss: 8.153438568115234\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 208, batch train loss: 7.315147876739502\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 209, batch train loss: 4.724140167236328\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 210, batch train loss: 5.464677333831787\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 211, batch train loss: 3.7249197959899902\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 212, batch train loss: 2.998342990875244\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 213, batch train loss: 3.8273863792419434\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 214, batch train loss: 3.8224079608917236\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 215, batch train loss: 3.267045736312866\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 216, batch train loss: 3.4328930377960205\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 217, batch train loss: 3.8316385746002197\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 218, batch train loss: 3.3867852687835693\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 219, batch train loss: 3.050487995147705\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 220, batch train loss: 4.022545337677002\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 221, batch train loss: 4.090155601501465\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 222, batch train loss: 3.922585964202881\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 223, batch train loss: 2.7616782188415527\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 224, batch train loss: 2.731783866882324\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 225, batch train loss: 3.1269690990448\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 226, batch train loss: 2.493621349334717\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 227, batch train loss: 2.8155908584594727\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 228, batch train loss: 2.4210760593414307\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 229, batch train loss: 3.3120346069335938\n",
      "\n",
      "\n",
      "Epoch: 21, batch_id: 230, batch train loss: 3.4804458618164062\n",
      "\n",
      "\n",
      "Epoch: 21/ 100, Loss: 3.1832109466842984\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:24<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 Validation Loss: 3.2770725806554157\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, batch_id: 1, batch train loss: 3.4478626251220703\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 2, batch train loss: 3.276888847351074\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 3, batch train loss: 3.256925344467163\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 4, batch train loss: 3.2888033390045166\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 5, batch train loss: 3.312474012374878\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 6, batch train loss: 3.2321956157684326\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 7, batch train loss: 3.4475507736206055\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 8, batch train loss: 4.408020496368408\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 9, batch train loss: 5.383435249328613\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 10, batch train loss: 3.299008369445801\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 11, batch train loss: 2.9727683067321777\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 12, batch train loss: 2.730433702468872\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 13, batch train loss: 2.852144241333008\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 14, batch train loss: 2.767535924911499\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 15, batch train loss: 3.2751636505126953\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 16, batch train loss: 3.6444694995880127\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 17, batch train loss: 3.3021724224090576\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 18, batch train loss: 2.5590364933013916\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 19, batch train loss: 4.386338233947754\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 20, batch train loss: 2.578526496887207\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 21, batch train loss: 4.308412551879883\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 22, batch train loss: 2.655839443206787\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 23, batch train loss: 2.7570102214813232\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 24, batch train loss: 3.174499988555908\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 25, batch train loss: 2.524167537689209\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 26, batch train loss: 2.7750139236450195\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 27, batch train loss: 3.4089713096618652\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 28, batch train loss: 2.7486910820007324\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 29, batch train loss: 2.5538556575775146\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 30, batch train loss: 1.8214468955993652\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 31, batch train loss: 3.0576982498168945\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 32, batch train loss: 2.399923324584961\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 33, batch train loss: 2.3499417304992676\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 34, batch train loss: 2.5280017852783203\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 35, batch train loss: 2.1110212802886963\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 36, batch train loss: 3.927225351333618\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 37, batch train loss: 3.3764257431030273\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 38, batch train loss: 3.261165142059326\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 39, batch train loss: 6.184892654418945\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 40, batch train loss: 4.272451400756836\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 41, batch train loss: 3.135266065597534\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 42, batch train loss: 5.613139629364014\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 43, batch train loss: 6.679760932922363\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 44, batch train loss: 3.3112101554870605\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 45, batch train loss: 5.5348219871521\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 46, batch train loss: 8.903129577636719\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 47, batch train loss: 3.544257879257202\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 48, batch train loss: 2.8492794036865234\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 49, batch train loss: 4.310966968536377\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 50, batch train loss: 4.046228408813477\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 51, batch train loss: 3.4410102367401123\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 52, batch train loss: 6.454875469207764\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 53, batch train loss: 4.5018134117126465\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 54, batch train loss: 4.294140815734863\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 55, batch train loss: 5.0694427490234375\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 56, batch train loss: 4.944035530090332\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 57, batch train loss: 3.4219963550567627\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 58, batch train loss: 3.9282898902893066\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 59, batch train loss: 2.270110845565796\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 60, batch train loss: 5.607985019683838\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 61, batch train loss: 3.9647183418273926\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 62, batch train loss: 4.076814651489258\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 63, batch train loss: 3.114746332168579\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 64, batch train loss: 2.7469637393951416\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 65, batch train loss: 4.027221202850342\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 66, batch train loss: 2.7195448875427246\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 67, batch train loss: 4.383430004119873\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 68, batch train loss: 2.9567463397979736\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 69, batch train loss: 2.574633836746216\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 70, batch train loss: 3.2287466526031494\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 71, batch train loss: 3.6567416191101074\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 72, batch train loss: 3.159050703048706\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 73, batch train loss: 3.1088597774505615\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 74, batch train loss: 4.3272480964660645\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 75, batch train loss: 2.445279121398926\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 76, batch train loss: 3.4645369052886963\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 77, batch train loss: 2.797910451889038\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 78, batch train loss: 2.89941668510437\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 79, batch train loss: 3.0168356895446777\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 80, batch train loss: 3.005110263824463\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 81, batch train loss: 2.8332414627075195\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 82, batch train loss: 2.731700897216797\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 83, batch train loss: 2.892953395843506\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 84, batch train loss: 2.87849497795105\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 85, batch train loss: 3.1781039237976074\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 86, batch train loss: 2.3828585147857666\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 87, batch train loss: 2.2196991443634033\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 88, batch train loss: 3.1420235633850098\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 89, batch train loss: 2.787883758544922\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 90, batch train loss: 3.101402997970581\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 91, batch train loss: 2.582148313522339\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 92, batch train loss: 2.5064048767089844\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 93, batch train loss: 3.4787919521331787\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 94, batch train loss: 2.0419137477874756\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 95, batch train loss: 2.741790294647217\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 96, batch train loss: 2.093066692352295\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 97, batch train loss: 2.6186912059783936\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 98, batch train loss: 2.655710458755493\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 99, batch train loss: 2.6038854122161865\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 100, batch train loss: 2.0661003589630127\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 101, batch train loss: 2.2013235092163086\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 102, batch train loss: 1.7309150695800781\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 103, batch train loss: 2.107900857925415\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 104, batch train loss: 2.528956174850464\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 105, batch train loss: 2.2202327251434326\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 106, batch train loss: 2.746629238128662\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 107, batch train loss: 2.7730748653411865\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 108, batch train loss: 4.416396141052246\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 109, batch train loss: 3.522484540939331\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 110, batch train loss: 3.067251443862915\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 111, batch train loss: 5.865081310272217\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 112, batch train loss: 6.277644634246826\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 113, batch train loss: 4.052221775054932\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 114, batch train loss: 4.501790523529053\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 115, batch train loss: 3.352949380874634\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 116, batch train loss: 3.1652770042419434\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 117, batch train loss: 7.816550254821777\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 118, batch train loss: 2.9585280418395996\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 119, batch train loss: 5.4781813621521\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 120, batch train loss: 5.3429036140441895\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 121, batch train loss: 5.058878421783447\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 122, batch train loss: 2.770397663116455\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 123, batch train loss: 4.635599613189697\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 124, batch train loss: 4.676626205444336\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 125, batch train loss: 4.175652980804443\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 126, batch train loss: 4.815850257873535\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 127, batch train loss: 7.266096115112305\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 128, batch train loss: 6.0523858070373535\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 129, batch train loss: 3.8812859058380127\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, batch_id: 130, batch train loss: 5.934191703796387\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 131, batch train loss: 6.129833221435547\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 132, batch train loss: 3.4291088581085205\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 133, batch train loss: 6.450217247009277\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 134, batch train loss: 5.482348442077637\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 135, batch train loss: 5.861486434936523\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 136, batch train loss: 3.5107169151306152\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 137, batch train loss: 6.254056930541992\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 138, batch train loss: 7.38810396194458\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 139, batch train loss: 5.46412992477417\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 140, batch train loss: 4.036448955535889\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 141, batch train loss: 3.1664798259735107\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 142, batch train loss: 2.629628896713257\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 143, batch train loss: 3.541245937347412\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 144, batch train loss: 5.501518249511719\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 145, batch train loss: 4.195578575134277\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 146, batch train loss: 4.7482218742370605\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 147, batch train loss: 4.490665912628174\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 148, batch train loss: 5.122617244720459\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 149, batch train loss: 5.941493511199951\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 150, batch train loss: 4.752058982849121\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 151, batch train loss: 3.882369041442871\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 152, batch train loss: 5.026646137237549\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 153, batch train loss: 5.162008285522461\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 154, batch train loss: 3.599637508392334\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 155, batch train loss: 5.936037063598633\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 156, batch train loss: 4.601898670196533\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 157, batch train loss: 4.630529880523682\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 158, batch train loss: 6.811211585998535\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 159, batch train loss: 4.074599742889404\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 160, batch train loss: 2.569945812225342\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 161, batch train loss: 3.093006134033203\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 162, batch train loss: 2.8693249225616455\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 163, batch train loss: 3.0831899642944336\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 164, batch train loss: 2.160281181335449\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 165, batch train loss: 2.8701071739196777\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 166, batch train loss: 2.383979558944702\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 167, batch train loss: 2.7529194355010986\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 168, batch train loss: 2.672037124633789\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 169, batch train loss: 2.2506697177886963\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 170, batch train loss: 2.7773396968841553\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 171, batch train loss: 2.123363733291626\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 172, batch train loss: 3.514810800552368\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 173, batch train loss: 3.8932178020477295\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 174, batch train loss: 2.0692527294158936\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 175, batch train loss: 2.8819522857666016\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 176, batch train loss: 3.0138511657714844\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 177, batch train loss: 2.2480742931365967\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 178, batch train loss: 3.4949307441711426\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 179, batch train loss: 2.506108283996582\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 180, batch train loss: 2.398555278778076\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 181, batch train loss: 2.483194351196289\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 182, batch train loss: 2.0713369846343994\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 183, batch train loss: 2.5105721950531006\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 184, batch train loss: 2.983680009841919\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 185, batch train loss: 2.2736964225769043\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 186, batch train loss: 2.2593863010406494\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 187, batch train loss: 2.1218671798706055\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 188, batch train loss: 1.717167615890503\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 189, batch train loss: 2.178299903869629\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 190, batch train loss: 2.7056872844696045\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 191, batch train loss: 1.8503133058547974\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 192, batch train loss: 1.8933663368225098\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 193, batch train loss: 1.9895094633102417\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 194, batch train loss: 2.30298113822937\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 195, batch train loss: 2.3398654460906982\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 196, batch train loss: 2.5638511180877686\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 197, batch train loss: 3.5475659370422363\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 198, batch train loss: 3.0437088012695312\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 199, batch train loss: 2.8078012466430664\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 200, batch train loss: 2.776487350463867\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 201, batch train loss: 2.2561285495758057\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 202, batch train loss: 2.5468223094940186\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 203, batch train loss: 2.4796864986419678\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 204, batch train loss: 2.4170711040496826\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 205, batch train loss: 1.8226128816604614\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 206, batch train loss: 3.0191826820373535\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 207, batch train loss: 2.460864782333374\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 208, batch train loss: 2.4557223320007324\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 209, batch train loss: 3.2163920402526855\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 210, batch train loss: 3.038759469985962\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 211, batch train loss: 2.878183126449585\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 212, batch train loss: 2.3313820362091064\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 213, batch train loss: 2.587205410003662\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 214, batch train loss: 2.024137496948242\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 215, batch train loss: 3.066592216491699\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 216, batch train loss: 1.973528265953064\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 217, batch train loss: 2.027738332748413\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 218, batch train loss: 2.424384355545044\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 219, batch train loss: 2.696023464202881\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 220, batch train loss: 2.6256208419799805\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 221, batch train loss: 2.3059475421905518\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 222, batch train loss: 1.9071491956710815\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 223, batch train loss: 1.8578332662582397\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 224, batch train loss: 1.6432169675827026\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 225, batch train loss: 1.713995099067688\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 226, batch train loss: 1.9417318105697632\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 227, batch train loss: 1.7996593713760376\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 228, batch train loss: 1.955180048942566\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 229, batch train loss: 1.486816167831421\n",
      "\n",
      "\n",
      "Epoch: 22, batch_id: 230, batch train loss: 2.9176886081695557\n",
      "\n",
      "\n",
      "Epoch: 22/ 100, Loss: 3.4079576476760534\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:30<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 Validation Loss: 2.550552546977997\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 23, batch_id: 1, batch train loss: 2.6523942947387695\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 2, batch train loss: 3.1098639965057373\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 3, batch train loss: 2.464731216430664\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 4, batch train loss: 4.94423770904541\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 5, batch train loss: 2.4940762519836426\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 6, batch train loss: 2.810835838317871\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 7, batch train loss: 1.9400827884674072\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 8, batch train loss: 2.7912802696228027\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 9, batch train loss: 2.072890520095825\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 10, batch train loss: 2.3803203105926514\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 11, batch train loss: 2.4253079891204834\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 12, batch train loss: 2.074458122253418\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 13, batch train loss: 3.000061511993408\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 14, batch train loss: 2.596668004989624\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 15, batch train loss: 2.859598159790039\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 16, batch train loss: 2.7117247581481934\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 17, batch train loss: 2.2071471214294434\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 18, batch train loss: 2.8278417587280273\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 19, batch train loss: 2.692113161087036\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 20, batch train loss: 2.0900189876556396\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 21, batch train loss: 2.5592427253723145\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 22, batch train loss: 3.5219225883483887\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 23, batch train loss: 2.5210213661193848\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 24, batch train loss: 2.5966734886169434\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 25, batch train loss: 2.7895660400390625\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 26, batch train loss: 2.641252279281616\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 27, batch train loss: 2.19581937789917\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 28, batch train loss: 2.2852625846862793\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 29, batch train loss: 1.5725806951522827\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 30, batch train loss: 2.2107529640197754\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 31, batch train loss: 2.7184195518493652\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 32, batch train loss: 2.3300042152404785\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 33, batch train loss: 2.3680222034454346\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 34, batch train loss: 2.392878770828247\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 35, batch train loss: 1.9685323238372803\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 36, batch train loss: 2.493988275527954\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 37, batch train loss: 2.206949234008789\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 38, batch train loss: 3.1308541297912598\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 39, batch train loss: 4.3632493019104\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 40, batch train loss: 3.0403873920440674\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 41, batch train loss: 3.702115058898926\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 42, batch train loss: 3.0457615852355957\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 43, batch train loss: 3.7574071884155273\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 44, batch train loss: 2.0810933113098145\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 45, batch train loss: 2.613645076751709\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 46, batch train loss: 2.4055352210998535\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 47, batch train loss: 2.3882224559783936\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 48, batch train loss: 2.2527434825897217\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 49, batch train loss: 2.561063766479492\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 50, batch train loss: 2.3077871799468994\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 51, batch train loss: 2.800058603286743\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 52, batch train loss: 2.6773452758789062\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 53, batch train loss: 3.7005178928375244\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 54, batch train loss: 1.709191918373108\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 55, batch train loss: 2.6856188774108887\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 56, batch train loss: 2.821475028991699\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 57, batch train loss: 2.264545202255249\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 58, batch train loss: 2.513298749923706\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 59, batch train loss: 3.585611581802368\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 60, batch train loss: 2.439124345779419\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 61, batch train loss: 2.0802555084228516\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 62, batch train loss: 2.2626891136169434\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 63, batch train loss: 2.4676244258880615\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 64, batch train loss: 2.800208568572998\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 65, batch train loss: 2.5893168449401855\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 66, batch train loss: 2.0364465713500977\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 67, batch train loss: 2.4529037475585938\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 68, batch train loss: 2.827786684036255\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 69, batch train loss: 2.362194061279297\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 70, batch train loss: 2.4316728115081787\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 71, batch train loss: 2.347792625427246\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 72, batch train loss: 3.362699508666992\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 73, batch train loss: 1.8355802297592163\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 74, batch train loss: 2.539874315261841\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 75, batch train loss: 3.3670592308044434\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 76, batch train loss: 2.786295175552368\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 77, batch train loss: 2.173818588256836\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 78, batch train loss: 2.5047619342803955\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 79, batch train loss: 1.8949495553970337\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 80, batch train loss: 3.1105122566223145\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 81, batch train loss: 1.9812465906143188\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 82, batch train loss: 3.785691261291504\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 83, batch train loss: 3.7971293926239014\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 84, batch train loss: 2.305340528488159\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 85, batch train loss: 4.221903324127197\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 86, batch train loss: 4.825343608856201\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 87, batch train loss: 3.1122360229492188\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 88, batch train loss: 3.800551652908325\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 89, batch train loss: 4.982888698577881\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 90, batch train loss: 2.905358076095581\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 91, batch train loss: 4.27700662612915\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 92, batch train loss: 4.136041641235352\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 93, batch train loss: 3.0070667266845703\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 94, batch train loss: 4.6058807373046875\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 95, batch train loss: 4.5534868240356445\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 96, batch train loss: 2.492596387863159\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 97, batch train loss: 5.1407670974731445\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 98, batch train loss: 2.9439079761505127\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 99, batch train loss: 2.2137835025787354\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 100, batch train loss: 2.2689602375030518\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 101, batch train loss: 2.2862071990966797\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 102, batch train loss: 8.394164085388184\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 103, batch train loss: 3.3090052604675293\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 104, batch train loss: 4.0137038230896\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 105, batch train loss: 3.159893751144409\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 106, batch train loss: 2.4762558937072754\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 107, batch train loss: 4.247687816619873\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 108, batch train loss: 2.176597833633423\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 109, batch train loss: 3.176077127456665\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 110, batch train loss: 4.274187088012695\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 111, batch train loss: 4.148627758026123\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 112, batch train loss: 2.2200403213500977\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 113, batch train loss: 2.7634832859039307\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 114, batch train loss: 2.168461561203003\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 115, batch train loss: 4.080498218536377\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 116, batch train loss: 3.7220873832702637\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 117, batch train loss: 2.6185107231140137\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 118, batch train loss: 3.107290029525757\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 119, batch train loss: 3.227759599685669\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 120, batch train loss: 2.1365468502044678\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 121, batch train loss: 3.2076587677001953\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 122, batch train loss: 3.0313971042633057\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 123, batch train loss: 2.208134651184082\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 124, batch train loss: 3.317690134048462\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 125, batch train loss: 3.5557055473327637\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 126, batch train loss: 3.016782283782959\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 127, batch train loss: 2.7678849697113037\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 128, batch train loss: 3.4744532108306885\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, batch_id: 129, batch train loss: 3.3354642391204834\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 130, batch train loss: 4.157528400421143\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 131, batch train loss: 2.774691104888916\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 132, batch train loss: 3.61357045173645\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 133, batch train loss: 2.7119381427764893\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 134, batch train loss: 3.211527109146118\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 135, batch train loss: 3.0019052028656006\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 136, batch train loss: 3.0841434001922607\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 137, batch train loss: 5.183231353759766\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 138, batch train loss: 5.184378147125244\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 139, batch train loss: 3.016192674636841\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 140, batch train loss: 3.1272835731506348\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 141, batch train loss: 3.0034055709838867\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 142, batch train loss: 4.062045097351074\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 143, batch train loss: 3.2986772060394287\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 144, batch train loss: 2.5721163749694824\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 145, batch train loss: 2.809478282928467\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 146, batch train loss: 3.906039237976074\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 147, batch train loss: 2.9631741046905518\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 148, batch train loss: 2.6276776790618896\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 149, batch train loss: 2.5622527599334717\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 150, batch train loss: 2.1140384674072266\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 151, batch train loss: 2.5935254096984863\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 152, batch train loss: 2.1120071411132812\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 153, batch train loss: 2.802370309829712\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 154, batch train loss: 3.130466938018799\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 155, batch train loss: 2.298906087875366\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 156, batch train loss: 3.760936975479126\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 157, batch train loss: 2.5879902839660645\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 158, batch train loss: 2.591492176055908\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 159, batch train loss: 4.514744758605957\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 160, batch train loss: 2.531747341156006\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 161, batch train loss: 2.7662930488586426\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 162, batch train loss: 3.492995262145996\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 163, batch train loss: 2.0832009315490723\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 164, batch train loss: 3.6209444999694824\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 165, batch train loss: 2.65722918510437\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 166, batch train loss: 3.387324333190918\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 167, batch train loss: 2.00449275970459\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 168, batch train loss: 2.202648162841797\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 169, batch train loss: 2.627147912979126\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 170, batch train loss: 2.547161340713501\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 171, batch train loss: 2.0154635906219482\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 172, batch train loss: 2.4808571338653564\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 173, batch train loss: 2.7358460426330566\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 174, batch train loss: 3.1887311935424805\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 175, batch train loss: 2.4984161853790283\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 176, batch train loss: 1.9674184322357178\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 177, batch train loss: 2.2381207942962646\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 178, batch train loss: 2.472611665725708\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 179, batch train loss: 1.8872084617614746\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 180, batch train loss: 2.725158214569092\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 181, batch train loss: 2.497182846069336\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 182, batch train loss: 3.2838294506073\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 183, batch train loss: 4.020699501037598\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 184, batch train loss: 2.5193071365356445\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 185, batch train loss: 3.4266295433044434\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 186, batch train loss: 3.642030954360962\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 187, batch train loss: 3.083660125732422\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 188, batch train loss: 3.7913293838500977\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 189, batch train loss: 3.35664439201355\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 190, batch train loss: 3.2777891159057617\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 191, batch train loss: 2.4927749633789062\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 192, batch train loss: 2.5768775939941406\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 193, batch train loss: 2.2658567428588867\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 194, batch train loss: 2.8545334339141846\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 195, batch train loss: 3.4661014080047607\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 196, batch train loss: 2.381936550140381\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 197, batch train loss: 2.0243937969207764\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 198, batch train loss: 2.7320752143859863\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 199, batch train loss: 2.522737741470337\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 200, batch train loss: 2.075929880142212\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 201, batch train loss: 3.3270976543426514\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 202, batch train loss: 1.913546085357666\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 203, batch train loss: 2.249099016189575\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 204, batch train loss: 2.7392637729644775\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 205, batch train loss: 1.7200785875320435\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 206, batch train loss: 2.3292932510375977\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 207, batch train loss: 3.6770997047424316\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 208, batch train loss: 2.235797882080078\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 209, batch train loss: 2.8079609870910645\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 210, batch train loss: 2.285815954208374\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 211, batch train loss: 2.748023271560669\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 212, batch train loss: 3.9061694145202637\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 213, batch train loss: 2.268681049346924\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 214, batch train loss: 2.3846335411071777\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 215, batch train loss: 2.317354440689087\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 216, batch train loss: 3.272052049636841\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 217, batch train loss: 2.436768054962158\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 218, batch train loss: 2.137584686279297\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 219, batch train loss: 2.9156432151794434\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 220, batch train loss: 3.1630406379699707\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 221, batch train loss: 3.408827066421509\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 222, batch train loss: 3.4313066005706787\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 223, batch train loss: 2.6072804927825928\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 224, batch train loss: 2.8662519454956055\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 225, batch train loss: 3.6080119609832764\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 226, batch train loss: 4.052635669708252\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 227, batch train loss: 3.8177437782287598\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 228, batch train loss: 2.7073938846588135\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 229, batch train loss: 3.214266061782837\n",
      "\n",
      "\n",
      "Epoch: 23, batch_id: 230, batch train loss: 2.376162528991699\n",
      "\n",
      "\n",
      "Epoch: 23/ 100, Loss: 2.9100218835084335\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:29<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 Validation Loss: 2.9268772264321643\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, batch_id: 1, batch train loss: 2.1667020320892334\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 2, batch train loss: 2.579878568649292\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 3, batch train loss: 2.0270864963531494\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 4, batch train loss: 2.508255958557129\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 5, batch train loss: 1.903136134147644\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 6, batch train loss: 2.494783639907837\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 7, batch train loss: 2.0459933280944824\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 8, batch train loss: 2.601717948913574\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 9, batch train loss: 3.440016746520996\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 10, batch train loss: 3.8923518657684326\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 11, batch train loss: 2.6600542068481445\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 12, batch train loss: 2.9107136726379395\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 13, batch train loss: 2.4040164947509766\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 14, batch train loss: 2.177255630493164\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 15, batch train loss: 1.9969474077224731\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 16, batch train loss: 3.819317579269409\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 17, batch train loss: 2.848438262939453\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 18, batch train loss: 3.0462467670440674\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 19, batch train loss: 2.6637773513793945\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 20, batch train loss: 2.9326601028442383\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 21, batch train loss: 3.1229238510131836\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 22, batch train loss: 1.7305576801300049\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 23, batch train loss: 2.6666419506073\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 24, batch train loss: 6.373721599578857\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 25, batch train loss: 2.9321463108062744\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 26, batch train loss: 4.982032299041748\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 27, batch train loss: 7.547935962677002\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 28, batch train loss: 3.834470510482788\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 29, batch train loss: 2.8169641494750977\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 30, batch train loss: 3.510014533996582\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 31, batch train loss: 2.639092206954956\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 32, batch train loss: 2.202859401702881\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 33, batch train loss: 2.6811702251434326\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 34, batch train loss: 3.183504343032837\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 35, batch train loss: 2.212099552154541\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 36, batch train loss: 1.9023170471191406\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 37, batch train loss: 2.6230714321136475\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 38, batch train loss: 2.331528425216675\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 39, batch train loss: 2.780076265335083\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 40, batch train loss: 3.060730218887329\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 41, batch train loss: 2.9578323364257812\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 42, batch train loss: 3.325277090072632\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 43, batch train loss: 2.5568833351135254\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 44, batch train loss: 6.240771293640137\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 45, batch train loss: 3.4455111026763916\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 46, batch train loss: 2.9612956047058105\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 47, batch train loss: 2.095968723297119\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 48, batch train loss: 2.0457711219787598\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 49, batch train loss: 1.9666626453399658\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 50, batch train loss: 3.5154011249542236\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 51, batch train loss: 2.310695171356201\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 52, batch train loss: 3.0717718601226807\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 53, batch train loss: 3.4205915927886963\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 54, batch train loss: 2.5260016918182373\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 55, batch train loss: 2.566340446472168\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 56, batch train loss: 2.304750442504883\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 57, batch train loss: 2.7179627418518066\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 58, batch train loss: 3.848254919052124\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 59, batch train loss: 3.098820686340332\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 60, batch train loss: 2.683440685272217\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 61, batch train loss: 3.010983467102051\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 62, batch train loss: 2.090235710144043\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 63, batch train loss: 3.172478199005127\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 64, batch train loss: 2.8797593116760254\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 65, batch train loss: 3.774418830871582\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 66, batch train loss: 3.571927785873413\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 67, batch train loss: 2.6207540035247803\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 68, batch train loss: 4.901625633239746\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 69, batch train loss: 3.451735019683838\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 70, batch train loss: 2.4012207984924316\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 71, batch train loss: 4.870173931121826\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 72, batch train loss: 3.185904026031494\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 73, batch train loss: 2.944929599761963\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 74, batch train loss: 4.434661388397217\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 75, batch train loss: 2.8381032943725586\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 76, batch train loss: 3.0195395946502686\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 77, batch train loss: 3.874276876449585\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 78, batch train loss: 3.1554362773895264\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 79, batch train loss: 6.52599573135376\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 80, batch train loss: 5.013725757598877\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 81, batch train loss: 3.9504504203796387\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 82, batch train loss: 4.323554515838623\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 83, batch train loss: 5.524906635284424\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 84, batch train loss: 3.4640088081359863\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 85, batch train loss: 2.680483102798462\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 86, batch train loss: 7.7460408210754395\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 87, batch train loss: 4.430132865905762\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 88, batch train loss: 4.376967430114746\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 89, batch train loss: 4.610644340515137\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 90, batch train loss: 3.831347703933716\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 91, batch train loss: 3.361863136291504\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 92, batch train loss: 3.6767923831939697\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 93, batch train loss: 2.8910486698150635\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 94, batch train loss: 4.583502292633057\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 95, batch train loss: 5.360141754150391\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 96, batch train loss: 4.214120388031006\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 97, batch train loss: 5.0286760330200195\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 98, batch train loss: 5.634103298187256\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 99, batch train loss: 3.1412479877471924\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 100, batch train loss: 5.1302032470703125\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 101, batch train loss: 4.564877986907959\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 102, batch train loss: 2.8109288215637207\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 103, batch train loss: 5.875523090362549\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 104, batch train loss: 3.7784957885742188\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 105, batch train loss: 4.090928554534912\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 106, batch train loss: 3.490567922592163\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 107, batch train loss: 3.594660997390747\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 108, batch train loss: 3.2716429233551025\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 109, batch train loss: 2.5096094608306885\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 110, batch train loss: 2.669116258621216\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 111, batch train loss: 2.798969268798828\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 112, batch train loss: 3.563488006591797\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 113, batch train loss: 2.9236814975738525\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 114, batch train loss: 2.8115901947021484\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 115, batch train loss: 2.4518494606018066\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 116, batch train loss: 2.502856731414795\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 117, batch train loss: 2.848306179046631\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 118, batch train loss: 2.6048619747161865\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 119, batch train loss: 2.6994717121124268\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 120, batch train loss: 2.968496561050415\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 121, batch train loss: 2.3848161697387695\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 122, batch train loss: 2.1175038814544678\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 123, batch train loss: 2.588627815246582\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 124, batch train loss: 3.577727794647217\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 125, batch train loss: 4.76170015335083\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 126, batch train loss: 3.5344924926757812\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 127, batch train loss: 2.428708553314209\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 128, batch train loss: 3.5660128593444824\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 129, batch train loss: 3.291050910949707\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, batch_id: 130, batch train loss: 2.6168506145477295\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 131, batch train loss: 3.5743460655212402\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 132, batch train loss: 2.5593621730804443\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 133, batch train loss: 3.57060170173645\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 134, batch train loss: 2.746519088745117\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 135, batch train loss: 2.656755208969116\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 136, batch train loss: 2.3212366104125977\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 137, batch train loss: 2.315028429031372\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 138, batch train loss: 4.86724328994751\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 139, batch train loss: 3.057990789413452\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 140, batch train loss: 2.984159231185913\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 141, batch train loss: 2.9690890312194824\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 142, batch train loss: 2.908123016357422\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 143, batch train loss: 2.5144619941711426\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 144, batch train loss: 4.157011032104492\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 145, batch train loss: 3.4592602252960205\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 146, batch train loss: 4.491389751434326\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 147, batch train loss: 4.590458393096924\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 148, batch train loss: 6.750373840332031\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 149, batch train loss: 6.52247428894043\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 150, batch train loss: 4.8125433921813965\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 151, batch train loss: 4.515270233154297\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 152, batch train loss: 3.995648145675659\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 153, batch train loss: 3.5929064750671387\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 154, batch train loss: 2.355607271194458\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 155, batch train loss: 4.603501796722412\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 156, batch train loss: 2.1710124015808105\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 157, batch train loss: 3.6984236240386963\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 158, batch train loss: 3.7471981048583984\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 159, batch train loss: 3.042687177658081\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 160, batch train loss: 2.408055305480957\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 161, batch train loss: 2.4826323986053467\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 162, batch train loss: 2.4950220584869385\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 163, batch train loss: 3.167233467102051\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 164, batch train loss: 5.160582065582275\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 165, batch train loss: 2.7567012310028076\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 166, batch train loss: 3.5076563358306885\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 167, batch train loss: 4.103463649749756\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 168, batch train loss: 3.0336122512817383\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 169, batch train loss: 3.2726659774780273\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 170, batch train loss: 4.745195388793945\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 171, batch train loss: 4.040969371795654\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 172, batch train loss: 3.1816353797912598\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 173, batch train loss: 2.2020671367645264\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 174, batch train loss: 3.2636759281158447\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 175, batch train loss: 3.7521045207977295\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 176, batch train loss: 2.3108551502227783\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 177, batch train loss: 2.3772780895233154\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 178, batch train loss: 3.376823663711548\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 179, batch train loss: 3.355381727218628\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 180, batch train loss: 3.392404079437256\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 181, batch train loss: 2.908748149871826\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 182, batch train loss: 2.2247815132141113\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 183, batch train loss: 1.5863772630691528\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 184, batch train loss: 2.3715803623199463\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 185, batch train loss: 3.156238555908203\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 186, batch train loss: 3.3817930221557617\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 187, batch train loss: 2.515340566635132\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 188, batch train loss: 2.2888829708099365\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 189, batch train loss: 2.2017977237701416\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 190, batch train loss: 3.265556573867798\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 191, batch train loss: 3.8692545890808105\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 192, batch train loss: 2.1626977920532227\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 193, batch train loss: 2.2478859424591064\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 194, batch train loss: 2.5755012035369873\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 195, batch train loss: 3.1130454540252686\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 196, batch train loss: 3.758361339569092\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 197, batch train loss: 2.9866998195648193\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 198, batch train loss: 3.5484228134155273\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 199, batch train loss: 2.594230890274048\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 200, batch train loss: 3.1495766639709473\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 201, batch train loss: 3.421262264251709\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 202, batch train loss: 3.8822901248931885\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 203, batch train loss: 4.207226753234863\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 204, batch train loss: 4.4254469871521\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 205, batch train loss: 3.5469648838043213\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 206, batch train loss: 3.335015058517456\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 207, batch train loss: 3.2383053302764893\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 208, batch train loss: 3.2324767112731934\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 209, batch train loss: 4.210046291351318\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 210, batch train loss: 2.554750919342041\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 211, batch train loss: 3.4674787521362305\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 212, batch train loss: 3.913893222808838\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 213, batch train loss: 2.7810614109039307\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 214, batch train loss: 4.556962490081787\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 215, batch train loss: 1.856350302696228\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 216, batch train loss: 2.917616367340088\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 217, batch train loss: 3.4885783195495605\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 218, batch train loss: 3.228945016860962\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 219, batch train loss: 2.6765666007995605\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 220, batch train loss: 4.0695672035217285\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 221, batch train loss: 3.834973096847534\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 222, batch train loss: 2.3501603603363037\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 223, batch train loss: 2.6028738021850586\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 224, batch train loss: 3.3350460529327393\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 225, batch train loss: 1.9979106187820435\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 226, batch train loss: 2.463162422180176\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 227, batch train loss: 2.532176971435547\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 228, batch train loss: 1.7702709436416626\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 229, batch train loss: 2.9985949993133545\n",
      "\n",
      "\n",
      "Epoch: 24, batch_id: 230, batch train loss: 2.530076742172241\n",
      "\n",
      "\n",
      "Epoch: 24/ 100, Loss: 3.2981663942337036\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:27<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 Validation Loss: 2.5529441634813943\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, batch_id: 1, batch train loss: 2.497420310974121\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 2, batch train loss: 2.5745315551757812\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 3, batch train loss: 2.553049325942993\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 4, batch train loss: 2.7842631340026855\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 5, batch train loss: 2.4149186611175537\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 6, batch train loss: 2.271087169647217\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 7, batch train loss: 2.709137201309204\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 8, batch train loss: 2.500891923904419\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 9, batch train loss: 2.7398343086242676\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 10, batch train loss: 3.0346434116363525\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 11, batch train loss: 2.628678321838379\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 12, batch train loss: 3.094118356704712\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 13, batch train loss: 2.2924063205718994\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 14, batch train loss: 2.0556023120880127\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 15, batch train loss: 3.040239095687866\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 16, batch train loss: 3.119621753692627\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 17, batch train loss: 3.1813817024230957\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 18, batch train loss: 4.119481563568115\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 19, batch train loss: 2.9144582748413086\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 20, batch train loss: 2.9246931076049805\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 21, batch train loss: 4.300268650054932\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 22, batch train loss: 2.9933080673217773\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 23, batch train loss: 2.898090124130249\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 24, batch train loss: 3.8097872734069824\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 25, batch train loss: 2.678323268890381\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 26, batch train loss: 2.656297206878662\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 27, batch train loss: 2.045440912246704\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 28, batch train loss: 1.9941939115524292\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 29, batch train loss: 2.4703891277313232\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 30, batch train loss: 2.3503894805908203\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 31, batch train loss: 2.4596734046936035\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 32, batch train loss: 2.204383373260498\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 33, batch train loss: 3.1641054153442383\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 34, batch train loss: 2.8688745498657227\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 35, batch train loss: 3.559962272644043\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 36, batch train loss: 3.2417006492614746\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 37, batch train loss: 4.819154262542725\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 38, batch train loss: 2.766677141189575\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 39, batch train loss: 4.819237232208252\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 40, batch train loss: 3.7750728130340576\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 41, batch train loss: 3.28781795501709\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 42, batch train loss: 4.799889087677002\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 43, batch train loss: 3.466754913330078\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 44, batch train loss: 1.838854193687439\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 45, batch train loss: 5.556003570556641\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 46, batch train loss: 3.5098185539245605\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 47, batch train loss: 2.0239763259887695\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 48, batch train loss: 5.174474239349365\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 49, batch train loss: 2.7314932346343994\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 50, batch train loss: 1.9615329504013062\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 51, batch train loss: 2.4629690647125244\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 52, batch train loss: 2.481904983520508\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 53, batch train loss: 1.8031193017959595\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 54, batch train loss: 1.7502360343933105\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 55, batch train loss: 1.529278039932251\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 56, batch train loss: 2.872347116470337\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 57, batch train loss: 2.4050145149230957\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 58, batch train loss: 2.774977684020996\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 59, batch train loss: 3.708920955657959\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 60, batch train loss: 2.8034844398498535\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 61, batch train loss: 3.382788896560669\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 62, batch train loss: 2.4980452060699463\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 63, batch train loss: 2.526487112045288\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 64, batch train loss: 3.8305537700653076\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 65, batch train loss: 2.266446352005005\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 66, batch train loss: 3.381627082824707\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 67, batch train loss: 3.7870585918426514\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 68, batch train loss: 3.4695653915405273\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 69, batch train loss: 3.6108577251434326\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 70, batch train loss: 2.5927298069000244\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 71, batch train loss: 2.8579764366149902\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 72, batch train loss: 2.8031790256500244\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 73, batch train loss: 2.4649507999420166\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 74, batch train loss: 3.0881173610687256\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 75, batch train loss: 3.904705047607422\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 76, batch train loss: 3.0948188304901123\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 77, batch train loss: 3.4586808681488037\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 78, batch train loss: 2.8005778789520264\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 79, batch train loss: 2.7956345081329346\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 80, batch train loss: 2.9337732791900635\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 81, batch train loss: 2.256037712097168\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 82, batch train loss: 3.3978118896484375\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 83, batch train loss: 2.975560188293457\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 84, batch train loss: 2.460402250289917\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 85, batch train loss: 2.7253785133361816\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 86, batch train loss: 2.4331204891204834\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 87, batch train loss: 1.944579839706421\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 88, batch train loss: 2.605617046356201\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 89, batch train loss: 3.9460649490356445\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 90, batch train loss: 4.3152756690979\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 91, batch train loss: 2.31097412109375\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 92, batch train loss: 4.009368419647217\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 93, batch train loss: 5.178118705749512\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 94, batch train loss: 4.660772800445557\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 95, batch train loss: 3.7593653202056885\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 96, batch train loss: 9.120526313781738\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 97, batch train loss: 3.9291911125183105\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 98, batch train loss: 4.829428672790527\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 99, batch train loss: 5.8366007804870605\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 100, batch train loss: 3.6460652351379395\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 101, batch train loss: 4.10967493057251\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 102, batch train loss: 5.571081638336182\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 103, batch train loss: 3.842556953430176\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 104, batch train loss: 2.932903528213501\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 105, batch train loss: 9.222540855407715\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 106, batch train loss: 8.519302368164062\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 107, batch train loss: 4.652040004730225\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 108, batch train loss: 3.3925483226776123\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 109, batch train loss: 4.702676773071289\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 110, batch train loss: 3.8458287715911865\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 111, batch train loss: 3.729508876800537\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 112, batch train loss: 4.450984477996826\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 113, batch train loss: 3.5213146209716797\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 114, batch train loss: 2.935366630554199\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 115, batch train loss: 5.699418544769287\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 116, batch train loss: 3.1983909606933594\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 117, batch train loss: 3.1404590606689453\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 118, batch train loss: 4.047935485839844\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 119, batch train loss: 2.6980810165405273\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 120, batch train loss: 3.825014591217041\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 121, batch train loss: 5.484679222106934\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 122, batch train loss: 4.776121616363525\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 123, batch train loss: 3.6124768257141113\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 124, batch train loss: 2.5696141719818115\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 125, batch train loss: 4.3884124755859375\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 126, batch train loss: 3.1619482040405273\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 127, batch train loss: 1.982502818107605\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 128, batch train loss: 3.559406042098999\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 129, batch train loss: 5.447797775268555\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, batch_id: 130, batch train loss: 2.7552788257598877\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 131, batch train loss: 4.832512378692627\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 132, batch train loss: 8.140889167785645\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 133, batch train loss: 6.853038787841797\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 134, batch train loss: 2.9117016792297363\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 135, batch train loss: 3.3096420764923096\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 136, batch train loss: 5.442905902862549\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 137, batch train loss: 4.762363910675049\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 138, batch train loss: 3.3559863567352295\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 139, batch train loss: 2.8364171981811523\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 140, batch train loss: 3.216038703918457\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 141, batch train loss: 3.7079012393951416\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 142, batch train loss: 2.9756739139556885\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 143, batch train loss: 2.9492878913879395\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 144, batch train loss: 3.2524349689483643\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 145, batch train loss: 2.7127954959869385\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 146, batch train loss: 2.0536186695098877\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 147, batch train loss: 2.131998300552368\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 148, batch train loss: 2.4937546253204346\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 149, batch train loss: 4.032690525054932\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 150, batch train loss: 2.9727392196655273\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 151, batch train loss: 2.9427175521850586\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 152, batch train loss: 2.6791439056396484\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 153, batch train loss: 3.221585512161255\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 154, batch train loss: 2.3887908458709717\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 155, batch train loss: 3.8151209354400635\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 156, batch train loss: 3.3763670921325684\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 157, batch train loss: 2.5850350856781006\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 158, batch train loss: 3.089540719985962\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 159, batch train loss: 2.7660231590270996\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 160, batch train loss: 4.027811527252197\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 161, batch train loss: 2.1064035892486572\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 162, batch train loss: 2.1705501079559326\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 163, batch train loss: 2.456406354904175\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 164, batch train loss: 3.0965793132781982\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 165, batch train loss: 2.500491142272949\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 166, batch train loss: 2.139270782470703\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 167, batch train loss: 2.8415558338165283\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 168, batch train loss: 2.9567770957946777\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 169, batch train loss: 2.5200772285461426\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 170, batch train loss: 2.8035759925842285\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 171, batch train loss: 2.4670472145080566\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 172, batch train loss: 2.4650845527648926\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 173, batch train loss: 2.158536195755005\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 174, batch train loss: 1.6227612495422363\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 175, batch train loss: 2.173137903213501\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 176, batch train loss: 2.5772972106933594\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 177, batch train loss: 2.309971570968628\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 178, batch train loss: 1.8958064317703247\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 179, batch train loss: 2.520073890686035\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 180, batch train loss: 1.918600082397461\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 181, batch train loss: 1.7781463861465454\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 182, batch train loss: 1.56698477268219\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 183, batch train loss: 1.8230544328689575\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 184, batch train loss: 1.7413761615753174\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 185, batch train loss: 1.5368024110794067\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 186, batch train loss: 1.3169713020324707\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 187, batch train loss: 2.371074914932251\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 188, batch train loss: 1.820935845375061\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 189, batch train loss: 1.5742889642715454\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 190, batch train loss: 2.070110321044922\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 191, batch train loss: 2.459202289581299\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 192, batch train loss: 2.3048481941223145\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 193, batch train loss: 2.1585209369659424\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 194, batch train loss: 1.8478736877441406\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 195, batch train loss: 2.0870964527130127\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 196, batch train loss: 1.8133705854415894\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 197, batch train loss: 1.853755235671997\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 198, batch train loss: 3.4013566970825195\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 199, batch train loss: 3.723853349685669\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 200, batch train loss: 3.3496649265289307\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 201, batch train loss: 2.8163208961486816\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 202, batch train loss: 2.7088866233825684\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 203, batch train loss: 2.9992711544036865\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 204, batch train loss: 3.0010008811950684\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 205, batch train loss: 2.0576891899108887\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 206, batch train loss: 2.3026304244995117\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 207, batch train loss: 1.964624285697937\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 208, batch train loss: 2.4076240062713623\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 209, batch train loss: 2.2906477451324463\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 210, batch train loss: 2.3116869926452637\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 211, batch train loss: 1.7869173288345337\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 212, batch train loss: 1.8677079677581787\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 213, batch train loss: 2.263444423675537\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 214, batch train loss: 1.9616973400115967\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 215, batch train loss: 1.8934729099273682\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 216, batch train loss: 2.1149046421051025\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 217, batch train loss: 1.9634696245193481\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 218, batch train loss: 1.7888981103897095\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 219, batch train loss: 1.449983835220337\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 220, batch train loss: 1.4704982042312622\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 221, batch train loss: 2.6252176761627197\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 222, batch train loss: 2.1602871417999268\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 223, batch train loss: 2.0555591583251953\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 224, batch train loss: 2.1432714462280273\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 225, batch train loss: 2.559077262878418\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 226, batch train loss: 1.9051766395568848\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 227, batch train loss: 2.678508996963501\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 228, batch train loss: 2.840824604034424\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 229, batch train loss: 2.253596305847168\n",
      "\n",
      "\n",
      "Epoch: 25, batch_id: 230, batch train loss: 4.443075656890869\n",
      "\n",
      "\n",
      "Epoch: 25/ 100, Loss: 3.0658919344777646\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:25<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 Validation Loss: 3.3779255112012225\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, batch_id: 1, batch train loss: 2.127924919128418\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 2, batch train loss: 3.0238680839538574\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 3, batch train loss: 3.8751795291900635\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 4, batch train loss: 3.3942911624908447\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 5, batch train loss: 2.425246477127075\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 6, batch train loss: 3.880504608154297\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 7, batch train loss: 3.028658390045166\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 8, batch train loss: 2.3020637035369873\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 9, batch train loss: 3.9171459674835205\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 10, batch train loss: 2.0174975395202637\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 11, batch train loss: 3.338700294494629\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 12, batch train loss: 4.498764514923096\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 13, batch train loss: 2.1825478076934814\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 14, batch train loss: 3.316923141479492\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 15, batch train loss: 3.7551562786102295\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 16, batch train loss: 2.171761989593506\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 17, batch train loss: 2.853358268737793\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 18, batch train loss: 2.1496479511260986\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 19, batch train loss: 2.0782976150512695\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 20, batch train loss: 1.568505883216858\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 21, batch train loss: 2.0809953212738037\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 22, batch train loss: 1.945500135421753\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 23, batch train loss: 1.9414217472076416\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 24, batch train loss: 1.689244031906128\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 25, batch train loss: 1.6715142726898193\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 26, batch train loss: 1.6920511722564697\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 27, batch train loss: 2.3192808628082275\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 28, batch train loss: 2.275808811187744\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 29, batch train loss: 2.0020217895507812\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 30, batch train loss: 1.7762739658355713\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 31, batch train loss: 2.318812608718872\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 32, batch train loss: 2.026353597640991\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 33, batch train loss: 2.2889862060546875\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 34, batch train loss: 2.858100175857544\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 35, batch train loss: 2.517483711242676\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 36, batch train loss: 3.2450082302093506\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 37, batch train loss: 2.2575862407684326\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 38, batch train loss: 2.3014886379241943\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 39, batch train loss: 1.800136685371399\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 40, batch train loss: 2.526834011077881\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 41, batch train loss: 2.2356255054473877\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 42, batch train loss: 1.5402257442474365\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 43, batch train loss: 1.4459348917007446\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 44, batch train loss: 3.16644287109375\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 45, batch train loss: 2.9627277851104736\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 46, batch train loss: 1.644104242324829\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 47, batch train loss: 2.02715802192688\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 48, batch train loss: 1.6707491874694824\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 49, batch train loss: 2.3109261989593506\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 50, batch train loss: 1.4033281803131104\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 51, batch train loss: 3.0272765159606934\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 52, batch train loss: 2.18404221534729\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 53, batch train loss: 2.5125319957733154\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 54, batch train loss: 2.7485547065734863\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 55, batch train loss: 3.3312413692474365\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 56, batch train loss: 2.237320899963379\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 57, batch train loss: 2.3502583503723145\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 58, batch train loss: 2.514023542404175\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 59, batch train loss: 2.8767364025115967\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 60, batch train loss: 2.169341564178467\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 61, batch train loss: 2.9893133640289307\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 62, batch train loss: 2.3438241481781006\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 63, batch train loss: 3.6953418254852295\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 64, batch train loss: 2.4427576065063477\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 65, batch train loss: 2.3214704990386963\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 66, batch train loss: 2.3732779026031494\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 67, batch train loss: 2.529472589492798\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 68, batch train loss: 2.0317299365997314\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 69, batch train loss: 2.7463037967681885\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 70, batch train loss: 1.9713879823684692\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 71, batch train loss: 2.3325681686401367\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 72, batch train loss: 1.7102802991867065\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 73, batch train loss: 1.8629919290542603\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 74, batch train loss: 1.554344654083252\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 75, batch train loss: 1.7251031398773193\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 76, batch train loss: 1.805321216583252\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 77, batch train loss: 2.2507681846618652\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 78, batch train loss: 1.8912162780761719\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 79, batch train loss: 2.575265407562256\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 80, batch train loss: 1.8948166370391846\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 81, batch train loss: 3.2266297340393066\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 82, batch train loss: 2.423450231552124\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 83, batch train loss: 2.5291311740875244\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 84, batch train loss: 3.55863356590271\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 85, batch train loss: 2.239075183868408\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 86, batch train loss: 3.4174020290374756\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 87, batch train loss: 2.6733651161193848\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 88, batch train loss: 2.5049283504486084\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 89, batch train loss: 3.1053898334503174\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 90, batch train loss: 2.35410737991333\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 91, batch train loss: 2.1882071495056152\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 92, batch train loss: 3.480299949645996\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 93, batch train loss: 2.1074419021606445\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 94, batch train loss: 3.724957227706909\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 95, batch train loss: 3.003438949584961\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 96, batch train loss: 2.0267345905303955\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 97, batch train loss: 2.5555336475372314\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 98, batch train loss: 1.8089414834976196\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 99, batch train loss: 2.2330126762390137\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 100, batch train loss: 1.6685866117477417\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 101, batch train loss: 1.6770602464675903\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 102, batch train loss: 1.999815821647644\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 103, batch train loss: 1.539842128753662\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 104, batch train loss: 1.4856986999511719\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 105, batch train loss: 2.4016828536987305\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 106, batch train loss: 2.0531742572784424\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 107, batch train loss: 1.6781834363937378\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 108, batch train loss: 1.7829684019088745\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 109, batch train loss: 1.4720598459243774\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 110, batch train loss: 2.2554945945739746\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 111, batch train loss: 2.2673864364624023\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 112, batch train loss: 1.9223272800445557\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 113, batch train loss: 1.5477839708328247\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 114, batch train loss: 1.8941161632537842\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 115, batch train loss: 3.4195995330810547\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 116, batch train loss: 2.0420517921447754\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 117, batch train loss: 2.4696693420410156\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 118, batch train loss: 2.402921676635742\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 119, batch train loss: 2.499830961227417\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 120, batch train loss: 2.5784904956817627\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 121, batch train loss: 2.5886306762695312\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 122, batch train loss: 1.7380270957946777\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 123, batch train loss: 2.937661647796631\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 124, batch train loss: 1.8591302633285522\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 125, batch train loss: 1.7563387155532837\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 126, batch train loss: 1.6146937608718872\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 127, batch train loss: 1.7811570167541504\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 128, batch train loss: 2.091336727142334\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 129, batch train loss: 3.8356847763061523\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, batch_id: 130, batch train loss: 1.9177545309066772\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 131, batch train loss: 2.1780261993408203\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 132, batch train loss: 3.0866129398345947\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 133, batch train loss: 2.521547794342041\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 134, batch train loss: 3.0064072608947754\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 135, batch train loss: 4.832687854766846\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 136, batch train loss: 2.574667453765869\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 137, batch train loss: 3.8516714572906494\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 138, batch train loss: 4.536186695098877\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 139, batch train loss: 2.3568179607391357\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 140, batch train loss: 2.900277614593506\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 141, batch train loss: 2.2892937660217285\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 142, batch train loss: 2.2802069187164307\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 143, batch train loss: 2.5734899044036865\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 144, batch train loss: 2.4499223232269287\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 145, batch train loss: 2.5143866539001465\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 146, batch train loss: 2.3623948097229004\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 147, batch train loss: 1.8806239366531372\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 148, batch train loss: 2.115321397781372\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 149, batch train loss: 2.0295019149780273\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 150, batch train loss: 2.1890225410461426\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 151, batch train loss: 2.5723302364349365\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 152, batch train loss: 2.058030843734741\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 153, batch train loss: 1.8729140758514404\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 154, batch train loss: 1.4045130014419556\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 155, batch train loss: 1.7542649507522583\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 156, batch train loss: 2.3252956867218018\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 157, batch train loss: 2.959439277648926\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 158, batch train loss: 2.1737539768218994\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 159, batch train loss: 2.33313250541687\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 160, batch train loss: 2.7946696281433105\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 161, batch train loss: 2.701279878616333\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 162, batch train loss: 1.8962011337280273\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 163, batch train loss: 2.118854284286499\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 164, batch train loss: 2.0338423252105713\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 165, batch train loss: 1.7462811470031738\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 166, batch train loss: 1.92022705078125\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 167, batch train loss: 1.361870288848877\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 168, batch train loss: 1.520526647567749\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 169, batch train loss: 1.6772663593292236\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 170, batch train loss: 2.2052910327911377\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 171, batch train loss: 1.6698534488677979\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 172, batch train loss: 2.222928524017334\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 173, batch train loss: 1.8513089418411255\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 174, batch train loss: 1.936675786972046\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 175, batch train loss: 1.8858832120895386\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 176, batch train loss: 2.338858127593994\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 177, batch train loss: 2.7430131435394287\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 178, batch train loss: 2.7476890087127686\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 179, batch train loss: 3.4873828887939453\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 180, batch train loss: 2.0949273109436035\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 181, batch train loss: 2.726567268371582\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 182, batch train loss: 2.1202735900878906\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 183, batch train loss: 1.9625920057296753\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 184, batch train loss: 1.6341394186019897\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 185, batch train loss: 1.5435128211975098\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 186, batch train loss: 2.1386232376098633\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 187, batch train loss: 1.8284108638763428\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 188, batch train loss: 1.511877179145813\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 189, batch train loss: 1.7575242519378662\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 190, batch train loss: 1.4042538404464722\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 191, batch train loss: 1.6915816068649292\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 192, batch train loss: 1.5043489933013916\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 193, batch train loss: 1.422135829925537\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 194, batch train loss: 2.2057089805603027\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 195, batch train loss: 1.310395359992981\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 196, batch train loss: 1.6293307542800903\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 197, batch train loss: 1.694732904434204\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 198, batch train loss: 2.182173490524292\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 199, batch train loss: 1.946798324584961\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 200, batch train loss: 1.4926241636276245\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 201, batch train loss: 1.7167181968688965\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 202, batch train loss: 1.2323721647262573\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 203, batch train loss: 1.4047808647155762\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 204, batch train loss: 1.193231463432312\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 205, batch train loss: 1.7455170154571533\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 206, batch train loss: 1.8379536867141724\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 207, batch train loss: 1.6959712505340576\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 208, batch train loss: 2.0139896869659424\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 209, batch train loss: 2.035571336746216\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 210, batch train loss: 2.798616647720337\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 211, batch train loss: 3.2024238109588623\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 212, batch train loss: 2.3000364303588867\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 213, batch train loss: 4.490175247192383\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 214, batch train loss: 4.020376205444336\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 215, batch train loss: 2.1990530490875244\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 216, batch train loss: 3.5209908485412598\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 217, batch train loss: 3.8505282402038574\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 218, batch train loss: 2.0807409286499023\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 219, batch train loss: 2.677325963973999\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 220, batch train loss: 4.760428428649902\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 221, batch train loss: 3.2414329051971436\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 222, batch train loss: 2.1099839210510254\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 223, batch train loss: 2.2949447631835938\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 224, batch train loss: 2.4702951908111572\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 225, batch train loss: 3.194037437438965\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 226, batch train loss: 1.9209743738174438\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 227, batch train loss: 2.4393415451049805\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 228, batch train loss: 2.5358777046203613\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 229, batch train loss: 3.3677639961242676\n",
      "\n",
      "\n",
      "Epoch: 26, batch_id: 230, batch train loss: 2.593479633331299\n",
      "\n",
      "\n",
      "Epoch: 26/ 100, Loss: 2.351204356421595\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:13<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 Validation Loss: 2.3800163745880125\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 27, batch_id: 1, batch train loss: 2.277838706970215\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 2, batch train loss: 3.121528387069702\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 3, batch train loss: 2.0145392417907715\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 4, batch train loss: 3.6107280254364014\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 5, batch train loss: 2.880021572113037\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 6, batch train loss: 3.4309473037719727\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 7, batch train loss: 2.793499231338501\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 8, batch train loss: 1.9577209949493408\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 9, batch train loss: 2.9244983196258545\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 10, batch train loss: 1.9722263813018799\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 11, batch train loss: 1.6717356443405151\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 12, batch train loss: 2.0729894638061523\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 13, batch train loss: 1.4377386569976807\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 14, batch train loss: 3.2038707733154297\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 15, batch train loss: 1.9880448579788208\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 16, batch train loss: 2.8172554969787598\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 17, batch train loss: 2.269829273223877\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 18, batch train loss: 2.7273433208465576\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 19, batch train loss: 3.3493239879608154\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 20, batch train loss: 3.2891030311584473\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 21, batch train loss: 2.0664045810699463\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 22, batch train loss: 4.054887294769287\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 23, batch train loss: 2.277376651763916\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 24, batch train loss: 2.8280718326568604\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 25, batch train loss: 4.918310165405273\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 26, batch train loss: 2.2058329582214355\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 27, batch train loss: 2.8154914379119873\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 28, batch train loss: 3.149418354034424\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 29, batch train loss: 2.259486198425293\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 30, batch train loss: 2.4880778789520264\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 31, batch train loss: 1.839375615119934\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 32, batch train loss: 2.269174098968506\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 33, batch train loss: 2.2271251678466797\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 34, batch train loss: 2.5031023025512695\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 35, batch train loss: 1.9293383359909058\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 36, batch train loss: 2.7281017303466797\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 37, batch train loss: 2.0203940868377686\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 38, batch train loss: 1.8370387554168701\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 39, batch train loss: 2.5223143100738525\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 40, batch train loss: 1.5892105102539062\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 41, batch train loss: 2.5189454555511475\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 42, batch train loss: 2.3123886585235596\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 43, batch train loss: 2.1985416412353516\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 44, batch train loss: 2.0712296962738037\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 45, batch train loss: 1.7889400720596313\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 46, batch train loss: 2.083087921142578\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 47, batch train loss: 1.391237735748291\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 48, batch train loss: 1.4919131994247437\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 49, batch train loss: 2.402916669845581\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 50, batch train loss: 1.8522217273712158\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 51, batch train loss: 2.455734968185425\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 52, batch train loss: 1.5360329151153564\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 53, batch train loss: 1.7802486419677734\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 54, batch train loss: 1.6261959075927734\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 55, batch train loss: 1.874407172203064\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 56, batch train loss: 1.9883898496627808\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 57, batch train loss: 1.8739217519760132\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 58, batch train loss: 1.5735923051834106\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 59, batch train loss: 1.56525719165802\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 60, batch train loss: 1.9429782629013062\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 61, batch train loss: 1.8340439796447754\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 62, batch train loss: 1.5229547023773193\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 63, batch train loss: 1.9945675134658813\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 64, batch train loss: 1.7061604261398315\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 65, batch train loss: 1.815049409866333\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 66, batch train loss: 1.5829187631607056\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 67, batch train loss: 1.7468091249465942\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 68, batch train loss: 1.6065552234649658\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 69, batch train loss: 1.5422290563583374\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 70, batch train loss: 2.603581666946411\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 71, batch train loss: 2.0277833938598633\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 72, batch train loss: 2.553983688354492\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 73, batch train loss: 2.265888214111328\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 74, batch train loss: 2.626678466796875\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 75, batch train loss: 1.8426378965377808\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 76, batch train loss: 2.4736368656158447\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 77, batch train loss: 2.0472216606140137\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 78, batch train loss: 1.8319183588027954\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 79, batch train loss: 1.3663028478622437\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 80, batch train loss: 2.899226665496826\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 81, batch train loss: 1.8420830965042114\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 82, batch train loss: 2.1175737380981445\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 83, batch train loss: 2.0496909618377686\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 84, batch train loss: 1.7933547496795654\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 85, batch train loss: 1.678886890411377\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 86, batch train loss: 3.051453113555908\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 87, batch train loss: 1.7738810777664185\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 88, batch train loss: 2.051622152328491\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 89, batch train loss: 2.6050479412078857\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 90, batch train loss: 2.231050968170166\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 91, batch train loss: 1.8446272611618042\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 92, batch train loss: 2.5277295112609863\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 93, batch train loss: 2.292102813720703\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 94, batch train loss: 1.4243344068527222\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 95, batch train loss: 2.448927164077759\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 96, batch train loss: 1.7927852869033813\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 97, batch train loss: 2.4011447429656982\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 98, batch train loss: 2.1441195011138916\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 99, batch train loss: 2.1175155639648438\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 100, batch train loss: 1.697272539138794\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 101, batch train loss: 1.7030112743377686\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 102, batch train loss: 1.6914680004119873\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 103, batch train loss: 2.1210849285125732\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 104, batch train loss: 1.7279090881347656\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 105, batch train loss: 1.6401013135910034\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 106, batch train loss: 1.8944993019104004\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 107, batch train loss: 2.3360936641693115\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 108, batch train loss: 1.6396607160568237\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 109, batch train loss: 2.158642053604126\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 110, batch train loss: 1.7918107509613037\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 111, batch train loss: 1.643973469734192\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 112, batch train loss: 1.9598662853240967\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 113, batch train loss: 2.8229877948760986\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 114, batch train loss: 1.807180404663086\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 115, batch train loss: 2.160003900527954\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 116, batch train loss: 2.2634172439575195\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 117, batch train loss: 1.4738441705703735\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 118, batch train loss: 2.353239059448242\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 119, batch train loss: 2.244659185409546\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 120, batch train loss: 1.7185145616531372\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 121, batch train loss: 2.211740016937256\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 122, batch train loss: 1.9754846096038818\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 123, batch train loss: 2.926283121109009\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 124, batch train loss: 2.0107691287994385\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 125, batch train loss: 2.722317695617676\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 126, batch train loss: 2.030745029449463\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 127, batch train loss: 1.806728482246399\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, batch_id: 128, batch train loss: 3.026294231414795\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 129, batch train loss: 2.732266664505005\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 130, batch train loss: 3.6732161045074463\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 131, batch train loss: 3.5385546684265137\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 132, batch train loss: 2.6010217666625977\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 133, batch train loss: 2.9744348526000977\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 134, batch train loss: 1.9518522024154663\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 135, batch train loss: 2.266078472137451\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 136, batch train loss: 2.2238073348999023\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 137, batch train loss: 2.4509079456329346\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 138, batch train loss: 2.6641485691070557\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 139, batch train loss: 2.412991523742676\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 140, batch train loss: 1.9590353965759277\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 141, batch train loss: 1.6860299110412598\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 142, batch train loss: 2.0708062648773193\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 143, batch train loss: 1.5337306261062622\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 144, batch train loss: 1.7370951175689697\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 145, batch train loss: 1.5236326456069946\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 146, batch train loss: 1.5810370445251465\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 147, batch train loss: 1.4621950387954712\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 148, batch train loss: 2.2405989170074463\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 149, batch train loss: 1.827308177947998\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 150, batch train loss: 1.8116472959518433\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 151, batch train loss: 2.3077821731567383\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 152, batch train loss: 2.1939826011657715\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 153, batch train loss: 3.9165430068969727\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 154, batch train loss: 3.644338369369507\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 155, batch train loss: 2.7537341117858887\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 156, batch train loss: 3.5807201862335205\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 157, batch train loss: 3.4999914169311523\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 158, batch train loss: 2.7659411430358887\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 159, batch train loss: 3.2233474254608154\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 160, batch train loss: 2.8847496509552\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 161, batch train loss: 3.7798869609832764\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 162, batch train loss: 2.3337810039520264\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 163, batch train loss: 2.5164616107940674\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 164, batch train loss: 2.914201021194458\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 165, batch train loss: 2.992882013320923\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 166, batch train loss: 2.5972225666046143\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 167, batch train loss: 2.7199251651763916\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 168, batch train loss: 2.145019054412842\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 169, batch train loss: 2.5239763259887695\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 170, batch train loss: 1.6850194931030273\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 171, batch train loss: 2.050906181335449\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 172, batch train loss: 2.4664366245269775\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 173, batch train loss: 3.434769630432129\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 174, batch train loss: 2.59885311126709\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 175, batch train loss: 1.9609075784683228\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 176, batch train loss: 1.9387598037719727\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 177, batch train loss: 2.958311080932617\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 178, batch train loss: 2.156888723373413\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 179, batch train loss: 2.331510543823242\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 180, batch train loss: 1.7940207719802856\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 181, batch train loss: 2.8822124004364014\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 182, batch train loss: 2.8714215755462646\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 183, batch train loss: 2.792656898498535\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 184, batch train loss: 2.1747822761535645\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 185, batch train loss: 2.1853435039520264\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 186, batch train loss: 2.0416016578674316\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 187, batch train loss: 2.503695011138916\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 188, batch train loss: 2.572061777114868\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 189, batch train loss: 3.2082009315490723\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 190, batch train loss: 3.1298117637634277\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 191, batch train loss: 3.168628692626953\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 192, batch train loss: 2.050769329071045\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 193, batch train loss: 3.074404001235962\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 194, batch train loss: 3.007875680923462\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 195, batch train loss: 2.1048619747161865\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 196, batch train loss: 2.0288619995117188\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 197, batch train loss: 1.834706425666809\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 198, batch train loss: 1.8997806310653687\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 199, batch train loss: 2.0196914672851562\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 200, batch train loss: 1.4734749794006348\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 201, batch train loss: 2.2266852855682373\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 202, batch train loss: 2.0210652351379395\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 203, batch train loss: 2.140624523162842\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 204, batch train loss: 1.9299572706222534\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 205, batch train loss: 1.8189921379089355\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 206, batch train loss: 1.9888614416122437\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 207, batch train loss: 1.4759286642074585\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 208, batch train loss: 2.3516573905944824\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 209, batch train loss: 1.6487325429916382\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 210, batch train loss: 1.5327624082565308\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 211, batch train loss: 1.9179538488388062\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 212, batch train loss: 1.559569239616394\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 213, batch train loss: 1.562235951423645\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 214, batch train loss: 2.062175989151001\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 215, batch train loss: 1.5004087686538696\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 216, batch train loss: 1.7809356451034546\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 217, batch train loss: 1.983504056930542\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 218, batch train loss: 1.4998385906219482\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 219, batch train loss: 1.8487986326217651\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 220, batch train loss: 1.5881085395812988\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 221, batch train loss: 1.4378325939178467\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 222, batch train loss: 1.462094783782959\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 223, batch train loss: 1.292817234992981\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 224, batch train loss: 1.1760265827178955\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 225, batch train loss: 1.6814991235733032\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 226, batch train loss: 1.5735970735549927\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 227, batch train loss: 1.4452593326568604\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 228, batch train loss: 1.7239298820495605\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 229, batch train loss: 1.3416531085968018\n",
      "\n",
      "\n",
      "Epoch: 27, batch_id: 230, batch train loss: 2.032910108566284\n",
      "\n",
      "\n",
      "Epoch: 27/ 100, Loss: 2.2196943583695785\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:17<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 Validation Loss: 1.7572203954060872\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 28, batch_id: 1, batch train loss: 1.5433810949325562\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 2, batch train loss: 1.6638870239257812\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 3, batch train loss: 1.5425748825073242\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 4, batch train loss: 1.3923434019088745\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 5, batch train loss: 1.2216377258300781\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 6, batch train loss: 2.1013805866241455\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 7, batch train loss: 1.7091078758239746\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 8, batch train loss: 2.048471689224243\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 9, batch train loss: 1.851349115371704\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 10, batch train loss: 1.8787654638290405\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 11, batch train loss: 2.8417954444885254\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 12, batch train loss: 2.1767663955688477\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 13, batch train loss: 2.066189765930176\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 14, batch train loss: 2.997220516204834\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 15, batch train loss: 2.8469245433807373\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 16, batch train loss: 2.4762845039367676\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 17, batch train loss: 2.062626361846924\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 18, batch train loss: 2.319744825363159\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 19, batch train loss: 2.472860813140869\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 20, batch train loss: 1.7458314895629883\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 21, batch train loss: 3.651385545730591\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 22, batch train loss: 2.0063343048095703\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 23, batch train loss: 3.5645971298217773\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 24, batch train loss: 2.4005846977233887\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 25, batch train loss: 2.851130485534668\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 26, batch train loss: 2.9635612964630127\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 27, batch train loss: 2.4565584659576416\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 28, batch train loss: 3.4865119457244873\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 29, batch train loss: 1.9489132165908813\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 30, batch train loss: 4.153006076812744\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 31, batch train loss: 5.275500297546387\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 32, batch train loss: 3.235419511795044\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 33, batch train loss: 2.178220748901367\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 34, batch train loss: 3.0923397541046143\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 35, batch train loss: 2.000088930130005\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 36, batch train loss: 4.398648738861084\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 37, batch train loss: 3.514634132385254\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 38, batch train loss: 2.9277961254119873\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 39, batch train loss: 2.7127928733825684\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 40, batch train loss: 2.2555124759674072\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 41, batch train loss: 2.290156602859497\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 42, batch train loss: 1.9592074155807495\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 43, batch train loss: 2.0766005516052246\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 44, batch train loss: 2.0154170989990234\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 45, batch train loss: 2.121692180633545\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 46, batch train loss: 2.0621650218963623\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 47, batch train loss: 2.1753034591674805\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 48, batch train loss: 1.7951737642288208\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 49, batch train loss: 2.6339635848999023\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 50, batch train loss: 2.7070584297180176\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 51, batch train loss: 1.859225869178772\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 52, batch train loss: 1.9951558113098145\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 53, batch train loss: 1.8075170516967773\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 54, batch train loss: 1.7752280235290527\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 55, batch train loss: 2.0728886127471924\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 56, batch train loss: 2.6782617568969727\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 57, batch train loss: 2.9005959033966064\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 58, batch train loss: 2.519289970397949\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 59, batch train loss: 3.3229753971099854\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 60, batch train loss: 3.1274940967559814\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 61, batch train loss: 2.875303268432617\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 62, batch train loss: 1.692171335220337\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 63, batch train loss: 2.2987060546875\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 64, batch train loss: 2.530329704284668\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 65, batch train loss: 1.9909394979476929\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 66, batch train loss: 3.7395873069763184\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 67, batch train loss: 2.178412914276123\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 68, batch train loss: 2.834444999694824\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 69, batch train loss: 2.2882392406463623\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 70, batch train loss: 2.662868022918701\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 71, batch train loss: 2.527454137802124\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 72, batch train loss: 3.041335344314575\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 73, batch train loss: 2.440035104751587\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 74, batch train loss: 3.039268970489502\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 75, batch train loss: 3.197094678878784\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 76, batch train loss: 2.393078327178955\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 77, batch train loss: 2.419414520263672\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 78, batch train loss: 2.0019235610961914\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 79, batch train loss: 2.1114938259124756\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 80, batch train loss: 2.144526481628418\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 81, batch train loss: 2.102621555328369\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 82, batch train loss: 1.687233328819275\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 83, batch train loss: 1.9254236221313477\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 84, batch train loss: 2.2587785720825195\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 85, batch train loss: 2.300034284591675\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 86, batch train loss: 1.8299312591552734\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 87, batch train loss: 2.338550329208374\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 88, batch train loss: 2.7014737129211426\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 89, batch train loss: 2.7795917987823486\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 90, batch train loss: 1.9795771837234497\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 91, batch train loss: 2.739194631576538\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 92, batch train loss: 3.0913491249084473\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 93, batch train loss: 2.4773738384246826\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 94, batch train loss: 3.002337694168091\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 95, batch train loss: 2.3251442909240723\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 96, batch train loss: 2.850144863128662\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 97, batch train loss: 2.3296940326690674\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 98, batch train loss: 2.581953763961792\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 99, batch train loss: 1.6791001558303833\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 100, batch train loss: 2.462160348892212\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 101, batch train loss: 1.9453004598617554\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 102, batch train loss: 2.605360507965088\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 103, batch train loss: 2.065319299697876\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 104, batch train loss: 3.1294755935668945\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 105, batch train loss: 2.541924476623535\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 106, batch train loss: 2.21177077293396\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 107, batch train loss: 2.6129226684570312\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 108, batch train loss: 2.026904821395874\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 109, batch train loss: 3.3889553546905518\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 110, batch train loss: 2.479663372039795\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 111, batch train loss: 2.8927152156829834\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 112, batch train loss: 3.603510856628418\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 113, batch train loss: 2.2501258850097656\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 114, batch train loss: 2.9498238563537598\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 115, batch train loss: 4.36331844329834\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 116, batch train loss: 1.8865779638290405\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 117, batch train loss: 4.800690174102783\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 118, batch train loss: 3.654348134994507\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 119, batch train loss: 2.8658130168914795\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 120, batch train loss: 2.7035701274871826\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 121, batch train loss: 2.345794439315796\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 122, batch train loss: 6.438833236694336\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 123, batch train loss: 2.3100414276123047\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 124, batch train loss: 5.044881343841553\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 125, batch train loss: 2.7261011600494385\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 126, batch train loss: 2.610959529876709\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 127, batch train loss: 3.798053503036499\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, batch_id: 128, batch train loss: 3.2314627170562744\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 129, batch train loss: 3.043720006942749\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 130, batch train loss: 2.604778289794922\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 131, batch train loss: 1.6385467052459717\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 132, batch train loss: 3.141085147857666\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 133, batch train loss: 3.056403875350952\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 134, batch train loss: 4.1228485107421875\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 135, batch train loss: 3.1587462425231934\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 136, batch train loss: 2.6313583850860596\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 137, batch train loss: 3.8196589946746826\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 138, batch train loss: 2.435885429382324\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 139, batch train loss: 3.0644378662109375\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 140, batch train loss: 3.652297258377075\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 141, batch train loss: 2.446756601333618\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 142, batch train loss: 2.6061511039733887\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 143, batch train loss: 3.116780996322632\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 144, batch train loss: 2.58915376663208\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 145, batch train loss: 3.232064723968506\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 146, batch train loss: 2.276944875717163\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 147, batch train loss: 2.2539892196655273\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 148, batch train loss: 2.6356353759765625\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 149, batch train loss: 2.253202199935913\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 150, batch train loss: 2.335034132003784\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 151, batch train loss: 2.765023708343506\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 152, batch train loss: 2.184971570968628\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 153, batch train loss: 2.135437488555908\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 154, batch train loss: 2.0218794345855713\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 155, batch train loss: 1.9483613967895508\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 156, batch train loss: 2.200356960296631\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 157, batch train loss: 1.9493799209594727\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 158, batch train loss: 2.3781979084014893\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 159, batch train loss: 1.951815128326416\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 160, batch train loss: 1.7389745712280273\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 161, batch train loss: 2.6321473121643066\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 162, batch train loss: 2.1251800060272217\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 163, batch train loss: 2.2714529037475586\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 164, batch train loss: 1.8555251359939575\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 165, batch train loss: 1.7654775381088257\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 166, batch train loss: 1.3678228855133057\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 167, batch train loss: 2.4497604370117188\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 168, batch train loss: 2.005805253982544\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 169, batch train loss: 2.5745787620544434\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 170, batch train loss: 2.129119396209717\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 171, batch train loss: 2.062316417694092\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 172, batch train loss: 2.303443193435669\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 173, batch train loss: 1.8196914196014404\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 174, batch train loss: 1.826165795326233\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 175, batch train loss: 2.042783498764038\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 176, batch train loss: 1.9903143644332886\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 177, batch train loss: 1.8170802593231201\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 178, batch train loss: 1.5727962255477905\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 179, batch train loss: 1.758565068244934\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 180, batch train loss: 2.114429473876953\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 181, batch train loss: 1.6441532373428345\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 182, batch train loss: 2.031275987625122\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 183, batch train loss: 1.7078922986984253\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 184, batch train loss: 1.6960529088974\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 185, batch train loss: 1.4469236135482788\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 186, batch train loss: 1.390174388885498\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 187, batch train loss: 2.1914682388305664\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 188, batch train loss: 1.6170631647109985\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 189, batch train loss: 2.0284152030944824\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 190, batch train loss: 1.5226093530654907\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 191, batch train loss: 2.5037922859191895\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 192, batch train loss: 1.756584882736206\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 193, batch train loss: 2.512443780899048\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 194, batch train loss: 1.984155297279358\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 195, batch train loss: 2.47725248336792\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 196, batch train loss: 4.431671619415283\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 197, batch train loss: 2.044595241546631\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 198, batch train loss: 3.210031747817993\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 199, batch train loss: 2.2228877544403076\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 200, batch train loss: 3.416494131088257\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 201, batch train loss: 4.201408386230469\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 202, batch train loss: 3.109398365020752\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 203, batch train loss: 3.8312509059906006\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 204, batch train loss: 2.4836905002593994\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 205, batch train loss: 2.8098485469818115\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 206, batch train loss: 2.475036144256592\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 207, batch train loss: 1.904700756072998\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 208, batch train loss: 2.537651538848877\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 209, batch train loss: 1.842586874961853\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 210, batch train loss: 2.4681386947631836\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 211, batch train loss: 1.5153226852416992\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 212, batch train loss: 1.519189715385437\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 213, batch train loss: 2.145087957382202\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 214, batch train loss: 2.003208875656128\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 215, batch train loss: 1.6865414381027222\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 216, batch train loss: 1.7158300876617432\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 217, batch train loss: 1.6401127576828003\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 218, batch train loss: 1.687809944152832\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 219, batch train loss: 1.5011138916015625\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 220, batch train loss: 2.008863925933838\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 221, batch train loss: 1.566625952720642\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 222, batch train loss: 1.322744607925415\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 223, batch train loss: 1.4958924055099487\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 224, batch train loss: 1.8911129236221313\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 225, batch train loss: 2.0926711559295654\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 226, batch train loss: 1.7251633405685425\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 227, batch train loss: 2.407090663909912\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 228, batch train loss: 2.1499860286712646\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 229, batch train loss: 2.519817590713501\n",
      "\n",
      "\n",
      "Epoch: 28, batch_id: 230, batch train loss: 1.8867555856704712\n",
      "\n",
      "\n",
      "Epoch: 28/ 100, Loss: 2.4483282084050386\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:09<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 Validation Loss: 2.088045730193456\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, batch_id: 1, batch train loss: 1.936279535293579\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 2, batch train loss: 2.1597683429718018\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 3, batch train loss: 2.0290589332580566\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 4, batch train loss: 2.9227867126464844\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 5, batch train loss: 2.522341012954712\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 6, batch train loss: 3.165936231613159\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 7, batch train loss: 2.859861135482788\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 8, batch train loss: 2.6147327423095703\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 9, batch train loss: 3.2202823162078857\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 10, batch train loss: 2.347050666809082\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 11, batch train loss: 2.084676742553711\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 12, batch train loss: 1.6806501150131226\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 13, batch train loss: 1.7242964506149292\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 14, batch train loss: 2.049826145172119\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 15, batch train loss: 1.8195300102233887\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 16, batch train loss: 1.740441918373108\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 17, batch train loss: 1.8528261184692383\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 18, batch train loss: 1.716613531112671\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 19, batch train loss: 2.208085536956787\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 20, batch train loss: 1.9816410541534424\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 21, batch train loss: 2.2045724391937256\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 22, batch train loss: 1.8508208990097046\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 23, batch train loss: 1.8701471090316772\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 24, batch train loss: 1.8159853219985962\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 25, batch train loss: 2.10868763923645\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 26, batch train loss: 1.711405873298645\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 27, batch train loss: 1.6811491250991821\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 28, batch train loss: 1.6360095739364624\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 29, batch train loss: 2.045151710510254\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 30, batch train loss: 2.2386412620544434\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 31, batch train loss: 1.911344051361084\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 32, batch train loss: 1.3855841159820557\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 33, batch train loss: 1.6557865142822266\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 34, batch train loss: 1.5053749084472656\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 35, batch train loss: 1.8278714418411255\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 36, batch train loss: 1.7510387897491455\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 37, batch train loss: 1.5482548475265503\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 38, batch train loss: 1.7127866744995117\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 39, batch train loss: 1.4422874450683594\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 40, batch train loss: 1.8692244291305542\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 41, batch train loss: 1.7353792190551758\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 42, batch train loss: 2.122222661972046\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 43, batch train loss: 2.1030309200286865\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 44, batch train loss: 2.5734949111938477\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 45, batch train loss: 1.9087581634521484\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 46, batch train loss: 2.0565123558044434\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 47, batch train loss: 2.1229355335235596\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 48, batch train loss: 2.4877266883850098\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 49, batch train loss: 2.1898698806762695\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 50, batch train loss: 1.9118090867996216\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 51, batch train loss: 1.7557709217071533\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 52, batch train loss: 1.7370643615722656\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 53, batch train loss: 1.8573966026306152\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 54, batch train loss: 1.6940587759017944\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 55, batch train loss: 2.759810209274292\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 56, batch train loss: 3.204110622406006\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 57, batch train loss: 2.382899284362793\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 58, batch train loss: 2.468719720840454\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 59, batch train loss: 2.269265651702881\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 60, batch train loss: 2.0994088649749756\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 61, batch train loss: 2.280653238296509\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 62, batch train loss: 1.970367431640625\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 63, batch train loss: 1.9646568298339844\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 64, batch train loss: 2.03934907913208\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 65, batch train loss: 1.9657416343688965\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 66, batch train loss: 2.3538997173309326\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 67, batch train loss: 2.479870080947876\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 68, batch train loss: 2.3413147926330566\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 69, batch train loss: 2.7675321102142334\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 70, batch train loss: 2.5892226696014404\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 71, batch train loss: 2.3661949634552\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 72, batch train loss: 1.9499906301498413\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 73, batch train loss: 1.9144673347473145\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 74, batch train loss: 2.159398317337036\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 75, batch train loss: 2.6881346702575684\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 76, batch train loss: 2.6841492652893066\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 77, batch train loss: 1.9549859762191772\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 78, batch train loss: 2.666156768798828\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 79, batch train loss: 2.116647481918335\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 80, batch train loss: 1.8680177927017212\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 81, batch train loss: 2.246095895767212\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 82, batch train loss: 2.1639883518218994\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 83, batch train loss: 2.1307246685028076\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 84, batch train loss: 2.1973111629486084\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 85, batch train loss: 1.7466520071029663\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 86, batch train loss: 1.6985331773757935\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 87, batch train loss: 1.606461524963379\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 88, batch train loss: 1.700101375579834\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 89, batch train loss: 1.482155680656433\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 90, batch train loss: 1.5542362928390503\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 91, batch train loss: 1.8644291162490845\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 92, batch train loss: 1.7605210542678833\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 93, batch train loss: 1.5095062255859375\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 94, batch train loss: 1.7706347703933716\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 95, batch train loss: 2.103947162628174\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 96, batch train loss: 1.5482902526855469\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 97, batch train loss: 1.9673278331756592\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 98, batch train loss: 2.7806811332702637\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 99, batch train loss: 1.8064402341842651\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 100, batch train loss: 2.1430575847625732\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 101, batch train loss: 2.4752485752105713\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 102, batch train loss: 2.2594246864318848\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 103, batch train loss: 2.0529847145080566\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 104, batch train loss: 2.3911499977111816\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 105, batch train loss: 2.084712505340576\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 106, batch train loss: 1.9945526123046875\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 107, batch train loss: 2.0084898471832275\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 108, batch train loss: 1.9659600257873535\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 109, batch train loss: 1.6131844520568848\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 110, batch train loss: 1.8962080478668213\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 111, batch train loss: 2.295412063598633\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 112, batch train loss: 2.015383720397949\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 113, batch train loss: 1.5989400148391724\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 114, batch train loss: 2.3017444610595703\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 115, batch train loss: 1.782928705215454\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 116, batch train loss: 2.2101333141326904\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 117, batch train loss: 1.9435240030288696\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 118, batch train loss: 2.4988114833831787\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 119, batch train loss: 1.6680680513381958\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 120, batch train loss: 2.2404727935791016\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 121, batch train loss: 1.8061745166778564\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 122, batch train loss: 1.9909714460372925\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 123, batch train loss: 2.1079108715057373\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 124, batch train loss: 3.290144681930542\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 125, batch train loss: 2.6449203491210938\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 126, batch train loss: 2.75148606300354\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 127, batch train loss: 2.4991018772125244\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 128, batch train loss: 2.985943078994751\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 129, batch train loss: 2.295074462890625\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, batch_id: 130, batch train loss: 3.234008312225342\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 131, batch train loss: 2.6973299980163574\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 132, batch train loss: 2.4041764736175537\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 133, batch train loss: 2.202014684677124\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 134, batch train loss: 1.987074613571167\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 135, batch train loss: 1.8349509239196777\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 136, batch train loss: 2.095911979675293\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 137, batch train loss: 3.1133928298950195\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 138, batch train loss: 1.8679190874099731\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 139, batch train loss: 2.9887614250183105\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 140, batch train loss: 2.283334255218506\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 141, batch train loss: 2.5662972927093506\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 142, batch train loss: 1.7138692140579224\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 143, batch train loss: 1.990752100944519\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 144, batch train loss: 1.6794917583465576\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 145, batch train loss: 1.890777349472046\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 146, batch train loss: 2.674581527709961\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 147, batch train loss: 2.281824827194214\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 148, batch train loss: 1.889051079750061\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 149, batch train loss: 2.828402280807495\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 150, batch train loss: 2.8582265377044678\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 151, batch train loss: 2.3405613899230957\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 152, batch train loss: 3.0424299240112305\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 153, batch train loss: 2.444406270980835\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 154, batch train loss: 2.219064950942993\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 155, batch train loss: 2.2012641429901123\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 156, batch train loss: 2.1329329013824463\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 157, batch train loss: 2.215038299560547\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 158, batch train loss: 2.5007858276367188\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 159, batch train loss: 1.9794470071792603\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 160, batch train loss: 1.767616629600525\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 161, batch train loss: 1.9845494031906128\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 162, batch train loss: 2.717057943344116\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 163, batch train loss: 1.8360785245895386\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 164, batch train loss: 2.7740068435668945\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 165, batch train loss: 2.241013765335083\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 166, batch train loss: 1.7884916067123413\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 167, batch train loss: 1.9590824842453003\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 168, batch train loss: 1.7206284999847412\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 169, batch train loss: 2.6978697776794434\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 170, batch train loss: 2.1169209480285645\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 171, batch train loss: 2.51505708694458\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 172, batch train loss: 2.177323579788208\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 173, batch train loss: 1.978602647781372\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 174, batch train loss: 2.2376675605773926\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 175, batch train loss: 1.6515167951583862\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 176, batch train loss: 3.813220262527466\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 177, batch train loss: 2.419726610183716\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 178, batch train loss: 2.419132709503174\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 179, batch train loss: 2.4230964183807373\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 180, batch train loss: 2.9882287979125977\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 181, batch train loss: 2.037604570388794\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 182, batch train loss: 1.968423843383789\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 183, batch train loss: 2.2984085083007812\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 184, batch train loss: 2.115741491317749\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 185, batch train loss: 3.097144842147827\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 186, batch train loss: 1.942319393157959\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 187, batch train loss: 1.7906076908111572\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 188, batch train loss: 1.5535409450531006\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 189, batch train loss: 2.997734546661377\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 190, batch train loss: 3.219045639038086\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 191, batch train loss: 2.0967211723327637\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 192, batch train loss: 1.8064744472503662\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 193, batch train loss: 2.4240713119506836\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 194, batch train loss: 2.0808825492858887\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 195, batch train loss: 2.084439277648926\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 196, batch train loss: 1.7234042882919312\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 197, batch train loss: 1.519327998161316\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 198, batch train loss: 3.095749616622925\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 199, batch train loss: 1.8687962293624878\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 200, batch train loss: 2.5736541748046875\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 201, batch train loss: 2.445401906967163\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 202, batch train loss: 1.8116216659545898\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 203, batch train loss: 2.449631690979004\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 204, batch train loss: 1.6848556995391846\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 205, batch train loss: 2.7570438385009766\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 206, batch train loss: 1.9002854824066162\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 207, batch train loss: 2.1391868591308594\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 208, batch train loss: 3.1138131618499756\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 209, batch train loss: 2.27778959274292\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 210, batch train loss: 2.954132318496704\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 211, batch train loss: 2.1359329223632812\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 212, batch train loss: 2.647042989730835\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 213, batch train loss: 2.2054364681243896\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 214, batch train loss: 2.813030242919922\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 215, batch train loss: 3.7421562671661377\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 216, batch train loss: 2.0685019493103027\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 217, batch train loss: 2.906392812728882\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 218, batch train loss: 1.5991127490997314\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 219, batch train loss: 3.8369078636169434\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 220, batch train loss: 3.0963480472564697\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 221, batch train loss: 3.3359320163726807\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 222, batch train loss: 3.1291909217834473\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 223, batch train loss: 3.663616418838501\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 224, batch train loss: 3.5392489433288574\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 225, batch train loss: 3.323090076446533\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 226, batch train loss: 3.75590443611145\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 227, batch train loss: 3.594688653945923\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 228, batch train loss: 3.159930944442749\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 229, batch train loss: 2.9182441234588623\n",
      "\n",
      "\n",
      "Epoch: 29, batch_id: 230, batch train loss: 3.0182507038116455\n",
      "\n",
      "\n",
      "Epoch: 29/ 100, Loss: 2.2483554088551063\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:06<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 Validation Loss: 3.1747796177864074\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, batch_id: 1, batch train loss: 3.8561108112335205\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 2, batch train loss: 4.123208522796631\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 3, batch train loss: 3.0466175079345703\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 4, batch train loss: 3.087221145629883\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 5, batch train loss: 4.283414840698242\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 6, batch train loss: 2.063552141189575\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 7, batch train loss: 3.1333653926849365\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 8, batch train loss: 3.289660692214966\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 9, batch train loss: 2.4698774814605713\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 10, batch train loss: 2.505366563796997\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 11, batch train loss: 2.336442708969116\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 12, batch train loss: 3.2802298069000244\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 13, batch train loss: 1.638474941253662\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 14, batch train loss: 3.0189223289489746\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 15, batch train loss: 2.2360970973968506\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 16, batch train loss: 2.86022686958313\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 17, batch train loss: 2.464923143386841\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 18, batch train loss: 2.37819242477417\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 19, batch train loss: 2.4898064136505127\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 20, batch train loss: 1.8492820262908936\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 21, batch train loss: 2.3774573802948\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 22, batch train loss: 2.944167137145996\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 23, batch train loss: 2.2750473022460938\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 24, batch train loss: 2.3510494232177734\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 25, batch train loss: 2.2824010848999023\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 26, batch train loss: 2.630805015563965\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 27, batch train loss: 2.4129858016967773\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 28, batch train loss: 2.1961472034454346\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 29, batch train loss: 1.997016191482544\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 30, batch train loss: 2.006080150604248\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 31, batch train loss: 2.119990348815918\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 32, batch train loss: 2.261657953262329\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 33, batch train loss: 1.5928375720977783\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 34, batch train loss: 2.646556854248047\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 35, batch train loss: 2.7523319721221924\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 36, batch train loss: 1.4398577213287354\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 37, batch train loss: 1.2477689981460571\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 38, batch train loss: 1.5484007596969604\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 39, batch train loss: 1.2565335035324097\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 40, batch train loss: 1.4223991632461548\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 41, batch train loss: 2.2940657138824463\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 42, batch train loss: 2.429511308670044\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 43, batch train loss: 1.931128740310669\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 44, batch train loss: 1.8637546300888062\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 45, batch train loss: 2.7244069576263428\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 46, batch train loss: 3.200791597366333\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 47, batch train loss: 2.802635908126831\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 48, batch train loss: 2.8938724994659424\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 49, batch train loss: 3.513339042663574\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 50, batch train loss: 2.0306921005249023\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 51, batch train loss: 4.353885650634766\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 52, batch train loss: 3.262600898742676\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 53, batch train loss: 2.670764684677124\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 54, batch train loss: 2.3959310054779053\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 55, batch train loss: 2.328374147415161\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 56, batch train loss: 3.193641424179077\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 57, batch train loss: 2.5745561122894287\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 58, batch train loss: 2.5100080966949463\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 59, batch train loss: 2.233535051345825\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 60, batch train loss: 2.7856624126434326\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 61, batch train loss: 2.6586544513702393\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 62, batch train loss: 1.963128924369812\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 63, batch train loss: 4.636038303375244\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 64, batch train loss: 2.308612108230591\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 65, batch train loss: 4.263096332550049\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 66, batch train loss: 4.034118175506592\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 67, batch train loss: 2.1521308422088623\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 68, batch train loss: 2.6860857009887695\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 69, batch train loss: 5.24648904800415\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 70, batch train loss: 2.8234407901763916\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 71, batch train loss: 3.310471296310425\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 72, batch train loss: 3.2284722328186035\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 73, batch train loss: 2.167881727218628\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 74, batch train loss: 2.9735398292541504\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 75, batch train loss: 1.8775272369384766\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 76, batch train loss: 2.4206910133361816\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 77, batch train loss: 1.6990588903427124\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 78, batch train loss: 1.7782002687454224\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 79, batch train loss: 1.62445867061615\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 80, batch train loss: 1.8425345420837402\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 81, batch train loss: 1.5422991514205933\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 82, batch train loss: 1.7824183702468872\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 83, batch train loss: 2.120143175125122\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 84, batch train loss: 2.6955440044403076\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 85, batch train loss: 2.0262110233306885\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 86, batch train loss: 2.4600753784179688\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 87, batch train loss: 1.9282985925674438\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 88, batch train loss: 1.7131760120391846\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 89, batch train loss: 1.7075982093811035\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 90, batch train loss: 2.126772165298462\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 91, batch train loss: 1.9045906066894531\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 92, batch train loss: 2.3254663944244385\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 93, batch train loss: 1.7076019048690796\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 94, batch train loss: 1.8528592586517334\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 95, batch train loss: 1.4748179912567139\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 96, batch train loss: 1.565783977508545\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 97, batch train loss: 1.2922743558883667\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 98, batch train loss: 1.3578051328659058\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 99, batch train loss: 1.8629610538482666\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 100, batch train loss: 1.7606121301651\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 101, batch train loss: 1.5371962785720825\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 102, batch train loss: 1.6344013214111328\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 103, batch train loss: 2.1305036544799805\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 104, batch train loss: 1.881548285484314\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 105, batch train loss: 1.7465647459030151\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 106, batch train loss: 1.6345314979553223\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 107, batch train loss: 2.584139823913574\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 108, batch train loss: 2.8585968017578125\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 109, batch train loss: 2.4329285621643066\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 110, batch train loss: 2.296434164047241\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 111, batch train loss: 4.8971781730651855\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 112, batch train loss: 2.9123897552490234\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 113, batch train loss: 4.262275218963623\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 114, batch train loss: 2.942244052886963\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 115, batch train loss: 4.125619411468506\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 116, batch train loss: 1.9324558973312378\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 117, batch train loss: 3.1372015476226807\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 118, batch train loss: 2.3530170917510986\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 119, batch train loss: 2.641810655593872\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 120, batch train loss: 4.122217655181885\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 121, batch train loss: 3.7856152057647705\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 122, batch train loss: 3.429130792617798\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 123, batch train loss: 3.342843770980835\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 124, batch train loss: 3.0793492794036865\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 125, batch train loss: 2.403782844543457\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 126, batch train loss: 2.0254135131835938\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 127, batch train loss: 2.6592724323272705\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 128, batch train loss: 2.4061079025268555\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 129, batch train loss: 2.814028263092041\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, batch_id: 130, batch train loss: 2.1625874042510986\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 131, batch train loss: 2.455669641494751\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 132, batch train loss: 1.9126381874084473\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 133, batch train loss: 2.1383910179138184\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 134, batch train loss: 2.133103132247925\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 135, batch train loss: 1.9442317485809326\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 136, batch train loss: 1.611714482307434\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 137, batch train loss: 2.4202163219451904\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 138, batch train loss: 2.1872477531433105\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 139, batch train loss: 2.8008499145507812\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 140, batch train loss: 3.8620519638061523\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 141, batch train loss: 2.4562695026397705\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 142, batch train loss: 3.2158377170562744\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 143, batch train loss: 2.4565677642822266\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 144, batch train loss: 2.709317445755005\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 145, batch train loss: 2.202021598815918\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 146, batch train loss: 3.06632661819458\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 147, batch train loss: 2.408918619155884\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 148, batch train loss: 2.4952523708343506\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 149, batch train loss: 2.312389612197876\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 150, batch train loss: 1.995713710784912\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 151, batch train loss: 2.3871288299560547\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 152, batch train loss: 3.698127031326294\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 153, batch train loss: 3.0712225437164307\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 154, batch train loss: 2.4739649295806885\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 155, batch train loss: 3.9354753494262695\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 156, batch train loss: 4.090638637542725\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 157, batch train loss: 3.2555298805236816\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 158, batch train loss: 2.198619842529297\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 159, batch train loss: 3.7569189071655273\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 160, batch train loss: 3.253300666809082\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 161, batch train loss: 3.3626437187194824\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 162, batch train loss: 2.95982027053833\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 163, batch train loss: 2.42090106010437\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 164, batch train loss: 2.3954854011535645\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 165, batch train loss: 2.5174129009246826\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 166, batch train loss: 3.135812282562256\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 167, batch train loss: 2.434541940689087\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 168, batch train loss: 3.0679500102996826\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 169, batch train loss: 2.581371307373047\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 170, batch train loss: 2.8456871509552\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 171, batch train loss: 3.057405710220337\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 172, batch train loss: 2.2733209133148193\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 173, batch train loss: 2.182074785232544\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 174, batch train loss: 3.0035104751586914\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 175, batch train loss: 2.9286880493164062\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 176, batch train loss: 2.607257843017578\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 177, batch train loss: 2.8655757904052734\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 178, batch train loss: 3.847050428390503\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 179, batch train loss: 2.62524151802063\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 180, batch train loss: 3.635793447494507\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 181, batch train loss: 3.0832138061523438\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 182, batch train loss: 5.565402030944824\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 183, batch train loss: 3.0002434253692627\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 184, batch train loss: 2.3588602542877197\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 185, batch train loss: 3.661001682281494\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 186, batch train loss: 3.387498378753662\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 187, batch train loss: 3.4617650508880615\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 188, batch train loss: 4.270226001739502\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 189, batch train loss: 4.032658576965332\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 190, batch train loss: 2.979395866394043\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 191, batch train loss: 2.157862424850464\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 192, batch train loss: 3.512270212173462\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 193, batch train loss: 2.887408971786499\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 194, batch train loss: 2.9393081665039062\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 195, batch train loss: 2.3260560035705566\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 196, batch train loss: 2.994126081466675\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 197, batch train loss: 2.7237207889556885\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 198, batch train loss: 3.2289047241210938\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 199, batch train loss: 4.722607135772705\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 200, batch train loss: 2.577529191970825\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 201, batch train loss: 3.074390172958374\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 202, batch train loss: 3.2945327758789062\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 203, batch train loss: 2.396256923675537\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 204, batch train loss: 3.063067674636841\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 205, batch train loss: 2.478213310241699\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 206, batch train loss: 3.414473533630371\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 207, batch train loss: 2.9755859375\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 208, batch train loss: 4.546757221221924\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 209, batch train loss: 3.407968044281006\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 210, batch train loss: 2.388446569442749\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 211, batch train loss: 3.5336575508117676\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 212, batch train loss: 2.6494603157043457\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 213, batch train loss: 1.9206491708755493\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 214, batch train loss: 1.4874639511108398\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 215, batch train loss: 2.5860421657562256\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 216, batch train loss: 2.0025315284729004\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 217, batch train loss: 2.870800495147705\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 218, batch train loss: 2.0605199337005615\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 219, batch train loss: 2.135000705718994\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 220, batch train loss: 1.7421932220458984\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 221, batch train loss: 2.586270809173584\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 222, batch train loss: 2.424375534057617\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 223, batch train loss: 1.9268876314163208\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 224, batch train loss: 4.706485271453857\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 225, batch train loss: 1.9789808988571167\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 226, batch train loss: 2.7899155616760254\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 227, batch train loss: 2.957582712173462\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 228, batch train loss: 2.70119571685791\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 229, batch train loss: 2.571516275405884\n",
      "\n",
      "\n",
      "Epoch: 30, batch_id: 230, batch train loss: 1.812835693359375\n",
      "\n",
      "\n",
      "Epoch: 30/ 100, Loss: 2.657592541238536\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:18<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 Validation Loss: 2.4077786087989805\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, batch_id: 1, batch train loss: 2.3305211067199707\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 2, batch train loss: 2.471245527267456\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 3, batch train loss: 2.8149518966674805\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 4, batch train loss: 2.7785208225250244\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 5, batch train loss: 1.7746622562408447\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 6, batch train loss: 2.7418746948242188\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 7, batch train loss: 2.344238758087158\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 8, batch train loss: 1.7729583978652954\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 9, batch train loss: 2.312380790710449\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 10, batch train loss: 1.8331528902053833\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 11, batch train loss: 1.897550106048584\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 12, batch train loss: 2.3417139053344727\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 13, batch train loss: 2.800403594970703\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 14, batch train loss: 2.066725730895996\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 15, batch train loss: 2.111341714859009\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 16, batch train loss: 1.9681156873703003\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 17, batch train loss: 1.7004660367965698\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 18, batch train loss: 1.6092517375946045\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 19, batch train loss: 1.8034279346466064\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 20, batch train loss: 1.737758755683899\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 21, batch train loss: 1.6819989681243896\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 22, batch train loss: 1.879359483718872\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 23, batch train loss: 2.0088791847229004\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 24, batch train loss: 1.6447389125823975\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 25, batch train loss: 2.5937154293060303\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 26, batch train loss: 2.4839119911193848\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 27, batch train loss: 2.1020357608795166\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 28, batch train loss: 3.2836506366729736\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 29, batch train loss: 2.0871517658233643\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 30, batch train loss: 2.149646282196045\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 31, batch train loss: 2.014606475830078\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 32, batch train loss: 2.820071220397949\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 33, batch train loss: 2.5512948036193848\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 34, batch train loss: 2.3221006393432617\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 35, batch train loss: 1.7408902645111084\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 36, batch train loss: 1.5446381568908691\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 37, batch train loss: 2.418966770172119\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 38, batch train loss: 2.03344464302063\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 39, batch train loss: 1.9074877500534058\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 40, batch train loss: 2.2759203910827637\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 41, batch train loss: 1.5273213386535645\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 42, batch train loss: 2.3956832885742188\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 43, batch train loss: 3.130674123764038\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 44, batch train loss: 2.7528445720672607\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 45, batch train loss: 2.324493408203125\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 46, batch train loss: 2.794999361038208\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 47, batch train loss: 2.441498279571533\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 48, batch train loss: 2.305427312850952\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 49, batch train loss: 2.7508180141448975\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 50, batch train loss: 2.662580966949463\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 51, batch train loss: 2.0017707347869873\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 52, batch train loss: 1.868778944015503\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 53, batch train loss: 3.456449270248413\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 54, batch train loss: 3.1809566020965576\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 55, batch train loss: 2.6119954586029053\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 56, batch train loss: 2.8153812885284424\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 57, batch train loss: 2.1082849502563477\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 58, batch train loss: 2.3582231998443604\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 59, batch train loss: 2.5171992778778076\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 60, batch train loss: 4.360255718231201\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 61, batch train loss: 4.6791815757751465\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 62, batch train loss: 4.716781139373779\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 63, batch train loss: 2.7886619567871094\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 64, batch train loss: 2.7647643089294434\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 65, batch train loss: 1.9436525106430054\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 66, batch train loss: 2.7189433574676514\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 67, batch train loss: 4.570302486419678\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 68, batch train loss: 9.111361503601074\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 69, batch train loss: 2.806555986404419\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 70, batch train loss: 2.8795223236083984\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 71, batch train loss: 2.0887911319732666\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 72, batch train loss: 3.540436267852783\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 73, batch train loss: 3.201669692993164\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 74, batch train loss: 3.725100517272949\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 75, batch train loss: 5.480944633483887\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 76, batch train loss: 3.0730507373809814\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 77, batch train loss: 3.208836555480957\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 78, batch train loss: 3.1624393463134766\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 79, batch train loss: 2.835550546646118\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 80, batch train loss: 2.610997200012207\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 81, batch train loss: 2.2016215324401855\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 82, batch train loss: 3.0614216327667236\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 83, batch train loss: 2.8239474296569824\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 84, batch train loss: 4.5432281494140625\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 85, batch train loss: 4.047444820404053\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 86, batch train loss: 2.8577678203582764\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 87, batch train loss: 2.5274546146392822\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 88, batch train loss: 2.363123893737793\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 89, batch train loss: 3.0726675987243652\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 90, batch train loss: 2.335620403289795\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 91, batch train loss: 4.013855934143066\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 92, batch train loss: 2.4988796710968018\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 93, batch train loss: 2.7797961235046387\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 94, batch train loss: 2.2427380084991455\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 95, batch train loss: 2.529921054840088\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 96, batch train loss: 2.3757898807525635\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 97, batch train loss: 2.334589719772339\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 98, batch train loss: 2.47868275642395\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 99, batch train loss: 3.2168614864349365\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 100, batch train loss: 2.1937108039855957\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 101, batch train loss: 2.146819591522217\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 102, batch train loss: 2.3015296459198\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 103, batch train loss: 2.1876380443573\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 104, batch train loss: 3.048245429992676\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 105, batch train loss: 3.4293875694274902\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 106, batch train loss: 3.1107871532440186\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 107, batch train loss: 3.5110726356506348\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 108, batch train loss: 2.9771363735198975\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 109, batch train loss: 2.3004696369171143\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 110, batch train loss: 4.288373947143555\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 111, batch train loss: 2.734480619430542\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 112, batch train loss: 2.543881893157959\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 113, batch train loss: 3.1524853706359863\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 114, batch train loss: 3.355830430984497\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 115, batch train loss: 3.2463014125823975\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 116, batch train loss: 3.2389588356018066\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 117, batch train loss: 2.29829478263855\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 118, batch train loss: 3.14587664604187\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 119, batch train loss: 3.2884151935577393\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 120, batch train loss: 2.7840726375579834\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 121, batch train loss: 3.3833794593811035\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 122, batch train loss: 3.0977914333343506\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 123, batch train loss: 2.4465861320495605\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 124, batch train loss: 2.209064245223999\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 125, batch train loss: 2.2022688388824463\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 126, batch train loss: 2.4228289127349854\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 127, batch train loss: 2.776454210281372\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 128, batch train loss: 2.514145612716675\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 129, batch train loss: 2.274566173553467\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, batch_id: 130, batch train loss: 1.9175230264663696\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 131, batch train loss: 2.2362635135650635\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 132, batch train loss: 3.191959857940674\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 133, batch train loss: 2.081418037414551\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 134, batch train loss: 1.714992642402649\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 135, batch train loss: 1.7321420907974243\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 136, batch train loss: 2.204723596572876\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 137, batch train loss: 2.839557409286499\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 138, batch train loss: 2.376044511795044\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 139, batch train loss: 2.9687042236328125\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 140, batch train loss: 2.7761595249176025\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 141, batch train loss: 2.7439000606536865\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 142, batch train loss: 3.291797637939453\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 143, batch train loss: 3.232823133468628\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 144, batch train loss: 2.6153459548950195\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 145, batch train loss: 2.5352938175201416\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 146, batch train loss: 1.900119423866272\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 147, batch train loss: 2.9029409885406494\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 148, batch train loss: 3.2766642570495605\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 149, batch train loss: 3.1596410274505615\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 150, batch train loss: 2.6002581119537354\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 151, batch train loss: 2.4701995849609375\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 152, batch train loss: 2.3146283626556396\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 153, batch train loss: 2.585979700088501\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 154, batch train loss: 3.4897689819335938\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 155, batch train loss: 2.753148078918457\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 156, batch train loss: 2.143291711807251\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 157, batch train loss: 2.259209394454956\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 158, batch train loss: 3.074658155441284\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 159, batch train loss: 2.711693525314331\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 160, batch train loss: 2.591500759124756\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 161, batch train loss: 2.923647165298462\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 162, batch train loss: 2.744143009185791\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 163, batch train loss: 2.281740188598633\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 164, batch train loss: 4.135143280029297\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 165, batch train loss: 4.971926212310791\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 166, batch train loss: 4.340402603149414\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 167, batch train loss: 3.0165278911590576\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 168, batch train loss: 2.5392587184906006\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 169, batch train loss: 2.0946884155273438\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 170, batch train loss: 3.301494836807251\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 171, batch train loss: 5.279223442077637\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 172, batch train loss: 2.9627082347869873\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 173, batch train loss: 2.222848892211914\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 174, batch train loss: 2.8923654556274414\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 175, batch train loss: 2.608139991760254\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 176, batch train loss: 2.504201889038086\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 177, batch train loss: 3.1494557857513428\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 178, batch train loss: 3.0734055042266846\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 179, batch train loss: 3.218729019165039\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 180, batch train loss: 3.2081644535064697\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 181, batch train loss: 4.455843925476074\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 182, batch train loss: 3.19366192817688\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 183, batch train loss: 3.6703450679779053\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 184, batch train loss: 4.1406450271606445\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 185, batch train loss: 4.390895843505859\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 186, batch train loss: 3.8569693565368652\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 187, batch train loss: 4.047191619873047\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 188, batch train loss: 3.6916942596435547\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 189, batch train loss: 3.5484859943389893\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 190, batch train loss: 3.722025156021118\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 191, batch train loss: 4.974028587341309\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 192, batch train loss: 2.8210036754608154\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 193, batch train loss: 2.9645655155181885\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 194, batch train loss: 3.822307825088501\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 195, batch train loss: 4.037578582763672\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 196, batch train loss: 2.506969690322876\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 197, batch train loss: 2.9644129276275635\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 198, batch train loss: 2.255993604660034\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 199, batch train loss: 2.7253923416137695\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 200, batch train loss: 2.3306710720062256\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 201, batch train loss: 2.2361645698547363\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 202, batch train loss: 3.1254560947418213\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 203, batch train loss: 2.2010254859924316\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 204, batch train loss: 3.3036463260650635\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 205, batch train loss: 2.074331283569336\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 206, batch train loss: 2.3070290088653564\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 207, batch train loss: 3.0841760635375977\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 208, batch train loss: 2.917069911956787\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 209, batch train loss: 3.7542316913604736\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 210, batch train loss: 4.0547590255737305\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 211, batch train loss: 2.3761301040649414\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 212, batch train loss: 2.678940773010254\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 213, batch train loss: 3.2943813800811768\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 214, batch train loss: 2.4506537914276123\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 215, batch train loss: 3.197650194168091\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 216, batch train loss: 2.576927423477173\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 217, batch train loss: 3.648911476135254\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 218, batch train loss: 4.824499130249023\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 219, batch train loss: 5.181718826293945\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 220, batch train loss: 2.1593270301818848\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 221, batch train loss: 4.106605529785156\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 222, batch train loss: 3.187424421310425\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 223, batch train loss: 4.606204986572266\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 224, batch train loss: 6.1670637130737305\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 225, batch train loss: 5.475601673126221\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 226, batch train loss: 3.3157260417938232\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 227, batch train loss: 3.284024953842163\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 228, batch train loss: 2.4841814041137695\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 229, batch train loss: 2.432396411895752\n",
      "\n",
      "\n",
      "Epoch: 31, batch_id: 230, batch train loss: 2.3484785556793213\n",
      "\n",
      "\n",
      "Epoch: 31/ 100, Loss: 2.8829617536586265\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:14<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 Validation Loss: 2.544896195332209\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, batch_id: 1, batch train loss: 2.6724557876586914\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 2, batch train loss: 2.53896427154541\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 3, batch train loss: 2.0944395065307617\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 4, batch train loss: 5.001278400421143\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 5, batch train loss: 3.0775671005249023\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 6, batch train loss: 4.106477737426758\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 7, batch train loss: 4.286916732788086\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 8, batch train loss: 3.5726158618927\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 9, batch train loss: 3.5729739665985107\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 10, batch train loss: 2.354184627532959\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 11, batch train loss: 2.2807087898254395\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 12, batch train loss: 3.104327917098999\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 13, batch train loss: 2.7891244888305664\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 14, batch train loss: 2.5744826793670654\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 15, batch train loss: 2.9632506370544434\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 16, batch train loss: 2.1329381465911865\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 17, batch train loss: 1.8918532133102417\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 18, batch train loss: 2.3041679859161377\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 19, batch train loss: 2.25223708152771\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 20, batch train loss: 2.5023622512817383\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 21, batch train loss: 3.051128387451172\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 22, batch train loss: 2.931532859802246\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 23, batch train loss: 2.8916821479797363\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 24, batch train loss: 3.777618885040283\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 25, batch train loss: 2.2307541370391846\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 26, batch train loss: 3.235929250717163\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 27, batch train loss: 2.050870895385742\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 28, batch train loss: 2.623814344406128\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 29, batch train loss: 2.7501168251037598\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 30, batch train loss: 1.872632622718811\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 31, batch train loss: 2.4048361778259277\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 32, batch train loss: 2.5437777042388916\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 33, batch train loss: 1.9722894430160522\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 34, batch train loss: 3.692464590072632\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 35, batch train loss: 2.457630157470703\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 36, batch train loss: 2.7625129222869873\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 37, batch train loss: 2.4506847858428955\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 38, batch train loss: 2.24226450920105\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 39, batch train loss: 2.4743354320526123\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 40, batch train loss: 2.0361135005950928\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 41, batch train loss: 2.1562108993530273\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 42, batch train loss: 2.1533236503601074\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 43, batch train loss: 2.191678285598755\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 44, batch train loss: 2.5954127311706543\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 45, batch train loss: 2.2781217098236084\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 46, batch train loss: 2.013388156890869\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 47, batch train loss: 2.257680654525757\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 48, batch train loss: 2.292783498764038\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 49, batch train loss: 2.4775259494781494\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 50, batch train loss: 2.0665087699890137\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 51, batch train loss: 1.5030168294906616\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 52, batch train loss: 1.8980700969696045\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 53, batch train loss: 2.657789707183838\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 54, batch train loss: 2.7798171043395996\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 55, batch train loss: 2.7262468338012695\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 56, batch train loss: 2.385706901550293\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 57, batch train loss: 2.396652936935425\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 58, batch train loss: 2.299635171890259\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 59, batch train loss: 2.277637243270874\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 60, batch train loss: 2.117387056350708\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 61, batch train loss: 2.0952391624450684\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 62, batch train loss: 1.7534570693969727\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 63, batch train loss: 1.6448339223861694\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 64, batch train loss: 2.1372640132904053\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 65, batch train loss: 2.5219850540161133\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 66, batch train loss: 1.8406188488006592\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 67, batch train loss: 3.241873025894165\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 68, batch train loss: 2.250206470489502\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 69, batch train loss: 2.6761648654937744\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 70, batch train loss: 2.6717140674591064\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 71, batch train loss: 2.632688283920288\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 72, batch train loss: 2.7221877574920654\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 73, batch train loss: 2.1690499782562256\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 74, batch train loss: 2.7449772357940674\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 75, batch train loss: 2.284485340118408\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 76, batch train loss: 2.921945095062256\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 77, batch train loss: 3.9129655361175537\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 78, batch train loss: 2.3282840251922607\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 79, batch train loss: 2.234553337097168\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 80, batch train loss: 1.9835646152496338\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 81, batch train loss: 2.2816684246063232\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 82, batch train loss: 2.141772747039795\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 83, batch train loss: 2.0166923999786377\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 84, batch train loss: 2.4465856552124023\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 85, batch train loss: 2.0094356536865234\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 86, batch train loss: 1.746168851852417\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 87, batch train loss: 2.031949043273926\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 88, batch train loss: 1.9843450784683228\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 89, batch train loss: 2.4382247924804688\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 90, batch train loss: 2.0814049243927\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 91, batch train loss: 2.2887773513793945\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 92, batch train loss: 2.3178868293762207\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 93, batch train loss: 2.8182737827301025\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 94, batch train loss: 2.1572535037994385\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 95, batch train loss: 3.2900209426879883\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 96, batch train loss: 2.597622871398926\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 97, batch train loss: 2.150055170059204\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 98, batch train loss: 3.0852065086364746\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 99, batch train loss: 1.53871750831604\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 100, batch train loss: 2.990743398666382\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 101, batch train loss: 1.7756894826889038\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 102, batch train loss: 2.5879175662994385\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 103, batch train loss: 3.213165521621704\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 104, batch train loss: 2.5721664428710938\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 105, batch train loss: 2.874218702316284\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 106, batch train loss: 1.7295039892196655\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 107, batch train loss: 2.3371388912200928\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 108, batch train loss: 1.5001646280288696\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 109, batch train loss: 2.307919502258301\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 110, batch train loss: 2.9840149879455566\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 111, batch train loss: 2.4054853916168213\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 112, batch train loss: 3.032588243484497\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 113, batch train loss: 1.8788676261901855\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 114, batch train loss: 2.8297173976898193\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 115, batch train loss: 2.3617076873779297\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 116, batch train loss: 2.105545997619629\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 117, batch train loss: 2.0167689323425293\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 118, batch train loss: 2.6936469078063965\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 119, batch train loss: 2.9870121479034424\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 120, batch train loss: 1.696323275566101\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 121, batch train loss: 3.4868404865264893\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 122, batch train loss: 2.6351754665374756\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 123, batch train loss: 2.9564075469970703\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 124, batch train loss: 2.3063530921936035\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 125, batch train loss: 2.0858983993530273\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 126, batch train loss: 2.7584447860717773\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 127, batch train loss: 1.3276550769805908\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 128, batch train loss: 2.152313470840454\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 129, batch train loss: 2.1479671001434326\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, batch_id: 130, batch train loss: 1.9024513959884644\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 131, batch train loss: 2.1846795082092285\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 132, batch train loss: 4.609199523925781\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 133, batch train loss: 2.514439821243286\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 134, batch train loss: 3.1755940914154053\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 135, batch train loss: 2.7772738933563232\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 136, batch train loss: 2.8554205894470215\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 137, batch train loss: 1.964637279510498\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 138, batch train loss: 2.089312791824341\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 139, batch train loss: 2.03783917427063\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 140, batch train loss: 2.1375975608825684\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 141, batch train loss: 2.0954208374023438\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 142, batch train loss: 2.830185890197754\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 143, batch train loss: 2.2458295822143555\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 144, batch train loss: 2.0895800590515137\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 145, batch train loss: 3.301189422607422\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 146, batch train loss: 1.9401153326034546\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 147, batch train loss: 1.7603002786636353\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 148, batch train loss: 2.6640915870666504\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 149, batch train loss: 2.4630141258239746\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 150, batch train loss: 2.0588648319244385\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 151, batch train loss: 2.163184642791748\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 152, batch train loss: 2.650942087173462\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 153, batch train loss: 2.8236584663391113\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 154, batch train loss: 1.755462408065796\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 155, batch train loss: 2.8253908157348633\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 156, batch train loss: 2.172785758972168\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 157, batch train loss: 2.1129586696624756\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 158, batch train loss: 2.7038562297821045\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 159, batch train loss: 1.9970316886901855\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 160, batch train loss: 2.563753366470337\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 161, batch train loss: 2.9226632118225098\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 162, batch train loss: 2.832463026046753\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 163, batch train loss: 2.088547468185425\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 164, batch train loss: 3.1188297271728516\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 165, batch train loss: 2.2327194213867188\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 166, batch train loss: 2.9437968730926514\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 167, batch train loss: 1.9506046772003174\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 168, batch train loss: 2.249279022216797\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 169, batch train loss: 2.957028865814209\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 170, batch train loss: 1.7653822898864746\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 171, batch train loss: 2.180492639541626\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 172, batch train loss: 2.008863687515259\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 173, batch train loss: 1.918391466140747\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 174, batch train loss: 2.138436794281006\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 175, batch train loss: 2.1657984256744385\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 176, batch train loss: 2.027562141418457\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 177, batch train loss: 1.9674127101898193\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 178, batch train loss: 1.6053435802459717\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 179, batch train loss: 3.1358964443206787\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 180, batch train loss: 1.507550597190857\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 181, batch train loss: 2.380915641784668\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 182, batch train loss: 2.4084503650665283\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 183, batch train loss: 4.619863510131836\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 184, batch train loss: 4.399467945098877\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 185, batch train loss: 3.0607333183288574\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 186, batch train loss: 2.6252458095550537\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 187, batch train loss: 3.8366878032684326\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 188, batch train loss: 2.7509994506835938\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 189, batch train loss: 3.316324234008789\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 190, batch train loss: 2.875425100326538\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 191, batch train loss: 2.340163230895996\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 192, batch train loss: 3.4623615741729736\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 193, batch train loss: 3.2807841300964355\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 194, batch train loss: 2.144440174102783\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 195, batch train loss: 3.061415195465088\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 196, batch train loss: 2.0553367137908936\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 197, batch train loss: 2.2998220920562744\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 198, batch train loss: 1.8776627779006958\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 199, batch train loss: 2.319406032562256\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 200, batch train loss: 1.9127033948898315\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 201, batch train loss: 2.3524203300476074\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 202, batch train loss: 2.1032297611236572\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 203, batch train loss: 1.7513104677200317\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 204, batch train loss: 1.8825358152389526\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 205, batch train loss: 2.6743004322052\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 206, batch train loss: 1.9794412851333618\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 207, batch train loss: 1.8370580673217773\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 208, batch train loss: 2.189471960067749\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 209, batch train loss: 1.984554409980774\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 210, batch train loss: 2.30875825881958\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 211, batch train loss: 2.394988775253296\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 212, batch train loss: 2.1375749111175537\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 213, batch train loss: 2.50443959236145\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 214, batch train loss: 1.910322666168213\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 215, batch train loss: 1.7851961851119995\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 216, batch train loss: 2.604769229888916\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 217, batch train loss: 2.271226167678833\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 218, batch train loss: 2.075364351272583\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 219, batch train loss: 1.912992000579834\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 220, batch train loss: 1.9691709280014038\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 221, batch train loss: 2.562148332595825\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 222, batch train loss: 2.0468177795410156\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 223, batch train loss: 1.535560965538025\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 224, batch train loss: 2.5478079319000244\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 225, batch train loss: 2.1642117500305176\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 226, batch train loss: 2.3673202991485596\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 227, batch train loss: 1.5507171154022217\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 228, batch train loss: 2.145977258682251\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 229, batch train loss: 2.30126953125\n",
      "\n",
      "\n",
      "Epoch: 32, batch_id: 230, batch train loss: 1.805701732635498\n",
      "\n",
      "\n",
      "Epoch: 32/ 100, Loss: 2.4471581930699555\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:10<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 Validation Loss: 1.8244961222012839\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, batch_id: 1, batch train loss: 1.6949189901351929\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 2, batch train loss: 1.7878060340881348\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 3, batch train loss: 2.3123040199279785\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 4, batch train loss: 2.4006927013397217\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 5, batch train loss: 1.9894834756851196\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 6, batch train loss: 2.0995962619781494\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 7, batch train loss: 1.6820718050003052\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 8, batch train loss: 1.9171278476715088\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 9, batch train loss: 1.8926578760147095\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 10, batch train loss: 1.6823339462280273\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 11, batch train loss: 2.301461935043335\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 12, batch train loss: 2.169252634048462\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 13, batch train loss: 2.2932887077331543\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 14, batch train loss: 2.2026352882385254\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 15, batch train loss: 1.7982348203659058\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 16, batch train loss: 1.8443701267242432\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 17, batch train loss: 1.9704532623291016\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 18, batch train loss: 1.9283838272094727\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 19, batch train loss: 2.2118287086486816\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 20, batch train loss: 2.3654210567474365\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 21, batch train loss: 2.0825769901275635\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 22, batch train loss: 2.3259940147399902\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 23, batch train loss: 1.4838131666183472\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 24, batch train loss: 1.6724534034729004\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 25, batch train loss: 1.9856679439544678\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 26, batch train loss: 1.7628121376037598\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 27, batch train loss: 2.0533385276794434\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 28, batch train loss: 2.438962697982788\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 29, batch train loss: 1.855610966682434\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 30, batch train loss: 1.8806034326553345\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 31, batch train loss: 2.3268752098083496\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 32, batch train loss: 2.5312366485595703\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 33, batch train loss: 5.693883419036865\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 34, batch train loss: 3.7529540061950684\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 35, batch train loss: 3.1594929695129395\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 36, batch train loss: 3.820282459259033\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 37, batch train loss: 3.2033815383911133\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 38, batch train loss: 3.1476457118988037\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 39, batch train loss: 4.178781032562256\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 40, batch train loss: 2.947178840637207\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 41, batch train loss: 2.6618459224700928\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 42, batch train loss: 3.6176366806030273\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 43, batch train loss: 2.051889181137085\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 44, batch train loss: 6.846407890319824\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 45, batch train loss: 4.242119312286377\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 46, batch train loss: 6.274835586547852\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 47, batch train loss: 3.6014647483825684\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 48, batch train loss: 2.8876962661743164\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 49, batch train loss: 2.933931827545166\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 50, batch train loss: 2.4186596870422363\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 51, batch train loss: 3.1621499061584473\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 52, batch train loss: 3.2015535831451416\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 53, batch train loss: 3.715057849884033\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 54, batch train loss: 4.691829204559326\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 55, batch train loss: 3.2337088584899902\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 56, batch train loss: 4.136282444000244\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 57, batch train loss: 4.841095924377441\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 58, batch train loss: 3.099672317504883\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 59, batch train loss: 6.958109378814697\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 60, batch train loss: 5.500714302062988\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 61, batch train loss: 3.9825007915496826\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 62, batch train loss: 4.104949951171875\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 63, batch train loss: 5.572108745574951\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 64, batch train loss: 3.532986640930176\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 65, batch train loss: 4.077250957489014\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 66, batch train loss: 4.34193229675293\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 67, batch train loss: 4.405566692352295\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 68, batch train loss: 5.623716354370117\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 69, batch train loss: 6.2491774559021\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 70, batch train loss: 4.453518867492676\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 71, batch train loss: 7.5279412269592285\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 72, batch train loss: 4.349867820739746\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 73, batch train loss: 8.89001178741455\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 74, batch train loss: 7.953344821929932\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 75, batch train loss: 4.656062602996826\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 76, batch train loss: 6.0187530517578125\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 77, batch train loss: 7.773439884185791\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 78, batch train loss: 3.9844393730163574\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 79, batch train loss: 3.522650957107544\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 80, batch train loss: 5.823452472686768\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 81, batch train loss: 4.262762069702148\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 82, batch train loss: 2.8704354763031006\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 83, batch train loss: 3.883247137069702\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 84, batch train loss: 3.688474178314209\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 85, batch train loss: 3.7069098949432373\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 86, batch train loss: 3.6997599601745605\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 87, batch train loss: 3.31815767288208\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 88, batch train loss: 2.804169178009033\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 89, batch train loss: 4.402846813201904\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 90, batch train loss: 4.464556694030762\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 91, batch train loss: 4.0251593589782715\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 92, batch train loss: 3.9405736923217773\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 93, batch train loss: 3.6201343536376953\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 94, batch train loss: 3.5232348442077637\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 95, batch train loss: 3.749687433242798\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 96, batch train loss: 2.5722944736480713\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 97, batch train loss: 3.1472463607788086\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 98, batch train loss: 2.7903459072113037\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 99, batch train loss: 2.656421661376953\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 100, batch train loss: 4.023210048675537\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 101, batch train loss: 2.899219036102295\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 102, batch train loss: 4.2242326736450195\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 103, batch train loss: 3.412119150161743\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 104, batch train loss: 2.478630304336548\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 105, batch train loss: 3.6023929119110107\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 106, batch train loss: 3.662912130355835\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 107, batch train loss: 2.934130907058716\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 108, batch train loss: 2.226820707321167\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 109, batch train loss: 2.9120991230010986\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 110, batch train loss: 3.663673162460327\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 111, batch train loss: 2.7513186931610107\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 112, batch train loss: 2.719442367553711\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 113, batch train loss: 2.45224928855896\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 114, batch train loss: 2.156014919281006\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 115, batch train loss: 1.9052915573120117\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 116, batch train loss: 1.766506314277649\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 117, batch train loss: 1.9783843755722046\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 118, batch train loss: 2.4366579055786133\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 119, batch train loss: 2.6532914638519287\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 120, batch train loss: 2.497061014175415\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 121, batch train loss: 2.1360816955566406\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 122, batch train loss: 1.8979005813598633\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 123, batch train loss: 2.558448076248169\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 124, batch train loss: 1.6150537729263306\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 125, batch train loss: 2.5062482357025146\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 126, batch train loss: 2.3983962535858154\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 127, batch train loss: 2.0068652629852295\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 128, batch train loss: 2.0127341747283936\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 129, batch train loss: 2.1463124752044678\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, batch_id: 130, batch train loss: 2.363612174987793\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 131, batch train loss: 2.027174472808838\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 132, batch train loss: 1.9875431060791016\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 133, batch train loss: 2.2944135665893555\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 134, batch train loss: 2.3214447498321533\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 135, batch train loss: 2.4566893577575684\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 136, batch train loss: 1.8634134531021118\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 137, batch train loss: 2.421764612197876\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 138, batch train loss: 2.2186052799224854\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 139, batch train loss: 2.394545793533325\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 140, batch train loss: 1.9777445793151855\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 141, batch train loss: 2.7160775661468506\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 142, batch train loss: 2.509047269821167\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 143, batch train loss: 2.4292423725128174\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 144, batch train loss: 1.9290693998336792\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 145, batch train loss: 2.32596492767334\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 146, batch train loss: 2.0840485095977783\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 147, batch train loss: 2.049834728240967\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 148, batch train loss: 2.2941882610321045\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 149, batch train loss: 1.8956876993179321\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 150, batch train loss: 1.8323585987091064\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 151, batch train loss: 1.5201842784881592\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 152, batch train loss: 2.3695197105407715\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 153, batch train loss: 2.136901378631592\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 154, batch train loss: 1.7817399501800537\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 155, batch train loss: 1.9543678760528564\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 156, batch train loss: 1.814971923828125\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 157, batch train loss: 1.82317054271698\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 158, batch train loss: 1.5827233791351318\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 159, batch train loss: 1.8378934860229492\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 160, batch train loss: 1.7964218854904175\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 161, batch train loss: 1.6162831783294678\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 162, batch train loss: 2.154215097427368\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 163, batch train loss: 1.5730993747711182\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 164, batch train loss: 1.4628037214279175\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 165, batch train loss: 1.7609952688217163\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 166, batch train loss: 1.6862047910690308\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 167, batch train loss: 1.3551666736602783\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 168, batch train loss: 1.9382840394973755\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 169, batch train loss: 1.5182890892028809\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 170, batch train loss: 2.2332794666290283\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 171, batch train loss: 1.9131176471710205\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 172, batch train loss: 2.298914909362793\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 173, batch train loss: 1.8368172645568848\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 174, batch train loss: 2.111217498779297\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 175, batch train loss: 1.7619991302490234\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 176, batch train loss: 3.094975471496582\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 177, batch train loss: 2.0263779163360596\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 178, batch train loss: 2.274078369140625\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 179, batch train loss: 2.0311708450317383\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 180, batch train loss: 1.9936106204986572\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 181, batch train loss: 3.3924882411956787\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 182, batch train loss: 3.1960229873657227\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 183, batch train loss: 1.9239050149917603\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 184, batch train loss: 2.0559117794036865\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 185, batch train loss: 2.304098606109619\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 186, batch train loss: 2.7321839332580566\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 187, batch train loss: 3.3357863426208496\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 188, batch train loss: 2.3316452503204346\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 189, batch train loss: 2.1798384189605713\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 190, batch train loss: 2.0917906761169434\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 191, batch train loss: 3.960977077484131\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 192, batch train loss: 2.349790096282959\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 193, batch train loss: 1.7654772996902466\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 194, batch train loss: 3.4143197536468506\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 195, batch train loss: 2.2540194988250732\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 196, batch train loss: 2.8725712299346924\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 197, batch train loss: 2.6819093227386475\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 198, batch train loss: 5.203926086425781\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 199, batch train loss: 3.6755049228668213\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 200, batch train loss: 3.245469570159912\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 201, batch train loss: 2.8182497024536133\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 202, batch train loss: 2.0597994327545166\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 203, batch train loss: 5.6842041015625\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 204, batch train loss: 4.161795616149902\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 205, batch train loss: 3.137481212615967\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 206, batch train loss: 3.88065505027771\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 207, batch train loss: 2.914170026779175\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 208, batch train loss: 2.283339023590088\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 209, batch train loss: 5.41619348526001\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 210, batch train loss: 5.138699531555176\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 211, batch train loss: 5.2873053550720215\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 212, batch train loss: 3.7901594638824463\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 213, batch train loss: 5.140372276306152\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 214, batch train loss: 5.594568729400635\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 215, batch train loss: 3.165855884552002\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 216, batch train loss: 3.5986075401306152\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 217, batch train loss: 3.3270673751831055\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 218, batch train loss: 2.9964823722839355\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 219, batch train loss: 2.0076324939727783\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 220, batch train loss: 1.535438895225525\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 221, batch train loss: 2.253901720046997\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 222, batch train loss: 1.9876867532730103\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 223, batch train loss: 2.169348955154419\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 224, batch train loss: 2.167022705078125\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 225, batch train loss: 2.017671823501587\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 226, batch train loss: 1.747701644897461\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 227, batch train loss: 2.5585286617279053\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 228, batch train loss: 2.4335837364196777\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 229, batch train loss: 3.5152673721313477\n",
      "\n",
      "\n",
      "Epoch: 33, batch_id: 230, batch train loss: 3.2375054359436035\n",
      "\n",
      "\n",
      "Epoch: 33/ 100, Loss: 2.9833631111227947\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 Validation Loss: 2.5031786998112997\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, batch_id: 1, batch train loss: 2.191058874130249\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 2, batch train loss: 3.8323111534118652\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 3, batch train loss: 4.061524391174316\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 4, batch train loss: 3.066570997238159\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 5, batch train loss: 3.5769894123077393\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 6, batch train loss: 3.2336432933807373\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 7, batch train loss: 2.0863146781921387\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 8, batch train loss: 3.1269984245300293\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 9, batch train loss: 2.235342264175415\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 10, batch train loss: 2.2669498920440674\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 11, batch train loss: 2.3785085678100586\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 12, batch train loss: 2.1174468994140625\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 13, batch train loss: 1.7829331159591675\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 14, batch train loss: 1.811895728111267\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 15, batch train loss: 2.9341373443603516\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 16, batch train loss: 2.1429595947265625\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 17, batch train loss: 2.577988386154175\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 18, batch train loss: 2.7360172271728516\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 19, batch train loss: 2.2430386543273926\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 20, batch train loss: 1.857082724571228\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 21, batch train loss: 1.9989005327224731\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 22, batch train loss: 2.0904157161712646\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 23, batch train loss: 2.451766014099121\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 24, batch train loss: 1.8625502586364746\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 25, batch train loss: 1.7743415832519531\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 26, batch train loss: 2.0333139896392822\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 27, batch train loss: 1.6885451078414917\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 28, batch train loss: 1.3134658336639404\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 29, batch train loss: 1.631984829902649\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 30, batch train loss: 1.4511747360229492\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 31, batch train loss: 2.0594587326049805\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 32, batch train loss: 1.705487847328186\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 33, batch train loss: 1.7346824407577515\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 34, batch train loss: 1.7953897714614868\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 35, batch train loss: 1.584161639213562\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 36, batch train loss: 2.5810770988464355\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 37, batch train loss: 1.7505415678024292\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 38, batch train loss: 2.403857946395874\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 39, batch train loss: 1.9590946435928345\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 40, batch train loss: 2.1241087913513184\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 41, batch train loss: 1.9762605428695679\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 42, batch train loss: 2.0854036808013916\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 43, batch train loss: 3.322718858718872\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 44, batch train loss: 1.889871597290039\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 45, batch train loss: 3.1992743015289307\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 46, batch train loss: 1.7701835632324219\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 47, batch train loss: 2.747345447540283\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 48, batch train loss: 2.2145535945892334\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 49, batch train loss: 2.8582727909088135\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 50, batch train loss: 2.200481414794922\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 51, batch train loss: 3.529205322265625\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 52, batch train loss: 3.541454553604126\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 53, batch train loss: 6.778881072998047\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 54, batch train loss: 3.624857187271118\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 55, batch train loss: 4.190147876739502\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 56, batch train loss: 5.298738479614258\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 57, batch train loss: 3.0309510231018066\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 58, batch train loss: 3.669248104095459\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 59, batch train loss: 4.466841697692871\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 60, batch train loss: 2.9554030895233154\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 61, batch train loss: 2.7194619178771973\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 62, batch train loss: 4.863173007965088\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 63, batch train loss: 2.9147226810455322\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 64, batch train loss: 2.138446569442749\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 65, batch train loss: 6.786220073699951\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 66, batch train loss: 2.585292100906372\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 67, batch train loss: 3.01814341545105\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 68, batch train loss: 5.491811275482178\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 69, batch train loss: 5.664177894592285\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 70, batch train loss: 3.7693774700164795\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 71, batch train loss: 2.515014410018921\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 72, batch train loss: 3.9600577354431152\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 73, batch train loss: 2.963426113128662\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 74, batch train loss: 2.633610486984253\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 75, batch train loss: 3.4534871578216553\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 76, batch train loss: 2.624455690383911\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 77, batch train loss: 3.3854095935821533\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 78, batch train loss: 2.0624382495880127\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 79, batch train loss: 4.259037971496582\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 80, batch train loss: 2.39845871925354\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 81, batch train loss: 2.783108711242676\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 82, batch train loss: 1.8304716348648071\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 83, batch train loss: 2.3057689666748047\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 84, batch train loss: 2.61582088470459\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 85, batch train loss: 1.83826744556427\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 86, batch train loss: 2.642781972885132\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 87, batch train loss: 1.960880994796753\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 88, batch train loss: 2.1794450283050537\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 89, batch train loss: 4.026572227478027\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 90, batch train loss: 2.771514892578125\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 91, batch train loss: 2.092912435531616\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 92, batch train loss: 2.3974461555480957\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 93, batch train loss: 1.7520196437835693\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 94, batch train loss: 1.9737036228179932\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 95, batch train loss: 2.4135468006134033\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 96, batch train loss: 2.493067502975464\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 97, batch train loss: 2.232699394226074\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 98, batch train loss: 2.027519464492798\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 99, batch train loss: 2.2958483695983887\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 100, batch train loss: 2.8424108028411865\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 101, batch train loss: 1.9867922067642212\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 102, batch train loss: 2.216878652572632\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 103, batch train loss: 1.881531834602356\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 104, batch train loss: 1.6088876724243164\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 105, batch train loss: 2.3291451930999756\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 106, batch train loss: 1.6978256702423096\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 107, batch train loss: 1.872869610786438\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 108, batch train loss: 2.1220180988311768\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 109, batch train loss: 2.531420946121216\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 110, batch train loss: 2.3916258811950684\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 111, batch train loss: 2.9206016063690186\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 112, batch train loss: 2.0261459350585938\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 113, batch train loss: 2.1275224685668945\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 114, batch train loss: 2.518237352371216\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 115, batch train loss: 2.5263400077819824\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 116, batch train loss: 2.0395686626434326\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 117, batch train loss: 2.3547303676605225\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 118, batch train loss: 1.8254988193511963\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 119, batch train loss: 2.9363129138946533\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 120, batch train loss: 3.960965633392334\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 121, batch train loss: 3.1155707836151123\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 122, batch train loss: 2.597132682800293\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 123, batch train loss: 4.378190517425537\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 124, batch train loss: 2.826103925704956\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 125, batch train loss: 3.2729382514953613\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 126, batch train loss: 4.726698875427246\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 127, batch train loss: 2.1382241249084473\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 128, batch train loss: 3.183119535446167\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 129, batch train loss: 3.2041282653808594\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, batch_id: 130, batch train loss: 1.5658719539642334\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 131, batch train loss: 2.9325172901153564\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 132, batch train loss: 3.1354572772979736\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 133, batch train loss: 4.305209159851074\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 134, batch train loss: 2.2964372634887695\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 135, batch train loss: 3.0381574630737305\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 136, batch train loss: 2.4664807319641113\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 137, batch train loss: 2.4595773220062256\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 138, batch train loss: 1.9966357946395874\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 139, batch train loss: 1.857317328453064\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 140, batch train loss: 1.979556679725647\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 141, batch train loss: 2.0514352321624756\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 142, batch train loss: 2.140179395675659\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 143, batch train loss: 2.5688352584838867\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 144, batch train loss: 3.2899041175842285\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 145, batch train loss: 1.9530574083328247\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 146, batch train loss: 2.3406336307525635\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 147, batch train loss: 1.29060697555542\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 148, batch train loss: 1.6782761812210083\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 149, batch train loss: 1.8449125289916992\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 150, batch train loss: 1.784746527671814\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 151, batch train loss: 2.1092536449432373\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 152, batch train loss: 2.089690923690796\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 153, batch train loss: 1.6432610750198364\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 154, batch train loss: 1.6570541858673096\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 155, batch train loss: 2.0281050205230713\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 156, batch train loss: 2.186382293701172\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 157, batch train loss: 2.1693854331970215\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 158, batch train loss: 2.667409658432007\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 159, batch train loss: 2.030860424041748\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 160, batch train loss: 1.703773021697998\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 161, batch train loss: 1.894534707069397\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 162, batch train loss: 2.3293399810791016\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 163, batch train loss: 1.7408597469329834\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 164, batch train loss: 1.8935917615890503\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 165, batch train loss: 1.6713804006576538\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 166, batch train loss: 2.359227180480957\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 167, batch train loss: 2.716700553894043\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 168, batch train loss: 2.245255470275879\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 169, batch train loss: 3.792246103286743\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 170, batch train loss: 2.33882737159729\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 171, batch train loss: 2.964867353439331\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 172, batch train loss: 2.1715075969696045\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 173, batch train loss: 3.0211451053619385\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 174, batch train loss: 2.6713027954101562\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 175, batch train loss: 2.481593370437622\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 176, batch train loss: 3.578970193862915\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 177, batch train loss: 3.0198609828948975\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 178, batch train loss: 2.845306634902954\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 179, batch train loss: 2.5733649730682373\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 180, batch train loss: 2.43705677986145\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 181, batch train loss: 2.993544816970825\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 182, batch train loss: 2.9901347160339355\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 183, batch train loss: 2.5075879096984863\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 184, batch train loss: 2.5847458839416504\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 185, batch train loss: 3.7249462604522705\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 186, batch train loss: 3.5480058193206787\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 187, batch train loss: 2.019249200820923\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 188, batch train loss: 2.984679698944092\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 189, batch train loss: 2.387634515762329\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 190, batch train loss: 2.0540099143981934\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 191, batch train loss: 3.763040781021118\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 192, batch train loss: 2.884648084640503\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 193, batch train loss: 2.5175302028656006\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 194, batch train loss: 4.485783576965332\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 195, batch train loss: 2.488104820251465\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 196, batch train loss: 1.9870001077651978\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 197, batch train loss: 2.5435609817504883\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 198, batch train loss: 3.1608800888061523\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 199, batch train loss: 3.101731061935425\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 200, batch train loss: 3.4072654247283936\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 201, batch train loss: 2.1587541103363037\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 202, batch train loss: 3.6213510036468506\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 203, batch train loss: 1.8449217081069946\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 204, batch train loss: 1.777479648590088\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 205, batch train loss: 1.818152666091919\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 206, batch train loss: 1.7229756116867065\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 207, batch train loss: 1.834334135055542\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 208, batch train loss: 2.3971340656280518\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 209, batch train loss: 1.6813428401947021\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 210, batch train loss: 1.724992036819458\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 211, batch train loss: 1.6105647087097168\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 212, batch train loss: 1.3825594186782837\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 213, batch train loss: 1.8046793937683105\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 214, batch train loss: 1.867397427558899\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 215, batch train loss: 1.9054375886917114\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 216, batch train loss: 1.518586277961731\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 217, batch train loss: 2.2315144538879395\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 218, batch train loss: 2.0512490272521973\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 219, batch train loss: 2.0691611766815186\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 220, batch train loss: 1.840345025062561\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 221, batch train loss: 1.807058334350586\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 222, batch train loss: 1.7191921472549438\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 223, batch train loss: 1.3680003881454468\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 224, batch train loss: 1.5446751117706299\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 225, batch train loss: 1.7646700143814087\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 226, batch train loss: 1.6162599325180054\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 227, batch train loss: 2.9994137287139893\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 228, batch train loss: 2.1328766345977783\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 229, batch train loss: 1.9236778020858765\n",
      "\n",
      "\n",
      "Epoch: 34, batch_id: 230, batch train loss: 3.504840850830078\n",
      "\n",
      "\n",
      "Epoch: 34/ 100, Loss: 2.5477773142897564\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:25<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 Validation Loss: 1.9617618600527444\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, batch_id: 1, batch train loss: 2.0819923877716064\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 2, batch train loss: 4.220283508300781\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 3, batch train loss: 3.338000535964966\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 4, batch train loss: 2.665147542953491\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 5, batch train loss: 3.5243523120880127\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 6, batch train loss: 1.8049118518829346\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 7, batch train loss: 2.226649045944214\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 8, batch train loss: 2.723949670791626\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 9, batch train loss: 4.139632225036621\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 10, batch train loss: 2.498154640197754\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 11, batch train loss: 2.6635727882385254\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 12, batch train loss: 3.449798583984375\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 13, batch train loss: 2.9344582557678223\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 14, batch train loss: 3.8470091819763184\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 15, batch train loss: 3.937819004058838\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 16, batch train loss: 3.588188409805298\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 17, batch train loss: 2.4319229125976562\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 18, batch train loss: 3.5256283283233643\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 19, batch train loss: 3.6672940254211426\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 20, batch train loss: 2.6345949172973633\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 21, batch train loss: 1.7746291160583496\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 22, batch train loss: 2.063718318939209\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 23, batch train loss: 2.8600504398345947\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 24, batch train loss: 2.8450381755828857\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 25, batch train loss: 1.6703048944473267\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 26, batch train loss: 1.744562029838562\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 27, batch train loss: 1.7987780570983887\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 28, batch train loss: 2.3373219966888428\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 29, batch train loss: 2.7065505981445312\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 30, batch train loss: 4.530494689941406\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 31, batch train loss: 3.426424980163574\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 32, batch train loss: 2.585139274597168\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 33, batch train loss: 2.8972063064575195\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 34, batch train loss: 2.640854835510254\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 35, batch train loss: 2.7017338275909424\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 36, batch train loss: 2.515415668487549\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 37, batch train loss: 2.1139824390411377\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 38, batch train loss: 2.5588138103485107\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 39, batch train loss: 2.405797004699707\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 40, batch train loss: 2.905629873275757\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 41, batch train loss: 2.457531452178955\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 42, batch train loss: 2.722017765045166\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 43, batch train loss: 2.958601474761963\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 44, batch train loss: 2.957209587097168\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 45, batch train loss: 2.7729413509368896\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 46, batch train loss: 2.2614829540252686\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 47, batch train loss: 2.2260005474090576\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 48, batch train loss: 3.6445984840393066\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 49, batch train loss: 3.4551565647125244\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 50, batch train loss: 3.1300854682922363\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 51, batch train loss: 2.761035680770874\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 52, batch train loss: 2.616755723953247\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 53, batch train loss: 2.7581841945648193\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 54, batch train loss: 2.3611512184143066\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 55, batch train loss: 3.2955915927886963\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 56, batch train loss: 4.111154079437256\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 57, batch train loss: 1.8525390625\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 58, batch train loss: 3.5113871097564697\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 59, batch train loss: 4.759605884552002\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 60, batch train loss: 2.4033210277557373\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 61, batch train loss: 3.027357339859009\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 62, batch train loss: 2.033633232116699\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 63, batch train loss: 2.2009384632110596\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 64, batch train loss: 3.0607802867889404\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 65, batch train loss: 2.641242265701294\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 66, batch train loss: 2.2246336936950684\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 67, batch train loss: 5.599081039428711\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 68, batch train loss: 2.4478697776794434\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 69, batch train loss: 3.131068229675293\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 70, batch train loss: 2.1343655586242676\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 71, batch train loss: 6.752614974975586\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 72, batch train loss: 6.291679859161377\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 73, batch train loss: 3.609744071960449\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 74, batch train loss: 5.185339450836182\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 75, batch train loss: 8.234750747680664\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 76, batch train loss: 5.576571941375732\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 77, batch train loss: 3.771710157394409\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 78, batch train loss: 9.272512435913086\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 79, batch train loss: 9.345331192016602\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 80, batch train loss: 4.342932224273682\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 81, batch train loss: 3.8839588165283203\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 82, batch train loss: 5.839832782745361\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 83, batch train loss: 4.500946521759033\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 84, batch train loss: 2.918431282043457\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 85, batch train loss: 6.8189377784729\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 86, batch train loss: 4.23270845413208\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 87, batch train loss: 4.3104329109191895\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 88, batch train loss: 6.576939582824707\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 89, batch train loss: 2.9139163494110107\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 90, batch train loss: 4.072242259979248\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 91, batch train loss: 2.6065618991851807\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 92, batch train loss: 3.4214859008789062\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 93, batch train loss: 2.8581607341766357\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 94, batch train loss: 2.160024881362915\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 95, batch train loss: 2.09346079826355\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 96, batch train loss: 2.604670763015747\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 97, batch train loss: 1.896935224533081\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 98, batch train loss: 2.4944543838500977\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 99, batch train loss: 2.244816303253174\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 100, batch train loss: 1.7678718566894531\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 101, batch train loss: 4.552645683288574\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 102, batch train loss: 3.4808895587921143\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 103, batch train loss: 3.3466641902923584\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 104, batch train loss: 2.532890558242798\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 105, batch train loss: 2.0136334896087646\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 106, batch train loss: 2.8912556171417236\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 107, batch train loss: 3.2502152919769287\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 108, batch train loss: 3.546489953994751\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 109, batch train loss: 2.799091339111328\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 110, batch train loss: 2.925272226333618\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 111, batch train loss: 2.5921647548675537\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 112, batch train loss: 2.7087528705596924\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 113, batch train loss: 3.147263288497925\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 114, batch train loss: 2.905064344406128\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 115, batch train loss: 2.654531240463257\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 116, batch train loss: 2.07659912109375\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 117, batch train loss: 2.779961109161377\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 118, batch train loss: 2.5074405670166016\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 119, batch train loss: 3.006406307220459\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 120, batch train loss: 3.2180168628692627\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 121, batch train loss: 2.5365819931030273\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 122, batch train loss: 2.333935022354126\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 123, batch train loss: 2.143977165222168\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 124, batch train loss: 2.2860827445983887\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 125, batch train loss: 2.426785945892334\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 126, batch train loss: 2.3273682594299316\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 127, batch train loss: 2.1416032314300537\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 128, batch train loss: 2.21305775642395\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 129, batch train loss: 2.323899984359741\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, batch_id: 130, batch train loss: 3.11576247215271\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 131, batch train loss: 2.9623448848724365\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 132, batch train loss: 2.900552272796631\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 133, batch train loss: 2.719136953353882\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 134, batch train loss: 3.1167664527893066\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 135, batch train loss: 2.1853206157684326\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 136, batch train loss: 3.352588415145874\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 137, batch train loss: 3.112438201904297\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 138, batch train loss: 3.4939863681793213\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 139, batch train loss: 3.3241357803344727\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 140, batch train loss: 4.176422119140625\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 141, batch train loss: 3.909996747970581\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 142, batch train loss: 2.453989267349243\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 143, batch train loss: 3.414839744567871\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 144, batch train loss: 3.1643686294555664\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 145, batch train loss: 2.5751590728759766\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 146, batch train loss: 3.3445017337799072\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 147, batch train loss: 2.4044511318206787\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 148, batch train loss: 2.6484856605529785\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 149, batch train loss: 3.6201610565185547\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 150, batch train loss: 2.735182523727417\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 151, batch train loss: 3.2275021076202393\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 152, batch train loss: 3.161027669906616\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 153, batch train loss: 3.751042366027832\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 154, batch train loss: 2.582473039627075\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 155, batch train loss: 2.9195563793182373\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 156, batch train loss: 2.7141480445861816\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 157, batch train loss: 4.846642017364502\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 158, batch train loss: 3.8097383975982666\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 159, batch train loss: 3.3655428886413574\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 160, batch train loss: 3.6157052516937256\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 161, batch train loss: 4.243001937866211\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 162, batch train loss: 4.1216559410095215\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 163, batch train loss: 3.852818250656128\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 164, batch train loss: 3.0457558631896973\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 165, batch train loss: 3.2284529209136963\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 166, batch train loss: 2.3781070709228516\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 167, batch train loss: 2.511497974395752\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 168, batch train loss: 3.1416876316070557\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 169, batch train loss: 3.3707199096679688\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 170, batch train loss: 3.3002450466156006\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 171, batch train loss: 2.4445903301239014\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 172, batch train loss: 4.118836879730225\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 173, batch train loss: 3.517282009124756\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 174, batch train loss: 3.901658058166504\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 175, batch train loss: 2.571974277496338\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 176, batch train loss: 3.805011510848999\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 177, batch train loss: 4.121915817260742\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 178, batch train loss: 2.7338063716888428\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 179, batch train loss: 2.9368746280670166\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 180, batch train loss: 2.254641056060791\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 181, batch train loss: 2.236947774887085\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 182, batch train loss: 2.0809895992279053\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 183, batch train loss: 1.8714408874511719\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 184, batch train loss: 1.6524453163146973\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 185, batch train loss: 2.2224159240722656\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 186, batch train loss: 1.9928981065750122\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 187, batch train loss: 2.018040895462036\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 188, batch train loss: 2.2873456478118896\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 189, batch train loss: 2.5527331829071045\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 190, batch train loss: 2.2009646892547607\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 191, batch train loss: 1.7908114194869995\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 192, batch train loss: 2.3842360973358154\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 193, batch train loss: 1.5349658727645874\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 194, batch train loss: 1.7835990190505981\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 195, batch train loss: 1.6142823696136475\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 196, batch train loss: 1.8884317874908447\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 197, batch train loss: 2.3410637378692627\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 198, batch train loss: 3.300853729248047\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 199, batch train loss: 2.9310975074768066\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 200, batch train loss: 3.5931143760681152\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 201, batch train loss: 2.8088057041168213\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 202, batch train loss: 2.3218438625335693\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 203, batch train loss: 2.5460386276245117\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 204, batch train loss: 2.0737197399139404\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 205, batch train loss: 2.3077187538146973\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 206, batch train loss: 2.147205114364624\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 207, batch train loss: 2.8919131755828857\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 208, batch train loss: 2.3483753204345703\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 209, batch train loss: 2.2806875705718994\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 210, batch train loss: 2.70648193359375\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 211, batch train loss: 2.494424343109131\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 212, batch train loss: 2.364295482635498\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 213, batch train loss: 3.201146125793457\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 214, batch train loss: 1.778441309928894\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 215, batch train loss: 2.3543055057525635\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 216, batch train loss: 2.326978921890259\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 217, batch train loss: 4.261389255523682\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 218, batch train loss: 2.5417873859405518\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 219, batch train loss: 3.0864202976226807\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 220, batch train loss: 2.294630527496338\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 221, batch train loss: 2.4368391036987305\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 222, batch train loss: 2.685776472091675\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 223, batch train loss: 2.811689615249634\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 224, batch train loss: 2.9765524864196777\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 225, batch train loss: 2.398496150970459\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 226, batch train loss: 2.185516119003296\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 227, batch train loss: 1.6581823825836182\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 228, batch train loss: 2.2076520919799805\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 229, batch train loss: 2.1025099754333496\n",
      "\n",
      "\n",
      "Epoch: 35, batch_id: 230, batch train loss: 3.5019595623016357\n",
      "\n",
      "\n",
      "Epoch: 35/ 100, Loss: 3.032506987841233\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:20<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 Validation Loss: 2.6919389526049295\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, batch_id: 1, batch train loss: 2.3266139030456543\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 2, batch train loss: 2.5550825595855713\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 3, batch train loss: 2.2140302658081055\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 4, batch train loss: 1.9125726222991943\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 5, batch train loss: 1.4286397695541382\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 6, batch train loss: 2.638500928878784\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 7, batch train loss: 4.183482646942139\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 8, batch train loss: 4.288022041320801\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 9, batch train loss: 2.652024984359741\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 10, batch train loss: 2.8915205001831055\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 11, batch train loss: 2.446295738220215\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 12, batch train loss: 2.6374199390411377\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 13, batch train loss: 2.3285763263702393\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 14, batch train loss: 2.2590386867523193\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 15, batch train loss: 2.1868114471435547\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 16, batch train loss: 2.1391239166259766\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 17, batch train loss: 2.610267400741577\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 18, batch train loss: 3.09501051902771\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 19, batch train loss: 5.180034160614014\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 20, batch train loss: 3.772388458251953\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 21, batch train loss: 2.203428030014038\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 22, batch train loss: 3.712191104888916\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 23, batch train loss: 3.7826790809631348\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 24, batch train loss: 3.099691867828369\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 25, batch train loss: 2.7761337757110596\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 26, batch train loss: 5.780101776123047\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 27, batch train loss: 1.8385988473892212\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 28, batch train loss: 2.811048984527588\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 29, batch train loss: 3.7229647636413574\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 30, batch train loss: 2.1953771114349365\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 31, batch train loss: 3.135014057159424\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 32, batch train loss: 2.2367422580718994\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 33, batch train loss: 2.1247122287750244\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 34, batch train loss: 2.8425049781799316\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 35, batch train loss: 2.0644690990448\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 36, batch train loss: 3.037437915802002\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 37, batch train loss: 2.0172059535980225\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 38, batch train loss: 2.986257791519165\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 39, batch train loss: 2.0265278816223145\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 40, batch train loss: 2.8398287296295166\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 41, batch train loss: 2.1864395141601562\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 42, batch train loss: 2.20137095451355\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 43, batch train loss: 1.8842034339904785\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 44, batch train loss: 2.3544540405273438\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 45, batch train loss: 2.1874711513519287\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 46, batch train loss: 2.4435551166534424\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 47, batch train loss: 2.0912163257598877\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 48, batch train loss: 2.347641706466675\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 49, batch train loss: 2.5612707138061523\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 50, batch train loss: 2.680335283279419\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 51, batch train loss: 2.06217885017395\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 52, batch train loss: 1.8560807704925537\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 53, batch train loss: 3.6858487129211426\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 54, batch train loss: 2.033538341522217\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 55, batch train loss: 3.2496964931488037\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 56, batch train loss: 2.088022470474243\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 57, batch train loss: 2.7223353385925293\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 58, batch train loss: 3.5538156032562256\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 59, batch train loss: 2.089383602142334\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 60, batch train loss: 2.416020393371582\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 61, batch train loss: 3.7543962001800537\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 62, batch train loss: 2.0822012424468994\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 63, batch train loss: 3.525380849838257\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 64, batch train loss: 3.341189384460449\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 65, batch train loss: 2.7102396488189697\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 66, batch train loss: 2.3354058265686035\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 67, batch train loss: 2.6492717266082764\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 68, batch train loss: 1.7778314352035522\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 69, batch train loss: 2.083742141723633\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 70, batch train loss: 2.624116897583008\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 71, batch train loss: 2.270059585571289\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 72, batch train loss: 1.6774065494537354\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 73, batch train loss: 2.214984893798828\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 74, batch train loss: 2.0167298316955566\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 75, batch train loss: 1.8492497205734253\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 76, batch train loss: 1.8110064268112183\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 77, batch train loss: 1.9755562543869019\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 78, batch train loss: 1.8454433679580688\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 79, batch train loss: 1.7972674369812012\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 80, batch train loss: 2.2739391326904297\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 81, batch train loss: 1.619421124458313\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 82, batch train loss: 2.2299931049346924\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 83, batch train loss: 1.239319920539856\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 84, batch train loss: 2.4017369747161865\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 85, batch train loss: 1.6690409183502197\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 86, batch train loss: 2.2545158863067627\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 87, batch train loss: 1.773942470550537\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 88, batch train loss: 1.7301998138427734\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 89, batch train loss: 2.03271484375\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 90, batch train loss: 1.7432781457901\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 91, batch train loss: 1.5474793910980225\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 92, batch train loss: 1.6225671768188477\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 93, batch train loss: 1.512908935546875\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 94, batch train loss: 2.6993045806884766\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 95, batch train loss: 2.6174323558807373\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 96, batch train loss: 2.5181994438171387\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 97, batch train loss: 2.378544807434082\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 98, batch train loss: 2.5712661743164062\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 99, batch train loss: 2.0670692920684814\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 100, batch train loss: 2.2010018825531006\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 101, batch train loss: 2.9342851638793945\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 102, batch train loss: 2.4727375507354736\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 103, batch train loss: 2.4552242755889893\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 104, batch train loss: 2.8678739070892334\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 105, batch train loss: 1.8736114501953125\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 106, batch train loss: 3.115018844604492\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 107, batch train loss: 2.5764920711517334\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 108, batch train loss: 2.2863900661468506\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 109, batch train loss: 2.8121836185455322\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 110, batch train loss: 2.686882972717285\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 111, batch train loss: 2.5768449306488037\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 112, batch train loss: 1.8762644529342651\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 113, batch train loss: 3.792290449142456\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 114, batch train loss: 2.569253921508789\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 115, batch train loss: 3.0018012523651123\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 116, batch train loss: 2.891800880432129\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 117, batch train loss: 2.527191400527954\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 118, batch train loss: 3.7824223041534424\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 119, batch train loss: 3.5881831645965576\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 120, batch train loss: 2.2120325565338135\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 121, batch train loss: 3.593714952468872\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 122, batch train loss: 4.39300012588501\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 123, batch train loss: 2.7950873374938965\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 124, batch train loss: 3.413201093673706\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 125, batch train loss: 2.8604636192321777\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 126, batch train loss: 2.8283488750457764\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 127, batch train loss: 3.1487159729003906\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 128, batch train loss: 2.8175570964813232\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 129, batch train loss: 2.948793649673462\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, batch_id: 130, batch train loss: 3.205416202545166\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 131, batch train loss: 2.3826985359191895\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 132, batch train loss: 2.2106995582580566\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 133, batch train loss: 2.889150857925415\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 134, batch train loss: 2.5217390060424805\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 135, batch train loss: 2.778994560241699\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 136, batch train loss: 2.326338052749634\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 137, batch train loss: 2.0982136726379395\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 138, batch train loss: 2.2656350135803223\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 139, batch train loss: 2.346374273300171\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 140, batch train loss: 1.8430196046829224\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 141, batch train loss: 1.8695257902145386\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 142, batch train loss: 1.8907724618911743\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 143, batch train loss: 1.9451711177825928\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 144, batch train loss: 1.7844630479812622\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 145, batch train loss: 2.2323248386383057\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 146, batch train loss: 2.1688389778137207\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 147, batch train loss: 2.011558771133423\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 148, batch train loss: 1.6122848987579346\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 149, batch train loss: 1.5852900743484497\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 150, batch train loss: 2.086942434310913\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 151, batch train loss: 1.4120210409164429\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 152, batch train loss: 1.588197946548462\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 153, batch train loss: 1.8483846187591553\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 154, batch train loss: 1.5168317556381226\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 155, batch train loss: 1.8098502159118652\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 156, batch train loss: 1.6695719957351685\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 157, batch train loss: 2.654689311981201\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 158, batch train loss: 2.925520420074463\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 159, batch train loss: 3.8751485347747803\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 160, batch train loss: 3.2641825675964355\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 161, batch train loss: 2.286149740219116\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 162, batch train loss: 2.919973611831665\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 163, batch train loss: 3.0098509788513184\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 164, batch train loss: 3.096390962600708\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 165, batch train loss: 1.9790666103363037\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 166, batch train loss: 2.3768885135650635\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 167, batch train loss: 1.8989640474319458\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 168, batch train loss: 1.6952531337738037\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 169, batch train loss: 2.332504987716675\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 170, batch train loss: 1.797152042388916\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 171, batch train loss: 1.656783938407898\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 172, batch train loss: 1.5920652151107788\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 173, batch train loss: 2.576307535171509\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 174, batch train loss: 2.692363977432251\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 175, batch train loss: 3.9033048152923584\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 176, batch train loss: 2.552933692932129\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 177, batch train loss: 2.8503646850585938\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 178, batch train loss: 3.3893380165100098\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 179, batch train loss: 2.800751209259033\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 180, batch train loss: 2.4349026679992676\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 181, batch train loss: 2.902402400970459\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 182, batch train loss: 2.87959885597229\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 183, batch train loss: 2.524273157119751\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 184, batch train loss: 3.2370564937591553\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 185, batch train loss: 2.3833556175231934\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 186, batch train loss: 2.394671678543091\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 187, batch train loss: 1.7849202156066895\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 188, batch train loss: 1.973086953163147\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 189, batch train loss: 2.505244255065918\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 190, batch train loss: 1.9875290393829346\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 191, batch train loss: 2.3190555572509766\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 192, batch train loss: 2.812941789627075\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 193, batch train loss: 2.5375959873199463\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 194, batch train loss: 2.0142128467559814\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 195, batch train loss: 1.8707749843597412\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 196, batch train loss: 1.6857514381408691\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 197, batch train loss: 1.7459757328033447\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 198, batch train loss: 1.4978808164596558\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 199, batch train loss: 2.076920509338379\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 200, batch train loss: 1.795108437538147\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 201, batch train loss: 1.6729050874710083\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 202, batch train loss: 1.392154335975647\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 203, batch train loss: 1.7644976377487183\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 204, batch train loss: 1.9264894723892212\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 205, batch train loss: 2.5024096965789795\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 206, batch train loss: 1.9901666641235352\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 207, batch train loss: 2.0404300689697266\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 208, batch train loss: 1.7608774900436401\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 209, batch train loss: 1.8367902040481567\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 210, batch train loss: 2.105729579925537\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 211, batch train loss: 1.7284696102142334\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 212, batch train loss: 1.5147544145584106\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 213, batch train loss: 1.4310883283615112\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 214, batch train loss: 1.7620455026626587\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 215, batch train loss: 1.6197634935379028\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 216, batch train loss: 2.0635876655578613\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 217, batch train loss: 1.7050598859786987\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 218, batch train loss: 1.475546956062317\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 219, batch train loss: 1.9439339637756348\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 220, batch train loss: 1.4920347929000854\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 221, batch train loss: 1.500914216041565\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 222, batch train loss: 2.094480276107788\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 223, batch train loss: 2.574068784713745\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 224, batch train loss: 2.4453630447387695\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 225, batch train loss: 1.9246166944503784\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 226, batch train loss: 1.9134732484817505\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 227, batch train loss: 2.037487268447876\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 228, batch train loss: 1.7462109327316284\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 229, batch train loss: 1.3874263763427734\n",
      "\n",
      "\n",
      "Epoch: 36, batch_id: 230, batch train loss: 1.2310824394226074\n",
      "\n",
      "\n",
      "Epoch: 36/ 100, Loss: 2.392998482870019\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:22<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 Validation Loss: 1.5850676159063974\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 37, batch_id: 1, batch train loss: 1.5238533020019531\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 2, batch train loss: 2.0196168422698975\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 3, batch train loss: 1.7335262298583984\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 4, batch train loss: 1.4024502038955688\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 5, batch train loss: 2.4531354904174805\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 6, batch train loss: 2.0705060958862305\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 7, batch train loss: 2.151904582977295\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 8, batch train loss: 1.4759827852249146\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 9, batch train loss: 2.093259572982788\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 10, batch train loss: 1.8645552396774292\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 11, batch train loss: 2.199075222015381\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 12, batch train loss: 1.5968924760818481\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 13, batch train loss: 2.3136682510375977\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 14, batch train loss: 1.326052188873291\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 15, batch train loss: 1.1829965114593506\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 16, batch train loss: 1.391696810722351\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 17, batch train loss: 1.5023832321166992\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 18, batch train loss: 1.7035444974899292\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 19, batch train loss: 1.3445923328399658\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 20, batch train loss: 1.3515785932540894\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 21, batch train loss: 1.3446329832077026\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 22, batch train loss: 1.1973588466644287\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 23, batch train loss: 1.5637626647949219\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 24, batch train loss: 1.8930678367614746\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 25, batch train loss: 1.5110394954681396\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 26, batch train loss: 1.641629695892334\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 27, batch train loss: 1.8094791173934937\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 28, batch train loss: 2.32601261138916\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 29, batch train loss: 1.798020839691162\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 30, batch train loss: 1.4915217161178589\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 31, batch train loss: 1.5435558557510376\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 32, batch train loss: 1.3834974765777588\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 33, batch train loss: 1.7988948822021484\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 34, batch train loss: 2.6958887577056885\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 35, batch train loss: 2.0794897079467773\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 36, batch train loss: 1.9715524911880493\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 37, batch train loss: 1.6141823530197144\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 38, batch train loss: 1.6751608848571777\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 39, batch train loss: 1.7332645654678345\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 40, batch train loss: 3.1703832149505615\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 41, batch train loss: 2.046570062637329\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 42, batch train loss: 3.0686235427856445\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 43, batch train loss: 4.364345073699951\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 44, batch train loss: 3.163315534591675\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 45, batch train loss: 3.3976616859436035\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 46, batch train loss: 2.5684452056884766\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 47, batch train loss: 2.6574437618255615\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 48, batch train loss: 5.004323482513428\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 49, batch train loss: 2.0015196800231934\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 50, batch train loss: 2.084155797958374\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 51, batch train loss: 2.574017286300659\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 52, batch train loss: 2.455019235610962\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 53, batch train loss: 2.3306193351745605\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 54, batch train loss: 2.5347180366516113\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 55, batch train loss: 2.65238881111145\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 56, batch train loss: 2.3272998332977295\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 57, batch train loss: 2.273939609527588\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 58, batch train loss: 2.9094691276550293\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 59, batch train loss: 2.57118821144104\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 60, batch train loss: 2.917783498764038\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 61, batch train loss: 2.301360845565796\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 62, batch train loss: 2.5902202129364014\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 63, batch train loss: 1.9081475734710693\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 64, batch train loss: 1.4731721878051758\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 65, batch train loss: 1.5981296300888062\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 66, batch train loss: 2.1827542781829834\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 67, batch train loss: 1.829443335533142\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 68, batch train loss: 2.011706590652466\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 69, batch train loss: 1.4130690097808838\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 70, batch train loss: 3.594064950942993\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 71, batch train loss: 1.7602639198303223\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 72, batch train loss: 2.2065353393554688\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 73, batch train loss: 1.502727746963501\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 74, batch train loss: 1.5749106407165527\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 75, batch train loss: 2.0450735092163086\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 76, batch train loss: 2.212602376937866\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 77, batch train loss: 2.468808174133301\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 78, batch train loss: 2.295107364654541\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 79, batch train loss: 2.4003469944000244\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 80, batch train loss: 2.55036997795105\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 81, batch train loss: 1.467410922050476\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 82, batch train loss: 3.152888298034668\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 83, batch train loss: 1.3400654792785645\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 84, batch train loss: 2.137645959854126\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 85, batch train loss: 1.9855704307556152\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 86, batch train loss: 1.8004018068313599\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 87, batch train loss: 1.7207180261611938\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 88, batch train loss: 1.9283679723739624\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 89, batch train loss: 1.4650897979736328\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 90, batch train loss: 2.3722591400146484\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 91, batch train loss: 1.5248769521713257\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 92, batch train loss: 2.2460029125213623\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 93, batch train loss: 1.8928982019424438\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 94, batch train loss: 2.029482126235962\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 95, batch train loss: 1.4631338119506836\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 96, batch train loss: 2.032036542892456\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 97, batch train loss: 1.519382119178772\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 98, batch train loss: 2.271669864654541\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 99, batch train loss: 1.6621097326278687\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 100, batch train loss: 2.2204134464263916\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 101, batch train loss: 1.6754522323608398\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 102, batch train loss: 1.8888543844223022\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 103, batch train loss: 2.113873243331909\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 104, batch train loss: 1.9348245859146118\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 105, batch train loss: 2.0573861598968506\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 106, batch train loss: 2.522726535797119\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 107, batch train loss: 1.5059146881103516\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 108, batch train loss: 4.672949314117432\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 109, batch train loss: 1.8072009086608887\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 110, batch train loss: 2.1561594009399414\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 111, batch train loss: 2.2451956272125244\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 112, batch train loss: 1.6853313446044922\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 113, batch train loss: 2.952343702316284\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 114, batch train loss: 1.9248303174972534\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 115, batch train loss: 3.160311460494995\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 116, batch train loss: 2.9099063873291016\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 117, batch train loss: 2.8109827041625977\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 118, batch train loss: 3.6603193283081055\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 119, batch train loss: 3.3522114753723145\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 120, batch train loss: 2.791703462600708\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 121, batch train loss: 6.780757904052734\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 122, batch train loss: 3.3963119983673096\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 123, batch train loss: 1.9913603067398071\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 124, batch train loss: 2.7011919021606445\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 125, batch train loss: 3.3642165660858154\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 126, batch train loss: 2.5356521606445312\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 127, batch train loss: 3.3645904064178467\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, batch_id: 128, batch train loss: 2.882366180419922\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 129, batch train loss: 1.9551560878753662\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 130, batch train loss: 2.1201276779174805\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 131, batch train loss: 3.1758203506469727\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 132, batch train loss: 3.1171011924743652\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 133, batch train loss: 2.5691771507263184\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 134, batch train loss: 3.6543688774108887\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 135, batch train loss: 2.7524573802948\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 136, batch train loss: 2.529984951019287\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 137, batch train loss: 3.4188387393951416\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 138, batch train loss: 3.023879051208496\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 139, batch train loss: 2.7516069412231445\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 140, batch train loss: 2.2814040184020996\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 141, batch train loss: 3.4182329177856445\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 142, batch train loss: 2.256030797958374\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 143, batch train loss: 3.2755236625671387\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 144, batch train loss: 3.2088589668273926\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 145, batch train loss: 2.6074490547180176\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 146, batch train loss: 3.1152522563934326\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 147, batch train loss: 4.570103645324707\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 148, batch train loss: 2.8205692768096924\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 149, batch train loss: 3.5376029014587402\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 150, batch train loss: 2.7580158710479736\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 151, batch train loss: 2.695338010787964\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 152, batch train loss: 4.239865779876709\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 153, batch train loss: 4.105325698852539\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 154, batch train loss: 2.7135212421417236\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 155, batch train loss: 2.9187231063842773\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 156, batch train loss: 3.9447457790374756\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 157, batch train loss: 2.1988368034362793\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 158, batch train loss: 2.49570369720459\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 159, batch train loss: 4.360940933227539\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 160, batch train loss: 6.074014663696289\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 161, batch train loss: 3.350080966949463\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 162, batch train loss: 4.128118515014648\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 163, batch train loss: 4.046547889709473\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 164, batch train loss: 2.0343940258026123\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 165, batch train loss: 2.3256912231445312\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 166, batch train loss: 2.88600754737854\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 167, batch train loss: 3.3046677112579346\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 168, batch train loss: 3.7366626262664795\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 169, batch train loss: 5.353847503662109\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 170, batch train loss: 6.707202911376953\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 171, batch train loss: 5.784753322601318\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 172, batch train loss: 4.081035614013672\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 173, batch train loss: 5.393712043762207\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 174, batch train loss: 5.527768135070801\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 175, batch train loss: 3.8976073265075684\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 176, batch train loss: 3.13451886177063\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 177, batch train loss: 4.4145050048828125\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 178, batch train loss: 5.63907527923584\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 179, batch train loss: 3.766230583190918\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 180, batch train loss: 4.0997633934021\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 181, batch train loss: 5.411280155181885\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 182, batch train loss: 3.793710231781006\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 183, batch train loss: 3.0688819885253906\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 184, batch train loss: 4.449731826782227\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 185, batch train loss: 5.7851152420043945\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 186, batch train loss: 2.672574520111084\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 187, batch train loss: 3.0138890743255615\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 188, batch train loss: 2.6242003440856934\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 189, batch train loss: 2.0822184085845947\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 190, batch train loss: 2.615513324737549\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 191, batch train loss: 2.1023850440979004\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 192, batch train loss: 7.576930999755859\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 193, batch train loss: 8.966238975524902\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 194, batch train loss: 3.701033592224121\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 195, batch train loss: 3.1423544883728027\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 196, batch train loss: 7.068492889404297\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 197, batch train loss: 5.034090042114258\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 198, batch train loss: 6.299859046936035\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 199, batch train loss: 4.035581111907959\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 200, batch train loss: 4.945348739624023\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 201, batch train loss: 2.71606183052063\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 202, batch train loss: 2.7223081588745117\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 203, batch train loss: 2.3597159385681152\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 204, batch train loss: 2.5965189933776855\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 205, batch train loss: 2.4434611797332764\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 206, batch train loss: 2.4630608558654785\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 207, batch train loss: 2.369744062423706\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 208, batch train loss: 2.393693208694458\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 209, batch train loss: 2.4797372817993164\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 210, batch train loss: 2.521296262741089\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 211, batch train loss: 2.3231422901153564\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 212, batch train loss: 2.4251508712768555\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 213, batch train loss: 3.616605520248413\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 214, batch train loss: 2.7014412879943848\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 215, batch train loss: 2.777519464492798\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 216, batch train loss: 2.8475723266601562\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 217, batch train loss: 2.2672648429870605\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 218, batch train loss: 3.1197574138641357\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 219, batch train loss: 2.3487374782562256\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 220, batch train loss: 2.686084747314453\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 221, batch train loss: 1.9873404502868652\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 222, batch train loss: 2.633148431777954\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 223, batch train loss: 2.626378297805786\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 224, batch train loss: 2.4574921131134033\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 225, batch train loss: 3.496654748916626\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 226, batch train loss: 3.035954475402832\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 227, batch train loss: 3.1988322734832764\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 228, batch train loss: 2.011244773864746\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 229, batch train loss: 2.3451614379882812\n",
      "\n",
      "\n",
      "Epoch: 37, batch_id: 230, batch train loss: 1.697981595993042\n",
      "\n",
      "\n",
      "Epoch: 37/ 100, Loss: 2.757295377358146\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:18<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 Validation Loss: 2.110515383879344\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, batch_id: 1, batch train loss: 2.0953562259674072\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 2, batch train loss: 1.28358793258667\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 3, batch train loss: 3.0636227130889893\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 4, batch train loss: 2.4470252990722656\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 5, batch train loss: 2.2796425819396973\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 6, batch train loss: 2.6105103492736816\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 7, batch train loss: 1.8747167587280273\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 8, batch train loss: 2.8129334449768066\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 9, batch train loss: 2.1724913120269775\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 10, batch train loss: 2.401087999343872\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 11, batch train loss: 2.5377678871154785\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 12, batch train loss: 2.20809006690979\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 13, batch train loss: 2.144217014312744\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 14, batch train loss: 2.3849387168884277\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 15, batch train loss: 1.95587158203125\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 16, batch train loss: 2.479551076889038\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 17, batch train loss: 2.3595731258392334\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 18, batch train loss: 2.2848775386810303\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 19, batch train loss: 2.0598721504211426\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 20, batch train loss: 1.7078806161880493\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 21, batch train loss: 2.083873987197876\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 22, batch train loss: 2.241328239440918\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 23, batch train loss: 2.9655601978302\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 24, batch train loss: 3.4770402908325195\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 25, batch train loss: 2.1222314834594727\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 26, batch train loss: 2.7629873752593994\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 27, batch train loss: 2.4533851146698\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 28, batch train loss: 4.69549036026001\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 29, batch train loss: 2.5195374488830566\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 30, batch train loss: 4.0999603271484375\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 31, batch train loss: 2.370867967605591\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 32, batch train loss: 5.5800909996032715\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 33, batch train loss: 2.825986385345459\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 34, batch train loss: 2.435918092727661\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 35, batch train loss: 3.6680831909179688\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 36, batch train loss: 2.1531436443328857\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 37, batch train loss: 5.062662124633789\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 38, batch train loss: 1.7482717037200928\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 39, batch train loss: 2.629535436630249\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 40, batch train loss: 5.74422025680542\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 41, batch train loss: 5.273301124572754\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 42, batch train loss: 2.245713949203491\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 43, batch train loss: 4.245913028717041\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 44, batch train loss: 2.5408787727355957\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 45, batch train loss: 3.201317310333252\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 46, batch train loss: 3.047860860824585\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 47, batch train loss: 3.562469005584717\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 48, batch train loss: 2.766721487045288\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 49, batch train loss: 2.8266379833221436\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 50, batch train loss: 2.7426795959472656\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 51, batch train loss: 3.4133267402648926\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 52, batch train loss: 2.337393283843994\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 53, batch train loss: 2.9578044414520264\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 54, batch train loss: 1.9308733940124512\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 55, batch train loss: 4.1911301612854\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 56, batch train loss: 4.053134918212891\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 57, batch train loss: 2.820117950439453\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 58, batch train loss: 2.6873960494995117\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 59, batch train loss: 2.4925265312194824\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 60, batch train loss: 2.5758237838745117\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 61, batch train loss: 2.5778894424438477\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 62, batch train loss: 2.7110743522644043\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 63, batch train loss: 2.8633248805999756\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 64, batch train loss: 2.2234044075012207\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 65, batch train loss: 3.785358428955078\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 66, batch train loss: 2.545609474182129\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 67, batch train loss: 2.025742530822754\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 68, batch train loss: 2.6841604709625244\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 69, batch train loss: 2.183053731918335\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 70, batch train loss: 3.8304524421691895\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 71, batch train loss: 2.486701250076294\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 72, batch train loss: 2.3188302516937256\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 73, batch train loss: 2.1787564754486084\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 74, batch train loss: 2.7488882541656494\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 75, batch train loss: 3.0018622875213623\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 76, batch train loss: 2.3130412101745605\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 77, batch train loss: 2.1357262134552\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 78, batch train loss: 2.413942575454712\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 79, batch train loss: 1.7691017389297485\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 80, batch train loss: 2.41837477684021\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 81, batch train loss: 2.3033523559570312\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 82, batch train loss: 2.051788806915283\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 83, batch train loss: 1.785546064376831\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 84, batch train loss: 1.9911994934082031\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 85, batch train loss: 1.6850978136062622\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 86, batch train loss: 1.547460913658142\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 87, batch train loss: 1.6451873779296875\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 88, batch train loss: 1.8346529006958008\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 89, batch train loss: 1.5628365278244019\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 90, batch train loss: 1.7543855905532837\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 91, batch train loss: 2.258180856704712\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 92, batch train loss: 1.8870880603790283\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 93, batch train loss: 2.3707926273345947\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 94, batch train loss: 2.266157865524292\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 95, batch train loss: 1.7851951122283936\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 96, batch train loss: 1.564153790473938\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 97, batch train loss: 1.5097222328186035\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 98, batch train loss: 1.6832391023635864\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 99, batch train loss: 1.9746097326278687\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 100, batch train loss: 1.9299613237380981\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 101, batch train loss: 1.879279375076294\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 102, batch train loss: 2.164512872695923\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 103, batch train loss: 1.9725492000579834\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 104, batch train loss: 1.6451416015625\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 105, batch train loss: 1.5214431285858154\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 106, batch train loss: 1.4463046789169312\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 107, batch train loss: 1.7875484228134155\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 108, batch train loss: 2.256047248840332\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 109, batch train loss: 2.0251924991607666\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 110, batch train loss: 2.01167368888855\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 111, batch train loss: 1.8527750968933105\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 112, batch train loss: 1.8309767246246338\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 113, batch train loss: 1.5498937368392944\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 114, batch train loss: 1.5775009393692017\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 115, batch train loss: 1.5088927745819092\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 116, batch train loss: 1.5300275087356567\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 117, batch train loss: 1.3940109014511108\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 118, batch train loss: 1.747308373451233\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 119, batch train loss: 1.6400140523910522\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 120, batch train loss: 2.049025535583496\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 121, batch train loss: 1.782352328300476\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 122, batch train loss: 1.7357134819030762\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 123, batch train loss: 1.8651444911956787\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 124, batch train loss: 2.947662591934204\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 125, batch train loss: 2.4666402339935303\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 126, batch train loss: 1.9505480527877808\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 127, batch train loss: 2.346378803253174\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 128, batch train loss: 1.8421069383621216\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 129, batch train loss: 2.413881301879883\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, batch_id: 130, batch train loss: 2.199727773666382\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 131, batch train loss: 1.848425269126892\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 132, batch train loss: 2.389331579208374\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 133, batch train loss: 1.8318532705307007\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 134, batch train loss: 2.276393413543701\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 135, batch train loss: 1.9423991441726685\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 136, batch train loss: 2.1008293628692627\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 137, batch train loss: 2.0681464672088623\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 138, batch train loss: 1.9115079641342163\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 139, batch train loss: 2.1941821575164795\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 140, batch train loss: 2.229077100753784\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 141, batch train loss: 2.092424154281616\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 142, batch train loss: 1.9500401020050049\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 143, batch train loss: 2.0753109455108643\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 144, batch train loss: 1.520883321762085\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 145, batch train loss: 2.0044217109680176\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 146, batch train loss: 1.467490792274475\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 147, batch train loss: 2.2427356243133545\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 148, batch train loss: 1.8052146434783936\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 149, batch train loss: 1.7507888078689575\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 150, batch train loss: 1.8312458992004395\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 151, batch train loss: 1.507781744003296\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 152, batch train loss: 1.5323266983032227\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 153, batch train loss: 1.6866352558135986\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 154, batch train loss: 1.3904626369476318\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 155, batch train loss: 1.5772136449813843\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 156, batch train loss: 1.7056673765182495\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 157, batch train loss: 1.8082491159439087\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 158, batch train loss: 1.6610729694366455\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 159, batch train loss: 1.4137922525405884\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 160, batch train loss: 2.109621286392212\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 161, batch train loss: 1.5394963026046753\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 162, batch train loss: 1.6004576683044434\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 163, batch train loss: 1.4772320985794067\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 164, batch train loss: 1.7464804649353027\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 165, batch train loss: 1.61727774143219\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 166, batch train loss: 1.6149829626083374\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 167, batch train loss: 2.4966187477111816\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 168, batch train loss: 1.9403064250946045\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 169, batch train loss: 2.49149489402771\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 170, batch train loss: 2.4954771995544434\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 171, batch train loss: 2.0395023822784424\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 172, batch train loss: 2.599350690841675\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 173, batch train loss: 2.364860773086548\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 174, batch train loss: 2.1772234439849854\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 175, batch train loss: 1.9869657754898071\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 176, batch train loss: 1.8695868253707886\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 177, batch train loss: 1.7658665180206299\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 178, batch train loss: 2.141672134399414\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 179, batch train loss: 2.7115530967712402\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 180, batch train loss: 1.7791149616241455\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 181, batch train loss: 2.5516133308410645\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 182, batch train loss: 2.3443493843078613\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 183, batch train loss: 3.3655943870544434\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 184, batch train loss: 2.602937936782837\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 185, batch train loss: 3.706317663192749\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 186, batch train loss: 2.8604869842529297\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 187, batch train loss: 1.747151494026184\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 188, batch train loss: 1.6380499601364136\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 189, batch train loss: 1.721147060394287\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 190, batch train loss: 2.529667854309082\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 191, batch train loss: 2.1447136402130127\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 192, batch train loss: 3.133903980255127\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 193, batch train loss: 1.9516751766204834\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 194, batch train loss: 2.225705623626709\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 195, batch train loss: 2.852635145187378\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 196, batch train loss: 2.598482131958008\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 197, batch train loss: 3.017272472381592\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 198, batch train loss: 2.1776907444000244\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 199, batch train loss: 2.98368763923645\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 200, batch train loss: 2.5287070274353027\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 201, batch train loss: 2.7474987506866455\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 202, batch train loss: 2.792520046234131\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 203, batch train loss: 3.5392074584960938\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 204, batch train loss: 3.3371174335479736\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 205, batch train loss: 2.9581446647644043\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 206, batch train loss: 2.7662606239318848\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 207, batch train loss: 3.890955924987793\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 208, batch train loss: 2.8533194065093994\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 209, batch train loss: 3.9062678813934326\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 210, batch train loss: 2.695919990539551\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 211, batch train loss: 3.8932955265045166\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 212, batch train loss: 3.83732533454895\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 213, batch train loss: 2.2349088191986084\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 214, batch train loss: 2.6548094749450684\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 215, batch train loss: 4.4179911613464355\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 216, batch train loss: 2.930171251296997\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 217, batch train loss: 2.819801092147827\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 218, batch train loss: 3.680344581604004\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 219, batch train loss: 2.386185646057129\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 220, batch train loss: 3.0843753814697266\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 221, batch train loss: 3.9243240356445312\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 222, batch train loss: 2.4294321537017822\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 223, batch train loss: 3.2312490940093994\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 224, batch train loss: 3.899907112121582\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 225, batch train loss: 2.4925897121429443\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 226, batch train loss: 3.172797679901123\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 227, batch train loss: 2.477649688720703\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 228, batch train loss: 3.0278067588806152\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 229, batch train loss: 3.5782430171966553\n",
      "\n",
      "\n",
      "Epoch: 38, batch_id: 230, batch train loss: 2.3227994441986084\n",
      "\n",
      "\n",
      "Epoch: 38/ 100, Loss: 2.423082791722339\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:08<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 Validation Loss: 2.7547775824864704\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, batch_id: 1, batch train loss: 2.6900978088378906\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 2, batch train loss: 2.9645822048187256\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 3, batch train loss: 2.1155827045440674\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 4, batch train loss: 3.6495327949523926\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 5, batch train loss: 2.223057746887207\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 6, batch train loss: 2.3960065841674805\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 7, batch train loss: 2.529796838760376\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 8, batch train loss: 2.267075300216675\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 9, batch train loss: 3.170166015625\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 10, batch train loss: 2.4679415225982666\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 11, batch train loss: 2.7972421646118164\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 12, batch train loss: 2.65875506401062\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 13, batch train loss: 2.2770700454711914\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 14, batch train loss: 2.375883102416992\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 15, batch train loss: 2.2854135036468506\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 16, batch train loss: 2.2587051391601562\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 17, batch train loss: 1.613892674446106\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 18, batch train loss: 2.6347897052764893\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 19, batch train loss: 2.454517126083374\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 20, batch train loss: 3.041830539703369\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 21, batch train loss: 2.5885090827941895\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 22, batch train loss: 2.05242657661438\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 23, batch train loss: 1.9276626110076904\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 24, batch train loss: 1.7166143655776978\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 25, batch train loss: 2.8185417652130127\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 26, batch train loss: 2.0509636402130127\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 27, batch train loss: 2.640756130218506\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 28, batch train loss: 2.74765944480896\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 29, batch train loss: 1.8765466213226318\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 30, batch train loss: 2.9332590103149414\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 31, batch train loss: 3.3801424503326416\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 32, batch train loss: 2.4363510608673096\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 33, batch train loss: 4.221136569976807\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 34, batch train loss: 4.48834228515625\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 35, batch train loss: 3.023273468017578\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 36, batch train loss: 2.792753219604492\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 37, batch train loss: 3.6235456466674805\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 38, batch train loss: 2.0024983882904053\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 39, batch train loss: 3.744699001312256\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 40, batch train loss: 3.4341437816619873\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 41, batch train loss: 3.734631299972534\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 42, batch train loss: 2.7647862434387207\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 43, batch train loss: 3.691465139389038\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 44, batch train loss: 2.6188178062438965\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 45, batch train loss: 2.1362366676330566\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 46, batch train loss: 2.964320182800293\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 47, batch train loss: 2.134716033935547\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 48, batch train loss: 2.452903985977173\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 49, batch train loss: 3.013775110244751\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 50, batch train loss: 2.495849370956421\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 51, batch train loss: 2.270268201828003\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 52, batch train loss: 2.050058364868164\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 53, batch train loss: 2.3294851779937744\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 54, batch train loss: 3.0136818885803223\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 55, batch train loss: 3.5748729705810547\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 56, batch train loss: 2.5820412635803223\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 57, batch train loss: 2.937891960144043\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 58, batch train loss: 3.257859706878662\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 59, batch train loss: 2.298288106918335\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 60, batch train loss: 2.2676937580108643\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 61, batch train loss: 2.248732566833496\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 62, batch train loss: 2.136732339859009\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 63, batch train loss: 3.2385594844818115\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 64, batch train loss: 2.4871160984039307\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 65, batch train loss: 2.050922155380249\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 66, batch train loss: 3.8038198947906494\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 67, batch train loss: 2.033923387527466\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 68, batch train loss: 3.621537208557129\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 69, batch train loss: 2.1655359268188477\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 70, batch train loss: 2.220517635345459\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 71, batch train loss: 2.1142702102661133\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 72, batch train loss: 3.3431625366210938\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 73, batch train loss: 2.6916048526763916\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 74, batch train loss: 1.9006425142288208\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 75, batch train loss: 2.28832745552063\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 76, batch train loss: 2.4193551540374756\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 77, batch train loss: 2.090580701828003\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 78, batch train loss: 2.270282745361328\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 79, batch train loss: 2.6389620304107666\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 80, batch train loss: 2.551211357116699\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 81, batch train loss: 2.308344602584839\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 82, batch train loss: 2.194876194000244\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 83, batch train loss: 2.4907002449035645\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 84, batch train loss: 2.3991124629974365\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 85, batch train loss: 2.4770052433013916\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 86, batch train loss: 2.7682321071624756\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 87, batch train loss: 1.9636293649673462\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 88, batch train loss: 1.9350444078445435\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 89, batch train loss: 2.039599895477295\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 90, batch train loss: 1.9735374450683594\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 91, batch train loss: 1.7049793004989624\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 92, batch train loss: 1.8050525188446045\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 93, batch train loss: 3.52059006690979\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 94, batch train loss: 1.6325777769088745\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 95, batch train loss: 2.5613114833831787\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 96, batch train loss: 2.4640324115753174\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 97, batch train loss: 1.817781925201416\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 98, batch train loss: 2.42549204826355\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 99, batch train loss: 2.3002188205718994\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 100, batch train loss: 2.1589362621307373\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 101, batch train loss: 2.727581024169922\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 102, batch train loss: 2.43570613861084\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 103, batch train loss: 4.414011001586914\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 104, batch train loss: 2.1078970432281494\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 105, batch train loss: 2.655176877975464\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 106, batch train loss: 3.7675700187683105\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 107, batch train loss: 2.923807144165039\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 108, batch train loss: 2.5276594161987305\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 109, batch train loss: 2.469093084335327\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 110, batch train loss: 2.3781819343566895\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 111, batch train loss: 2.7345032691955566\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 112, batch train loss: 4.409860610961914\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 113, batch train loss: 3.8054544925689697\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 114, batch train loss: 3.1569361686706543\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 115, batch train loss: 5.180389404296875\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 116, batch train loss: 4.199625015258789\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 117, batch train loss: 3.053426504135132\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 118, batch train loss: 3.953727960586548\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 119, batch train loss: 3.6059701442718506\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 120, batch train loss: 2.375291585922241\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 121, batch train loss: 3.2862906455993652\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 122, batch train loss: 2.624640703201294\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 123, batch train loss: 2.1282289028167725\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 124, batch train loss: 1.786264419555664\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 125, batch train loss: 2.4968037605285645\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 126, batch train loss: 2.448302745819092\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 127, batch train loss: 2.5315494537353516\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 128, batch train loss: 2.7292520999908447\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 129, batch train loss: 2.6352949142456055\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, batch_id: 130, batch train loss: 2.5058281421661377\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 131, batch train loss: 2.330974817276001\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 132, batch train loss: 2.661815881729126\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 133, batch train loss: 1.9406750202178955\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 134, batch train loss: 1.8943662643432617\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 135, batch train loss: 2.1341142654418945\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 136, batch train loss: 2.0169310569763184\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 137, batch train loss: 2.334429979324341\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 138, batch train loss: 2.3695459365844727\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 139, batch train loss: 1.9714603424072266\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 140, batch train loss: 2.8015334606170654\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 141, batch train loss: 2.0912649631500244\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 142, batch train loss: 2.048022985458374\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 143, batch train loss: 2.1511640548706055\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 144, batch train loss: 2.6671342849731445\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 145, batch train loss: 1.9730480909347534\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 146, batch train loss: 2.5913476943969727\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 147, batch train loss: 2.04508113861084\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 148, batch train loss: 3.045905351638794\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 149, batch train loss: 3.5573861598968506\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 150, batch train loss: 3.5421953201293945\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 151, batch train loss: 3.521756649017334\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 152, batch train loss: 2.987830877304077\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 153, batch train loss: 2.7528915405273438\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 154, batch train loss: 3.0357506275177\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 155, batch train loss: 2.9976186752319336\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 156, batch train loss: 1.8953189849853516\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 157, batch train loss: 3.1532554626464844\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 158, batch train loss: 2.1124372482299805\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 159, batch train loss: 2.626307249069214\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 160, batch train loss: 3.0939810276031494\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 161, batch train loss: 1.726416826248169\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 162, batch train loss: 1.8116573095321655\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 163, batch train loss: 2.499204158782959\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 164, batch train loss: 2.3525466918945312\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 165, batch train loss: 3.256546974182129\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 166, batch train loss: 2.2205185890197754\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 167, batch train loss: 2.054011821746826\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 168, batch train loss: 2.5618317127227783\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 169, batch train loss: 1.4906604290008545\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 170, batch train loss: 2.5006134510040283\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 171, batch train loss: 1.7002882957458496\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 172, batch train loss: 2.4127111434936523\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 173, batch train loss: 2.0885374546051025\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 174, batch train loss: 1.846290946006775\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 175, batch train loss: 1.8262064456939697\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 176, batch train loss: 1.5136005878448486\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 177, batch train loss: 1.5348633527755737\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 178, batch train loss: 1.638421893119812\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 179, batch train loss: 2.350890874862671\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 180, batch train loss: 2.33951997756958\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 181, batch train loss: 2.471876382827759\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 182, batch train loss: 3.160268545150757\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 183, batch train loss: 2.653740167617798\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 184, batch train loss: 2.1888551712036133\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 185, batch train loss: 2.002060651779175\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 186, batch train loss: 2.477992296218872\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 187, batch train loss: 2.5796778202056885\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 188, batch train loss: 2.22092604637146\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 189, batch train loss: 2.669416904449463\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 190, batch train loss: 1.8266080617904663\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 191, batch train loss: 2.557354211807251\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 192, batch train loss: 2.4195363521575928\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 193, batch train loss: 2.3217456340789795\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 194, batch train loss: 2.2416577339172363\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 195, batch train loss: 2.0563747882843018\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 196, batch train loss: 1.806270718574524\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 197, batch train loss: 2.086534023284912\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 198, batch train loss: 2.1430552005767822\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 199, batch train loss: 2.9100842475891113\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 200, batch train loss: 2.1844887733459473\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 201, batch train loss: 1.5200605392456055\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 202, batch train loss: 1.9594922065734863\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 203, batch train loss: 1.6334099769592285\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 204, batch train loss: 2.446729898452759\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 205, batch train loss: 2.2030577659606934\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 206, batch train loss: 1.9698209762573242\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 207, batch train loss: 1.8217012882232666\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 208, batch train loss: 1.6514285802841187\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 209, batch train loss: 2.525907039642334\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 210, batch train loss: 3.052628517150879\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 211, batch train loss: 4.091163635253906\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 212, batch train loss: 4.412737846374512\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 213, batch train loss: 5.13556432723999\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 214, batch train loss: 2.7992312908172607\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 215, batch train loss: 3.4266650676727295\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 216, batch train loss: 5.927395343780518\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 217, batch train loss: 2.063798666000366\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 218, batch train loss: 3.7488741874694824\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 219, batch train loss: 2.940423011779785\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 220, batch train loss: 4.215150356292725\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 221, batch train loss: 3.4439713954925537\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 222, batch train loss: 3.8603618144989014\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 223, batch train loss: 5.176238536834717\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 224, batch train loss: 3.4018325805664062\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 225, batch train loss: 1.8848838806152344\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 226, batch train loss: 3.4322681427001953\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 227, batch train loss: 3.8111917972564697\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 228, batch train loss: 4.892343521118164\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 229, batch train loss: 3.208444595336914\n",
      "\n",
      "\n",
      "Epoch: 39, batch_id: 230, batch train loss: 4.34782075881958\n",
      "\n",
      "\n",
      "Epoch: 39/ 100, Loss: 2.649246034933173\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:21<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 Validation Loss: 3.9710870107014973\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, batch_id: 1, batch train loss: 4.051822185516357\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 2, batch train loss: 2.0510635375976562\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 3, batch train loss: 2.6060123443603516\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 4, batch train loss: 3.9495413303375244\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 5, batch train loss: 2.518578052520752\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 6, batch train loss: 2.6138739585876465\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 7, batch train loss: 3.0486457347869873\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 8, batch train loss: 3.0046050548553467\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 9, batch train loss: 2.0360267162323\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 10, batch train loss: 1.958472490310669\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 11, batch train loss: 2.311588764190674\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 12, batch train loss: 1.4360445737838745\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 13, batch train loss: 1.6051698923110962\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 14, batch train loss: 1.8226560354232788\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 15, batch train loss: 1.7737268209457397\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 16, batch train loss: 1.7361810207366943\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 17, batch train loss: 1.5111559629440308\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 18, batch train loss: 2.3340468406677246\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 19, batch train loss: 2.5325560569763184\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 20, batch train loss: 1.490753173828125\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 21, batch train loss: 2.077000617980957\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 22, batch train loss: 1.8647702932357788\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 23, batch train loss: 1.6999682188034058\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 24, batch train loss: 1.6980717182159424\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 25, batch train loss: 2.015692949295044\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 26, batch train loss: 1.7627580165863037\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 27, batch train loss: 1.683510422706604\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 28, batch train loss: 2.200984477996826\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 29, batch train loss: 2.1231298446655273\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 30, batch train loss: 1.9072144031524658\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 31, batch train loss: 2.2226033210754395\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 32, batch train loss: 2.164548635482788\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 33, batch train loss: 2.440601110458374\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 34, batch train loss: 2.0966081619262695\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 35, batch train loss: 1.8754318952560425\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 36, batch train loss: 1.650374412536621\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 37, batch train loss: 2.148867130279541\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 38, batch train loss: 2.227416753768921\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 39, batch train loss: 1.7115029096603394\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 40, batch train loss: 2.238206148147583\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 41, batch train loss: 2.1355948448181152\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 42, batch train loss: 2.0697999000549316\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 43, batch train loss: 1.8536670207977295\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 44, batch train loss: 2.4912002086639404\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 45, batch train loss: 2.209519386291504\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 46, batch train loss: 1.8954392671585083\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 47, batch train loss: 1.4761064052581787\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 48, batch train loss: 1.9735366106033325\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 49, batch train loss: 1.4760509729385376\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 50, batch train loss: 1.6841979026794434\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 51, batch train loss: 2.3046793937683105\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 52, batch train loss: 2.017430305480957\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 53, batch train loss: 1.9280908107757568\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 54, batch train loss: 2.7528812885284424\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 55, batch train loss: 2.3120675086975098\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 56, batch train loss: 2.0717711448669434\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 57, batch train loss: 2.1001100540161133\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 58, batch train loss: 2.490844488143921\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 59, batch train loss: 2.029484748840332\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 60, batch train loss: 3.4268696308135986\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 61, batch train loss: 2.5239765644073486\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 62, batch train loss: 2.131136655807495\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 63, batch train loss: 2.9976656436920166\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 64, batch train loss: 1.5611908435821533\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 65, batch train loss: 2.530881881713867\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 66, batch train loss: 2.3933322429656982\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 67, batch train loss: 2.4679698944091797\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 68, batch train loss: 3.2425661087036133\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 69, batch train loss: 2.182736396789551\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 70, batch train loss: 4.043965816497803\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 71, batch train loss: 5.179999828338623\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 72, batch train loss: 3.597144365310669\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 73, batch train loss: 3.630718469619751\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 74, batch train loss: 6.1130523681640625\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 75, batch train loss: 3.1846964359283447\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 76, batch train loss: 6.8249664306640625\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 77, batch train loss: 3.394411325454712\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 78, batch train loss: 5.700254917144775\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 79, batch train loss: 5.016413688659668\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 80, batch train loss: 2.6189138889312744\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 81, batch train loss: 5.176230430603027\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 82, batch train loss: 7.230026721954346\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 83, batch train loss: 5.575806617736816\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 84, batch train loss: 3.2847888469696045\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 85, batch train loss: 4.63728666305542\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 86, batch train loss: 5.522107124328613\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 87, batch train loss: 3.5044734477996826\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 88, batch train loss: 4.637827396392822\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 89, batch train loss: 5.585622787475586\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 90, batch train loss: 3.761370897293091\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 91, batch train loss: 2.7302634716033936\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 92, batch train loss: 4.398290634155273\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 93, batch train loss: 2.5264389514923096\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 94, batch train loss: 2.3191449642181396\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 95, batch train loss: 2.6591663360595703\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 96, batch train loss: 2.171431303024292\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 97, batch train loss: 2.5915799140930176\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 98, batch train loss: 2.8335072994232178\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 99, batch train loss: 2.667059898376465\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 100, batch train loss: 2.404189348220825\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 101, batch train loss: 2.24583101272583\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 102, batch train loss: 2.0629653930664062\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 103, batch train loss: 1.7145702838897705\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 104, batch train loss: 2.007750988006592\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 105, batch train loss: 1.9561389684677124\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 106, batch train loss: 1.8008031845092773\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 107, batch train loss: 1.633310079574585\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 108, batch train loss: 1.7945358753204346\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 109, batch train loss: 1.7705817222595215\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 110, batch train loss: 1.6459476947784424\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 111, batch train loss: 1.5574771165847778\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 112, batch train loss: 1.5119552612304688\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 113, batch train loss: 2.2270638942718506\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 114, batch train loss: 1.741000771522522\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 115, batch train loss: 1.955997109413147\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 116, batch train loss: 2.4195568561553955\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 117, batch train loss: 2.26029372215271\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 118, batch train loss: 2.1761674880981445\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 119, batch train loss: 1.696844220161438\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 120, batch train loss: 1.4635285139083862\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 121, batch train loss: 1.3306783437728882\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 122, batch train loss: 1.2613098621368408\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 123, batch train loss: 1.8809360265731812\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 124, batch train loss: 2.417470693588257\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 125, batch train loss: 2.1829147338867188\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 126, batch train loss: 1.5767632722854614\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 127, batch train loss: 2.060678720474243\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 128, batch train loss: 2.2607202529907227\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 129, batch train loss: 1.8601889610290527\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, batch_id: 130, batch train loss: 1.8353654146194458\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 131, batch train loss: 2.2169852256774902\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 132, batch train loss: 2.2721774578094482\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 133, batch train loss: 1.8783966302871704\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 134, batch train loss: 1.9014066457748413\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 135, batch train loss: 1.783244013786316\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 136, batch train loss: 1.9590588808059692\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 137, batch train loss: 1.6136338710784912\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 138, batch train loss: 2.2203242778778076\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 139, batch train loss: 1.6476714611053467\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 140, batch train loss: 1.880808711051941\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 141, batch train loss: 1.6777876615524292\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 142, batch train loss: 1.6649008989334106\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 143, batch train loss: 1.5878230333328247\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 144, batch train loss: 1.8373852968215942\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 145, batch train loss: 1.2184065580368042\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 146, batch train loss: 1.7944450378417969\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 147, batch train loss: 2.109373092651367\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 148, batch train loss: 2.473917007446289\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 149, batch train loss: 1.820923089981079\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 150, batch train loss: 2.1891067028045654\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 151, batch train loss: 3.545999765396118\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 152, batch train loss: 1.9335163831710815\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 153, batch train loss: 4.1822829246521\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 154, batch train loss: 4.007144451141357\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 155, batch train loss: 2.4052748680114746\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 156, batch train loss: 4.070030212402344\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 157, batch train loss: 2.2432353496551514\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 158, batch train loss: 5.3255510330200195\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 159, batch train loss: 2.2543883323669434\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 160, batch train loss: 3.5067672729492188\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 161, batch train loss: 2.3399386405944824\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 162, batch train loss: 3.5327413082122803\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 163, batch train loss: 3.2952311038970947\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 164, batch train loss: 3.0682830810546875\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 165, batch train loss: 3.2861173152923584\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 166, batch train loss: 2.0490658283233643\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 167, batch train loss: 1.9287080764770508\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 168, batch train loss: 1.7549552917480469\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 169, batch train loss: 1.819085717201233\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 170, batch train loss: 2.9857337474823\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 171, batch train loss: 2.1047120094299316\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 172, batch train loss: 1.7419785261154175\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 173, batch train loss: 2.1014978885650635\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 174, batch train loss: 1.7461590766906738\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 175, batch train loss: 2.965319871902466\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 176, batch train loss: 1.6659308671951294\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 177, batch train loss: 1.686751127243042\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 178, batch train loss: 1.3108271360397339\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 179, batch train loss: 2.1203203201293945\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 180, batch train loss: 1.661982536315918\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 181, batch train loss: 1.7588635683059692\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 182, batch train loss: 1.8629752397537231\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 183, batch train loss: 2.229243278503418\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 184, batch train loss: 1.4850742816925049\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 185, batch train loss: 2.061495542526245\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 186, batch train loss: 1.6475579738616943\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 187, batch train loss: 2.463879346847534\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 188, batch train loss: 1.8006913661956787\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 189, batch train loss: 2.1638786792755127\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 190, batch train loss: 1.5300999879837036\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 191, batch train loss: 1.8611458539962769\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 192, batch train loss: 1.5585150718688965\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 193, batch train loss: 1.975131869316101\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 194, batch train loss: 1.9170302152633667\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 195, batch train loss: 2.352245569229126\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 196, batch train loss: 1.810655951499939\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 197, batch train loss: 2.08323073387146\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 198, batch train loss: 2.161194324493408\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 199, batch train loss: 3.25848388671875\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 200, batch train loss: 2.0679638385772705\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 201, batch train loss: 2.554962635040283\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 202, batch train loss: 1.86029851436615\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 203, batch train loss: 2.7918052673339844\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 204, batch train loss: 2.000868797302246\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 205, batch train loss: 2.1778900623321533\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 206, batch train loss: 1.7600494623184204\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 207, batch train loss: 2.0819380283355713\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 208, batch train loss: 1.7596869468688965\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 209, batch train loss: 2.017956018447876\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 210, batch train loss: 1.7850083112716675\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 211, batch train loss: 1.6722729206085205\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 212, batch train loss: 2.075155019760132\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 213, batch train loss: 1.8762186765670776\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 214, batch train loss: 1.9759089946746826\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 215, batch train loss: 1.9283527135849\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 216, batch train loss: 1.8189949989318848\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 217, batch train loss: 2.009345769882202\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 218, batch train loss: 1.8604964017868042\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 219, batch train loss: 1.7182092666625977\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 220, batch train loss: 2.127462863922119\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 221, batch train loss: 1.4159973859786987\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 222, batch train loss: 1.9763604402542114\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 223, batch train loss: 2.0744998455047607\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 224, batch train loss: 1.7718377113342285\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 225, batch train loss: 2.0930440425872803\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 226, batch train loss: 2.0418832302093506\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 227, batch train loss: 2.4428458213806152\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 228, batch train loss: 1.402455449104309\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 229, batch train loss: 1.4951390027999878\n",
      "\n",
      "\n",
      "Epoch: 40, batch_id: 230, batch train loss: 2.028749704360962\n",
      "\n",
      "\n",
      "Epoch: 40/ 100, Loss: 2.3817192766977393\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:18<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 Validation Loss: 1.8268623312314352\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, batch_id: 1, batch train loss: 1.8820873498916626\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 2, batch train loss: 1.4543031454086304\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 3, batch train loss: 1.4743461608886719\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 4, batch train loss: 1.315085530281067\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 5, batch train loss: 1.309295892715454\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 6, batch train loss: 1.417494773864746\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 7, batch train loss: 1.5680063962936401\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 8, batch train loss: 2.21089243888855\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 9, batch train loss: 2.2111740112304688\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 10, batch train loss: 1.8983573913574219\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 11, batch train loss: 1.4011592864990234\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 12, batch train loss: 2.2162060737609863\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 13, batch train loss: 1.7099571228027344\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 14, batch train loss: 2.497206687927246\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 15, batch train loss: 1.7484875917434692\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 16, batch train loss: 2.2323811054229736\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 17, batch train loss: 1.3147207498550415\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 18, batch train loss: 1.6258763074874878\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 19, batch train loss: 1.6677325963974\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 20, batch train loss: 2.4346015453338623\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 21, batch train loss: 1.9540303945541382\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 22, batch train loss: 2.6249661445617676\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 23, batch train loss: 2.5746142864227295\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 24, batch train loss: 1.8138309717178345\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 25, batch train loss: 2.344058036804199\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 26, batch train loss: 1.5950719118118286\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 27, batch train loss: 2.189396858215332\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 28, batch train loss: 1.919162631034851\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 29, batch train loss: 1.8173128366470337\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 30, batch train loss: 2.2039732933044434\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 31, batch train loss: 1.792535662651062\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 32, batch train loss: 1.7814676761627197\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 33, batch train loss: 1.8338820934295654\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 34, batch train loss: 2.2261664867401123\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 35, batch train loss: 1.7378257513046265\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 36, batch train loss: 1.7258268594741821\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 37, batch train loss: 2.2347054481506348\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 38, batch train loss: 1.5268065929412842\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 39, batch train loss: 1.517343282699585\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 40, batch train loss: 1.423801302909851\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 41, batch train loss: 1.803293228149414\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 42, batch train loss: 1.4126548767089844\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 43, batch train loss: 1.4245219230651855\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 44, batch train loss: 1.6382490396499634\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 45, batch train loss: 1.7911471128463745\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 46, batch train loss: 1.574928879737854\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 47, batch train loss: 1.4087860584259033\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 48, batch train loss: 1.315200924873352\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 49, batch train loss: 1.5247937440872192\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 50, batch train loss: 1.3204094171524048\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 51, batch train loss: 1.5941985845565796\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 52, batch train loss: 1.4390077590942383\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 53, batch train loss: 1.5019614696502686\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 54, batch train loss: 1.5370320081710815\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 55, batch train loss: 1.6316807270050049\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 56, batch train loss: 1.7057905197143555\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 57, batch train loss: 2.377415657043457\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 58, batch train loss: 2.3002188205718994\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 59, batch train loss: 1.8047462701797485\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 60, batch train loss: 2.1695563793182373\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 61, batch train loss: 1.763360857963562\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 62, batch train loss: 3.4153223037719727\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 63, batch train loss: 2.9468119144439697\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 64, batch train loss: 2.319793224334717\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 65, batch train loss: 2.849072217941284\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 66, batch train loss: 1.9325915575027466\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 67, batch train loss: 3.0373003482818604\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 68, batch train loss: 2.1654348373413086\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 69, batch train loss: 2.526416540145874\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 70, batch train loss: 2.3922529220581055\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 71, batch train loss: 1.7318106889724731\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 72, batch train loss: 3.4746756553649902\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 73, batch train loss: 2.4954841136932373\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 74, batch train loss: 2.7901105880737305\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 75, batch train loss: 4.642353534698486\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 76, batch train loss: 3.743612051010132\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 77, batch train loss: 2.7318503856658936\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 78, batch train loss: 2.6214070320129395\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 79, batch train loss: 2.9998245239257812\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 80, batch train loss: 2.9101898670196533\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 81, batch train loss: 3.8325414657592773\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 82, batch train loss: 4.23811674118042\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 83, batch train loss: 4.633745193481445\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 84, batch train loss: 3.4183523654937744\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 85, batch train loss: 3.2576842308044434\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 86, batch train loss: 4.010034084320068\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 87, batch train loss: 3.2969088554382324\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 88, batch train loss: 2.974681854248047\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 89, batch train loss: 3.8165760040283203\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 90, batch train loss: 2.639784812927246\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 91, batch train loss: 1.765342354774475\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 92, batch train loss: 1.8464372158050537\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 93, batch train loss: 2.8985610008239746\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 94, batch train loss: 2.7527577877044678\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 95, batch train loss: 4.267920970916748\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 96, batch train loss: 1.9193798303604126\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 97, batch train loss: 2.4367966651916504\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 98, batch train loss: 1.6206834316253662\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 99, batch train loss: 2.3098700046539307\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 100, batch train loss: 2.688634157180786\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 101, batch train loss: 2.0555098056793213\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 102, batch train loss: 2.0607028007507324\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 103, batch train loss: 1.8213386535644531\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 104, batch train loss: 2.6784846782684326\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 105, batch train loss: 1.7148183584213257\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 106, batch train loss: 2.2623677253723145\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 107, batch train loss: 2.1618168354034424\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 108, batch train loss: 1.9861692190170288\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 109, batch train loss: 1.6537855863571167\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 110, batch train loss: 2.617823600769043\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 111, batch train loss: 3.027294158935547\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 112, batch train loss: 3.1452956199645996\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 113, batch train loss: 2.3343887329101562\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 114, batch train loss: 2.8426730632781982\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 115, batch train loss: 3.2053639888763428\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 116, batch train loss: 2.1918647289276123\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 117, batch train loss: 2.7318954467773438\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 118, batch train loss: 2.324913740158081\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 119, batch train loss: 2.8160812854766846\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 120, batch train loss: 3.593824863433838\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 121, batch train loss: 2.5800890922546387\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 122, batch train loss: 3.4235925674438477\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 123, batch train loss: 2.531113624572754\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 124, batch train loss: 2.0403518676757812\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 125, batch train loss: 2.045081377029419\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 126, batch train loss: 3.200122356414795\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 127, batch train loss: 4.614392280578613\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 128, batch train loss: 2.3724300861358643\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 129, batch train loss: 2.657761812210083\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, batch_id: 130, batch train loss: 3.3769798278808594\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 131, batch train loss: 1.9901217222213745\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 132, batch train loss: 4.295152187347412\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 133, batch train loss: 1.975727915763855\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 134, batch train loss: 2.526487112045288\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 135, batch train loss: 1.7060115337371826\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 136, batch train loss: 1.947879433631897\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 137, batch train loss: 2.2289175987243652\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 138, batch train loss: 2.2534332275390625\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 139, batch train loss: 1.9420100450515747\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 140, batch train loss: 1.7337628602981567\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 141, batch train loss: 2.1963160037994385\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 142, batch train loss: 1.9530253410339355\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 143, batch train loss: 2.394141435623169\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 144, batch train loss: 1.9225126504898071\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 145, batch train loss: 2.0774478912353516\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 146, batch train loss: 2.3673651218414307\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 147, batch train loss: 1.659576177597046\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 148, batch train loss: 2.316871166229248\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 149, batch train loss: 2.292635440826416\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 150, batch train loss: 2.0048153400421143\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 151, batch train loss: 1.5934499502182007\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 152, batch train loss: 2.0318551063537598\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 153, batch train loss: 1.9867501258850098\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 154, batch train loss: 2.759516716003418\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 155, batch train loss: 2.2760884761810303\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 156, batch train loss: 2.2507786750793457\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 157, batch train loss: 2.0614571571350098\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 158, batch train loss: 2.4649064540863037\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 159, batch train loss: 1.768584132194519\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 160, batch train loss: 1.613368034362793\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 161, batch train loss: 1.49805748462677\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 162, batch train loss: 1.5906130075454712\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 163, batch train loss: 1.8993035554885864\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 164, batch train loss: 1.616353154182434\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 165, batch train loss: 1.322679877281189\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 166, batch train loss: 1.4937573671340942\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 167, batch train loss: 1.731790542602539\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 168, batch train loss: 2.116758346557617\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 169, batch train loss: 1.9289937019348145\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 170, batch train loss: 2.034193754196167\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 171, batch train loss: 1.7707000970840454\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 172, batch train loss: 1.837949275970459\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 173, batch train loss: 2.1707546710968018\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 174, batch train loss: 2.0776000022888184\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 175, batch train loss: 2.0199203491210938\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 176, batch train loss: 1.6196227073669434\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 177, batch train loss: 1.6404058933258057\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 178, batch train loss: 1.539955973625183\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 179, batch train loss: 1.4543554782867432\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 180, batch train loss: 1.821076512336731\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 181, batch train loss: 1.5272877216339111\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 182, batch train loss: 1.769041895866394\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 183, batch train loss: 1.905389666557312\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 184, batch train loss: 2.285212993621826\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 185, batch train loss: 2.7578649520874023\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 186, batch train loss: 1.5461758375167847\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 187, batch train loss: 2.9980361461639404\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 188, batch train loss: 1.7797690629959106\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 189, batch train loss: 2.267845392227173\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 190, batch train loss: 2.40822172164917\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 191, batch train loss: 2.513545513153076\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 192, batch train loss: 3.96370530128479\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 193, batch train loss: 2.628399610519409\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 194, batch train loss: 2.2246124744415283\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 195, batch train loss: 2.842134952545166\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 196, batch train loss: 2.2979683876037598\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 197, batch train loss: 2.3248400688171387\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 198, batch train loss: 2.1691884994506836\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 199, batch train loss: 1.9097318649291992\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 200, batch train loss: 2.0359511375427246\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 201, batch train loss: 1.8433728218078613\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 202, batch train loss: 2.6567203998565674\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 203, batch train loss: 2.098921298980713\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 204, batch train loss: 2.0056793689727783\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 205, batch train loss: 2.0565876960754395\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 206, batch train loss: 1.7955875396728516\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 207, batch train loss: 1.6149684190750122\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 208, batch train loss: 1.7137463092803955\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 209, batch train loss: 1.9708536863327026\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 210, batch train loss: 1.9447375535964966\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 211, batch train loss: 1.237795352935791\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 212, batch train loss: 1.4399144649505615\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 213, batch train loss: 1.6352695226669312\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 214, batch train loss: 1.63507878780365\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 215, batch train loss: 1.8190644979476929\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 216, batch train loss: 1.5501739978790283\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 217, batch train loss: 1.917967677116394\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 218, batch train loss: 1.9925470352172852\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 219, batch train loss: 1.9142663478851318\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 220, batch train loss: 1.9278464317321777\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 221, batch train loss: 2.723949670791626\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 222, batch train loss: 1.5702836513519287\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 223, batch train loss: 2.0469934940338135\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 224, batch train loss: 1.73828125\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 225, batch train loss: 3.2977213859558105\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 226, batch train loss: 2.883467674255371\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 227, batch train loss: 2.156047821044922\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 228, batch train loss: 2.4643282890319824\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 229, batch train loss: 2.0218706130981445\n",
      "\n",
      "\n",
      "Epoch: 41, batch_id: 230, batch train loss: 1.7846745252609253\n",
      "\n",
      "\n",
      "Epoch: 41/ 100, Loss: 2.2055391461952873\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 Validation Loss: 2.983830487728119\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, batch_id: 1, batch train loss: 2.0060315132141113\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 2, batch train loss: 3.3285458087921143\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 3, batch train loss: 2.670365333557129\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 4, batch train loss: 2.2587287425994873\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 5, batch train loss: 2.634718656539917\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 6, batch train loss: 2.5671846866607666\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 7, batch train loss: 3.978555202484131\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 8, batch train loss: 2.8973779678344727\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 9, batch train loss: 2.116373062133789\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 10, batch train loss: 2.4276304244995117\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 11, batch train loss: 1.75920832157135\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 12, batch train loss: 1.5866976976394653\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 13, batch train loss: 2.803981304168701\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 14, batch train loss: 3.3956058025360107\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 15, batch train loss: 2.886491537094116\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 16, batch train loss: 2.274486780166626\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 17, batch train loss: 2.587432622909546\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 18, batch train loss: 2.2003703117370605\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 19, batch train loss: 3.4897091388702393\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 20, batch train loss: 3.0288431644439697\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 21, batch train loss: 2.9142470359802246\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 22, batch train loss: 1.804429531097412\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 23, batch train loss: 2.247539520263672\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 24, batch train loss: 2.086803674697876\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 25, batch train loss: 2.447824239730835\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 26, batch train loss: 1.7764601707458496\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 27, batch train loss: 2.006537914276123\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 28, batch train loss: 1.4297850131988525\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 29, batch train loss: 2.8622617721557617\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 30, batch train loss: 2.424574613571167\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 31, batch train loss: 2.6313626766204834\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 32, batch train loss: 2.7301695346832275\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 33, batch train loss: 3.349619150161743\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 34, batch train loss: 4.097874164581299\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 35, batch train loss: 4.482506275177002\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 36, batch train loss: 3.1529693603515625\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 37, batch train loss: 3.089768171310425\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 38, batch train loss: 3.868694543838501\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 39, batch train loss: 2.913839817047119\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 40, batch train loss: 2.7436575889587402\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 41, batch train loss: 6.221062183380127\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 42, batch train loss: 3.3212227821350098\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 43, batch train loss: 2.2895214557647705\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 44, batch train loss: 4.120196342468262\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 45, batch train loss: 3.766688346862793\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 46, batch train loss: 2.7678492069244385\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 47, batch train loss: 2.6119384765625\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 48, batch train loss: 1.8159973621368408\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 49, batch train loss: 2.409923791885376\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 50, batch train loss: 1.9281558990478516\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 51, batch train loss: 3.5395638942718506\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 52, batch train loss: 2.3227179050445557\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 53, batch train loss: 3.3441696166992188\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 54, batch train loss: 2.442624568939209\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 55, batch train loss: 2.561251401901245\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 56, batch train loss: 2.6761138439178467\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 57, batch train loss: 2.96256422996521\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 58, batch train loss: 2.1615586280822754\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 59, batch train loss: 4.130396842956543\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 60, batch train loss: 3.3992087841033936\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 61, batch train loss: 2.205925941467285\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 62, batch train loss: 4.092911720275879\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 63, batch train loss: 4.217377662658691\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 64, batch train loss: 2.299572706222534\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 65, batch train loss: 4.34878396987915\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 66, batch train loss: 3.2806625366210938\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 67, batch train loss: 5.105624675750732\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 68, batch train loss: 4.042867660522461\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 69, batch train loss: 2.1181249618530273\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 70, batch train loss: 2.3418567180633545\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 71, batch train loss: 2.6457772254943848\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 72, batch train loss: 1.5885777473449707\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 73, batch train loss: 1.7708072662353516\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 74, batch train loss: 2.693263530731201\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 75, batch train loss: 2.5405666828155518\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 76, batch train loss: 2.1122405529022217\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 77, batch train loss: 2.0800788402557373\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 78, batch train loss: 2.8517465591430664\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 79, batch train loss: 2.2319343090057373\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 80, batch train loss: 3.7584707736968994\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 81, batch train loss: 2.711899518966675\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 82, batch train loss: 4.214156627655029\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 83, batch train loss: 3.524742364883423\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 84, batch train loss: 3.9250218868255615\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 85, batch train loss: 3.681795358657837\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 86, batch train loss: 2.5127556324005127\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 87, batch train loss: 4.328741550445557\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 88, batch train loss: 2.4969189167022705\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 89, batch train loss: 2.691282033920288\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 90, batch train loss: 2.678497076034546\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 91, batch train loss: 1.7398008108139038\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 92, batch train loss: 3.0068106651306152\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 93, batch train loss: 2.235175609588623\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 94, batch train loss: 2.9502246379852295\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 95, batch train loss: 4.314571380615234\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 96, batch train loss: 2.014059543609619\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 97, batch train loss: 3.073021411895752\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 98, batch train loss: 3.2522335052490234\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 99, batch train loss: 2.7614099979400635\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 100, batch train loss: 4.300932884216309\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 101, batch train loss: 5.35854434967041\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 102, batch train loss: 4.068981170654297\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 103, batch train loss: 3.288330316543579\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 104, batch train loss: 4.075864791870117\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 105, batch train loss: 2.600428819656372\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 106, batch train loss: 2.495410680770874\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 107, batch train loss: 2.5352962017059326\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 108, batch train loss: 3.712123155593872\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 109, batch train loss: 4.6838459968566895\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 110, batch train loss: 5.275359153747559\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 111, batch train loss: 5.299518585205078\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 112, batch train loss: 7.332057476043701\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 113, batch train loss: 5.759378433227539\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 114, batch train loss: 3.4665534496307373\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 115, batch train loss: 5.023683071136475\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 116, batch train loss: 3.7316946983337402\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 117, batch train loss: 6.201293468475342\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 118, batch train loss: 3.4481253623962402\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 119, batch train loss: 4.624950885772705\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 120, batch train loss: 5.222843647003174\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 121, batch train loss: 2.381131887435913\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 122, batch train loss: 4.179483890533447\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 123, batch train loss: 3.0114378929138184\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 124, batch train loss: 4.652246952056885\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 125, batch train loss: 2.1740217208862305\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 126, batch train loss: 4.574824810028076\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 127, batch train loss: 3.1782968044281006\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 128, batch train loss: 4.204959392547607\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 129, batch train loss: 3.2291858196258545\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, batch_id: 130, batch train loss: 3.2507894039154053\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 131, batch train loss: 2.8638877868652344\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 132, batch train loss: 4.63644552230835\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 133, batch train loss: 3.962411403656006\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 134, batch train loss: 4.502991676330566\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 135, batch train loss: 7.202538967132568\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 136, batch train loss: 3.5169637203216553\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 137, batch train loss: 4.0671515464782715\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 138, batch train loss: 6.570884704589844\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 139, batch train loss: 5.146387100219727\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 140, batch train loss: 5.607308387756348\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 141, batch train loss: 4.488292217254639\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 142, batch train loss: 5.750992774963379\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 143, batch train loss: 6.458613395690918\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 144, batch train loss: 4.5265350341796875\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 145, batch train loss: 4.496486663818359\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 146, batch train loss: 5.6981987953186035\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 147, batch train loss: 3.5449771881103516\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 148, batch train loss: 3.1872408390045166\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 149, batch train loss: 3.5362768173217773\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 150, batch train loss: 7.7863874435424805\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 151, batch train loss: 9.38794994354248\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 152, batch train loss: 15.120699882507324\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 153, batch train loss: 6.311266899108887\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 154, batch train loss: 6.244579792022705\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 155, batch train loss: 6.870614528656006\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 156, batch train loss: 9.2286376953125\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 157, batch train loss: 4.679249286651611\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 158, batch train loss: 6.157539367675781\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 159, batch train loss: 6.292201519012451\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 160, batch train loss: 6.509312152862549\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 161, batch train loss: 5.835594654083252\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 162, batch train loss: 4.319572925567627\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 163, batch train loss: 6.852757930755615\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 164, batch train loss: 7.507107734680176\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 165, batch train loss: 7.786221504211426\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 166, batch train loss: 5.271703243255615\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 167, batch train loss: 6.468552112579346\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 168, batch train loss: 5.61776876449585\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 169, batch train loss: 6.291711807250977\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 170, batch train loss: 5.404513359069824\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 171, batch train loss: 8.858633041381836\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 172, batch train loss: 9.31429672241211\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 173, batch train loss: 5.555030345916748\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 174, batch train loss: 7.023931503295898\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 175, batch train loss: 7.704846382141113\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 176, batch train loss: 8.069321632385254\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 177, batch train loss: 7.824835777282715\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 178, batch train loss: 6.310721397399902\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 179, batch train loss: 4.846955299377441\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 180, batch train loss: 5.866001129150391\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 181, batch train loss: 6.68228006362915\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 182, batch train loss: 5.5067458152771\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 183, batch train loss: 6.245751857757568\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 184, batch train loss: 6.926892280578613\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 185, batch train loss: 3.808218479156494\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 186, batch train loss: 4.445037364959717\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 187, batch train loss: 5.377569675445557\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 188, batch train loss: 5.668309211730957\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 189, batch train loss: 6.841741561889648\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 190, batch train loss: 5.582995414733887\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 191, batch train loss: 5.784829139709473\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 192, batch train loss: 4.700234889984131\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 193, batch train loss: 4.249565601348877\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 194, batch train loss: 5.090847969055176\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 195, batch train loss: 4.813309192657471\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 196, batch train loss: 6.992278575897217\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 197, batch train loss: 6.236886501312256\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 198, batch train loss: 6.419227123260498\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 199, batch train loss: 5.7340087890625\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 200, batch train loss: 6.692129135131836\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 201, batch train loss: 9.91880989074707\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 202, batch train loss: 6.250275611877441\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 203, batch train loss: 5.883304595947266\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 204, batch train loss: 4.640054702758789\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 205, batch train loss: 7.559739589691162\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 206, batch train loss: 7.4967041015625\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 207, batch train loss: 9.1600980758667\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 208, batch train loss: 10.308219909667969\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 209, batch train loss: 17.433977127075195\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 210, batch train loss: 9.386897087097168\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 211, batch train loss: 12.018383026123047\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 212, batch train loss: 10.302578926086426\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 213, batch train loss: 9.049570083618164\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 214, batch train loss: 7.77700662612915\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 215, batch train loss: 7.645555019378662\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 216, batch train loss: 5.23495626449585\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 217, batch train loss: 7.705389976501465\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 218, batch train loss: 6.114724636077881\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 219, batch train loss: 5.910745620727539\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 220, batch train loss: 5.540509223937988\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 221, batch train loss: 13.44935131072998\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 222, batch train loss: 7.085522651672363\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 223, batch train loss: 7.339700698852539\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 224, batch train loss: 6.173383712768555\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 225, batch train loss: 7.051746368408203\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 226, batch train loss: 6.634917736053467\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 227, batch train loss: 5.9890241622924805\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 228, batch train loss: 5.800167560577393\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 229, batch train loss: 7.063745975494385\n",
      "\n",
      "\n",
      "Epoch: 42, batch_id: 230, batch train loss: 5.686030387878418\n",
      "\n",
      "\n",
      "Epoch: 42/ 100, Loss: 4.656638799024665\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:24<00:00,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 Validation Loss: 5.404202695687612\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, batch_id: 1, batch train loss: 5.350919723510742\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 2, batch train loss: 6.11522102355957\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 3, batch train loss: 4.897775650024414\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 4, batch train loss: 4.366137504577637\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 5, batch train loss: 4.721817970275879\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 6, batch train loss: 4.716871738433838\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 7, batch train loss: 3.9654996395111084\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 8, batch train loss: 4.496800422668457\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 9, batch train loss: 6.021480083465576\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 10, batch train loss: 5.1790056228637695\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 11, batch train loss: 4.1152753829956055\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 12, batch train loss: 4.431573867797852\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 13, batch train loss: 4.913722038269043\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 14, batch train loss: 6.684332847595215\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 15, batch train loss: 6.273528575897217\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 16, batch train loss: 4.691807746887207\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 17, batch train loss: 4.799191474914551\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 18, batch train loss: 4.177190780639648\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 19, batch train loss: 4.660537242889404\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 20, batch train loss: 3.9425249099731445\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 21, batch train loss: 3.42578125\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 22, batch train loss: 4.35528564453125\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 23, batch train loss: 3.4235079288482666\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 24, batch train loss: 3.3436689376831055\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 25, batch train loss: 3.6162145137786865\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 26, batch train loss: 3.797975778579712\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 27, batch train loss: 3.541151523590088\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 28, batch train loss: 3.108275890350342\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 29, batch train loss: 3.295187473297119\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 30, batch train loss: 2.6322383880615234\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 31, batch train loss: 2.881467580795288\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 32, batch train loss: 2.991879463195801\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 33, batch train loss: 2.364137649536133\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 34, batch train loss: 2.8133177757263184\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 35, batch train loss: 2.6087639331817627\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 36, batch train loss: 3.136676549911499\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 37, batch train loss: 2.6446826457977295\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 38, batch train loss: 2.7082841396331787\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 39, batch train loss: 4.210158824920654\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 40, batch train loss: 3.482928514480591\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 41, batch train loss: 3.5523438453674316\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 42, batch train loss: 3.0461902618408203\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 43, batch train loss: 3.0797736644744873\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 44, batch train loss: 6.374851703643799\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 45, batch train loss: 4.532703876495361\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 46, batch train loss: 4.23148250579834\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 47, batch train loss: 3.269721508026123\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 48, batch train loss: 4.882012367248535\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 49, batch train loss: 4.699377536773682\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 50, batch train loss: 4.103509902954102\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 51, batch train loss: 5.496747016906738\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 52, batch train loss: 4.797995090484619\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 53, batch train loss: 4.555086135864258\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 54, batch train loss: 4.054759502410889\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 55, batch train loss: 3.7958080768585205\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 56, batch train loss: 5.194846153259277\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 57, batch train loss: 3.3847527503967285\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 58, batch train loss: 6.32428503036499\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 59, batch train loss: 5.318386554718018\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 60, batch train loss: 8.046845436096191\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 61, batch train loss: 4.220286846160889\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 62, batch train loss: 3.7995312213897705\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 63, batch train loss: 5.938047885894775\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 64, batch train loss: 6.942466735839844\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 65, batch train loss: 3.8170056343078613\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 66, batch train loss: 3.4432413578033447\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 67, batch train loss: 4.66517448425293\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 68, batch train loss: 5.736550331115723\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 69, batch train loss: 4.242002010345459\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 70, batch train loss: 3.419761896133423\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 71, batch train loss: 4.149563312530518\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 72, batch train loss: 4.113738059997559\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 73, batch train loss: 4.8233113288879395\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 74, batch train loss: 4.148481845855713\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 75, batch train loss: 4.178772449493408\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 76, batch train loss: 3.5780022144317627\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 77, batch train loss: 3.365365982055664\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 78, batch train loss: 4.641308307647705\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 79, batch train loss: 4.074148654937744\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 80, batch train loss: 4.1054768562316895\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 81, batch train loss: 4.581270217895508\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 82, batch train loss: 3.516436815261841\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 83, batch train loss: 4.685991287231445\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 84, batch train loss: 5.82697057723999\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 85, batch train loss: 4.721879959106445\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 86, batch train loss: 4.215615749359131\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 87, batch train loss: 3.965310573577881\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 88, batch train loss: 3.1784780025482178\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 89, batch train loss: 3.6768362522125244\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 90, batch train loss: 3.4163196086883545\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 91, batch train loss: 3.524076223373413\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 92, batch train loss: 3.974865674972534\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 93, batch train loss: 3.4917666912078857\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 94, batch train loss: 3.2634117603302\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 95, batch train loss: 3.557471513748169\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 96, batch train loss: 3.1408727169036865\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 97, batch train loss: 3.455416679382324\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 98, batch train loss: 2.9481022357940674\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 99, batch train loss: 2.8677024841308594\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 100, batch train loss: 2.8777220249176025\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 101, batch train loss: 2.475545644760132\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 102, batch train loss: 2.687802314758301\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 103, batch train loss: 2.5313003063201904\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 104, batch train loss: 4.242288589477539\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 105, batch train loss: 2.9960081577301025\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 106, batch train loss: 2.93143892288208\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 107, batch train loss: 3.302943229675293\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 108, batch train loss: 4.5467071533203125\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 109, batch train loss: 3.426828145980835\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 110, batch train loss: 4.244866847991943\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 111, batch train loss: 2.8601200580596924\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 112, batch train loss: 3.650047540664673\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 113, batch train loss: 4.143554210662842\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 114, batch train loss: 2.9196784496307373\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 115, batch train loss: 3.548657178878784\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 116, batch train loss: 3.7723474502563477\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 117, batch train loss: 4.082642555236816\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 118, batch train loss: 5.148688793182373\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 119, batch train loss: 4.91931676864624\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 120, batch train loss: 3.6314289569854736\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 121, batch train loss: 4.639010906219482\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 122, batch train loss: 5.825736045837402\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 123, batch train loss: 4.011009216308594\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 124, batch train loss: 4.507837772369385\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 125, batch train loss: 4.12247896194458\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 126, batch train loss: 3.828073263168335\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 127, batch train loss: 2.687295436859131\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 128, batch train loss: 5.9740309715271\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 129, batch train loss: 4.203517436981201\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 130, batch train loss: 3.2513022422790527\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, batch_id: 131, batch train loss: 7.116281032562256\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 132, batch train loss: 5.6308722496032715\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 133, batch train loss: 4.0476250648498535\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 134, batch train loss: 5.279939651489258\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 135, batch train loss: 5.63107442855835\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 136, batch train loss: 3.0567383766174316\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 137, batch train loss: 3.6890640258789062\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 138, batch train loss: 3.0136282444000244\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 139, batch train loss: 3.614184617996216\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 140, batch train loss: 4.120199203491211\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 141, batch train loss: 3.501584053039551\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 142, batch train loss: 3.7022151947021484\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 143, batch train loss: 3.180234670639038\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 144, batch train loss: 3.404972791671753\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 145, batch train loss: 3.9492952823638916\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 146, batch train loss: 3.047224521636963\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 147, batch train loss: 3.094761848449707\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 148, batch train loss: 3.4105939865112305\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 149, batch train loss: 3.9218673706054688\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 150, batch train loss: 5.153692722320557\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 151, batch train loss: 3.831566095352173\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 152, batch train loss: 3.4481637477874756\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 153, batch train loss: 5.54848051071167\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 154, batch train loss: 4.499165058135986\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 155, batch train loss: 3.3078954219818115\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 156, batch train loss: 5.430208206176758\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 157, batch train loss: 4.390374183654785\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 158, batch train loss: 4.456206798553467\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 159, batch train loss: 3.094635009765625\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 160, batch train loss: 2.9332361221313477\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 161, batch train loss: 2.3659279346466064\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 162, batch train loss: 2.2254433631896973\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 163, batch train loss: 2.4309122562408447\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 164, batch train loss: 2.1208364963531494\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 165, batch train loss: 2.2473723888397217\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 166, batch train loss: 1.8559573888778687\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 167, batch train loss: 2.1586532592773438\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 168, batch train loss: 4.622190952301025\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 169, batch train loss: 3.4574148654937744\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 170, batch train loss: 3.635568141937256\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 171, batch train loss: 2.697039842605591\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 172, batch train loss: 3.2905826568603516\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 173, batch train loss: 2.622314929962158\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 174, batch train loss: 2.222909450531006\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 175, batch train loss: 2.395599842071533\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 176, batch train loss: 2.424372673034668\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 177, batch train loss: 2.193591356277466\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 178, batch train loss: 2.9880919456481934\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 179, batch train loss: 2.3597238063812256\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 180, batch train loss: 2.2258613109588623\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 181, batch train loss: 1.930755376815796\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 182, batch train loss: 2.78181529045105\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 183, batch train loss: 2.1419413089752197\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 184, batch train loss: 2.0197594165802\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 185, batch train loss: 1.8781540393829346\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 186, batch train loss: 2.066295862197876\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 187, batch train loss: 2.234812021255493\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 188, batch train loss: 1.8084553480148315\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 189, batch train loss: 1.9315669536590576\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 190, batch train loss: 1.7127854824066162\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 191, batch train loss: 1.908044695854187\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 192, batch train loss: 1.7634086608886719\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 193, batch train loss: 1.7831259965896606\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 194, batch train loss: 1.6051733493804932\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 195, batch train loss: 1.5143463611602783\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 196, batch train loss: 1.423690676689148\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 197, batch train loss: 1.5528432130813599\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 198, batch train loss: 2.2989108562469482\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 199, batch train loss: 2.109097957611084\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 200, batch train loss: 1.7556685209274292\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 201, batch train loss: 1.9344083070755005\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 202, batch train loss: 1.9655942916870117\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 203, batch train loss: 2.0675909519195557\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 204, batch train loss: 2.1772189140319824\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 205, batch train loss: 1.7029423713684082\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 206, batch train loss: 1.7350406646728516\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 207, batch train loss: 2.3597655296325684\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 208, batch train loss: 2.1162402629852295\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 209, batch train loss: 2.0109918117523193\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 210, batch train loss: 2.0186336040496826\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 211, batch train loss: 2.4273390769958496\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 212, batch train loss: 2.1467642784118652\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 213, batch train loss: 2.1119167804718018\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 214, batch train loss: 2.2508137226104736\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 215, batch train loss: 1.6654499769210815\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 216, batch train loss: 2.3132123947143555\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 217, batch train loss: 1.7078157663345337\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 218, batch train loss: 1.6024986505508423\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 219, batch train loss: 1.9706147909164429\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 220, batch train loss: 1.6082038879394531\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 221, batch train loss: 1.469659686088562\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 222, batch train loss: 1.786858081817627\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 223, batch train loss: 1.7794160842895508\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 224, batch train loss: 1.5066053867340088\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 225, batch train loss: 1.6876871585845947\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 226, batch train loss: 1.5858197212219238\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 227, batch train loss: 1.513849139213562\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 228, batch train loss: 1.6198760271072388\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 229, batch train loss: 1.795853853225708\n",
      "\n",
      "\n",
      "Epoch: 43, batch_id: 230, batch train loss: 1.5299221277236938\n",
      "\n",
      "\n",
      "Epoch: 43/ 100, Loss: 3.4890484156815904\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:19<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 Validation Loss: 1.6148616472880046\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, batch_id: 1, batch train loss: 1.4584506750106812\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 2, batch train loss: 1.6433402299880981\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 3, batch train loss: 1.5825767517089844\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 4, batch train loss: 1.726433277130127\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 5, batch train loss: 1.824160099029541\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 6, batch train loss: 1.4949713945388794\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 7, batch train loss: 1.7188279628753662\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 8, batch train loss: 1.8773443698883057\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 9, batch train loss: 1.4447131156921387\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 10, batch train loss: 1.7365301847457886\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 11, batch train loss: 1.9395086765289307\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 12, batch train loss: 1.3094404935836792\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 13, batch train loss: 1.5917680263519287\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 14, batch train loss: 1.9895641803741455\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 15, batch train loss: 1.531502604484558\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 16, batch train loss: 1.8383017778396606\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 17, batch train loss: 1.3574438095092773\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 18, batch train loss: 1.5966339111328125\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 19, batch train loss: 1.6688708066940308\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 20, batch train loss: 1.4351173639297485\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 21, batch train loss: 1.7400336265563965\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 22, batch train loss: 1.4464281797409058\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 23, batch train loss: 1.6317689418792725\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 24, batch train loss: 1.5627161264419556\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 25, batch train loss: 1.9824802875518799\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 26, batch train loss: 1.4530718326568604\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 27, batch train loss: 1.5795245170593262\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 28, batch train loss: 1.5148580074310303\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 29, batch train loss: 1.316147804260254\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 30, batch train loss: 1.4938510656356812\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 31, batch train loss: 1.3642539978027344\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 32, batch train loss: 1.2784212827682495\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 33, batch train loss: 1.7620518207550049\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 34, batch train loss: 1.7584326267242432\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 35, batch train loss: 1.4386235475540161\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 36, batch train loss: 2.177440881729126\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 37, batch train loss: 1.8869112730026245\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 38, batch train loss: 1.412292718887329\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 39, batch train loss: 2.656017303466797\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 40, batch train loss: 1.8745646476745605\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 41, batch train loss: 2.029885768890381\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 42, batch train loss: 2.673187732696533\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 43, batch train loss: 2.3965229988098145\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 44, batch train loss: 2.2053020000457764\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 45, batch train loss: 2.1698191165924072\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 46, batch train loss: 2.999828577041626\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 47, batch train loss: 3.376041889190674\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 48, batch train loss: 1.9137864112854004\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 49, batch train loss: 3.827549695968628\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 50, batch train loss: 2.7687814235687256\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 51, batch train loss: 1.7180733680725098\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 52, batch train loss: 2.8677306175231934\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 53, batch train loss: 3.3581230640411377\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 54, batch train loss: 2.274630546569824\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 55, batch train loss: 2.5639560222625732\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 56, batch train loss: 3.2769014835357666\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 57, batch train loss: 4.689356327056885\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 58, batch train loss: 2.151336193084717\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 59, batch train loss: 2.235651969909668\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 60, batch train loss: 2.418686628341675\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 61, batch train loss: 1.8334025144577026\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 62, batch train loss: 1.7229081392288208\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 63, batch train loss: 3.028627634048462\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 64, batch train loss: 2.3057727813720703\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 65, batch train loss: 2.2096800804138184\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 66, batch train loss: 2.0153913497924805\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 67, batch train loss: 2.322561740875244\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 68, batch train loss: 2.2314677238464355\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 69, batch train loss: 2.4211373329162598\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 70, batch train loss: 2.170036792755127\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 71, batch train loss: 1.6642024517059326\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 72, batch train loss: 1.914218783378601\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 73, batch train loss: 2.168069839477539\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 74, batch train loss: 2.013328790664673\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 75, batch train loss: 1.6564834117889404\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 76, batch train loss: 1.7996264696121216\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 77, batch train loss: 2.103803873062134\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 78, batch train loss: 1.6593722105026245\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 79, batch train loss: 2.250133514404297\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 80, batch train loss: 2.2205114364624023\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 81, batch train loss: 2.8479526042938232\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 82, batch train loss: 2.8331594467163086\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 83, batch train loss: 1.7898972034454346\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 84, batch train loss: 2.0439183712005615\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 85, batch train loss: 1.8755525350570679\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 86, batch train loss: 2.399538278579712\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 87, batch train loss: 3.0185225009918213\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 88, batch train loss: 2.305889368057251\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 89, batch train loss: 1.9841489791870117\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 90, batch train loss: 2.055687427520752\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 91, batch train loss: 2.5017526149749756\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 92, batch train loss: 2.031299352645874\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 93, batch train loss: 2.292682409286499\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 94, batch train loss: 2.015066146850586\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 95, batch train loss: 2.357161521911621\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 96, batch train loss: 2.351893424987793\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 97, batch train loss: 1.853678822517395\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 98, batch train loss: 1.9332830905914307\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 99, batch train loss: 1.671785593032837\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 100, batch train loss: 1.5304173231124878\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 101, batch train loss: 1.645472526550293\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 102, batch train loss: 1.6725469827651978\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 103, batch train loss: 1.7014018297195435\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 104, batch train loss: 1.4831433296203613\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 105, batch train loss: 1.526259422302246\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 106, batch train loss: 3.8721210956573486\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 107, batch train loss: 1.9677009582519531\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 108, batch train loss: 3.025131940841675\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 109, batch train loss: 2.8586266040802\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 110, batch train loss: 2.1381747722625732\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 111, batch train loss: 2.039081335067749\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 112, batch train loss: 3.341017484664917\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 113, batch train loss: 1.9776157140731812\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 114, batch train loss: 3.3324878215789795\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 115, batch train loss: 1.7212074995040894\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 116, batch train loss: 2.0302436351776123\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 117, batch train loss: 4.154273509979248\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 118, batch train loss: 1.7518261671066284\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 119, batch train loss: 2.5538008213043213\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 120, batch train loss: 1.832295536994934\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 121, batch train loss: 2.320809841156006\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 122, batch train loss: 1.6213264465332031\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 123, batch train loss: 1.781731367111206\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 124, batch train loss: 1.562767744064331\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 125, batch train loss: 1.8851853609085083\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 126, batch train loss: 1.8549104928970337\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 127, batch train loss: 1.4369045495986938\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 128, batch train loss: 1.5552294254302979\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 129, batch train loss: 2.1225147247314453\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, batch_id: 130, batch train loss: 2.562695264816284\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 131, batch train loss: 1.7841912508010864\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 132, batch train loss: 2.7399885654449463\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 133, batch train loss: 2.3138186931610107\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 134, batch train loss: 2.7266125679016113\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 135, batch train loss: 2.4814956188201904\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 136, batch train loss: 2.0540101528167725\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 137, batch train loss: 1.974904179573059\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 138, batch train loss: 1.7434258460998535\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 139, batch train loss: 1.9650769233703613\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 140, batch train loss: 1.5490013360977173\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 141, batch train loss: 1.711686611175537\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 142, batch train loss: 1.8936173915863037\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 143, batch train loss: 1.6222589015960693\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 144, batch train loss: 2.683631420135498\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 145, batch train loss: 1.9796741008758545\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 146, batch train loss: 2.1867551803588867\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 147, batch train loss: 2.1627113819122314\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 148, batch train loss: 1.8542439937591553\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 149, batch train loss: 1.747426152229309\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 150, batch train loss: 1.743533968925476\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 151, batch train loss: 1.5659176111221313\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 152, batch train loss: 2.171005964279175\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 153, batch train loss: 1.8453400135040283\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 154, batch train loss: 2.0979065895080566\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 155, batch train loss: 1.7713855504989624\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 156, batch train loss: 1.7414363622665405\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 157, batch train loss: 1.538147211074829\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 158, batch train loss: 1.8163970708847046\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 159, batch train loss: 2.219338893890381\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 160, batch train loss: 1.8691601753234863\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 161, batch train loss: 2.0600709915161133\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 162, batch train loss: 1.543286919593811\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 163, batch train loss: 1.5793789625167847\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 164, batch train loss: 1.8104820251464844\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 165, batch train loss: 1.4986093044281006\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 166, batch train loss: 1.3860206604003906\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 167, batch train loss: 2.2183735370635986\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 168, batch train loss: 2.206105947494507\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 169, batch train loss: 1.786378026008606\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 170, batch train loss: 2.014296531677246\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 171, batch train loss: 2.3686606884002686\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 172, batch train loss: 1.910000205039978\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 173, batch train loss: 2.333010673522949\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 174, batch train loss: 1.8788458108901978\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 175, batch train loss: 2.2414188385009766\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 176, batch train loss: 3.041306972503662\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 177, batch train loss: 2.3074257373809814\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 178, batch train loss: 1.9646366834640503\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 179, batch train loss: 2.27010178565979\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 180, batch train loss: 1.888838291168213\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 181, batch train loss: 2.7551357746124268\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 182, batch train loss: 2.456946611404419\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 183, batch train loss: 3.332415819168091\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 184, batch train loss: 3.615481376647949\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 185, batch train loss: 2.7698814868927\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 186, batch train loss: 2.955461025238037\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 187, batch train loss: 2.9886887073516846\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 188, batch train loss: 2.7047548294067383\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 189, batch train loss: 1.8939114809036255\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 190, batch train loss: 4.1710124015808105\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 191, batch train loss: 2.799860954284668\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 192, batch train loss: 2.755650520324707\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 193, batch train loss: 3.5158731937408447\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 194, batch train loss: 2.8355326652526855\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 195, batch train loss: 2.316397190093994\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 196, batch train loss: 5.5386481285095215\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 197, batch train loss: 2.2894716262817383\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 198, batch train loss: 1.9405678510665894\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 199, batch train loss: 2.3435285091400146\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 200, batch train loss: 2.524261474609375\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 201, batch train loss: 2.5031464099884033\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 202, batch train loss: 1.935068964958191\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 203, batch train loss: 2.741584539413452\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 204, batch train loss: 2.016427516937256\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 205, batch train loss: 2.769279718399048\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 206, batch train loss: 2.079263210296631\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 207, batch train loss: 2.5851452350616455\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 208, batch train loss: 1.8503971099853516\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 209, batch train loss: 2.0044479370117188\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 210, batch train loss: 2.5663764476776123\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 211, batch train loss: 3.103334903717041\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 212, batch train loss: 2.4482603073120117\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 213, batch train loss: 1.9455021619796753\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 214, batch train loss: 2.2660043239593506\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 215, batch train loss: 2.1397249698638916\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 216, batch train loss: 1.6802986860275269\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 217, batch train loss: 2.0730884075164795\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 218, batch train loss: 1.968248724937439\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 219, batch train loss: 2.3206868171691895\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 220, batch train loss: 2.2120251655578613\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 221, batch train loss: 1.8021403551101685\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 222, batch train loss: 1.8022593259811401\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 223, batch train loss: 2.149284601211548\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 224, batch train loss: 1.8271712064743042\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 225, batch train loss: 1.7691808938980103\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 226, batch train loss: 1.8868120908737183\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 227, batch train loss: 2.1956958770751953\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 228, batch train loss: 1.892207384109497\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 229, batch train loss: 1.4331398010253906\n",
      "\n",
      "\n",
      "Epoch: 44, batch_id: 230, batch train loss: 1.858045220375061\n",
      "\n",
      "\n",
      "Epoch: 44/ 100, Loss: 2.143183253640714\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:15<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 Validation Loss: 2.146254140138626\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, batch_id: 1, batch train loss: 1.848381757736206\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 2, batch train loss: 2.036588191986084\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 3, batch train loss: 2.220933675765991\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 4, batch train loss: 2.2264840602874756\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 5, batch train loss: 2.342181444168091\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 6, batch train loss: 2.1994664669036865\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 7, batch train loss: 2.066789150238037\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 8, batch train loss: 2.0239083766937256\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 9, batch train loss: 1.849711298942566\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 10, batch train loss: 1.6549561023712158\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 11, batch train loss: 1.657201886177063\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 12, batch train loss: 1.9172875881195068\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 13, batch train loss: 1.645231008529663\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 14, batch train loss: 1.835423231124878\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 15, batch train loss: 1.6410948038101196\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 16, batch train loss: 1.636698603630066\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 17, batch train loss: 1.540884017944336\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 18, batch train loss: 3.2121658325195312\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 19, batch train loss: 1.822685718536377\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 20, batch train loss: 2.5500969886779785\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 21, batch train loss: 2.291445016860962\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 22, batch train loss: 2.636303186416626\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 23, batch train loss: 2.556710720062256\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 24, batch train loss: 1.7812836170196533\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 25, batch train loss: 2.192591667175293\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 26, batch train loss: 1.667502999305725\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 27, batch train loss: 1.7120274305343628\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 28, batch train loss: 1.8470890522003174\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 29, batch train loss: 1.9608747959136963\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 30, batch train loss: 1.9690238237380981\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 31, batch train loss: 1.9165211915969849\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 32, batch train loss: 1.7184847593307495\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 33, batch train loss: 1.7916007041931152\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 34, batch train loss: 2.1354987621307373\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 35, batch train loss: 2.5938706398010254\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 36, batch train loss: 1.8642362356185913\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 37, batch train loss: 1.7274959087371826\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 38, batch train loss: 1.4354755878448486\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 39, batch train loss: 1.2419260740280151\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 40, batch train loss: 1.5939322710037231\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 41, batch train loss: 1.721380352973938\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 42, batch train loss: 1.5912083387374878\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 43, batch train loss: 1.981177568435669\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 44, batch train loss: 1.613465666770935\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 45, batch train loss: 1.4520363807678223\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 46, batch train loss: 1.5507174730300903\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 47, batch train loss: 1.4872398376464844\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 48, batch train loss: 1.341223120689392\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 49, batch train loss: 1.3421261310577393\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 50, batch train loss: 1.1728935241699219\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 51, batch train loss: 1.5954797267913818\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 52, batch train loss: 1.7614930868148804\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 53, batch train loss: 1.7680240869522095\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 54, batch train loss: 1.238877534866333\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 55, batch train loss: 1.3744826316833496\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 56, batch train loss: 1.3638248443603516\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 57, batch train loss: 1.5078192949295044\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 58, batch train loss: 1.705901861190796\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 59, batch train loss: 1.38381028175354\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 60, batch train loss: 1.4816312789916992\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 61, batch train loss: 1.8287866115570068\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 62, batch train loss: 1.6427483558654785\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 63, batch train loss: 1.332726240158081\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 64, batch train loss: 2.632491111755371\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 65, batch train loss: 2.0843441486358643\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 66, batch train loss: 1.784151554107666\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 67, batch train loss: 2.2681589126586914\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 68, batch train loss: 2.701305627822876\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 69, batch train loss: 1.847718358039856\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 70, batch train loss: 1.7112630605697632\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 71, batch train loss: 1.970676302909851\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 72, batch train loss: 1.6719930171966553\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 73, batch train loss: 2.7293217182159424\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 74, batch train loss: 1.9392495155334473\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 75, batch train loss: 3.3124938011169434\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 76, batch train loss: 2.1426775455474854\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 77, batch train loss: 2.200517177581787\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 78, batch train loss: 3.321915626525879\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 79, batch train loss: 2.047110080718994\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 80, batch train loss: 1.9689512252807617\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 81, batch train loss: 1.6598057746887207\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 82, batch train loss: 2.9716408252716064\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 83, batch train loss: 3.331242561340332\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 84, batch train loss: 3.6612467765808105\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 85, batch train loss: 4.911126136779785\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 86, batch train loss: 3.7020437717437744\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 87, batch train loss: 2.5797924995422363\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 88, batch train loss: 4.524359226226807\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 89, batch train loss: 2.6174464225769043\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 90, batch train loss: 3.582423448562622\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 91, batch train loss: 3.413323402404785\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 92, batch train loss: 5.417606830596924\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 93, batch train loss: 2.730182409286499\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 94, batch train loss: 3.02683424949646\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 95, batch train loss: 4.18729829788208\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 96, batch train loss: 2.474705696105957\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 97, batch train loss: 2.8136398792266846\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 98, batch train loss: 2.7708981037139893\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 99, batch train loss: 2.0380451679229736\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 100, batch train loss: 2.7809841632843018\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 101, batch train loss: 2.8140177726745605\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 102, batch train loss: 2.521986484527588\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 103, batch train loss: 2.6853408813476562\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 104, batch train loss: 1.8935376405715942\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 105, batch train loss: 1.5649157762527466\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 106, batch train loss: 1.8928059339523315\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 107, batch train loss: 1.6353566646575928\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 108, batch train loss: 2.1416993141174316\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 109, batch train loss: 2.236497402191162\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 110, batch train loss: 1.7866740226745605\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 111, batch train loss: 1.3533411026000977\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 112, batch train loss: 1.5543959140777588\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 113, batch train loss: 1.6635485887527466\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 114, batch train loss: 1.805514931678772\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 115, batch train loss: 1.535492181777954\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 116, batch train loss: 1.177348256111145\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 117, batch train loss: 1.670979619026184\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 118, batch train loss: 1.2095565795898438\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 119, batch train loss: 1.5591193437576294\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 120, batch train loss: 2.2686150074005127\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 121, batch train loss: 1.7032153606414795\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 122, batch train loss: 1.7470029592514038\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 123, batch train loss: 1.4997036457061768\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 124, batch train loss: 1.5719012022018433\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 125, batch train loss: 1.9015779495239258\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 126, batch train loss: 1.6536452770233154\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 127, batch train loss: 1.2708975076675415\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 128, batch train loss: 1.4940186738967896\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 129, batch train loss: 1.7870328426361084\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, batch_id: 130, batch train loss: 1.2227939367294312\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 131, batch train loss: 2.681790351867676\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 132, batch train loss: 2.3739445209503174\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 133, batch train loss: 2.4935059547424316\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 134, batch train loss: 2.5113532543182373\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 135, batch train loss: 2.208604574203491\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 136, batch train loss: 1.9495235681533813\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 137, batch train loss: 1.7756949663162231\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 138, batch train loss: 2.090510368347168\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 139, batch train loss: 1.7923247814178467\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 140, batch train loss: 1.800105333328247\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 141, batch train loss: 1.5002466440200806\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 142, batch train loss: 1.2584245204925537\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 143, batch train loss: 1.576568841934204\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 144, batch train loss: 1.4091591835021973\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 145, batch train loss: 1.7442595958709717\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 146, batch train loss: 1.732130765914917\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 147, batch train loss: 1.3417937755584717\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 148, batch train loss: 1.7319931983947754\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 149, batch train loss: 1.3097145557403564\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 150, batch train loss: 1.5117608308792114\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 151, batch train loss: 1.6200205087661743\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 152, batch train loss: 1.5309456586837769\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 153, batch train loss: 1.841702938079834\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 154, batch train loss: 1.7137837409973145\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 155, batch train loss: 1.7581980228424072\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 156, batch train loss: 1.4030917882919312\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 157, batch train loss: 1.7947765588760376\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 158, batch train loss: 1.208076000213623\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 159, batch train loss: 1.52473783493042\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 160, batch train loss: 1.2844644784927368\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 161, batch train loss: 1.252900242805481\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 162, batch train loss: 1.5870232582092285\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 163, batch train loss: 1.2651758193969727\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 164, batch train loss: 2.0801970958709717\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 165, batch train loss: 1.5000641345977783\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 166, batch train loss: 2.9373977184295654\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 167, batch train loss: 2.3286194801330566\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 168, batch train loss: 2.1492292881011963\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 169, batch train loss: 2.130028486251831\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 170, batch train loss: 2.3070626258850098\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 171, batch train loss: 2.483342170715332\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 172, batch train loss: 1.9466817378997803\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 173, batch train loss: 2.4086434841156006\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 174, batch train loss: 1.5734062194824219\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 175, batch train loss: 1.832096815109253\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 176, batch train loss: 1.6372835636138916\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 177, batch train loss: 1.5597646236419678\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 178, batch train loss: 1.5266257524490356\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 179, batch train loss: 2.0975136756896973\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 180, batch train loss: 1.979000449180603\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 181, batch train loss: 1.9875986576080322\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 182, batch train loss: 2.092914581298828\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 183, batch train loss: 1.9570906162261963\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 184, batch train loss: 1.5875455141067505\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 185, batch train loss: 1.5684716701507568\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 186, batch train loss: 1.8546195030212402\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 187, batch train loss: 1.836890697479248\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 188, batch train loss: 1.7861040830612183\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 189, batch train loss: 1.2915372848510742\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 190, batch train loss: 1.4902814626693726\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 191, batch train loss: 1.5101724863052368\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 192, batch train loss: 1.4795235395431519\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 193, batch train loss: 2.009939432144165\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 194, batch train loss: 1.505088448524475\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 195, batch train loss: 1.4516812562942505\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 196, batch train loss: 1.8231546878814697\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 197, batch train loss: 1.5149184465408325\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 198, batch train loss: 1.8059605360031128\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 199, batch train loss: 2.0197877883911133\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 200, batch train loss: 1.768836498260498\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 201, batch train loss: 1.7313048839569092\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 202, batch train loss: 2.395268678665161\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 203, batch train loss: 2.1350839138031006\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 204, batch train loss: 2.5554158687591553\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 205, batch train loss: 3.2895169258117676\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 206, batch train loss: 3.2453551292419434\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 207, batch train loss: 3.488537073135376\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 208, batch train loss: 3.086773157119751\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 209, batch train loss: 3.9987049102783203\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 210, batch train loss: 2.918478012084961\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 211, batch train loss: 2.5988070964813232\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 212, batch train loss: 2.9613237380981445\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 213, batch train loss: 3.9472615718841553\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 214, batch train loss: 2.5878067016601562\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 215, batch train loss: 3.654543161392212\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 216, batch train loss: 2.8537561893463135\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 217, batch train loss: 2.2773890495300293\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 218, batch train loss: 3.2083516120910645\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 219, batch train loss: 2.184684991836548\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 220, batch train loss: 4.291219711303711\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 221, batch train loss: 2.1002955436706543\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 222, batch train loss: 2.362279176712036\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 223, batch train loss: 1.9446601867675781\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 224, batch train loss: 1.8959543704986572\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 225, batch train loss: 1.6334835290908813\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 226, batch train loss: 1.6781216859817505\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 227, batch train loss: 2.309934377670288\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 228, batch train loss: 1.939020037651062\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 229, batch train loss: 2.349977731704712\n",
      "\n",
      "\n",
      "Epoch: 45, batch_id: 230, batch train loss: 1.968275785446167\n",
      "\n",
      "\n",
      "Epoch: 45/ 100, Loss: 2.065833138382953\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:21<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 Validation Loss: 2.5156307021776834\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, batch_id: 1, batch train loss: 2.0749850273132324\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 2, batch train loss: 2.355480670928955\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 3, batch train loss: 1.7969242334365845\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 4, batch train loss: 2.2198524475097656\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 5, batch train loss: 3.1960690021514893\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 6, batch train loss: 2.727407217025757\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 7, batch train loss: 1.7900416851043701\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 8, batch train loss: 3.6942410469055176\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 9, batch train loss: 1.7939510345458984\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 10, batch train loss: 2.319772243499756\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 11, batch train loss: 2.196364641189575\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 12, batch train loss: 1.9122259616851807\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 13, batch train loss: 1.7143017053604126\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 14, batch train loss: 2.776484251022339\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 15, batch train loss: 2.743591547012329\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 16, batch train loss: 2.283275842666626\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 17, batch train loss: 2.3673975467681885\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 18, batch train loss: 1.6718802452087402\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 19, batch train loss: 2.801546573638916\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 20, batch train loss: 1.7829952239990234\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 21, batch train loss: 2.383263111114502\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 22, batch train loss: 3.2954447269439697\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 23, batch train loss: 1.7142826318740845\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 24, batch train loss: 1.6831848621368408\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 25, batch train loss: 1.9774495363235474\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 26, batch train loss: 1.8172261714935303\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 27, batch train loss: 1.7913031578063965\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 28, batch train loss: 1.4476619958877563\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 29, batch train loss: 2.0781631469726562\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 30, batch train loss: 1.8669352531433105\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 31, batch train loss: 2.927216053009033\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 32, batch train loss: 1.4453192949295044\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 33, batch train loss: 1.5632483959197998\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 34, batch train loss: 1.8906701803207397\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 35, batch train loss: 3.216054916381836\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 36, batch train loss: 2.561688184738159\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 37, batch train loss: 1.9973256587982178\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 38, batch train loss: 2.439822196960449\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 39, batch train loss: 1.7130179405212402\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 40, batch train loss: 2.3484156131744385\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 41, batch train loss: 2.1271817684173584\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 42, batch train loss: 1.8914895057678223\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 43, batch train loss: 3.632777452468872\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 44, batch train loss: 2.177825927734375\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 45, batch train loss: 2.992196559906006\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 46, batch train loss: 1.7227221727371216\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 47, batch train loss: 2.6960830688476562\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 48, batch train loss: 2.247659206390381\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 49, batch train loss: 2.650240421295166\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 50, batch train loss: 1.9418489933013916\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 51, batch train loss: 2.5463387966156006\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 52, batch train loss: 1.7708821296691895\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 53, batch train loss: 1.3245925903320312\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 54, batch train loss: 2.101254463195801\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 55, batch train loss: 2.6365158557891846\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 56, batch train loss: 1.572508454322815\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 57, batch train loss: 1.666100025177002\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 58, batch train loss: 1.5589141845703125\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 59, batch train loss: 2.3205008506774902\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 60, batch train loss: 1.9345170259475708\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 61, batch train loss: 1.818750023841858\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 62, batch train loss: 1.5245012044906616\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 63, batch train loss: 1.285241723060608\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 64, batch train loss: 1.8294970989227295\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 65, batch train loss: 1.7571042776107788\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 66, batch train loss: 1.6071261167526245\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 67, batch train loss: 2.1147313117980957\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 68, batch train loss: 1.7014833688735962\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 69, batch train loss: 1.5911558866500854\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 70, batch train loss: 1.450332760810852\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 71, batch train loss: 1.7095235586166382\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 72, batch train loss: 1.5158706903457642\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 73, batch train loss: 1.5248197317123413\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 74, batch train loss: 2.2211923599243164\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 75, batch train loss: 1.4967328310012817\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 76, batch train loss: 1.742387056350708\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 77, batch train loss: 2.3251953125\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 78, batch train loss: 2.3546056747436523\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 79, batch train loss: 2.1181082725524902\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 80, batch train loss: 3.0515613555908203\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 81, batch train loss: 1.6698358058929443\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 82, batch train loss: 1.865424394607544\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 83, batch train loss: 1.9107041358947754\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 84, batch train loss: 1.6213611364364624\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 85, batch train loss: 3.175976037979126\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 86, batch train loss: 2.348975419998169\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 87, batch train loss: 2.5366861820220947\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 88, batch train loss: 3.105620861053467\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 89, batch train loss: 1.9624429941177368\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 90, batch train loss: 2.429591178894043\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 91, batch train loss: 2.399876594543457\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 92, batch train loss: 2.6853275299072266\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 93, batch train loss: 3.5840752124786377\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 94, batch train loss: 2.790886878967285\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 95, batch train loss: 2.0773983001708984\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 96, batch train loss: 3.844303846359253\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 97, batch train loss: 3.0190982818603516\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 98, batch train loss: 3.1629478931427\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 99, batch train loss: 1.5451998710632324\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 100, batch train loss: 2.475748300552368\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 101, batch train loss: 1.8167221546173096\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 102, batch train loss: 2.2074947357177734\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 103, batch train loss: 3.2345244884490967\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 104, batch train loss: 3.105962038040161\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 105, batch train loss: 2.689950466156006\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 106, batch train loss: 2.0711727142333984\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 107, batch train loss: 1.9844006299972534\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 108, batch train loss: 1.822285771369934\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 109, batch train loss: 1.8626717329025269\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 110, batch train loss: 1.9606437683105469\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 111, batch train loss: 1.441620111465454\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 112, batch train loss: 1.4752602577209473\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 113, batch train loss: 1.5157124996185303\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 114, batch train loss: 1.528661847114563\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 115, batch train loss: 2.105534791946411\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 116, batch train loss: 2.3275306224823\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 117, batch train loss: 2.576584577560425\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 118, batch train loss: 1.7258644104003906\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 119, batch train loss: 3.008901357650757\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 120, batch train loss: 3.204698085784912\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 121, batch train loss: 1.5195876359939575\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 122, batch train loss: 2.8938615322113037\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 123, batch train loss: 1.3446625471115112\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 124, batch train loss: 2.4821298122406006\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 125, batch train loss: 2.2057318687438965\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 126, batch train loss: 1.5643736124038696\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 127, batch train loss: 2.042858123779297\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 128, batch train loss: 1.4567326307296753\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 129, batch train loss: 1.6196465492248535\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, batch_id: 130, batch train loss: 1.4596352577209473\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 131, batch train loss: 1.5253437757492065\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 132, batch train loss: 1.589504599571228\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 133, batch train loss: 1.7404897212982178\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 134, batch train loss: 1.5866265296936035\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 135, batch train loss: 2.734084129333496\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 136, batch train loss: 1.55345618724823\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 137, batch train loss: 1.8957165479660034\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 138, batch train loss: 1.7626904249191284\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 139, batch train loss: 2.0874099731445312\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 140, batch train loss: 2.822915554046631\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 141, batch train loss: 2.174529552459717\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 142, batch train loss: 2.57971453666687\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 143, batch train loss: 3.1855361461639404\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 144, batch train loss: 2.5188746452331543\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 145, batch train loss: 1.8320121765136719\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 146, batch train loss: 6.514319896697998\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 147, batch train loss: 2.566086530685425\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 148, batch train loss: 3.0279808044433594\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 149, batch train loss: 3.2367963790893555\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 150, batch train loss: 2.4232709407806396\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 151, batch train loss: 3.294703245162964\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 152, batch train loss: 2.6200146675109863\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 153, batch train loss: 1.8365867137908936\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 154, batch train loss: 2.3159830570220947\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 155, batch train loss: 2.208487033843994\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 156, batch train loss: 2.1649117469787598\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 157, batch train loss: 2.053487539291382\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 158, batch train loss: 2.121628522872925\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 159, batch train loss: 1.940430760383606\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 160, batch train loss: 2.287407636642456\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 161, batch train loss: 2.261930227279663\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 162, batch train loss: 1.857987642288208\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 163, batch train loss: 2.0348105430603027\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 164, batch train loss: 2.2027082443237305\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 165, batch train loss: 3.3349528312683105\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 166, batch train loss: 2.523671865463257\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 167, batch train loss: 2.414436101913452\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 168, batch train loss: 3.3652448654174805\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 169, batch train loss: 1.8200297355651855\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 170, batch train loss: 2.896737575531006\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 171, batch train loss: 1.511428952217102\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 172, batch train loss: 2.43803334236145\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 173, batch train loss: 2.0063672065734863\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 174, batch train loss: 1.8852003812789917\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 175, batch train loss: 3.2215561866760254\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 176, batch train loss: 1.4577622413635254\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 177, batch train loss: 1.7270442247390747\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 178, batch train loss: 1.338334083557129\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 179, batch train loss: 1.726705551147461\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 180, batch train loss: 2.011218547821045\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 181, batch train loss: 1.9916263818740845\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 182, batch train loss: 2.2109389305114746\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 183, batch train loss: 2.246619462966919\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 184, batch train loss: 1.8232191801071167\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 185, batch train loss: 2.0588958263397217\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 186, batch train loss: 2.2727766036987305\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 187, batch train loss: 4.052300453186035\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 188, batch train loss: 4.618825912475586\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 189, batch train loss: 2.234187364578247\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 190, batch train loss: 3.1273508071899414\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 191, batch train loss: 2.912365674972534\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 192, batch train loss: 2.6547892093658447\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 193, batch train loss: 2.0865237712860107\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 194, batch train loss: 4.113752841949463\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 195, batch train loss: 6.2940239906311035\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 196, batch train loss: 2.452031373977661\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 197, batch train loss: 2.9349145889282227\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 198, batch train loss: 2.8375892639160156\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 199, batch train loss: 2.6884748935699463\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 200, batch train loss: 3.273660659790039\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 201, batch train loss: 3.140716791152954\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 202, batch train loss: 2.591231107711792\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 203, batch train loss: 1.9086191654205322\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 204, batch train loss: 2.156780481338501\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 205, batch train loss: 2.5389299392700195\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 206, batch train loss: 2.9946322441101074\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 207, batch train loss: 2.5577101707458496\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 208, batch train loss: 1.642048716545105\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 209, batch train loss: 2.2996370792388916\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 210, batch train loss: 1.9509944915771484\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 211, batch train loss: 2.38942551612854\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 212, batch train loss: 1.8783503770828247\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 213, batch train loss: 2.0470809936523438\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 214, batch train loss: 2.1687376499176025\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 215, batch train loss: 4.133007526397705\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 216, batch train loss: 2.514319896697998\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 217, batch train loss: 4.518925189971924\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 218, batch train loss: 3.0757646560668945\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 219, batch train loss: 3.5381758213043213\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 220, batch train loss: 2.680222272872925\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 221, batch train loss: 1.8243451118469238\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 222, batch train loss: 1.8923852443695068\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 223, batch train loss: 2.3841726779937744\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 224, batch train loss: 2.345759391784668\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 225, batch train loss: 2.2274677753448486\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 226, batch train loss: 2.05027174949646\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 227, batch train loss: 2.4292993545532227\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 228, batch train loss: 2.13590669631958\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 229, batch train loss: 2.5523011684417725\n",
      "\n",
      "\n",
      "Epoch: 46, batch_id: 230, batch train loss: 2.9017462730407715\n",
      "\n",
      "\n",
      "Epoch: 46/ 100, Loss: 2.3116801816484203\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:22<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 Validation Loss: 2.5194360335667927\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, batch_id: 1, batch train loss: 2.7165775299072266\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 2, batch train loss: 2.147719383239746\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 3, batch train loss: 2.1180593967437744\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 4, batch train loss: 2.005242347717285\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 5, batch train loss: 1.5278525352478027\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 6, batch train loss: 1.7495977878570557\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 7, batch train loss: 1.6436021327972412\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 8, batch train loss: 1.5610196590423584\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 9, batch train loss: 1.3263286352157593\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 10, batch train loss: 1.6691739559173584\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 11, batch train loss: 1.6253496408462524\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 12, batch train loss: 1.848783016204834\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 13, batch train loss: 1.7564300298690796\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 14, batch train loss: 1.5384669303894043\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 15, batch train loss: 1.465482234954834\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 16, batch train loss: 1.2990965843200684\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 17, batch train loss: 1.6249890327453613\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 18, batch train loss: 1.8405203819274902\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 19, batch train loss: 2.111781597137451\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 20, batch train loss: 1.446679949760437\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 21, batch train loss: 1.719907283782959\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 22, batch train loss: 1.3873642683029175\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 23, batch train loss: 1.5052392482757568\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 24, batch train loss: 1.7447564601898193\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 25, batch train loss: 2.3371877670288086\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 26, batch train loss: 2.4393317699432373\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 27, batch train loss: 1.971724033355713\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 28, batch train loss: 2.2977421283721924\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 29, batch train loss: 1.690885305404663\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 30, batch train loss: 2.165174961090088\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 31, batch train loss: 1.713484525680542\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 32, batch train loss: 1.3290773630142212\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 33, batch train loss: 1.6214631795883179\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 34, batch train loss: 1.985748052597046\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 35, batch train loss: 1.6600085496902466\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 36, batch train loss: 1.6150418519973755\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 37, batch train loss: 1.9023330211639404\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 38, batch train loss: 1.9276831150054932\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 39, batch train loss: 1.4973832368850708\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 40, batch train loss: 1.6868051290512085\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 41, batch train loss: 1.5685094594955444\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 42, batch train loss: 2.334461212158203\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 43, batch train loss: 1.6146135330200195\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 44, batch train loss: 1.665683627128601\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 45, batch train loss: 1.7161012887954712\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 46, batch train loss: 1.681383728981018\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 47, batch train loss: 1.7105165719985962\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 48, batch train loss: 1.5679816007614136\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 49, batch train loss: 1.7679357528686523\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 50, batch train loss: 2.0588481426239014\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 51, batch train loss: 2.1894121170043945\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 52, batch train loss: 1.8515163660049438\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 53, batch train loss: 1.8725099563598633\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 54, batch train loss: 1.8619321584701538\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 55, batch train loss: 1.981200933456421\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 56, batch train loss: 1.7364835739135742\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 57, batch train loss: 1.6095845699310303\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 58, batch train loss: 1.6834595203399658\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 59, batch train loss: 2.5015945434570312\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 60, batch train loss: 2.1125710010528564\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 61, batch train loss: 1.684889316558838\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 62, batch train loss: 1.5666364431381226\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 63, batch train loss: 1.7054719924926758\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 64, batch train loss: 1.846082329750061\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 65, batch train loss: 1.650215744972229\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 66, batch train loss: 1.5296508073806763\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 67, batch train loss: 1.7915258407592773\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 68, batch train loss: 1.670506238937378\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 69, batch train loss: 1.7617785930633545\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 70, batch train loss: 1.6544604301452637\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 71, batch train loss: 1.4483336210250854\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 72, batch train loss: 2.400918960571289\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 73, batch train loss: 1.7527471780776978\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 74, batch train loss: 2.1911001205444336\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 75, batch train loss: 2.2969613075256348\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 76, batch train loss: 1.8283593654632568\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 77, batch train loss: 1.5333762168884277\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 78, batch train loss: 1.6777775287628174\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 79, batch train loss: 1.3995778560638428\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 80, batch train loss: 1.5262703895568848\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 81, batch train loss: 1.5286169052124023\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 82, batch train loss: 2.383310556411743\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 83, batch train loss: 2.25343656539917\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 84, batch train loss: 2.0592920780181885\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 85, batch train loss: 1.8673317432403564\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 86, batch train loss: 2.183938503265381\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 87, batch train loss: 2.3147566318511963\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 88, batch train loss: 2.7695822715759277\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 89, batch train loss: 2.106417655944824\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 90, batch train loss: 3.4826862812042236\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 91, batch train loss: 2.1856610774993896\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 92, batch train loss: 2.2994909286499023\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 93, batch train loss: 2.7013893127441406\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 94, batch train loss: 1.9058561325073242\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 95, batch train loss: 2.0496296882629395\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 96, batch train loss: 2.0537328720092773\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 97, batch train loss: 2.484477996826172\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 98, batch train loss: 1.5575939416885376\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 99, batch train loss: 2.1414523124694824\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 100, batch train loss: 1.9942106008529663\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 101, batch train loss: 1.966797113418579\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 102, batch train loss: 2.3653006553649902\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 103, batch train loss: 2.0143773555755615\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 104, batch train loss: 1.750471591949463\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 105, batch train loss: 1.6464287042617798\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 106, batch train loss: 2.3871679306030273\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 107, batch train loss: 2.873932361602783\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 108, batch train loss: 2.420492649078369\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 109, batch train loss: 2.0765795707702637\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 110, batch train loss: 2.2850430011749268\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 111, batch train loss: 2.550745964050293\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 112, batch train loss: 1.961042881011963\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 113, batch train loss: 1.8601361513137817\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 114, batch train loss: 1.7634199857711792\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 115, batch train loss: 1.7632999420166016\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 116, batch train loss: 1.4637166261672974\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 117, batch train loss: 1.5122584104537964\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 118, batch train loss: 1.4094970226287842\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 119, batch train loss: 1.2607210874557495\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 120, batch train loss: 1.1470359563827515\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 121, batch train loss: 1.8393287658691406\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 122, batch train loss: 1.5344295501708984\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 123, batch train loss: 1.6484062671661377\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 124, batch train loss: 1.3441824913024902\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 125, batch train loss: 1.4062343835830688\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 126, batch train loss: 2.011038064956665\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 127, batch train loss: 1.5681068897247314\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 128, batch train loss: 1.6507772207260132\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 129, batch train loss: 1.6338785886764526\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, batch_id: 130, batch train loss: 1.7303351163864136\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 131, batch train loss: 1.6270674467086792\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 132, batch train loss: 1.8114066123962402\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 133, batch train loss: 1.9327197074890137\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 134, batch train loss: 1.927099585533142\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 135, batch train loss: 1.3328263759613037\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 136, batch train loss: 1.8891503810882568\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 137, batch train loss: 1.2485058307647705\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 138, batch train loss: 1.3672080039978027\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 139, batch train loss: 1.6215534210205078\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 140, batch train loss: 1.862444281578064\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 141, batch train loss: 3.041541814804077\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 142, batch train loss: 1.9711631536483765\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 143, batch train loss: 2.6676859855651855\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 144, batch train loss: 2.5843050479888916\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 145, batch train loss: 1.9817150831222534\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 146, batch train loss: 2.067685127258301\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 147, batch train loss: 1.67001211643219\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 148, batch train loss: 2.1748204231262207\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 149, batch train loss: 2.3328657150268555\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 150, batch train loss: 2.1074774265289307\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 151, batch train loss: 2.5485332012176514\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 152, batch train loss: 1.8468133211135864\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 153, batch train loss: 2.6575963497161865\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 154, batch train loss: 1.9300484657287598\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 155, batch train loss: 2.4073362350463867\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 156, batch train loss: 1.8654963970184326\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 157, batch train loss: 1.9743735790252686\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 158, batch train loss: 1.6494332551956177\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 159, batch train loss: 1.8260058164596558\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 160, batch train loss: 1.335136890411377\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 161, batch train loss: 1.6398494243621826\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 162, batch train loss: 1.4647622108459473\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 163, batch train loss: 1.3969309329986572\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 164, batch train loss: 1.5517433881759644\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 165, batch train loss: 1.5463266372680664\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 166, batch train loss: 2.0969440937042236\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 167, batch train loss: 1.3644238710403442\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 168, batch train loss: 1.397481083869934\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 169, batch train loss: 1.3828600645065308\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 170, batch train loss: 1.4621191024780273\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 171, batch train loss: 1.3627992868423462\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 172, batch train loss: 1.5080785751342773\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 173, batch train loss: 1.2861504554748535\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 174, batch train loss: 1.1178548336029053\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 175, batch train loss: 1.11555016040802\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 176, batch train loss: 1.4235167503356934\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 177, batch train loss: 1.3034864664077759\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 178, batch train loss: 1.476203441619873\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 179, batch train loss: 1.2845876216888428\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 180, batch train loss: 1.2603811025619507\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 181, batch train loss: 1.4332294464111328\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 182, batch train loss: 1.5396572351455688\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 183, batch train loss: 2.462047815322876\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 184, batch train loss: 1.8292405605316162\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 185, batch train loss: 2.1141059398651123\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 186, batch train loss: 3.026531219482422\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 187, batch train loss: 1.512445330619812\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 188, batch train loss: 2.2786865234375\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 189, batch train loss: 1.9463075399398804\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 190, batch train loss: 1.9701491594314575\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 191, batch train loss: 2.0008902549743652\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 192, batch train loss: 1.4798816442489624\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 193, batch train loss: 1.2773267030715942\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 194, batch train loss: 1.7452945709228516\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 195, batch train loss: 1.9985374212265015\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 196, batch train loss: 1.972726821899414\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 197, batch train loss: 2.2219042778015137\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 198, batch train loss: 1.9598103761672974\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 199, batch train loss: 1.9636844396591187\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 200, batch train loss: 1.5611259937286377\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 201, batch train loss: 1.798525333404541\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 202, batch train loss: 1.6377021074295044\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 203, batch train loss: 2.293379306793213\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 204, batch train loss: 2.0628907680511475\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 205, batch train loss: 1.7858552932739258\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 206, batch train loss: 2.1921627521514893\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 207, batch train loss: 1.7978334426879883\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 208, batch train loss: 3.252680540084839\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 209, batch train loss: 1.628149151802063\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 210, batch train loss: 1.6764243841171265\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 211, batch train loss: 1.9368916749954224\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 212, batch train loss: 1.8998208045959473\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 213, batch train loss: 1.85480535030365\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 214, batch train loss: 1.7757415771484375\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 215, batch train loss: 1.8230795860290527\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 216, batch train loss: 1.591465950012207\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 217, batch train loss: 1.3823740482330322\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 218, batch train loss: 1.6101449728012085\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 219, batch train loss: 1.6004878282546997\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 220, batch train loss: 1.4996788501739502\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 221, batch train loss: 1.4741394519805908\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 222, batch train loss: 1.294187307357788\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 223, batch train loss: 1.2769876718521118\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 224, batch train loss: 1.5537875890731812\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 225, batch train loss: 1.5049643516540527\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 226, batch train loss: 1.045714259147644\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 227, batch train loss: 1.853621006011963\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 228, batch train loss: 1.8421539068222046\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 229, batch train loss: 1.5771758556365967\n",
      "\n",
      "\n",
      "Epoch: 47, batch_id: 230, batch train loss: 1.4890724420547485\n",
      "\n",
      "\n",
      "Epoch: 47/ 100, Loss: 1.8278245117353356\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:20<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 Validation Loss: 1.6007014175256093\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, batch_id: 1, batch train loss: 1.5854532718658447\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 2, batch train loss: 1.8899800777435303\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 3, batch train loss: 1.4420727491378784\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 4, batch train loss: 1.334658145904541\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 5, batch train loss: 2.1396188735961914\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 6, batch train loss: 1.828524112701416\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 7, batch train loss: 1.9073987007141113\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 8, batch train loss: 2.157470464706421\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 9, batch train loss: 1.8319705724716187\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 10, batch train loss: 1.6814357042312622\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 11, batch train loss: 2.9726710319519043\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 12, batch train loss: 1.5042506456375122\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 13, batch train loss: 2.073683977127075\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 14, batch train loss: 2.016791343688965\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 15, batch train loss: 2.2059977054595947\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 16, batch train loss: 2.420748472213745\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 17, batch train loss: 1.4337592124938965\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 18, batch train loss: 2.15456223487854\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 19, batch train loss: 1.5287742614746094\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 20, batch train loss: 1.8093903064727783\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 21, batch train loss: 1.6132503747940063\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 22, batch train loss: 1.937250018119812\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 23, batch train loss: 1.6753658056259155\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 24, batch train loss: 1.5459991693496704\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 25, batch train loss: 1.52438223361969\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 26, batch train loss: 1.7587069272994995\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 27, batch train loss: 1.6430771350860596\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 28, batch train loss: 1.7683225870132446\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 29, batch train loss: 1.9358817338943481\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 30, batch train loss: 2.7778642177581787\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 31, batch train loss: 2.11576247215271\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 32, batch train loss: 1.5300968885421753\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 33, batch train loss: 2.2497012615203857\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 34, batch train loss: 1.8033766746520996\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 35, batch train loss: 2.0478663444519043\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 36, batch train loss: 1.6430585384368896\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 37, batch train loss: 1.967895746231079\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 38, batch train loss: 1.592024326324463\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 39, batch train loss: 1.4939954280853271\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 40, batch train loss: 1.5825351476669312\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 41, batch train loss: 1.3952158689498901\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 42, batch train loss: 1.8388047218322754\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 43, batch train loss: 1.3088327646255493\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 44, batch train loss: 1.651634931564331\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 45, batch train loss: 1.2222626209259033\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 46, batch train loss: 1.4156701564788818\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 47, batch train loss: 1.3405044078826904\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 48, batch train loss: 1.24796724319458\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 49, batch train loss: 1.0904161930084229\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 50, batch train loss: 1.0627576112747192\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 51, batch train loss: 0.8770155906677246\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 52, batch train loss: 1.1129549741744995\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 53, batch train loss: 1.2132070064544678\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 54, batch train loss: 1.4813233613967896\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 55, batch train loss: 1.247344970703125\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 56, batch train loss: 1.8968336582183838\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 57, batch train loss: 1.5515940189361572\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 58, batch train loss: 1.717044472694397\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 59, batch train loss: 1.8797296285629272\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 60, batch train loss: 2.1081197261810303\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 61, batch train loss: 1.6760826110839844\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 62, batch train loss: 1.353271722793579\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 63, batch train loss: 1.0867767333984375\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 64, batch train loss: 1.3948416709899902\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 65, batch train loss: 1.1842809915542603\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 66, batch train loss: 1.5685356855392456\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 67, batch train loss: 1.3337070941925049\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 68, batch train loss: 1.278070330619812\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 69, batch train loss: 1.1906003952026367\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 70, batch train loss: 1.3096028566360474\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 71, batch train loss: 1.7674450874328613\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 72, batch train loss: 1.5810189247131348\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 73, batch train loss: 1.2850333452224731\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 74, batch train loss: 1.2828034162521362\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 75, batch train loss: 1.1414289474487305\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 76, batch train loss: 1.6582850217819214\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 77, batch train loss: 1.5366942882537842\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 78, batch train loss: 1.2679469585418701\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 79, batch train loss: 1.3283828496932983\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 80, batch train loss: 1.3263386487960815\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 81, batch train loss: 1.097121000289917\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 82, batch train loss: 1.1165771484375\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 83, batch train loss: 1.4033006429672241\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 84, batch train loss: 1.749009609222412\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 85, batch train loss: 1.466566562652588\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 86, batch train loss: 1.3036366701126099\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 87, batch train loss: 1.238530158996582\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 88, batch train loss: 1.526220440864563\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 89, batch train loss: 1.5851523876190186\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 90, batch train loss: 1.5214638710021973\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 91, batch train loss: 1.5264006853103638\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 92, batch train loss: 1.3246177434921265\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 93, batch train loss: 1.2719060182571411\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 94, batch train loss: 1.6315062046051025\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 95, batch train loss: 1.8093860149383545\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 96, batch train loss: 1.7033576965332031\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 97, batch train loss: 1.885565161705017\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 98, batch train loss: 1.6249830722808838\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 99, batch train loss: 1.4625792503356934\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 100, batch train loss: 1.889279842376709\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 101, batch train loss: 1.6106839179992676\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 102, batch train loss: 1.3646337985992432\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 103, batch train loss: 1.4985926151275635\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 104, batch train loss: 1.8079231977462769\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 105, batch train loss: 1.700303554534912\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 106, batch train loss: 1.4234950542449951\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 107, batch train loss: 2.019167423248291\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 108, batch train loss: 1.5695964097976685\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 109, batch train loss: 1.4934343099594116\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 110, batch train loss: 1.4857193231582642\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 111, batch train loss: 1.4492571353912354\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 112, batch train loss: 1.451839566230774\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 113, batch train loss: 1.3583917617797852\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 114, batch train loss: 1.6095025539398193\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 115, batch train loss: 1.433088779449463\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 116, batch train loss: 1.4469923973083496\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 117, batch train loss: 1.7992124557495117\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 118, batch train loss: 1.5123374462127686\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 119, batch train loss: 1.78563392162323\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 120, batch train loss: 1.6908962726593018\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 121, batch train loss: 1.762630581855774\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 122, batch train loss: 1.7997163534164429\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 123, batch train loss: 1.8745211362838745\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 124, batch train loss: 1.6385746002197266\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 125, batch train loss: 1.4095144271850586\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 126, batch train loss: 2.0200085639953613\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 127, batch train loss: 1.8194901943206787\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 128, batch train loss: 1.8141965866088867\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 129, batch train loss: 2.6451683044433594\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, batch_id: 130, batch train loss: 2.90799880027771\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 131, batch train loss: 2.307438611984253\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 132, batch train loss: 3.9576611518859863\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 133, batch train loss: 2.8745343685150146\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 134, batch train loss: 2.1322851181030273\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 135, batch train loss: 1.7388297319412231\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 136, batch train loss: 4.096264839172363\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 137, batch train loss: 2.8389434814453125\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 138, batch train loss: 2.851741075515747\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 139, batch train loss: 1.949873447418213\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 140, batch train loss: 1.8900753259658813\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 141, batch train loss: 2.194392442703247\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 142, batch train loss: 1.7660605907440186\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 143, batch train loss: 2.029348611831665\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 144, batch train loss: 2.0314927101135254\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 145, batch train loss: 1.9004056453704834\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 146, batch train loss: 2.5096540451049805\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 147, batch train loss: 1.929477334022522\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 148, batch train loss: 2.3746731281280518\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 149, batch train loss: 1.4799611568450928\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 150, batch train loss: 1.3363078832626343\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 151, batch train loss: 1.8822156190872192\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 152, batch train loss: 1.3257105350494385\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 153, batch train loss: 1.9488292932510376\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 154, batch train loss: 1.641223430633545\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 155, batch train loss: 1.947306513786316\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 156, batch train loss: 2.0215933322906494\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 157, batch train loss: 2.1340081691741943\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 158, batch train loss: 1.771101474761963\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 159, batch train loss: 2.0025086402893066\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 160, batch train loss: 1.880275845527649\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 161, batch train loss: 1.6960265636444092\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 162, batch train loss: 2.552488088607788\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 163, batch train loss: 2.345116138458252\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 164, batch train loss: 1.8000752925872803\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 165, batch train loss: 2.2660679817199707\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 166, batch train loss: 1.6977249383926392\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 167, batch train loss: 2.4191293716430664\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 168, batch train loss: 1.9219633340835571\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 169, batch train loss: 2.10835337638855\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 170, batch train loss: 2.243892192840576\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 171, batch train loss: 1.9435632228851318\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 172, batch train loss: 2.444683790206909\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 173, batch train loss: 2.947293996810913\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 174, batch train loss: 1.6728966236114502\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 175, batch train loss: 1.5632579326629639\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 176, batch train loss: 1.7221496105194092\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 177, batch train loss: 1.664933204650879\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 178, batch train loss: 1.603920817375183\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 179, batch train loss: 1.5254396200180054\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 180, batch train loss: 1.5774967670440674\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 181, batch train loss: 1.6444045305252075\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 182, batch train loss: 1.8400461673736572\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 183, batch train loss: 1.4580888748168945\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 184, batch train loss: 1.214794635772705\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 185, batch train loss: 1.2012594938278198\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 186, batch train loss: 1.4576506614685059\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 187, batch train loss: 2.1287033557891846\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 188, batch train loss: 1.505800485610962\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 189, batch train loss: 1.9564197063446045\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 190, batch train loss: 1.7310974597930908\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 191, batch train loss: 1.8576159477233887\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 192, batch train loss: 2.5426225662231445\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 193, batch train loss: 2.6759440898895264\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 194, batch train loss: 2.533576250076294\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 195, batch train loss: 2.0402021408081055\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 196, batch train loss: 3.407646894454956\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 197, batch train loss: 2.5401265621185303\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 198, batch train loss: 2.676056146621704\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 199, batch train loss: 2.2186665534973145\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 200, batch train loss: 2.3203442096710205\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 201, batch train loss: 2.0969350337982178\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 202, batch train loss: 1.576812744140625\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 203, batch train loss: 1.6509900093078613\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 204, batch train loss: 1.4966566562652588\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 205, batch train loss: 2.0747127532958984\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 206, batch train loss: 1.6197985410690308\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 207, batch train loss: 1.7575209140777588\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 208, batch train loss: 2.4994091987609863\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 209, batch train loss: 2.1451239585876465\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 210, batch train loss: 1.9301429986953735\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 211, batch train loss: 1.6889946460723877\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 212, batch train loss: 2.69779109954834\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 213, batch train loss: 1.6921789646148682\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 214, batch train loss: 3.5605461597442627\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 215, batch train loss: 2.317570686340332\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 216, batch train loss: 2.5358569622039795\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 217, batch train loss: 2.6097123622894287\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 218, batch train loss: 4.175342082977295\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 219, batch train loss: 2.7922606468200684\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 220, batch train loss: 4.196251392364502\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 221, batch train loss: 2.192800998687744\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 222, batch train loss: 2.328589677810669\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 223, batch train loss: 5.2418694496154785\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 224, batch train loss: 3.9732699394226074\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 225, batch train loss: 2.5985071659088135\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 226, batch train loss: 2.9242851734161377\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 227, batch train loss: 1.885589361190796\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 228, batch train loss: 1.9234000444412231\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 229, batch train loss: 3.0315864086151123\n",
      "\n",
      "\n",
      "Epoch: 48, batch_id: 230, batch train loss: 4.5407562255859375\n",
      "\n",
      "\n",
      "Epoch: 48/ 100, Loss: 1.8906203627586364\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:27<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 Validation Loss: 4.4291315595308935\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, batch_id: 1, batch train loss: 6.55940580368042\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 2, batch train loss: 3.546035051345825\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 3, batch train loss: 2.8266024589538574\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 4, batch train loss: 3.1131844520568848\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 5, batch train loss: 1.8669525384902954\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 6, batch train loss: 2.5810439586639404\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 7, batch train loss: 3.082932233810425\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 8, batch train loss: 4.256232738494873\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 9, batch train loss: 3.4451863765716553\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 10, batch train loss: 2.893374443054199\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 11, batch train loss: 4.859408855438232\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 12, batch train loss: 2.1862127780914307\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 13, batch train loss: 2.69035267829895\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 14, batch train loss: 3.2339491844177246\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 15, batch train loss: 3.746767997741699\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 16, batch train loss: 3.2280335426330566\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 17, batch train loss: 6.680629253387451\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 18, batch train loss: 8.025309562683105\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 19, batch train loss: 5.653637409210205\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 20, batch train loss: 2.6437296867370605\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 21, batch train loss: 4.8139967918396\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 22, batch train loss: 6.818241596221924\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 23, batch train loss: 3.315333604812622\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 24, batch train loss: 4.279321193695068\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 25, batch train loss: 4.105059623718262\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 26, batch train loss: 2.5502843856811523\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 27, batch train loss: 2.335688829421997\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 28, batch train loss: 2.6355974674224854\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 29, batch train loss: 2.6392385959625244\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 30, batch train loss: 3.747847557067871\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 31, batch train loss: 2.627032518386841\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 32, batch train loss: 3.4577717781066895\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 33, batch train loss: 3.7125582695007324\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 34, batch train loss: 4.214843273162842\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 35, batch train loss: 4.13699197769165\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 36, batch train loss: 2.8149642944335938\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 37, batch train loss: 4.855125904083252\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 38, batch train loss: 3.511915683746338\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 39, batch train loss: 1.918116807937622\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 40, batch train loss: 2.5290534496307373\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 41, batch train loss: 3.3826911449432373\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 42, batch train loss: 2.7575244903564453\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 43, batch train loss: 3.6643378734588623\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 44, batch train loss: 4.079550743103027\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 45, batch train loss: 2.927725315093994\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 46, batch train loss: 2.028325080871582\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 47, batch train loss: 4.476874351501465\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 48, batch train loss: 3.9183602333068848\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 49, batch train loss: 1.966176986694336\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 50, batch train loss: 4.088865756988525\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 51, batch train loss: 2.94938588142395\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 52, batch train loss: 1.7211698293685913\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 53, batch train loss: 2.1291913986206055\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 54, batch train loss: 4.094654083251953\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 55, batch train loss: 2.4644739627838135\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 56, batch train loss: 2.420191764831543\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 57, batch train loss: 2.3919243812561035\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 58, batch train loss: 2.542222261428833\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 59, batch train loss: 2.2778759002685547\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 60, batch train loss: 3.382692575454712\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 61, batch train loss: 2.037196159362793\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 62, batch train loss: 2.833953857421875\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 63, batch train loss: 3.285292863845825\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 64, batch train loss: 3.5615615844726562\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 65, batch train loss: 2.4020347595214844\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 66, batch train loss: 4.927563667297363\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 67, batch train loss: 5.323012828826904\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 68, batch train loss: 3.041736602783203\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 69, batch train loss: 3.0424587726593018\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 70, batch train loss: 1.8688409328460693\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 71, batch train loss: 2.8211796283721924\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 72, batch train loss: 3.5533487796783447\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 73, batch train loss: 2.0953569412231445\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 74, batch train loss: 2.2899885177612305\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 75, batch train loss: 2.8979527950286865\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 76, batch train loss: 2.1004064083099365\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 77, batch train loss: 2.774850368499756\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 78, batch train loss: 1.8432320356369019\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 79, batch train loss: 1.9542944431304932\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 80, batch train loss: 4.160519123077393\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 81, batch train loss: 2.291532039642334\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 82, batch train loss: 1.6278526782989502\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 83, batch train loss: 1.615601658821106\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 84, batch train loss: 1.9909846782684326\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 85, batch train loss: 1.808983325958252\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 86, batch train loss: 1.4085984230041504\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 87, batch train loss: 1.7618969678878784\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 88, batch train loss: 1.5989634990692139\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 89, batch train loss: 1.9556652307510376\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 90, batch train loss: 1.5566627979278564\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 91, batch train loss: 1.7775685787200928\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 92, batch train loss: 1.9000329971313477\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 93, batch train loss: 1.600954532623291\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 94, batch train loss: 2.1398797035217285\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 95, batch train loss: 1.4023172855377197\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 96, batch train loss: 1.8346402645111084\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 97, batch train loss: 2.5134811401367188\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 98, batch train loss: 2.231773853302002\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 99, batch train loss: 2.09550404548645\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 100, batch train loss: 2.1886327266693115\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 101, batch train loss: 1.594398856163025\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 102, batch train loss: 1.876525640487671\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 103, batch train loss: 1.7034971714019775\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 104, batch train loss: 1.3916358947753906\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 105, batch train loss: 1.8366882801055908\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 106, batch train loss: 1.9573291540145874\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 107, batch train loss: 1.5257043838500977\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 108, batch train loss: 1.5057058334350586\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 109, batch train loss: 1.9889158010482788\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 110, batch train loss: 2.1446192264556885\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 111, batch train loss: 1.6072361469268799\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 112, batch train loss: 1.5404846668243408\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 113, batch train loss: 1.3549097776412964\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 114, batch train loss: 1.2393876314163208\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 115, batch train loss: 1.700449824333191\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 116, batch train loss: 1.9387437105178833\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 117, batch train loss: 1.6705197095870972\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 118, batch train loss: 1.5212174654006958\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 119, batch train loss: 1.5712906122207642\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 120, batch train loss: 1.3895525932312012\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 121, batch train loss: 1.7750093936920166\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 122, batch train loss: 1.4015017747879028\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 123, batch train loss: 2.3080453872680664\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 124, batch train loss: 3.068901300430298\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 125, batch train loss: 3.3564934730529785\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 126, batch train loss: 2.0062196254730225\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 127, batch train loss: 3.5668351650238037\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 128, batch train loss: 2.3870792388916016\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 129, batch train loss: 2.464259147644043\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, batch_id: 130, batch train loss: 3.469698190689087\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 131, batch train loss: 2.33809232711792\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 132, batch train loss: 2.179090738296509\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 133, batch train loss: 2.731585741043091\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 134, batch train loss: 2.346438407897949\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 135, batch train loss: 2.9333486557006836\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 136, batch train loss: 3.286461353302002\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 137, batch train loss: 2.168064832687378\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 138, batch train loss: 2.5081169605255127\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 139, batch train loss: 3.569973945617676\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 140, batch train loss: 1.8747973442077637\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 141, batch train loss: 2.8447961807250977\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 142, batch train loss: 4.239509105682373\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 143, batch train loss: 1.797946572303772\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 144, batch train loss: 3.104766845703125\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 145, batch train loss: 3.590463161468506\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 146, batch train loss: 1.9715449810028076\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 147, batch train loss: 2.6034045219421387\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 148, batch train loss: 3.2734439373016357\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 149, batch train loss: 7.419212818145752\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 150, batch train loss: 3.1877260208129883\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 151, batch train loss: 3.7523953914642334\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 152, batch train loss: 3.8185083866119385\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 153, batch train loss: 2.871957778930664\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 154, batch train loss: 4.226125717163086\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 155, batch train loss: 2.6673479080200195\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 156, batch train loss: 1.4710623025894165\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 157, batch train loss: 3.9812207221984863\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 158, batch train loss: 3.172316789627075\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 159, batch train loss: 2.3014075756073\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 160, batch train loss: 1.8917584419250488\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 161, batch train loss: 1.6639404296875\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 162, batch train loss: 2.0218284130096436\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 163, batch train loss: 4.127566337585449\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 164, batch train loss: 4.187885284423828\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 165, batch train loss: 4.275752067565918\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 166, batch train loss: 3.5215864181518555\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 167, batch train loss: 4.676301956176758\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 168, batch train loss: 4.378237247467041\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 169, batch train loss: 6.590610504150391\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 170, batch train loss: 3.4753217697143555\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 171, batch train loss: 3.7093586921691895\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 172, batch train loss: 2.8521499633789062\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 173, batch train loss: 2.4297802448272705\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 174, batch train loss: 2.5013978481292725\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 175, batch train loss: 1.6825852394104004\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 176, batch train loss: 1.7772479057312012\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 177, batch train loss: 2.1659770011901855\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 178, batch train loss: 2.7460591793060303\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 179, batch train loss: 2.1712646484375\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 180, batch train loss: 2.1225953102111816\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 181, batch train loss: 1.5402098894119263\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 182, batch train loss: 2.508746862411499\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 183, batch train loss: 1.850441336631775\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 184, batch train loss: 1.597234845161438\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 185, batch train loss: 1.284621238708496\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 186, batch train loss: 1.3604671955108643\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 187, batch train loss: 1.5368402004241943\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 188, batch train loss: 1.7001792192459106\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 189, batch train loss: 1.704882025718689\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 190, batch train loss: 1.189518928527832\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 191, batch train loss: 2.6611483097076416\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 192, batch train loss: 1.496944546699524\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 193, batch train loss: 1.9365328550338745\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 194, batch train loss: 1.7330774068832397\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 195, batch train loss: 1.7781320810317993\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 196, batch train loss: 1.4288114309310913\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 197, batch train loss: 1.7789239883422852\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 198, batch train loss: 2.009389638900757\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 199, batch train loss: 1.5583446025848389\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 200, batch train loss: 1.8423283100128174\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 201, batch train loss: 1.7768332958221436\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 202, batch train loss: 2.1652822494506836\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 203, batch train loss: 1.6515570878982544\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 204, batch train loss: 1.9899024963378906\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 205, batch train loss: 1.9670528173446655\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 206, batch train loss: 1.668818712234497\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 207, batch train loss: 1.5002312660217285\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 208, batch train loss: 1.6154396533966064\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 209, batch train loss: 1.6213160753250122\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 210, batch train loss: 1.7898401021957397\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 211, batch train loss: 2.161259889602661\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 212, batch train loss: 1.8692054748535156\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 213, batch train loss: 1.461666226387024\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 214, batch train loss: 1.4236564636230469\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 215, batch train loss: 1.6363688707351685\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 216, batch train loss: 1.3669462203979492\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 217, batch train loss: 1.3426058292388916\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 218, batch train loss: 1.426687479019165\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 219, batch train loss: 1.4544214010238647\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 220, batch train loss: 1.2318198680877686\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 221, batch train loss: 1.5189098119735718\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 222, batch train loss: 1.4527758359909058\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 223, batch train loss: 1.4724034070968628\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 224, batch train loss: 1.5212901830673218\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 225, batch train loss: 1.6219550371170044\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 226, batch train loss: 1.6007972955703735\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 227, batch train loss: 2.541161298751831\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 228, batch train loss: 1.9952354431152344\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 229, batch train loss: 1.9905163049697876\n",
      "\n",
      "\n",
      "Epoch: 49, batch_id: 230, batch train loss: 2.8756442070007324\n",
      "\n",
      "\n",
      "Epoch: 49/ 100, Loss: 2.618217601465142\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:11<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 Validation Loss: 1.8616477648417156\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, batch_id: 1, batch train loss: 1.743984341621399\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 2, batch train loss: 1.704979658126831\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 3, batch train loss: 1.733439564704895\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 4, batch train loss: 2.3758199214935303\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 5, batch train loss: 2.2889153957366943\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 6, batch train loss: 1.8691328763961792\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 7, batch train loss: 1.9972745180130005\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 8, batch train loss: 1.8081040382385254\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 9, batch train loss: 1.9963421821594238\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 10, batch train loss: 2.1777541637420654\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 11, batch train loss: 1.6196234226226807\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 12, batch train loss: 1.4449734687805176\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 13, batch train loss: 1.341930866241455\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 14, batch train loss: 1.3478782176971436\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 15, batch train loss: 2.192363739013672\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 16, batch train loss: 2.130173921585083\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 17, batch train loss: 1.4557887315750122\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 18, batch train loss: 1.5700485706329346\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 19, batch train loss: 2.5477118492126465\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 20, batch train loss: 3.182692050933838\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 21, batch train loss: 2.3562731742858887\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 22, batch train loss: 1.7762876749038696\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 23, batch train loss: 2.3989548683166504\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 24, batch train loss: 1.9907035827636719\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 25, batch train loss: 2.080676555633545\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 26, batch train loss: 1.666712999343872\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 27, batch train loss: 1.7341219186782837\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 28, batch train loss: 1.7943743467330933\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 29, batch train loss: 1.2861731052398682\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 30, batch train loss: 1.463894248008728\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 31, batch train loss: 1.6713379621505737\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 32, batch train loss: 1.384253978729248\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 33, batch train loss: 1.9597872495651245\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 34, batch train loss: 1.281144142150879\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 35, batch train loss: 1.7015331983566284\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 36, batch train loss: 1.608974575996399\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 37, batch train loss: 1.5728894472122192\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 38, batch train loss: 2.08638596534729\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 39, batch train loss: 1.9151924848556519\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 40, batch train loss: 2.545764446258545\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 41, batch train loss: 1.5166523456573486\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 42, batch train loss: 2.346233606338501\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 43, batch train loss: 1.6527844667434692\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 44, batch train loss: 3.2561938762664795\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 45, batch train loss: 2.7888283729553223\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 46, batch train loss: 1.900614619255066\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 47, batch train loss: 2.6109652519226074\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 48, batch train loss: 3.226032018661499\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 49, batch train loss: 2.0249288082122803\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 50, batch train loss: 3.026440382003784\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 51, batch train loss: 2.3244028091430664\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 52, batch train loss: 2.3852832317352295\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 53, batch train loss: 2.637012481689453\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 54, batch train loss: 3.269636869430542\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 55, batch train loss: 4.099803924560547\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 56, batch train loss: 3.5039045810699463\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 57, batch train loss: 2.5557820796966553\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 58, batch train loss: 3.516268253326416\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 59, batch train loss: 1.9954962730407715\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 60, batch train loss: 2.659604787826538\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 61, batch train loss: 1.951399564743042\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 62, batch train loss: 1.9623589515686035\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 63, batch train loss: 2.0668351650238037\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 64, batch train loss: 2.062412738800049\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 65, batch train loss: 1.6844457387924194\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 66, batch train loss: 1.74334716796875\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 67, batch train loss: 2.291912317276001\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 68, batch train loss: 1.954695463180542\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 69, batch train loss: 2.4206576347351074\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 70, batch train loss: 1.9908441305160522\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 71, batch train loss: 2.0110158920288086\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 72, batch train loss: 1.7831345796585083\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 73, batch train loss: 2.108724355697632\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 74, batch train loss: 1.4821271896362305\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 75, batch train loss: 1.7535938024520874\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 76, batch train loss: 1.3806618452072144\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 77, batch train loss: 1.5191633701324463\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 78, batch train loss: 1.5353813171386719\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 79, batch train loss: 1.9513198137283325\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 80, batch train loss: 2.4021029472351074\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 81, batch train loss: 1.9292596578598022\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 82, batch train loss: 2.2261431217193604\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 83, batch train loss: 1.179671049118042\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 84, batch train loss: 1.831817865371704\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 85, batch train loss: 1.6892368793487549\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 86, batch train loss: 1.7977465391159058\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 87, batch train loss: 1.7638734579086304\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 88, batch train loss: 1.474858045578003\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 89, batch train loss: 1.3024626970291138\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 90, batch train loss: 1.3959708213806152\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 91, batch train loss: 1.7083103656768799\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 92, batch train loss: 1.2591052055358887\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 93, batch train loss: 1.582480549812317\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 94, batch train loss: 1.5109654664993286\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 95, batch train loss: 1.5823255777359009\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 96, batch train loss: 1.4620128870010376\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 97, batch train loss: 1.3257179260253906\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 98, batch train loss: 1.5854501724243164\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 99, batch train loss: 1.6839101314544678\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 100, batch train loss: 1.8682011365890503\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 101, batch train loss: 1.187545895576477\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 102, batch train loss: 1.1989344358444214\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 103, batch train loss: 1.5297083854675293\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 104, batch train loss: 1.2296291589736938\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 105, batch train loss: 1.5203819274902344\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 106, batch train loss: 1.6889429092407227\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 107, batch train loss: 1.4274101257324219\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 108, batch train loss: 1.187463641166687\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 109, batch train loss: 1.3690359592437744\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 110, batch train loss: 1.4810336828231812\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 111, batch train loss: 1.650272250175476\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 112, batch train loss: 1.9849357604980469\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 113, batch train loss: 1.368129849433899\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 114, batch train loss: 1.338120937347412\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 115, batch train loss: 1.184954047203064\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 116, batch train loss: 1.4049371480941772\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 117, batch train loss: 1.3518872261047363\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 118, batch train loss: 1.592124581336975\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 119, batch train loss: 1.8555208444595337\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 120, batch train loss: 1.6600581407546997\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 121, batch train loss: 2.800379991531372\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 122, batch train loss: 1.4949150085449219\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 123, batch train loss: 1.9844245910644531\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 124, batch train loss: 2.118450403213501\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 125, batch train loss: 2.010141611099243\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 126, batch train loss: 1.6211658716201782\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 127, batch train loss: 3.226818323135376\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 128, batch train loss: 2.0253727436065674\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 129, batch train loss: 2.7672019004821777\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, batch_id: 130, batch train loss: 2.646096706390381\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 131, batch train loss: 1.7721408605575562\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 132, batch train loss: 1.970342993736267\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 133, batch train loss: 2.156132221221924\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 134, batch train loss: 2.1029767990112305\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 135, batch train loss: 1.496446132659912\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 136, batch train loss: 1.249430537223816\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 137, batch train loss: 1.5368839502334595\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 138, batch train loss: 1.289705753326416\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 139, batch train loss: 1.9507195949554443\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 140, batch train loss: 1.550561547279358\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 141, batch train loss: 1.1664758920669556\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 142, batch train loss: 1.4174162149429321\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 143, batch train loss: 1.5504361391067505\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 144, batch train loss: 2.2675986289978027\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 145, batch train loss: 1.7793277502059937\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 146, batch train loss: 1.4374077320098877\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 147, batch train loss: 1.6867954730987549\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 148, batch train loss: 1.8753324747085571\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 149, batch train loss: 1.243781566619873\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 150, batch train loss: 1.5189123153686523\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 151, batch train loss: 1.3235255479812622\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 152, batch train loss: 2.138747215270996\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 153, batch train loss: 1.883396863937378\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 154, batch train loss: 1.7237180471420288\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 155, batch train loss: 1.1025781631469727\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 156, batch train loss: 1.9576064348220825\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 157, batch train loss: 1.765176773071289\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 158, batch train loss: 3.102890968322754\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 159, batch train loss: 2.3418991565704346\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 160, batch train loss: 2.8428070545196533\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 161, batch train loss: 3.3056797981262207\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 162, batch train loss: 4.661334991455078\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 163, batch train loss: 2.4778406620025635\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 164, batch train loss: 4.353155612945557\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 165, batch train loss: 3.5720374584198\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 166, batch train loss: 2.653914451599121\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 167, batch train loss: 5.105040073394775\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 168, batch train loss: 6.678191661834717\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 169, batch train loss: 4.08839225769043\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 170, batch train loss: 2.5293378829956055\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 171, batch train loss: 3.4092798233032227\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 172, batch train loss: 4.4385085105896\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 173, batch train loss: 4.053127765655518\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 174, batch train loss: 2.76047945022583\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 175, batch train loss: 5.394534587860107\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 176, batch train loss: 6.355893135070801\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 177, batch train loss: 4.165890693664551\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 178, batch train loss: 6.844522476196289\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 179, batch train loss: 5.955070972442627\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 180, batch train loss: 2.9021427631378174\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 181, batch train loss: 4.484559535980225\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 182, batch train loss: 2.287440776824951\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 183, batch train loss: 1.6162351369857788\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 184, batch train loss: 3.407083034515381\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 185, batch train loss: 4.683746814727783\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 186, batch train loss: 4.039781093597412\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 187, batch train loss: 3.951038360595703\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 188, batch train loss: 3.506225109100342\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 189, batch train loss: 4.26056432723999\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 190, batch train loss: 4.526468753814697\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 191, batch train loss: 2.3634204864501953\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 192, batch train loss: 2.2217955589294434\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 193, batch train loss: 3.80442214012146\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 194, batch train loss: 3.4836156368255615\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 195, batch train loss: 3.043942451477051\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 196, batch train loss: 3.3558592796325684\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 197, batch train loss: 2.4648661613464355\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 198, batch train loss: 3.399658203125\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 199, batch train loss: 3.0584733486175537\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 200, batch train loss: 1.7773005962371826\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 201, batch train loss: 3.684329032897949\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 202, batch train loss: 2.0354623794555664\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 203, batch train loss: 2.180819511413574\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 204, batch train loss: 3.125025987625122\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 205, batch train loss: 1.9869269132614136\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 206, batch train loss: 2.6601953506469727\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 207, batch train loss: 1.937819004058838\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 208, batch train loss: 2.0287628173828125\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 209, batch train loss: 1.7753751277923584\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 210, batch train loss: 1.5352599620819092\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 211, batch train loss: 2.6318187713623047\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 212, batch train loss: 1.8809354305267334\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 213, batch train loss: 2.1630492210388184\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 214, batch train loss: 1.521660327911377\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 215, batch train loss: 2.5592339038848877\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 216, batch train loss: 1.9191474914550781\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 217, batch train loss: 2.122739553451538\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 218, batch train loss: 2.603109836578369\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 219, batch train loss: 1.3901287317276\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 220, batch train loss: 3.2507200241088867\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 221, batch train loss: 2.015514612197876\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 222, batch train loss: 2.1467125415802\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 223, batch train loss: 2.323331594467163\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 224, batch train loss: 1.531798243522644\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 225, batch train loss: 2.7617592811584473\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 226, batch train loss: 1.7847908735275269\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 227, batch train loss: 2.377195119857788\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 228, batch train loss: 2.1567130088806152\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 229, batch train loss: 1.4445908069610596\n",
      "\n",
      "\n",
      "Epoch: 50, batch_id: 230, batch train loss: 2.36263108253479\n",
      "\n",
      "\n",
      "Epoch: 50/ 100, Loss: 2.2641847097355385\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:14<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 Validation Loss: 2.2764063517252606\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, batch_id: 1, batch train loss: 2.348257303237915\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 2, batch train loss: 2.5757853984832764\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 3, batch train loss: 3.198636770248413\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 4, batch train loss: 3.8237006664276123\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 5, batch train loss: 2.696809768676758\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 6, batch train loss: 4.558853626251221\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 7, batch train loss: 4.144024848937988\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 8, batch train loss: 1.9840232133865356\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 9, batch train loss: 4.478641986846924\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 10, batch train loss: 4.454168796539307\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 11, batch train loss: 3.9651038646698\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 12, batch train loss: 1.9110103845596313\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 13, batch train loss: 2.682474374771118\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 14, batch train loss: 2.260669708251953\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 15, batch train loss: 3.8744068145751953\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 16, batch train loss: 4.267074108123779\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 17, batch train loss: 3.902027130126953\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 18, batch train loss: 3.892639636993408\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 19, batch train loss: 4.80810022354126\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 20, batch train loss: 2.29250431060791\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 21, batch train loss: 2.3444526195526123\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 22, batch train loss: 5.693693161010742\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 23, batch train loss: 2.6929614543914795\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 24, batch train loss: 5.672150135040283\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 25, batch train loss: 7.155313968658447\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 26, batch train loss: 3.720477819442749\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 27, batch train loss: 2.222306728363037\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 28, batch train loss: 2.378857374191284\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 29, batch train loss: 2.5980887413024902\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 30, batch train loss: 2.9086787700653076\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 31, batch train loss: 2.9822075366973877\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 32, batch train loss: 2.6086368560791016\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 33, batch train loss: 2.0338222980499268\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 34, batch train loss: 2.6589741706848145\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 35, batch train loss: 2.2196521759033203\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 36, batch train loss: 3.528006076812744\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 37, batch train loss: 2.9894261360168457\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 38, batch train loss: 2.7937705516815186\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 39, batch train loss: 2.9771671295166016\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 40, batch train loss: 2.0885562896728516\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 41, batch train loss: 5.707342147827148\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 42, batch train loss: 3.741586923599243\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 43, batch train loss: 4.3680596351623535\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 44, batch train loss: 3.462285041809082\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 45, batch train loss: 4.07565450668335\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 46, batch train loss: 6.942126274108887\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 47, batch train loss: 20.840654373168945\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 48, batch train loss: 20.170639038085938\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 49, batch train loss: 26.602041244506836\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 50, batch train loss: 39.532318115234375\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 51, batch train loss: 39.62001037597656\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 52, batch train loss: 35.99690246582031\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 53, batch train loss: 69.10331726074219\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 54, batch train loss: 26.020296096801758\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 55, batch train loss: 20.028377532958984\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 56, batch train loss: 22.589872360229492\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 57, batch train loss: 45.67057800292969\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 58, batch train loss: 46.56166076660156\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 59, batch train loss: 13.368412017822266\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 60, batch train loss: 14.026010513305664\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 61, batch train loss: 27.538232803344727\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 62, batch train loss: 23.042118072509766\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 63, batch train loss: 26.956558227539062\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 64, batch train loss: 14.885345458984375\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 65, batch train loss: 14.459221839904785\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 66, batch train loss: 16.143953323364258\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 67, batch train loss: 10.395453453063965\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 68, batch train loss: 15.854022979736328\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 69, batch train loss: 12.743634223937988\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 70, batch train loss: 8.863638877868652\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 71, batch train loss: 9.17701530456543\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 72, batch train loss: 12.219887733459473\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 73, batch train loss: 8.233333587646484\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 74, batch train loss: 6.7702507972717285\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 75, batch train loss: 10.551349639892578\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 76, batch train loss: 9.9041109085083\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 77, batch train loss: 7.169610977172852\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 78, batch train loss: 4.71927547454834\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 79, batch train loss: 7.907363414764404\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 80, batch train loss: 6.328354835510254\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 81, batch train loss: 6.0851616859436035\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 82, batch train loss: 5.960090637207031\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 83, batch train loss: 5.422863483428955\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 84, batch train loss: 6.453251838684082\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 85, batch train loss: 4.967928409576416\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 86, batch train loss: 5.378750324249268\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 87, batch train loss: 4.041054725646973\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 88, batch train loss: 6.377201557159424\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 89, batch train loss: 4.174717426300049\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 90, batch train loss: 4.1379475593566895\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 91, batch train loss: 5.577348709106445\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 92, batch train loss: 4.217833518981934\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 93, batch train loss: 3.8169689178466797\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 94, batch train loss: 4.703528881072998\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 95, batch train loss: 5.6854352951049805\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 96, batch train loss: 4.076993942260742\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 97, batch train loss: 3.1631383895874023\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 98, batch train loss: 3.101234197616577\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 99, batch train loss: 3.465703010559082\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 100, batch train loss: 4.511092662811279\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 101, batch train loss: 4.403871059417725\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 102, batch train loss: 4.653810024261475\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 103, batch train loss: 3.2433454990386963\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 104, batch train loss: 4.4808173179626465\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 105, batch train loss: 3.496269941329956\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 106, batch train loss: 2.937396287918091\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 107, batch train loss: 3.8084733486175537\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 108, batch train loss: 3.1496429443359375\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 109, batch train loss: 3.1360466480255127\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 110, batch train loss: 3.293081760406494\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 111, batch train loss: 2.9728169441223145\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 112, batch train loss: 3.379007339477539\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 113, batch train loss: 3.1076509952545166\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 114, batch train loss: 3.2754743099212646\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 115, batch train loss: 4.354175567626953\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 116, batch train loss: 2.771479606628418\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 117, batch train loss: 2.816129684448242\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 118, batch train loss: 2.615117073059082\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 119, batch train loss: 2.6435227394104004\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 120, batch train loss: 2.8486547470092773\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 121, batch train loss: 4.054110527038574\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 122, batch train loss: 3.226513624191284\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 123, batch train loss: 2.7018802165985107\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 124, batch train loss: 2.1786704063415527\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 125, batch train loss: 2.2886245250701904\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 126, batch train loss: 3.5285534858703613\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 127, batch train loss: 2.6539924144744873\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 128, batch train loss: 3.3520548343658447\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 129, batch train loss: 2.314467430114746\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, batch_id: 130, batch train loss: 2.5082337856292725\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 131, batch train loss: 2.1043694019317627\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 132, batch train loss: 3.0120787620544434\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 133, batch train loss: 2.544728994369507\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 134, batch train loss: 3.296804189682007\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 135, batch train loss: 1.9553974866867065\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 136, batch train loss: 2.2018091678619385\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 137, batch train loss: 2.817185163497925\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 138, batch train loss: 3.2049543857574463\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 139, batch train loss: 2.7706475257873535\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 140, batch train loss: 2.7922093868255615\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 141, batch train loss: 2.9495675563812256\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 142, batch train loss: 4.039779186248779\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 143, batch train loss: 2.3281302452087402\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 144, batch train loss: 3.1835222244262695\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 145, batch train loss: 3.5627880096435547\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 146, batch train loss: 2.675841808319092\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 147, batch train loss: 2.367034912109375\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 148, batch train loss: 2.821270704269409\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 149, batch train loss: 2.7753946781158447\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 150, batch train loss: 2.5344741344451904\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 151, batch train loss: 3.569568395614624\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 152, batch train loss: 2.8717541694641113\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 153, batch train loss: 3.0985629558563232\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 154, batch train loss: 2.492819309234619\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 155, batch train loss: 2.966486692428589\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 156, batch train loss: 2.326594829559326\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 157, batch train loss: 1.9740948677062988\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 158, batch train loss: 3.4119551181793213\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 159, batch train loss: 3.3624744415283203\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 160, batch train loss: 2.1848840713500977\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 161, batch train loss: 2.7353756427764893\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 162, batch train loss: 2.6217880249023438\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 163, batch train loss: 1.98235023021698\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 164, batch train loss: 2.484044075012207\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 165, batch train loss: 3.4035110473632812\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 166, batch train loss: 2.2465553283691406\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 167, batch train loss: 3.1829895973205566\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 168, batch train loss: 1.9495512247085571\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 169, batch train loss: 2.2677958011627197\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 170, batch train loss: 2.333554744720459\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 171, batch train loss: 2.0314295291900635\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 172, batch train loss: 2.6858580112457275\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 173, batch train loss: 3.0106472969055176\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 174, batch train loss: 3.7889232635498047\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 175, batch train loss: 3.9960074424743652\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 176, batch train loss: 2.8254823684692383\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 177, batch train loss: 3.055191993713379\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 178, batch train loss: 3.08701491355896\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 179, batch train loss: 2.5425806045532227\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 180, batch train loss: 2.6684682369232178\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 181, batch train loss: 3.745666027069092\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 182, batch train loss: 2.02825665473938\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 183, batch train loss: 2.9640469551086426\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 184, batch train loss: 4.341292858123779\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 185, batch train loss: 2.907761573791504\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 186, batch train loss: 3.0760488510131836\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 187, batch train loss: 3.4982588291168213\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 188, batch train loss: 2.7573442459106445\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 189, batch train loss: 2.684230089187622\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 190, batch train loss: 2.3584489822387695\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 191, batch train loss: 2.7437500953674316\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 192, batch train loss: 2.108656883239746\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 193, batch train loss: 2.937955617904663\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 194, batch train loss: 2.3080644607543945\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 195, batch train loss: 1.7905679941177368\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 196, batch train loss: 2.9794352054595947\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 197, batch train loss: 2.5315210819244385\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 198, batch train loss: 2.1223859786987305\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 199, batch train loss: 2.5967864990234375\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 200, batch train loss: 2.654433488845825\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 201, batch train loss: 2.369046688079834\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 202, batch train loss: 2.0929722785949707\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 203, batch train loss: 3.6739883422851562\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 204, batch train loss: 2.556325912475586\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 205, batch train loss: 2.842315673828125\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 206, batch train loss: 2.0639233589172363\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 207, batch train loss: 2.3807950019836426\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 208, batch train loss: 2.6118388175964355\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 209, batch train loss: 2.062912940979004\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 210, batch train loss: 2.2628166675567627\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 211, batch train loss: 1.5744256973266602\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 212, batch train loss: 2.1556389331817627\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 213, batch train loss: 1.4950878620147705\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 214, batch train loss: 1.4158473014831543\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 215, batch train loss: 2.2031424045562744\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 216, batch train loss: 1.631711483001709\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 217, batch train loss: 1.7343746423721313\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 218, batch train loss: 1.9345369338989258\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 219, batch train loss: 1.7490415573120117\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 220, batch train loss: 1.6817386150360107\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 221, batch train loss: 3.1697335243225098\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 222, batch train loss: 2.38653302192688\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 223, batch train loss: 1.7515887022018433\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 224, batch train loss: 2.361765146255493\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 225, batch train loss: 3.471959114074707\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 226, batch train loss: 2.668761968612671\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 227, batch train loss: 2.541036605834961\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 228, batch train loss: 2.7875070571899414\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 229, batch train loss: 2.5646049976348877\n",
      "\n",
      "\n",
      "Epoch: 51, batch_id: 230, batch train loss: 2.3296127319335938\n",
      "\n",
      "\n",
      "Epoch: 51/ 100, Loss: 5.691069210093954\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 Validation Loss: 2.4279033104578653\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, batch_id: 1, batch train loss: 2.3682119846343994\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 2, batch train loss: 2.471039295196533\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 3, batch train loss: 2.5896999835968018\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 4, batch train loss: 2.10514760017395\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 5, batch train loss: 3.7830913066864014\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 6, batch train loss: 2.9868876934051514\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 7, batch train loss: 3.871473789215088\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 8, batch train loss: 2.993166208267212\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 9, batch train loss: 2.3752171993255615\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 10, batch train loss: 2.210566759109497\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 11, batch train loss: 3.8847668170928955\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 12, batch train loss: 3.002882480621338\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 13, batch train loss: 3.331204891204834\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 14, batch train loss: 3.3118224143981934\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 15, batch train loss: 2.776566982269287\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 16, batch train loss: 2.8543074131011963\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 17, batch train loss: 3.562464714050293\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 18, batch train loss: 2.306175947189331\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 19, batch train loss: 1.8526686429977417\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 20, batch train loss: 2.3717215061187744\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 21, batch train loss: 3.944352626800537\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 22, batch train loss: 2.6743297576904297\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 23, batch train loss: 2.4653267860412598\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 24, batch train loss: 2.6986050605773926\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 25, batch train loss: 2.687922239303589\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 26, batch train loss: 2.946859836578369\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 27, batch train loss: 2.547574996948242\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 28, batch train loss: 2.928447723388672\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 29, batch train loss: 3.896949052810669\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 30, batch train loss: 2.190936326980591\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 31, batch train loss: 3.9651455879211426\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 32, batch train loss: 2.8311262130737305\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 33, batch train loss: 2.823136568069458\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 34, batch train loss: 3.111377239227295\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 35, batch train loss: 4.659487247467041\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 36, batch train loss: 3.3239259719848633\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 37, batch train loss: 3.4206347465515137\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 38, batch train loss: 2.675773859024048\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 39, batch train loss: 2.0438849925994873\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 40, batch train loss: 2.820483446121216\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 41, batch train loss: 4.2179388999938965\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 42, batch train loss: 2.6987218856811523\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 43, batch train loss: 2.1641194820404053\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 44, batch train loss: 3.554173231124878\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 45, batch train loss: 1.8379793167114258\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 46, batch train loss: 3.232118606567383\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 47, batch train loss: 2.199165105819702\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 48, batch train loss: 1.6059114933013916\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 49, batch train loss: 2.4791319370269775\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 50, batch train loss: 2.241748809814453\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 51, batch train loss: 2.0988080501556396\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 52, batch train loss: 3.507277727127075\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 53, batch train loss: 2.1060571670532227\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 54, batch train loss: 2.5342319011688232\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 55, batch train loss: 2.7833216190338135\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 56, batch train loss: 2.5319294929504395\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 57, batch train loss: 2.426844835281372\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 58, batch train loss: 2.36169695854187\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 59, batch train loss: 2.139890432357788\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 60, batch train loss: 1.6179232597351074\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 61, batch train loss: 2.0697693824768066\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 62, batch train loss: 1.5789037942886353\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 63, batch train loss: 1.9818035364151\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 64, batch train loss: 2.342228889465332\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 65, batch train loss: 1.7680373191833496\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 66, batch train loss: 2.0697121620178223\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 67, batch train loss: 2.0257978439331055\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 68, batch train loss: 1.7080899477005005\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 69, batch train loss: 1.563391923904419\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 70, batch train loss: 2.166977643966675\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 71, batch train loss: 1.8436962366104126\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 72, batch train loss: 2.3197596073150635\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 73, batch train loss: 2.4506824016571045\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 74, batch train loss: 1.937563419342041\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 75, batch train loss: 2.686399221420288\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 76, batch train loss: 2.005384922027588\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 77, batch train loss: 2.6399734020233154\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 78, batch train loss: 1.7739436626434326\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 79, batch train loss: 2.0375547409057617\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 80, batch train loss: 2.1722562313079834\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 81, batch train loss: 2.6184186935424805\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 82, batch train loss: 2.33062744140625\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 83, batch train loss: 2.4926297664642334\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 84, batch train loss: 2.2469701766967773\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 85, batch train loss: 2.016812324523926\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 86, batch train loss: 3.2560153007507324\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 87, batch train loss: 2.2006678581237793\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 88, batch train loss: 2.4632201194763184\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 89, batch train loss: 2.3993279933929443\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 90, batch train loss: 3.4677233695983887\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 91, batch train loss: 2.1168594360351562\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 92, batch train loss: 2.2093684673309326\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 93, batch train loss: 2.1586899757385254\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 94, batch train loss: 2.166576623916626\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 95, batch train loss: 2.7717037200927734\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 96, batch train loss: 2.973252058029175\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 97, batch train loss: 3.061650037765503\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 98, batch train loss: 2.6967334747314453\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 99, batch train loss: 2.2066545486450195\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 100, batch train loss: 2.506066083908081\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 101, batch train loss: 2.110438108444214\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 102, batch train loss: 3.0645103454589844\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 103, batch train loss: 2.351186990737915\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 104, batch train loss: 2.228785514831543\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 105, batch train loss: 3.592338800430298\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 106, batch train loss: 3.1356587409973145\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 107, batch train loss: 3.292532205581665\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 108, batch train loss: 2.385505199432373\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 109, batch train loss: 2.726332664489746\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 110, batch train loss: 2.3996317386627197\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 111, batch train loss: 2.5510787963867188\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 112, batch train loss: 2.5326693058013916\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 113, batch train loss: 3.3052334785461426\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 114, batch train loss: 2.4464821815490723\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 115, batch train loss: 2.4742891788482666\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 116, batch train loss: 2.715557098388672\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 117, batch train loss: 2.8525044918060303\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 118, batch train loss: 2.0440773963928223\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 119, batch train loss: 2.278012275695801\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 120, batch train loss: 2.6406688690185547\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 121, batch train loss: 3.4089596271514893\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 122, batch train loss: 2.343400478363037\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 123, batch train loss: 2.8769538402557373\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 124, batch train loss: 2.573561429977417\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 125, batch train loss: 2.4514694213867188\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 126, batch train loss: 2.4861485958099365\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 127, batch train loss: 2.5621683597564697\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 128, batch train loss: 2.137361526489258\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 129, batch train loss: 2.5443673133850098\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, batch_id: 130, batch train loss: 2.9239466190338135\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 131, batch train loss: 2.4854159355163574\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 132, batch train loss: 2.00688099861145\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 133, batch train loss: 2.03886079788208\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 134, batch train loss: 2.2737419605255127\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 135, batch train loss: 2.4993412494659424\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 136, batch train loss: 2.3675310611724854\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 137, batch train loss: 3.0148324966430664\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 138, batch train loss: 2.6916234493255615\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 139, batch train loss: 3.377739906311035\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 140, batch train loss: 3.6131348609924316\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 141, batch train loss: 2.8167426586151123\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 142, batch train loss: 2.4123709201812744\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 143, batch train loss: 1.9824371337890625\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 144, batch train loss: 3.4096133708953857\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 145, batch train loss: 2.4658446311950684\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 146, batch train loss: 2.9570956230163574\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 147, batch train loss: 2.8424134254455566\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 148, batch train loss: 2.4304749965667725\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 149, batch train loss: 2.7829642295837402\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 150, batch train loss: 3.306283712387085\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 151, batch train loss: 2.3789126873016357\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 152, batch train loss: 3.2388553619384766\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 153, batch train loss: 2.4427895545959473\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 154, batch train loss: 3.3900582790374756\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 155, batch train loss: 2.8512473106384277\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 156, batch train loss: 2.461423397064209\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 157, batch train loss: 2.3094422817230225\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 158, batch train loss: 2.270400047302246\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 159, batch train loss: 2.1047654151916504\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 160, batch train loss: 2.0308830738067627\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 161, batch train loss: 2.3379664421081543\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 162, batch train loss: 2.371901750564575\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 163, batch train loss: 2.3364219665527344\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 164, batch train loss: 2.2827072143554688\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 165, batch train loss: 1.9876357316970825\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 166, batch train loss: 2.1915969848632812\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 167, batch train loss: 2.0714919567108154\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 168, batch train loss: 1.657792091369629\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 169, batch train loss: 1.8553576469421387\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 170, batch train loss: 1.8412846326828003\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 171, batch train loss: 1.8065646886825562\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 172, batch train loss: 1.653106927871704\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 173, batch train loss: 1.8012796640396118\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 174, batch train loss: 2.1044137477874756\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 175, batch train loss: 1.8144598007202148\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 176, batch train loss: 1.5589244365692139\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 177, batch train loss: 1.5405206680297852\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 178, batch train loss: 2.0595576763153076\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 179, batch train loss: 1.7437041997909546\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 180, batch train loss: 2.2553467750549316\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 181, batch train loss: 2.2949705123901367\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 182, batch train loss: 1.8530210256576538\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 183, batch train loss: 2.3817639350891113\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 184, batch train loss: 2.1869897842407227\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 185, batch train loss: 2.11641001701355\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 186, batch train loss: 1.930208683013916\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 187, batch train loss: 1.8135367631912231\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 188, batch train loss: 1.8597699403762817\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 189, batch train loss: 1.6445218324661255\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 190, batch train loss: 1.9538942575454712\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 191, batch train loss: 1.9011147022247314\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 192, batch train loss: 3.4505622386932373\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 193, batch train loss: 2.5115184783935547\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 194, batch train loss: 3.127971887588501\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 195, batch train loss: 2.5628011226654053\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 196, batch train loss: 2.4096415042877197\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 197, batch train loss: 2.9178597927093506\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 198, batch train loss: 2.1153321266174316\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 199, batch train loss: 2.0682621002197266\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 200, batch train loss: 2.551161766052246\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 201, batch train loss: 2.5724947452545166\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 202, batch train loss: 2.432136297225952\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 203, batch train loss: 2.816387891769409\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 204, batch train loss: 2.1084823608398438\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 205, batch train loss: 2.1817643642425537\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 206, batch train loss: 4.027689456939697\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 207, batch train loss: 2.9140546321868896\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 208, batch train loss: 2.6267879009246826\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 209, batch train loss: 2.504697799682617\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 210, batch train loss: 2.5056145191192627\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 211, batch train loss: 2.256891965866089\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 212, batch train loss: 2.172384262084961\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 213, batch train loss: 1.7097691297531128\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 214, batch train loss: 2.356405258178711\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 215, batch train loss: 2.1446521282196045\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 216, batch train loss: 2.920591115951538\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 217, batch train loss: 3.363839626312256\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 218, batch train loss: 2.9804489612579346\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 219, batch train loss: 2.999675750732422\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 220, batch train loss: 3.0818893909454346\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 221, batch train loss: 5.298373222351074\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 222, batch train loss: 3.765064001083374\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 223, batch train loss: 4.157837390899658\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 224, batch train loss: 5.014528274536133\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 225, batch train loss: 4.5140061378479\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 226, batch train loss: 5.036961555480957\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 227, batch train loss: 4.3485107421875\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 228, batch train loss: 5.318295955657959\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 229, batch train loss: 6.489313125610352\n",
      "\n",
      "\n",
      "Epoch: 52, batch_id: 230, batch train loss: 5.916448593139648\n",
      "\n",
      "\n",
      "Epoch: 52/ 100, Loss: 2.633284970988398\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 Validation Loss: 5.642310659090678\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53, batch_id: 1, batch train loss: 4.547684192657471\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 2, batch train loss: 4.8168253898620605\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 3, batch train loss: 4.311748504638672\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 4, batch train loss: 4.010686874389648\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 5, batch train loss: 4.032283306121826\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 6, batch train loss: 3.4985909461975098\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 7, batch train loss: 4.409669876098633\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 8, batch train loss: 3.839230537414551\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 9, batch train loss: 3.512209415435791\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 10, batch train loss: 4.082951068878174\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 11, batch train loss: 3.151141881942749\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 12, batch train loss: 5.914466381072998\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 13, batch train loss: 4.4021782875061035\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 14, batch train loss: 6.684439182281494\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 15, batch train loss: 6.206387996673584\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 16, batch train loss: 5.353572368621826\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 17, batch train loss: 4.206814765930176\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 18, batch train loss: 3.8823506832122803\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 19, batch train loss: 3.403430700302124\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 20, batch train loss: 5.475972652435303\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 21, batch train loss: 3.117311954498291\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 22, batch train loss: 4.623767375946045\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 23, batch train loss: 3.8783586025238037\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 24, batch train loss: 4.533876895904541\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 25, batch train loss: 4.231172561645508\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 26, batch train loss: 3.733078718185425\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 27, batch train loss: 4.335345268249512\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 28, batch train loss: 5.108414173126221\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 29, batch train loss: 5.441690444946289\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 30, batch train loss: 6.123370170593262\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 31, batch train loss: 6.793275356292725\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 32, batch train loss: 7.198680877685547\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 33, batch train loss: 6.595938205718994\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 34, batch train loss: 6.929264545440674\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 35, batch train loss: 6.319503307342529\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 36, batch train loss: 7.379159927368164\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 37, batch train loss: 6.880577087402344\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 38, batch train loss: 6.859344959259033\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 39, batch train loss: 6.567453384399414\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 40, batch train loss: 6.985507965087891\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 41, batch train loss: 6.853108882904053\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 42, batch train loss: 6.5472731590271\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 43, batch train loss: 6.349969387054443\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 44, batch train loss: 5.787683963775635\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 45, batch train loss: 4.576428413391113\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 46, batch train loss: 4.821361064910889\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 47, batch train loss: 5.358827114105225\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 48, batch train loss: 4.2087016105651855\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 49, batch train loss: 4.740965366363525\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 50, batch train loss: 3.791604518890381\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 51, batch train loss: 3.9647417068481445\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 52, batch train loss: 3.7429373264312744\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 53, batch train loss: 4.109373569488525\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 54, batch train loss: 4.514279842376709\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 55, batch train loss: 4.607484817504883\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 56, batch train loss: 4.2972092628479\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 57, batch train loss: 4.413251876831055\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 58, batch train loss: 4.019277095794678\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 59, batch train loss: 3.5386605262756348\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 60, batch train loss: 3.6750826835632324\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 61, batch train loss: 3.57908034324646\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 62, batch train loss: 3.760540723800659\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 63, batch train loss: 4.122254848480225\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 64, batch train loss: 3.6586902141571045\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 65, batch train loss: 3.1394357681274414\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 66, batch train loss: 3.682978868484497\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 67, batch train loss: 3.235314130783081\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 68, batch train loss: 3.065014600753784\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 69, batch train loss: 3.6477112770080566\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 70, batch train loss: 3.3898346424102783\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 71, batch train loss: 3.1254889965057373\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 72, batch train loss: 2.6571593284606934\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 73, batch train loss: 3.243920087814331\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 74, batch train loss: 3.584914445877075\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 75, batch train loss: 3.689457893371582\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 76, batch train loss: 3.150452136993408\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 77, batch train loss: 3.1358723640441895\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 78, batch train loss: 2.587078094482422\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 79, batch train loss: 2.7697620391845703\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 80, batch train loss: 3.335853338241577\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 81, batch train loss: 3.1552469730377197\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 82, batch train loss: 3.0552260875701904\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 83, batch train loss: 2.4611878395080566\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 84, batch train loss: 2.7335989475250244\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 85, batch train loss: 2.635145425796509\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 86, batch train loss: 2.2269022464752197\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 87, batch train loss: 2.2150027751922607\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 88, batch train loss: 2.928920269012451\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 89, batch train loss: 2.535240650177002\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 90, batch train loss: 3.1756954193115234\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 91, batch train loss: 2.7042572498321533\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 92, batch train loss: 2.8399555683135986\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 93, batch train loss: 2.324474573135376\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 94, batch train loss: 4.279850482940674\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 95, batch train loss: 2.964933156967163\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 96, batch train loss: 2.9040162563323975\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 97, batch train loss: 2.928349494934082\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 98, batch train loss: 2.849067449569702\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 99, batch train loss: 2.806243658065796\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 100, batch train loss: 2.768202304840088\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 101, batch train loss: 3.1226396560668945\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 102, batch train loss: 2.5357086658477783\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 103, batch train loss: 2.4530138969421387\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 104, batch train loss: 2.40832257270813\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 105, batch train loss: 2.43312668800354\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 106, batch train loss: 2.8502469062805176\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 107, batch train loss: 2.623316526412964\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 108, batch train loss: 2.5154454708099365\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 109, batch train loss: 2.7963922023773193\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 110, batch train loss: 3.1742963790893555\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 111, batch train loss: 2.9247398376464844\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 112, batch train loss: 2.9731898307800293\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 113, batch train loss: 2.3776133060455322\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 114, batch train loss: 2.3979403972625732\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 115, batch train loss: 2.230832099914551\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 116, batch train loss: 2.4248857498168945\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 117, batch train loss: 2.1467859745025635\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 118, batch train loss: 2.16036319732666\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 119, batch train loss: 2.7998807430267334\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 120, batch train loss: 2.835059642791748\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 121, batch train loss: 3.397489309310913\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 122, batch train loss: 2.517888069152832\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 123, batch train loss: 3.0700953006744385\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 124, batch train loss: 2.5196304321289062\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 125, batch train loss: 2.6649229526519775\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 126, batch train loss: 3.0333919525146484\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 127, batch train loss: 2.6913695335388184\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 128, batch train loss: 2.6192896366119385\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 129, batch train loss: 1.7722049951553345\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 130, batch train loss: 2.0881917476654053\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53, batch_id: 131, batch train loss: 2.2764387130737305\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 132, batch train loss: 2.631113052368164\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 133, batch train loss: 2.6131772994995117\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 134, batch train loss: 2.665128469467163\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 135, batch train loss: 2.170006036758423\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 136, batch train loss: 2.5387344360351562\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 137, batch train loss: 2.650813341140747\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 138, batch train loss: 3.3502092361450195\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 139, batch train loss: 2.7182037830352783\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 140, batch train loss: 2.9190001487731934\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 141, batch train loss: 2.7645959854125977\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 142, batch train loss: 2.661747932434082\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 143, batch train loss: 2.3742306232452393\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 144, batch train loss: 2.4005773067474365\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 145, batch train loss: 2.174398899078369\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 146, batch train loss: 2.17791485786438\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 147, batch train loss: 1.800266981124878\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 148, batch train loss: 3.3710293769836426\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 149, batch train loss: 2.5114834308624268\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 150, batch train loss: 2.129106283187866\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 151, batch train loss: 2.49465012550354\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 152, batch train loss: 3.063181161880493\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 153, batch train loss: 3.239445686340332\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 154, batch train loss: 3.5269775390625\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 155, batch train loss: 2.2271370887756348\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 156, batch train loss: 2.597533702850342\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 157, batch train loss: 2.2922122478485107\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 158, batch train loss: 1.835484266281128\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 159, batch train loss: 3.8284244537353516\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 160, batch train loss: 2.444589376449585\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 161, batch train loss: 2.3430192470550537\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 162, batch train loss: 2.2707951068878174\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 163, batch train loss: 2.251645803451538\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 164, batch train loss: 4.157968997955322\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 165, batch train loss: 3.801846981048584\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 166, batch train loss: 2.501358985900879\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 167, batch train loss: 2.68751859664917\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 168, batch train loss: 2.621668815612793\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 169, batch train loss: 3.4139575958251953\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 170, batch train loss: 2.5331201553344727\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 171, batch train loss: 2.4668822288513184\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 172, batch train loss: 2.330644130706787\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 173, batch train loss: 2.470573902130127\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 174, batch train loss: 3.298032522201538\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 175, batch train loss: 2.6799564361572266\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 176, batch train loss: 2.0892419815063477\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 177, batch train loss: 2.111245632171631\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 178, batch train loss: 2.8723509311676025\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 179, batch train loss: 2.5233535766601562\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 180, batch train loss: 2.0880720615386963\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 181, batch train loss: 2.1046295166015625\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 182, batch train loss: 2.025176763534546\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 183, batch train loss: 2.010097026824951\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 184, batch train loss: 3.14353346824646\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 185, batch train loss: 2.506349802017212\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 186, batch train loss: 2.556210517883301\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 187, batch train loss: 2.039358615875244\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 188, batch train loss: 2.8892276287078857\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 189, batch train loss: 2.658857822418213\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 190, batch train loss: 2.7306888103485107\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 191, batch train loss: 3.1984663009643555\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 192, batch train loss: 2.144263505935669\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 193, batch train loss: 3.7845442295074463\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 194, batch train loss: 2.550673723220825\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 195, batch train loss: 2.7836291790008545\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 196, batch train loss: 1.9143195152282715\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 197, batch train loss: 2.4926817417144775\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 198, batch train loss: 2.845778703689575\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 199, batch train loss: 2.510439157485962\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 200, batch train loss: 2.9150562286376953\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 201, batch train loss: 3.3243696689605713\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 202, batch train loss: 2.139909029006958\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 203, batch train loss: 2.777894973754883\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 204, batch train loss: 4.1834397315979\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 205, batch train loss: 3.465630292892456\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 206, batch train loss: 5.074315547943115\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 207, batch train loss: 3.1275041103363037\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 208, batch train loss: 2.9069266319274902\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 209, batch train loss: 3.5725436210632324\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 210, batch train loss: 2.261023998260498\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 211, batch train loss: 2.7580974102020264\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 212, batch train loss: 7.05703592300415\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 213, batch train loss: 2.510922908782959\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 214, batch train loss: 3.906308889389038\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 215, batch train loss: 5.057504653930664\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 216, batch train loss: 2.3264031410217285\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 217, batch train loss: 3.4150049686431885\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 218, batch train loss: 3.037529706954956\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 219, batch train loss: 2.2047481536865234\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 220, batch train loss: 2.848423719406128\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 221, batch train loss: 2.8243556022644043\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 222, batch train loss: 2.169100046157837\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 223, batch train loss: 2.2634356021881104\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 224, batch train loss: 1.9747694730758667\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 225, batch train loss: 3.0563831329345703\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 226, batch train loss: 3.280322790145874\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 227, batch train loss: 2.5328421592712402\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 228, batch train loss: 3.7185115814208984\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 229, batch train loss: 2.6061131954193115\n",
      "\n",
      "\n",
      "Epoch: 53, batch_id: 230, batch train loss: 2.3010592460632324\n",
      "\n",
      "\n",
      "Epoch: 53/ 100, Loss: 3.3798001361929852\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:25<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 Validation Loss: 2.7969090223312376\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54, batch_id: 1, batch train loss: 2.591261386871338\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 2, batch train loss: 2.132636070251465\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 3, batch train loss: 2.9346749782562256\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 4, batch train loss: 3.173729658126831\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 5, batch train loss: 2.2395753860473633\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 6, batch train loss: 2.248087167739868\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 7, batch train loss: 2.2105941772460938\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 8, batch train loss: 2.7497990131378174\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 9, batch train loss: 2.9498465061187744\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 10, batch train loss: 2.033576488494873\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 11, batch train loss: 1.8865761756896973\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 12, batch train loss: 2.3530728816986084\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 13, batch train loss: 2.3615963459014893\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 14, batch train loss: 2.818763494491577\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 15, batch train loss: 2.926039457321167\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 16, batch train loss: 2.5858702659606934\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 17, batch train loss: 2.6904914379119873\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 18, batch train loss: 2.311375856399536\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 19, batch train loss: 2.267868995666504\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 20, batch train loss: 1.8345420360565186\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 21, batch train loss: 1.663239598274231\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 22, batch train loss: 3.035391330718994\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 23, batch train loss: 2.0602827072143555\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 24, batch train loss: 2.521975517272949\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 25, batch train loss: 2.392333745956421\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 26, batch train loss: 2.7781436443328857\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 27, batch train loss: 1.5219841003417969\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 28, batch train loss: 1.8283015489578247\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 29, batch train loss: 2.112961530685425\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 30, batch train loss: 2.063055992126465\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 31, batch train loss: 2.1525771617889404\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 32, batch train loss: 2.1554250717163086\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 33, batch train loss: 2.060835599899292\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 34, batch train loss: 2.0702290534973145\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 35, batch train loss: 1.7565720081329346\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 36, batch train loss: 2.226174831390381\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 37, batch train loss: 1.7808187007904053\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 38, batch train loss: 2.599038600921631\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 39, batch train loss: 1.8634330034255981\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 40, batch train loss: 1.885522484779358\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 41, batch train loss: 2.1309986114501953\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 42, batch train loss: 2.3493497371673584\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 43, batch train loss: 1.8799564838409424\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 44, batch train loss: 2.0483314990997314\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 45, batch train loss: 2.0814497470855713\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 46, batch train loss: 1.9961190223693848\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 47, batch train loss: 1.7707427740097046\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 48, batch train loss: 2.1479761600494385\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 49, batch train loss: 1.9759037494659424\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 50, batch train loss: 1.665923833847046\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 51, batch train loss: 1.772405982017517\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 52, batch train loss: 1.8721920251846313\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 53, batch train loss: 1.862613558769226\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 54, batch train loss: 1.6952698230743408\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 55, batch train loss: 2.528244733810425\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 56, batch train loss: 1.7284572124481201\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 57, batch train loss: 1.854875087738037\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 58, batch train loss: 1.4031275510787964\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 59, batch train loss: 1.5563052892684937\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 60, batch train loss: 1.2304569482803345\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 61, batch train loss: 1.5594109296798706\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 62, batch train loss: 1.5969300270080566\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 63, batch train loss: 1.6832515001296997\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 64, batch train loss: 1.757509708404541\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 65, batch train loss: 1.8006012439727783\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 66, batch train loss: 1.5678770542144775\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 67, batch train loss: 1.635892391204834\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 68, batch train loss: 1.2767733335494995\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 69, batch train loss: 1.8664637804031372\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 70, batch train loss: 1.6066770553588867\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 71, batch train loss: 1.7544662952423096\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 72, batch train loss: 1.751733660697937\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 73, batch train loss: 1.5263763666152954\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 74, batch train loss: 1.638869047164917\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 75, batch train loss: 1.7868300676345825\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 76, batch train loss: 1.6353418827056885\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 77, batch train loss: 1.384838581085205\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 78, batch train loss: 2.144719123840332\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 79, batch train loss: 1.7543011903762817\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 80, batch train loss: 2.14237904548645\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 81, batch train loss: 1.7175917625427246\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 82, batch train loss: 1.5853052139282227\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 83, batch train loss: 1.6109732389450073\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 84, batch train loss: 2.315737009048462\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 85, batch train loss: 2.067009210586548\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 86, batch train loss: 1.81195068359375\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 87, batch train loss: 1.7156840562820435\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 88, batch train loss: 2.3794543743133545\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 89, batch train loss: 1.589685082435608\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 90, batch train loss: 1.9157049655914307\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 91, batch train loss: 2.0721209049224854\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 92, batch train loss: 1.7751851081848145\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 93, batch train loss: 1.7794901132583618\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 94, batch train loss: 1.8409191370010376\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 95, batch train loss: 2.7997212409973145\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 96, batch train loss: 2.1328036785125732\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 97, batch train loss: 2.736325979232788\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 98, batch train loss: 1.9112111330032349\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 99, batch train loss: 2.2011663913726807\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 100, batch train loss: 2.8221287727355957\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 101, batch train loss: 2.5982894897460938\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 102, batch train loss: 2.072835922241211\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 103, batch train loss: 1.9936938285827637\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 104, batch train loss: 1.8261373043060303\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 105, batch train loss: 2.6409904956817627\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 106, batch train loss: 2.166799783706665\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 107, batch train loss: 3.0890586376190186\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 108, batch train loss: 1.9290586709976196\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 109, batch train loss: 2.347547769546509\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 110, batch train loss: 2.119396924972534\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 111, batch train loss: 1.9319924116134644\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 112, batch train loss: 4.2109761238098145\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 113, batch train loss: 2.2713444232940674\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 114, batch train loss: 2.595947027206421\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 115, batch train loss: 2.830430030822754\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 116, batch train loss: 2.5057199001312256\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 117, batch train loss: 3.1341426372528076\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 118, batch train loss: 2.2172279357910156\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 119, batch train loss: 4.82601261138916\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 120, batch train loss: 3.1616992950439453\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 121, batch train loss: 1.8643580675125122\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 122, batch train loss: 2.7161316871643066\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 123, batch train loss: 2.7910358905792236\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 124, batch train loss: 2.9385950565338135\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 125, batch train loss: 2.8380324840545654\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 126, batch train loss: 2.8355553150177\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 127, batch train loss: 2.452178478240967\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 128, batch train loss: 4.089944362640381\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 129, batch train loss: 2.4635658264160156\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54, batch_id: 130, batch train loss: 3.5766122341156006\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 131, batch train loss: 2.951641321182251\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 132, batch train loss: 3.5340914726257324\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 133, batch train loss: 3.8581888675689697\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 134, batch train loss: 4.770992755889893\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 135, batch train loss: 3.4604358673095703\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 136, batch train loss: 4.03955078125\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 137, batch train loss: 3.342517614364624\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 138, batch train loss: 2.396198272705078\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 139, batch train loss: 4.435015678405762\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 140, batch train loss: 4.115769863128662\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 141, batch train loss: 3.6343278884887695\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 142, batch train loss: 2.4326987266540527\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 143, batch train loss: 3.026649236679077\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 144, batch train loss: 2.3830811977386475\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 145, batch train loss: 3.2346243858337402\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 146, batch train loss: 3.9580883979797363\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 147, batch train loss: 2.906327962875366\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 148, batch train loss: 3.1873819828033447\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 149, batch train loss: 2.445420026779175\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 150, batch train loss: 2.051968812942505\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 151, batch train loss: 2.803081750869751\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 152, batch train loss: 1.8055318593978882\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 153, batch train loss: 2.4820258617401123\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 154, batch train loss: 2.001713752746582\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 155, batch train loss: 2.0215156078338623\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 156, batch train loss: 2.2815301418304443\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 157, batch train loss: 1.7070019245147705\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 158, batch train loss: 1.7138539552688599\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 159, batch train loss: 1.9803051948547363\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 160, batch train loss: 2.894918918609619\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 161, batch train loss: 2.4447288513183594\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 162, batch train loss: 1.8046878576278687\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 163, batch train loss: 1.9746474027633667\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 164, batch train loss: 1.8735835552215576\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 165, batch train loss: 1.965016484260559\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 166, batch train loss: 2.193772077560425\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 167, batch train loss: 1.6761029958724976\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 168, batch train loss: 2.207129716873169\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 169, batch train loss: 1.7288708686828613\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 170, batch train loss: 2.1673600673675537\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 171, batch train loss: 1.4783800840377808\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 172, batch train loss: 1.8490175008773804\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 173, batch train loss: 2.2152647972106934\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 174, batch train loss: 2.9068939685821533\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 175, batch train loss: 2.21699595451355\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 176, batch train loss: 2.2379424571990967\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 177, batch train loss: 2.6206181049346924\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 178, batch train loss: 2.0040581226348877\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 179, batch train loss: 1.7650814056396484\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 180, batch train loss: 2.8701367378234863\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 181, batch train loss: 1.9613330364227295\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 182, batch train loss: 2.404836416244507\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 183, batch train loss: 1.986684799194336\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 184, batch train loss: 2.25307559967041\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 185, batch train loss: 2.0861892700195312\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 186, batch train loss: 3.862635850906372\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 187, batch train loss: 1.9336248636245728\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 188, batch train loss: 1.9626975059509277\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 189, batch train loss: 1.8853486776351929\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 190, batch train loss: 1.848841905593872\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 191, batch train loss: 1.575679898262024\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 192, batch train loss: 1.6001551151275635\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 193, batch train loss: 2.477792263031006\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 194, batch train loss: 2.263334274291992\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 195, batch train loss: 2.0165674686431885\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 196, batch train loss: 1.8232338428497314\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 197, batch train loss: 1.4665178060531616\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 198, batch train loss: 1.2341090440750122\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 199, batch train loss: 1.9253352880477905\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 200, batch train loss: 2.6542906761169434\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 201, batch train loss: 1.9054536819458008\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 202, batch train loss: 1.8975363969802856\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 203, batch train loss: 2.3356692790985107\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 204, batch train loss: 1.8180904388427734\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 205, batch train loss: 1.8373534679412842\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 206, batch train loss: 2.1959290504455566\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 207, batch train loss: 1.832078218460083\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 208, batch train loss: 2.14505934715271\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 209, batch train loss: 1.9003771543502808\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 210, batch train loss: 2.4655420780181885\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 211, batch train loss: 2.0755598545074463\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 212, batch train loss: 1.7872366905212402\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 213, batch train loss: 2.8376073837280273\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 214, batch train loss: 1.9488418102264404\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 215, batch train loss: 3.2230732440948486\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 216, batch train loss: 2.6789164543151855\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 217, batch train loss: 2.3500096797943115\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 218, batch train loss: 2.5649499893188477\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 219, batch train loss: 1.8428068161010742\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 220, batch train loss: 2.262869119644165\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 221, batch train loss: 1.9484777450561523\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 222, batch train loss: 2.3661179542541504\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 223, batch train loss: 2.2943034172058105\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 224, batch train loss: 1.8159328699111938\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 225, batch train loss: 1.9427473545074463\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 226, batch train loss: 1.8339990377426147\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 227, batch train loss: 1.9657721519470215\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 228, batch train loss: 1.651474118232727\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 229, batch train loss: 1.973341703414917\n",
      "\n",
      "\n",
      "Epoch: 54, batch_id: 230, batch train loss: 1.9511195421218872\n",
      "\n",
      "\n",
      "Epoch: 54/ 100, Loss: 2.2608389719672823\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:16<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 Validation Loss: 1.7119624098141988\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55, batch_id: 1, batch train loss: 1.923132300376892\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 2, batch train loss: 1.732966661453247\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 3, batch train loss: 1.9943501949310303\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 4, batch train loss: 2.436798572540283\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 5, batch train loss: 1.950560450553894\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 6, batch train loss: 2.2738301753997803\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 7, batch train loss: 1.6071664094924927\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 8, batch train loss: 1.811920404434204\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 9, batch train loss: 1.5295692682266235\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 10, batch train loss: 1.4928765296936035\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 11, batch train loss: 1.441306710243225\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 12, batch train loss: 1.4770933389663696\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 13, batch train loss: 2.1374948024749756\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 14, batch train loss: 1.6801329851150513\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 15, batch train loss: 1.9499125480651855\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 16, batch train loss: 1.6085869073867798\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 17, batch train loss: 2.0673418045043945\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 18, batch train loss: 1.6316955089569092\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 19, batch train loss: 1.7214465141296387\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 20, batch train loss: 1.731648325920105\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 21, batch train loss: 1.5109124183654785\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 22, batch train loss: 1.8558762073516846\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 23, batch train loss: 2.3898961544036865\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 24, batch train loss: 1.6089881658554077\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 25, batch train loss: 1.7799896001815796\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 26, batch train loss: 1.5163981914520264\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 27, batch train loss: 1.8530397415161133\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 28, batch train loss: 1.8208396434783936\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 29, batch train loss: 1.6057283878326416\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 30, batch train loss: 1.8127070665359497\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 31, batch train loss: 1.4211313724517822\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 32, batch train loss: 1.2966208457946777\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 33, batch train loss: 1.9747012853622437\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 34, batch train loss: 1.956243872642517\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 35, batch train loss: 1.688759684562683\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 36, batch train loss: 1.8765830993652344\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 37, batch train loss: 1.3794516324996948\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 38, batch train loss: 1.5423704385757446\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 39, batch train loss: 3.9184789657592773\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 40, batch train loss: 2.0522329807281494\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 41, batch train loss: 2.332059860229492\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 42, batch train loss: 2.5013089179992676\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 43, batch train loss: 2.8135933876037598\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 44, batch train loss: 1.9326355457305908\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 45, batch train loss: 2.7346115112304688\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 46, batch train loss: 2.3563079833984375\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 47, batch train loss: 2.203732490539551\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 48, batch train loss: 2.062767744064331\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 49, batch train loss: 2.0809473991394043\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 50, batch train loss: 1.7990344762802124\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 51, batch train loss: 1.7178324460983276\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 52, batch train loss: 1.730028510093689\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 53, batch train loss: 1.9617547988891602\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 54, batch train loss: 1.9046651124954224\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 55, batch train loss: 2.4631857872009277\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 56, batch train loss: 1.820311427116394\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 57, batch train loss: 2.3874266147613525\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 58, batch train loss: 1.3507797718048096\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 59, batch train loss: 2.573697328567505\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 60, batch train loss: 1.7466566562652588\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 61, batch train loss: 2.223187208175659\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 62, batch train loss: 1.8465861082077026\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 63, batch train loss: 1.8807153701782227\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 64, batch train loss: 1.832715630531311\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 65, batch train loss: 1.821984887123108\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 66, batch train loss: 1.9446964263916016\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 67, batch train loss: 2.3694498538970947\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 68, batch train loss: 2.0236852169036865\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 69, batch train loss: 2.841843366622925\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 70, batch train loss: 2.23600697517395\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 71, batch train loss: 1.6580030918121338\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 72, batch train loss: 1.7071954011917114\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 73, batch train loss: 2.520761013031006\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 74, batch train loss: 1.9414085149765015\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 75, batch train loss: 1.7942044734954834\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 76, batch train loss: 1.3650925159454346\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 77, batch train loss: 1.3732987642288208\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 78, batch train loss: 2.0818727016448975\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 79, batch train loss: 2.1884021759033203\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 80, batch train loss: 2.094078540802002\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 81, batch train loss: 1.8087944984436035\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 82, batch train loss: 1.7040139436721802\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 83, batch train loss: 1.3933982849121094\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 84, batch train loss: 1.6375781297683716\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 85, batch train loss: 1.7017258405685425\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 86, batch train loss: 1.8339414596557617\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 87, batch train loss: 2.506399393081665\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 88, batch train loss: 1.9819130897521973\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 89, batch train loss: 1.629967451095581\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 90, batch train loss: 2.211988925933838\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 91, batch train loss: 1.65780770778656\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 92, batch train loss: 2.1704559326171875\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 93, batch train loss: 1.8271775245666504\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 94, batch train loss: 1.9109667539596558\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 95, batch train loss: 1.707357406616211\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 96, batch train loss: 1.7653506994247437\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 97, batch train loss: 2.5157077312469482\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 98, batch train loss: 1.5859158039093018\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 99, batch train loss: 2.13057017326355\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 100, batch train loss: 1.481114387512207\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 101, batch train loss: 1.2922320365905762\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 102, batch train loss: 1.595201849937439\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 103, batch train loss: 1.6719212532043457\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 104, batch train loss: 1.7441999912261963\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 105, batch train loss: 1.4981077909469604\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 106, batch train loss: 1.686220645904541\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 107, batch train loss: 1.4656741619110107\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 108, batch train loss: 2.0567100048065186\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 109, batch train loss: 1.467366337776184\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 110, batch train loss: 1.971072793006897\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 111, batch train loss: 1.4009604454040527\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 112, batch train loss: 1.7090258598327637\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 113, batch train loss: 2.3844237327575684\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 114, batch train loss: 2.355682373046875\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 115, batch train loss: 2.5601537227630615\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 116, batch train loss: 1.6619343757629395\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 117, batch train loss: 1.8248199224472046\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 118, batch train loss: 2.3436737060546875\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 119, batch train loss: 1.5761908292770386\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 120, batch train loss: 2.9964802265167236\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 121, batch train loss: 2.3696184158325195\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 122, batch train loss: 2.760780096054077\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 123, batch train loss: 3.7907235622406006\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 124, batch train loss: 2.0941803455352783\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 125, batch train loss: 2.8528029918670654\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 126, batch train loss: 3.020983934402466\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 127, batch train loss: 1.4088845252990723\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 128, batch train loss: 2.795635938644409\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 129, batch train loss: 2.9282705783843994\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55, batch_id: 130, batch train loss: 1.9849551916122437\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 131, batch train loss: 1.912943959236145\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 132, batch train loss: 2.700929880142212\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 133, batch train loss: 2.984881639480591\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 134, batch train loss: 1.822418212890625\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 135, batch train loss: 3.240896701812744\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 136, batch train loss: 2.8135671615600586\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 137, batch train loss: 2.5432701110839844\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 138, batch train loss: 2.8924319744110107\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 139, batch train loss: 2.3915586471557617\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 140, batch train loss: 2.5679872035980225\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 141, batch train loss: 3.483612537384033\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 142, batch train loss: 1.977624773979187\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 143, batch train loss: 3.3190906047821045\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 144, batch train loss: 3.301103353500366\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 145, batch train loss: 1.955064296722412\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 146, batch train loss: 3.467479705810547\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 147, batch train loss: 2.0962846279144287\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 148, batch train loss: 1.6526588201522827\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 149, batch train loss: 3.0051636695861816\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 150, batch train loss: 2.082144260406494\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 151, batch train loss: 2.0890941619873047\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 152, batch train loss: 3.4070820808410645\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 153, batch train loss: 2.6397085189819336\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 154, batch train loss: 3.0382139682769775\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 155, batch train loss: 2.38449764251709\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 156, batch train loss: 2.770397186279297\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 157, batch train loss: 3.4319381713867188\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 158, batch train loss: 1.5108884572982788\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 159, batch train loss: 2.8574471473693848\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 160, batch train loss: 1.9170687198638916\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 161, batch train loss: 3.5687007904052734\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 162, batch train loss: 2.420396327972412\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 163, batch train loss: 2.268122673034668\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 164, batch train loss: 2.6737189292907715\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 165, batch train loss: 2.9626638889312744\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 166, batch train loss: 2.7495555877685547\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 167, batch train loss: 2.972421884536743\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 168, batch train loss: 1.765844702720642\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 169, batch train loss: 3.260188579559326\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 170, batch train loss: 2.871809482574463\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 171, batch train loss: 2.2175302505493164\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 172, batch train loss: 1.7715543508529663\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 173, batch train loss: 2.0720458030700684\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 174, batch train loss: 1.4686435461044312\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 175, batch train loss: 2.613750696182251\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 176, batch train loss: 3.3433759212493896\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 177, batch train loss: 2.1938116550445557\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 178, batch train loss: 2.3621134757995605\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 179, batch train loss: 3.027885675430298\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 180, batch train loss: 2.6235244274139404\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 181, batch train loss: 2.040224313735962\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 182, batch train loss: 2.0281059741973877\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 183, batch train loss: 1.6825318336486816\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 184, batch train loss: 2.048642635345459\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 185, batch train loss: 1.584309697151184\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 186, batch train loss: 2.1318299770355225\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 187, batch train loss: 1.9370863437652588\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 188, batch train loss: 1.9977396726608276\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 189, batch train loss: 1.9835119247436523\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 190, batch train loss: 1.8878369331359863\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 191, batch train loss: 1.568934679031372\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 192, batch train loss: 1.5759620666503906\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 193, batch train loss: 1.385986089706421\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 194, batch train loss: 1.4054205417633057\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 195, batch train loss: 1.5098832845687866\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 196, batch train loss: 1.4817993640899658\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 197, batch train loss: 1.5178439617156982\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 198, batch train loss: 1.483649492263794\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 199, batch train loss: 1.7292033433914185\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 200, batch train loss: 1.4704985618591309\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 201, batch train loss: 1.8071951866149902\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 202, batch train loss: 1.8351938724517822\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 203, batch train loss: 2.0871188640594482\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 204, batch train loss: 1.8648724555969238\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 205, batch train loss: 1.6537659168243408\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 206, batch train loss: 1.5483745336532593\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 207, batch train loss: 1.7947992086410522\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 208, batch train loss: 1.8648946285247803\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 209, batch train loss: 1.3593778610229492\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 210, batch train loss: 1.4432621002197266\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 211, batch train loss: 1.3740952014923096\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 212, batch train loss: 1.4978458881378174\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 213, batch train loss: 1.3944768905639648\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 214, batch train loss: 1.2989964485168457\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 215, batch train loss: 1.4220705032348633\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 216, batch train loss: 1.418712854385376\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 217, batch train loss: 1.6974776983261108\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 218, batch train loss: 1.2715641260147095\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 219, batch train loss: 1.2585002183914185\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 220, batch train loss: 1.2439305782318115\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 221, batch train loss: 1.4976361989974976\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 222, batch train loss: 1.5669924020767212\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 223, batch train loss: 1.2634905576705933\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 224, batch train loss: 1.3844760656356812\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 225, batch train loss: 1.4265977144241333\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 226, batch train loss: 1.378119945526123\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 227, batch train loss: 1.659598469734192\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 228, batch train loss: 1.5989294052124023\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 229, batch train loss: 1.3498170375823975\n",
      "\n",
      "\n",
      "Epoch: 55, batch_id: 230, batch train loss: 1.3549003601074219\n",
      "\n",
      "\n",
      "Epoch: 55/ 100, Loss: 2.0227979551190916\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:16<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 Validation Loss: 1.5936447978019714\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, batch_id: 1, batch train loss: 1.9426718950271606\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 2, batch train loss: 2.024232864379883\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 3, batch train loss: 1.5389362573623657\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 4, batch train loss: 1.9802262783050537\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 5, batch train loss: 1.9000262022018433\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 6, batch train loss: 1.9779701232910156\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 7, batch train loss: 2.306716203689575\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 8, batch train loss: 2.0384864807128906\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 9, batch train loss: 2.287292718887329\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 10, batch train loss: 2.352184534072876\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 11, batch train loss: 2.104389190673828\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 12, batch train loss: 1.3600258827209473\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 13, batch train loss: 1.894343614578247\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 14, batch train loss: 1.6678683757781982\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 15, batch train loss: 2.1853504180908203\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 16, batch train loss: 1.6174062490463257\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 17, batch train loss: 1.5604609251022339\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 18, batch train loss: 1.2712278366088867\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 19, batch train loss: 1.3954715728759766\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 20, batch train loss: 1.6392757892608643\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 21, batch train loss: 2.194458246231079\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 22, batch train loss: 2.0669474601745605\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 23, batch train loss: 1.7358312606811523\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 24, batch train loss: 1.4963399171829224\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 25, batch train loss: 1.4478908777236938\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 26, batch train loss: 1.5565099716186523\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 27, batch train loss: 1.9772497415542603\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 28, batch train loss: 2.0490405559539795\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 29, batch train loss: 2.7842676639556885\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 30, batch train loss: 2.6370861530303955\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 31, batch train loss: 1.6358234882354736\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 32, batch train loss: 2.7189698219299316\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 33, batch train loss: 2.180499792098999\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 34, batch train loss: 3.500081777572632\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 35, batch train loss: 3.670194149017334\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 36, batch train loss: 2.166062355041504\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 37, batch train loss: 2.507417917251587\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 38, batch train loss: 3.4491543769836426\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 39, batch train loss: 2.434812307357788\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 40, batch train loss: 2.8438825607299805\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 41, batch train loss: 2.7427709102630615\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 42, batch train loss: 2.19339919090271\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 43, batch train loss: 4.201157569885254\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 44, batch train loss: 2.2923052310943604\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 45, batch train loss: 2.5246524810791016\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 46, batch train loss: 2.519860029220581\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 47, batch train loss: 1.9313498735427856\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 48, batch train loss: 2.6341328620910645\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 49, batch train loss: 1.712030053138733\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 50, batch train loss: 1.6406041383743286\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 51, batch train loss: 3.22519588470459\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 52, batch train loss: 2.020474672317505\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 53, batch train loss: 2.4845333099365234\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 54, batch train loss: 2.3438456058502197\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 55, batch train loss: 2.3929243087768555\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 56, batch train loss: 2.6183972358703613\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 57, batch train loss: 1.7580993175506592\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 58, batch train loss: 2.240283489227295\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 59, batch train loss: 2.103537082672119\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 60, batch train loss: 2.7299370765686035\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 61, batch train loss: 2.310450315475464\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 62, batch train loss: 2.7618765830993652\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 63, batch train loss: 1.8970527648925781\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 64, batch train loss: 1.8844128847122192\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 65, batch train loss: 2.538254737854004\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 66, batch train loss: 2.148489236831665\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 67, batch train loss: 2.4194185733795166\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 68, batch train loss: 1.8869982957839966\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 69, batch train loss: 2.317854166030884\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 70, batch train loss: 2.096149444580078\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 71, batch train loss: 3.5468289852142334\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 72, batch train loss: 2.5732293128967285\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 73, batch train loss: 2.690150022506714\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 74, batch train loss: 2.337204933166504\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 75, batch train loss: 2.4082579612731934\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 76, batch train loss: 3.1878294944763184\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 77, batch train loss: 2.2792930603027344\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 78, batch train loss: 3.1766483783721924\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 79, batch train loss: 2.822754144668579\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 80, batch train loss: 2.4141464233398438\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 81, batch train loss: 3.3304240703582764\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 82, batch train loss: 2.6905243396759033\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 83, batch train loss: 3.4968786239624023\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 84, batch train loss: 2.511239528656006\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 85, batch train loss: 4.461370944976807\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 86, batch train loss: 4.897455215454102\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 87, batch train loss: 2.69128680229187\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 88, batch train loss: 2.9453063011169434\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 89, batch train loss: 4.095089435577393\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 90, batch train loss: 2.909025192260742\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 91, batch train loss: 3.0408525466918945\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 92, batch train loss: 4.189191818237305\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 93, batch train loss: 2.722382068634033\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 94, batch train loss: 2.1760127544403076\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 95, batch train loss: 2.345114231109619\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 96, batch train loss: 1.823168158531189\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 97, batch train loss: 1.793544054031372\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 98, batch train loss: 1.8593041896820068\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 99, batch train loss: 1.8042165040969849\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 100, batch train loss: 1.7841054201126099\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 101, batch train loss: 1.551693320274353\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 102, batch train loss: 1.7588346004486084\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 103, batch train loss: 1.5257302522659302\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 104, batch train loss: 1.4411811828613281\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 105, batch train loss: 1.6090096235275269\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 106, batch train loss: 1.2104192972183228\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 107, batch train loss: 3.598906993865967\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 108, batch train loss: 1.49311101436615\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 109, batch train loss: 2.0501911640167236\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 110, batch train loss: 1.4494673013687134\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 111, batch train loss: 1.773228406906128\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 112, batch train loss: 1.9496822357177734\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 113, batch train loss: 1.5593327283859253\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 114, batch train loss: 1.7850934267044067\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 115, batch train loss: 1.7656244039535522\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 116, batch train loss: 1.417332410812378\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 117, batch train loss: 1.5558440685272217\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 118, batch train loss: 1.4254852533340454\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 119, batch train loss: 1.5796576738357544\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 120, batch train loss: 1.7964946031570435\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 121, batch train loss: 1.8105307817459106\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 122, batch train loss: 1.5989190340042114\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 123, batch train loss: 1.651301622390747\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 124, batch train loss: 2.10689377784729\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 125, batch train loss: 1.360795259475708\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 126, batch train loss: 1.8634626865386963\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 127, batch train loss: 1.875612735748291\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 128, batch train loss: 2.026367664337158\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 129, batch train loss: 2.2994987964630127\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56, batch_id: 130, batch train loss: 2.28205943107605\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 131, batch train loss: 1.6623737812042236\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 132, batch train loss: 2.0453288555145264\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 133, batch train loss: 2.711230754852295\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 134, batch train loss: 1.9644280672073364\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 135, batch train loss: 2.4872846603393555\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 136, batch train loss: 1.857412338256836\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 137, batch train loss: 1.6385725736618042\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 138, batch train loss: 2.855666160583496\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 139, batch train loss: 1.6491252183914185\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 140, batch train loss: 2.112327814102173\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 141, batch train loss: 4.165287971496582\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 142, batch train loss: 2.1210029125213623\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 143, batch train loss: 2.3456788063049316\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 144, batch train loss: 2.2101857662200928\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 145, batch train loss: 1.988671898841858\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 146, batch train loss: 2.0732181072235107\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 147, batch train loss: 2.0068254470825195\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 148, batch train loss: 3.2635297775268555\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 149, batch train loss: 2.414257287979126\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 150, batch train loss: 4.489237308502197\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 151, batch train loss: 3.3232293128967285\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 152, batch train loss: 2.4313628673553467\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 153, batch train loss: 3.157909631729126\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 154, batch train loss: 4.054008960723877\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 155, batch train loss: 2.4515492916107178\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 156, batch train loss: 3.4656901359558105\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 157, batch train loss: 2.759258508682251\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 158, batch train loss: 2.1999785900115967\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 159, batch train loss: 2.0098555088043213\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 160, batch train loss: 1.9807889461517334\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 161, batch train loss: 1.7001125812530518\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 162, batch train loss: 2.4349496364593506\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 163, batch train loss: 2.016998767852783\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 164, batch train loss: 2.00514554977417\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 165, batch train loss: 2.129751682281494\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 166, batch train loss: 1.5671639442443848\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 167, batch train loss: 1.7836387157440186\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 168, batch train loss: 2.3298757076263428\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 169, batch train loss: 1.7472641468048096\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 170, batch train loss: 2.812372922897339\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 171, batch train loss: 3.1745827198028564\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 172, batch train loss: 2.5735971927642822\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 173, batch train loss: 3.737924814224243\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 174, batch train loss: 3.9011361598968506\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 175, batch train loss: 2.4107091426849365\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 176, batch train loss: 3.2223877906799316\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 177, batch train loss: 3.1494715213775635\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 178, batch train loss: 2.219193935394287\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 179, batch train loss: 3.960871696472168\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 180, batch train loss: 4.133625030517578\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 181, batch train loss: 2.0030593872070312\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 182, batch train loss: 1.9353387355804443\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 183, batch train loss: 2.908639669418335\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 184, batch train loss: 2.516937494277954\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 185, batch train loss: 1.9691009521484375\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 186, batch train loss: 2.9339890480041504\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 187, batch train loss: 1.7881826162338257\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 188, batch train loss: 1.6576613187789917\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 189, batch train loss: 1.8205180168151855\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 190, batch train loss: 1.834814429283142\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 191, batch train loss: 2.96460223197937\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 192, batch train loss: 3.021225690841675\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 193, batch train loss: 3.054046869277954\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 194, batch train loss: 3.5298566818237305\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 195, batch train loss: 2.8331193923950195\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 196, batch train loss: 2.523261547088623\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 197, batch train loss: 3.262655735015869\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 198, batch train loss: 2.3706037998199463\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 199, batch train loss: 2.091708183288574\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 200, batch train loss: 2.645271062850952\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 201, batch train loss: 2.205303907394409\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 202, batch train loss: 4.171993732452393\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 203, batch train loss: 3.6411662101745605\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 204, batch train loss: 3.512253522872925\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 205, batch train loss: 2.5308873653411865\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 206, batch train loss: 2.429110050201416\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 207, batch train loss: 4.788826942443848\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 208, batch train loss: 4.306517124176025\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 209, batch train loss: 2.2916064262390137\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 210, batch train loss: 3.0650339126586914\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 211, batch train loss: 2.772285223007202\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 212, batch train loss: 1.996894121170044\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 213, batch train loss: 2.225919485092163\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 214, batch train loss: 2.5975441932678223\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 215, batch train loss: 1.9427343606948853\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 216, batch train loss: 1.9397605657577515\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 217, batch train loss: 1.9170336723327637\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 218, batch train loss: 2.1111581325531006\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 219, batch train loss: 1.7623083591461182\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 220, batch train loss: 1.8125828504562378\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 221, batch train loss: 1.6541483402252197\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 222, batch train loss: 2.1019654273986816\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 223, batch train loss: 1.465285062789917\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 224, batch train loss: 1.61331045627594\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 225, batch train loss: 1.7969218492507935\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 226, batch train loss: 1.9268587827682495\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 227, batch train loss: 1.8383604288101196\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 228, batch train loss: 1.3717436790466309\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 229, batch train loss: 2.138828754425049\n",
      "\n",
      "\n",
      "Epoch: 56, batch_id: 230, batch train loss: 1.6626431941986084\n",
      "\n",
      "\n",
      "Epoch: 56/ 100, Loss: 2.3608859031096747\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:11<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 Validation Loss: 1.8879867951075235\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57, batch_id: 1, batch train loss: 1.7369199991226196\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 2, batch train loss: 1.6380282640457153\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 3, batch train loss: 1.6053224802017212\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 4, batch train loss: 1.466338038444519\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 5, batch train loss: 1.3918389081954956\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 6, batch train loss: 1.6114658117294312\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 7, batch train loss: 1.419887900352478\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 8, batch train loss: 1.3683191537857056\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 9, batch train loss: 1.8424334526062012\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 10, batch train loss: 1.772868275642395\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 11, batch train loss: 1.4255732297897339\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 12, batch train loss: 1.7540494203567505\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 13, batch train loss: 1.8327046632766724\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 14, batch train loss: 2.1224260330200195\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 15, batch train loss: 2.5697193145751953\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 16, batch train loss: 1.9486291408538818\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 17, batch train loss: 2.785010576248169\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 18, batch train loss: 1.994157075881958\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 19, batch train loss: 1.6853660345077515\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 20, batch train loss: 1.4211559295654297\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 21, batch train loss: 1.4230666160583496\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 22, batch train loss: 1.3282114267349243\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 23, batch train loss: 1.4510881900787354\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 24, batch train loss: 1.5578718185424805\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 25, batch train loss: 1.6061495542526245\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 26, batch train loss: 1.3609986305236816\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 27, batch train loss: 2.175835371017456\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 28, batch train loss: 1.983954906463623\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 29, batch train loss: 2.797333240509033\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 30, batch train loss: 1.4608362913131714\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 31, batch train loss: 2.1746721267700195\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 32, batch train loss: 1.8438224792480469\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 33, batch train loss: 2.7014975547790527\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 34, batch train loss: 2.7024497985839844\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 35, batch train loss: 2.33148193359375\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 36, batch train loss: 4.340773582458496\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 37, batch train loss: 2.327531337738037\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 38, batch train loss: 3.065402030944824\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 39, batch train loss: 2.38421893119812\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 40, batch train loss: 2.464137077331543\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 41, batch train loss: 2.9922099113464355\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 42, batch train loss: 2.8686254024505615\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 43, batch train loss: 2.1370151042938232\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 44, batch train loss: 2.4324233531951904\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 45, batch train loss: 1.5755640268325806\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 46, batch train loss: 1.9229304790496826\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 47, batch train loss: 4.026117324829102\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 48, batch train loss: 2.481689214706421\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 49, batch train loss: 1.980942964553833\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 50, batch train loss: 2.8929362297058105\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 51, batch train loss: 2.6257283687591553\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 52, batch train loss: 3.0110607147216797\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 53, batch train loss: 3.632188320159912\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 54, batch train loss: 1.89214289188385\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 55, batch train loss: 1.918513536453247\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 56, batch train loss: 3.4883527755737305\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 57, batch train loss: 1.5147979259490967\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 58, batch train loss: 3.7445731163024902\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 59, batch train loss: 3.6909115314483643\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 60, batch train loss: 4.068019390106201\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 61, batch train loss: 3.1407222747802734\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 62, batch train loss: 2.0723705291748047\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 63, batch train loss: 3.3825926780700684\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 64, batch train loss: 3.766373634338379\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 65, batch train loss: 2.5967230796813965\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 66, batch train loss: 4.067289352416992\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 67, batch train loss: 3.928122043609619\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 68, batch train loss: 2.307236671447754\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 69, batch train loss: 2.671483039855957\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 70, batch train loss: 3.3321313858032227\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 71, batch train loss: 2.4321115016937256\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 72, batch train loss: 2.4179768562316895\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 73, batch train loss: 2.884546995162964\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 74, batch train loss: 2.590956211090088\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 75, batch train loss: 2.4067301750183105\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 76, batch train loss: 2.447666883468628\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 77, batch train loss: 3.532905340194702\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 78, batch train loss: 2.250767707824707\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 79, batch train loss: 2.607198476791382\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 80, batch train loss: 3.0002405643463135\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 81, batch train loss: 3.15759015083313\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 82, batch train loss: 2.436570644378662\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 83, batch train loss: 3.0433051586151123\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 84, batch train loss: 2.10575795173645\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 85, batch train loss: 2.5468814373016357\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 86, batch train loss: 1.7596248388290405\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 87, batch train loss: 3.17950439453125\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 88, batch train loss: 2.090719223022461\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 89, batch train loss: 2.7374303340911865\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 90, batch train loss: 2.5727202892303467\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 91, batch train loss: 1.5716983079910278\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 92, batch train loss: 2.2776758670806885\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 93, batch train loss: 2.7117042541503906\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 94, batch train loss: 2.797872543334961\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 95, batch train loss: 2.574352741241455\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 96, batch train loss: 2.2037041187286377\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 97, batch train loss: 1.8665753602981567\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 98, batch train loss: 2.108319044113159\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 99, batch train loss: 3.0998270511627197\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 100, batch train loss: 2.68721866607666\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 101, batch train loss: 2.8093771934509277\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 102, batch train loss: 3.2260680198669434\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 103, batch train loss: 3.063002586364746\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 104, batch train loss: 3.311527729034424\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 105, batch train loss: 2.1691982746124268\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 106, batch train loss: 2.3882012367248535\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 107, batch train loss: 2.789806604385376\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 108, batch train loss: 1.9146040678024292\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 109, batch train loss: 2.1838150024414062\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 110, batch train loss: 2.039684295654297\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 111, batch train loss: 2.5803470611572266\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 112, batch train loss: 2.004427671432495\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 113, batch train loss: 1.8650012016296387\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 114, batch train loss: 2.4693150520324707\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 115, batch train loss: 3.7383577823638916\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 116, batch train loss: 4.188859939575195\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 117, batch train loss: 3.198439359664917\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 118, batch train loss: 1.738165020942688\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 119, batch train loss: 1.404096245765686\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 120, batch train loss: 1.6576766967773438\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 121, batch train loss: 2.726539134979248\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 122, batch train loss: 2.5969815254211426\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 123, batch train loss: 3.3006906509399414\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 124, batch train loss: 2.1674771308898926\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 125, batch train loss: 1.7757560014724731\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 126, batch train loss: 2.502931594848633\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 127, batch train loss: 1.5943931341171265\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 128, batch train loss: 2.3249597549438477\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 129, batch train loss: 1.764906644821167\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57, batch_id: 130, batch train loss: 2.357825517654419\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 131, batch train loss: 1.8054829835891724\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 132, batch train loss: 1.6104683876037598\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 133, batch train loss: 1.4595664739608765\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 134, batch train loss: 1.5546653270721436\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 135, batch train loss: 1.3577018976211548\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 136, batch train loss: 1.9646384716033936\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 137, batch train loss: 1.5815349817276\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 138, batch train loss: 2.185513973236084\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 139, batch train loss: 1.6687555313110352\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 140, batch train loss: 1.908691644668579\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 141, batch train loss: 2.2918248176574707\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 142, batch train loss: 1.8406970500946045\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 143, batch train loss: 1.917259931564331\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 144, batch train loss: 1.6066640615463257\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 145, batch train loss: 3.019965648651123\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 146, batch train loss: 1.9008314609527588\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 147, batch train loss: 2.7252469062805176\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 148, batch train loss: 2.319472551345825\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 149, batch train loss: 1.6735634803771973\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 150, batch train loss: 2.0522751808166504\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 151, batch train loss: 2.126284599304199\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 152, batch train loss: 1.655542254447937\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 153, batch train loss: 2.3076717853546143\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 154, batch train loss: 1.609410285949707\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 155, batch train loss: 2.7430145740509033\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 156, batch train loss: 2.941800117492676\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 157, batch train loss: 1.598677396774292\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 158, batch train loss: 2.7604660987854004\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 159, batch train loss: 2.949849843978882\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 160, batch train loss: 1.7133489847183228\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 161, batch train loss: 2.4021363258361816\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 162, batch train loss: 1.5481956005096436\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 163, batch train loss: 1.6415221691131592\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 164, batch train loss: 1.575035810470581\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 165, batch train loss: 1.7045081853866577\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 166, batch train loss: 1.8652527332305908\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 167, batch train loss: 1.7240287065505981\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 168, batch train loss: 1.8159908056259155\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 169, batch train loss: 1.4415444135665894\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 170, batch train loss: 1.6524943113327026\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 171, batch train loss: 1.9357380867004395\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 172, batch train loss: 1.9801955223083496\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 173, batch train loss: 1.6134529113769531\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 174, batch train loss: 1.4842478036880493\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 175, batch train loss: 1.9133617877960205\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 176, batch train loss: 1.641122579574585\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 177, batch train loss: 1.811860203742981\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 178, batch train loss: 2.5142476558685303\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 179, batch train loss: 2.2413578033447266\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 180, batch train loss: 2.2472212314605713\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 181, batch train loss: 1.961687445640564\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 182, batch train loss: 1.893080472946167\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 183, batch train loss: 1.5913630723953247\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 184, batch train loss: 3.329354763031006\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 185, batch train loss: 2.3436717987060547\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 186, batch train loss: 2.222553253173828\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 187, batch train loss: 2.1243560314178467\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 188, batch train loss: 1.6220955848693848\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 189, batch train loss: 2.143242597579956\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 190, batch train loss: 1.5723718404769897\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 191, batch train loss: 3.183971405029297\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 192, batch train loss: 3.187445640563965\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 193, batch train loss: 3.0306756496429443\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 194, batch train loss: 2.1222872734069824\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 195, batch train loss: 2.6123459339141846\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 196, batch train loss: 2.8310439586639404\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 197, batch train loss: 2.6759889125823975\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 198, batch train loss: 2.3493549823760986\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 199, batch train loss: 2.0493967533111572\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 200, batch train loss: 2.091573715209961\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 201, batch train loss: 1.962262749671936\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 202, batch train loss: 2.015834093093872\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 203, batch train loss: 1.7385501861572266\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 204, batch train loss: 2.4854907989501953\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 205, batch train loss: 2.266430616378784\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 206, batch train loss: 1.4689695835113525\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 207, batch train loss: 1.5470608472824097\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 208, batch train loss: 1.8919928073883057\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 209, batch train loss: 1.7165956497192383\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 210, batch train loss: 1.705949306488037\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 211, batch train loss: 1.5178020000457764\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 212, batch train loss: 1.4879878759384155\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 213, batch train loss: 1.7354247570037842\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 214, batch train loss: 1.9710304737091064\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 215, batch train loss: 1.5980168581008911\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 216, batch train loss: 2.7405734062194824\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 217, batch train loss: 2.2489893436431885\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 218, batch train loss: 1.9561580419540405\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 219, batch train loss: 1.971204400062561\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 220, batch train loss: 2.884265184402466\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 221, batch train loss: 2.2655656337738037\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 222, batch train loss: 1.9841547012329102\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 223, batch train loss: 1.9328362941741943\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 224, batch train loss: 1.962615728378296\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 225, batch train loss: 1.8235925436019897\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 226, batch train loss: 2.915553092956543\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 227, batch train loss: 2.7424561977386475\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 228, batch train loss: 2.2272610664367676\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 229, batch train loss: 2.197303295135498\n",
      "\n",
      "\n",
      "Epoch: 57, batch_id: 230, batch train loss: 1.6451842784881592\n",
      "\n",
      "\n",
      "Epoch: 57/ 100, Loss: 2.261466492777285\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:13<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 Validation Loss: 2.383188174168269\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, batch_id: 1, batch train loss: 3.6716268062591553\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 2, batch train loss: 2.033177375793457\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 3, batch train loss: 2.419473886489868\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 4, batch train loss: 2.055755376815796\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 5, batch train loss: 1.9869508743286133\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 6, batch train loss: 2.1004810333251953\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 7, batch train loss: 1.8118165731430054\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 8, batch train loss: 1.8572251796722412\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 9, batch train loss: 3.9610912799835205\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 10, batch train loss: 5.5475687980651855\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 11, batch train loss: 3.3019778728485107\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 12, batch train loss: 3.970594882965088\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 13, batch train loss: 4.75016450881958\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 14, batch train loss: 3.2474236488342285\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 15, batch train loss: 3.115715742111206\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 16, batch train loss: 4.0908989906311035\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 17, batch train loss: 3.1098554134368896\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 18, batch train loss: 2.5014216899871826\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 19, batch train loss: 4.214280605316162\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 20, batch train loss: 5.131523132324219\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 21, batch train loss: 5.229661464691162\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 22, batch train loss: 3.7710676193237305\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 23, batch train loss: 7.0231804847717285\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 24, batch train loss: 7.885721206665039\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 25, batch train loss: 6.856685161590576\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 26, batch train loss: 4.62094259262085\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 27, batch train loss: 2.7571728229522705\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 28, batch train loss: 5.632647514343262\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 29, batch train loss: 6.437549591064453\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 30, batch train loss: 4.3878021240234375\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 31, batch train loss: 2.4928882122039795\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 32, batch train loss: 5.919824600219727\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 33, batch train loss: 6.747116565704346\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 34, batch train loss: 3.7806050777435303\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 35, batch train loss: 2.1250219345092773\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 36, batch train loss: 5.744109630584717\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 37, batch train loss: 2.8355538845062256\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 38, batch train loss: 3.208815097808838\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 39, batch train loss: 3.0472943782806396\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 40, batch train loss: 3.5528361797332764\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 41, batch train loss: 3.195396661758423\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 42, batch train loss: 3.0542664527893066\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 43, batch train loss: 2.312852144241333\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 44, batch train loss: 4.545904159545898\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 45, batch train loss: 2.0948338508605957\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 46, batch train loss: 1.720542550086975\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 47, batch train loss: 4.353505611419678\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 48, batch train loss: 1.895816683769226\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 49, batch train loss: 2.5340592861175537\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 50, batch train loss: 3.7376904487609863\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 51, batch train loss: 4.85720682144165\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 52, batch train loss: 3.2898576259613037\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 53, batch train loss: 2.828831434249878\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 54, batch train loss: 5.691682815551758\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 55, batch train loss: 3.721782922744751\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 56, batch train loss: 3.230966091156006\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 57, batch train loss: 2.796653985977173\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 58, batch train loss: 3.417367458343506\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 59, batch train loss: 1.7660669088363647\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 60, batch train loss: 2.0454771518707275\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 61, batch train loss: 2.990705966949463\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 62, batch train loss: 2.3485941886901855\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 63, batch train loss: 3.1906232833862305\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 64, batch train loss: 1.8172999620437622\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 65, batch train loss: 2.1248600482940674\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 66, batch train loss: 2.0802063941955566\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 67, batch train loss: 2.1994988918304443\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 68, batch train loss: 3.159179210662842\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 69, batch train loss: 6.071461200714111\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 70, batch train loss: 2.2082369327545166\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 71, batch train loss: 2.720982074737549\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 72, batch train loss: 2.292393922805786\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 73, batch train loss: 1.63385808467865\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 74, batch train loss: 3.3542847633361816\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 75, batch train loss: 1.8471248149871826\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 76, batch train loss: 2.24889874458313\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 77, batch train loss: 2.138949394226074\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 78, batch train loss: 1.8451920747756958\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 79, batch train loss: 1.8391613960266113\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 80, batch train loss: 2.1250078678131104\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 81, batch train loss: 1.8419045209884644\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 82, batch train loss: 2.029219388961792\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 83, batch train loss: 1.9215303659439087\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 84, batch train loss: 3.484365224838257\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 85, batch train loss: 2.1095240116119385\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 86, batch train loss: 2.0281076431274414\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 87, batch train loss: 2.1313540935516357\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 88, batch train loss: 2.3605661392211914\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 89, batch train loss: 2.763150453567505\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 90, batch train loss: 2.1962714195251465\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 91, batch train loss: 1.9533178806304932\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 92, batch train loss: 2.011253595352173\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 93, batch train loss: 1.694428563117981\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 94, batch train loss: 1.9943546056747437\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 95, batch train loss: 1.857503890991211\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 96, batch train loss: 1.6591249704360962\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 97, batch train loss: 1.7367196083068848\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 98, batch train loss: 1.7044732570648193\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 99, batch train loss: 1.6770482063293457\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 100, batch train loss: 1.9373152256011963\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 101, batch train loss: 1.9675744771957397\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 102, batch train loss: 1.763662338256836\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 103, batch train loss: 1.7909448146820068\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 104, batch train loss: 2.0768203735351562\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 105, batch train loss: 1.7079805135726929\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 106, batch train loss: 1.6122931241989136\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 107, batch train loss: 1.4896410703659058\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 108, batch train loss: 1.4864588975906372\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 109, batch train loss: 1.798821210861206\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 110, batch train loss: 1.7635327577590942\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 111, batch train loss: 2.1794211864471436\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 112, batch train loss: 1.7006524801254272\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 113, batch train loss: 1.8809924125671387\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 114, batch train loss: 1.4183093309402466\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 115, batch train loss: 1.3993066549301147\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 116, batch train loss: 1.2059398889541626\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 117, batch train loss: 2.0905916690826416\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 118, batch train loss: 1.5531460046768188\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 119, batch train loss: 1.5916224718093872\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 120, batch train loss: 1.5610594749450684\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 121, batch train loss: 1.9160021543502808\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 122, batch train loss: 1.6041200160980225\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 123, batch train loss: 1.63777756690979\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 124, batch train loss: 1.6915829181671143\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 125, batch train loss: 1.842285394668579\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 126, batch train loss: 1.4359673261642456\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 127, batch train loss: 2.1967599391937256\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 128, batch train loss: 1.6821353435516357\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 129, batch train loss: 1.7057924270629883\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58, batch_id: 130, batch train loss: 1.565895438194275\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 131, batch train loss: 1.8635780811309814\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 132, batch train loss: 1.9184759855270386\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 133, batch train loss: 2.4441964626312256\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 134, batch train loss: 2.1875362396240234\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 135, batch train loss: 1.7018619775772095\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 136, batch train loss: 2.015822649002075\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 137, batch train loss: 1.8435178995132446\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 138, batch train loss: 1.915781021118164\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 139, batch train loss: 1.3828558921813965\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 140, batch train loss: 1.8747094869613647\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 141, batch train loss: 1.8354909420013428\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 142, batch train loss: 2.0076842308044434\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 143, batch train loss: 1.8657615184783936\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 144, batch train loss: 1.6686882972717285\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 145, batch train loss: 1.7763936519622803\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 146, batch train loss: 1.7430416345596313\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 147, batch train loss: 1.8717164993286133\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 148, batch train loss: 2.061724901199341\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 149, batch train loss: 1.7254753112792969\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 150, batch train loss: 1.895476222038269\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 151, batch train loss: 1.9493987560272217\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 152, batch train loss: 1.5691391229629517\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 153, batch train loss: 1.5603091716766357\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 154, batch train loss: 1.5714911222457886\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 155, batch train loss: 1.937109112739563\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 156, batch train loss: 2.0626304149627686\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 157, batch train loss: 1.779520034790039\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 158, batch train loss: 1.4630094766616821\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 159, batch train loss: 1.7184486389160156\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 160, batch train loss: 1.6684871912002563\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 161, batch train loss: 2.594519853591919\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 162, batch train loss: 2.3016979694366455\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 163, batch train loss: 2.7993295192718506\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 164, batch train loss: 3.0203239917755127\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 165, batch train loss: 1.9409584999084473\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 166, batch train loss: 2.5007143020629883\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 167, batch train loss: 3.018017530441284\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 168, batch train loss: 1.8895914554595947\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 169, batch train loss: 2.4962317943573\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 170, batch train loss: 3.26690673828125\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 171, batch train loss: 1.8792200088500977\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 172, batch train loss: 3.5361735820770264\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 173, batch train loss: 3.2631125450134277\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 174, batch train loss: 2.0187454223632812\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 175, batch train loss: 2.5102450847625732\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 176, batch train loss: 2.545510768890381\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 177, batch train loss: 2.224820375442505\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 178, batch train loss: 2.019240617752075\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 179, batch train loss: 2.1679069995880127\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 180, batch train loss: 2.1677663326263428\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 181, batch train loss: 1.8236171007156372\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 182, batch train loss: 1.4336344003677368\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 183, batch train loss: 1.6095235347747803\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 184, batch train loss: 1.8453351259231567\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 185, batch train loss: 1.4022098779678345\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 186, batch train loss: 1.8428874015808105\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 187, batch train loss: 1.9934979677200317\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 188, batch train loss: 1.9647685289382935\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 189, batch train loss: 2.0058655738830566\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 190, batch train loss: 2.018082857131958\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 191, batch train loss: 2.2281835079193115\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 192, batch train loss: 1.8340551853179932\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 193, batch train loss: 2.493263006210327\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 194, batch train loss: 1.6631290912628174\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 195, batch train loss: 2.0201618671417236\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 196, batch train loss: 1.5537559986114502\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 197, batch train loss: 1.7585701942443848\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 198, batch train loss: 1.8321101665496826\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 199, batch train loss: 1.509867787361145\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 200, batch train loss: 1.8252698183059692\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 201, batch train loss: 1.34940505027771\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 202, batch train loss: 1.5739307403564453\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 203, batch train loss: 1.6507885456085205\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 204, batch train loss: 1.5922033786773682\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 205, batch train loss: 1.419271469116211\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 206, batch train loss: 1.7380458116531372\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 207, batch train loss: 1.4956947565078735\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 208, batch train loss: 1.7174463272094727\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 209, batch train loss: 1.556103229522705\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 210, batch train loss: 1.9558571577072144\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 211, batch train loss: 1.239020586013794\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 212, batch train loss: 1.6261987686157227\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 213, batch train loss: 1.3397185802459717\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 214, batch train loss: 1.2336783409118652\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 215, batch train loss: 1.5976672172546387\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 216, batch train loss: 1.463150978088379\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 217, batch train loss: 1.4944629669189453\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 218, batch train loss: 1.4325610399246216\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 219, batch train loss: 1.591336965560913\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 220, batch train loss: 1.636407732963562\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 221, batch train loss: 1.3920179605484009\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 222, batch train loss: 1.5242341756820679\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 223, batch train loss: 1.2447429895401\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 224, batch train loss: 1.5041224956512451\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 225, batch train loss: 1.1145352125167847\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 226, batch train loss: 1.4991743564605713\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 227, batch train loss: 1.2249058485031128\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 228, batch train loss: 1.456965446472168\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 229, batch train loss: 1.3808014392852783\n",
      "\n",
      "\n",
      "Epoch: 58, batch_id: 230, batch train loss: 1.452359914779663\n",
      "\n",
      "\n",
      "Epoch: 58/ 100, Loss: 2.3950712463130124\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58 Validation Loss: 1.3341763238112132\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 59, batch_id: 1, batch train loss: 1.2665331363677979\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 2, batch train loss: 1.3129280805587769\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 3, batch train loss: 1.2676528692245483\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 4, batch train loss: 1.3417528867721558\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 5, batch train loss: 1.541455864906311\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 6, batch train loss: 1.4754551649093628\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 7, batch train loss: 1.2213975191116333\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 8, batch train loss: 1.4584169387817383\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 9, batch train loss: 1.4196339845657349\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 10, batch train loss: 1.2000837326049805\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 11, batch train loss: 2.2861154079437256\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 12, batch train loss: 1.755218505859375\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 13, batch train loss: 1.7609080076217651\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 14, batch train loss: 1.6019854545593262\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 15, batch train loss: 1.820824146270752\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 16, batch train loss: 2.477790117263794\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 17, batch train loss: 2.370668649673462\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 18, batch train loss: 1.9416264295578003\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 19, batch train loss: 2.3488268852233887\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 20, batch train loss: 1.935651421546936\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 21, batch train loss: 2.545602321624756\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 22, batch train loss: 4.1415791511535645\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 23, batch train loss: 3.0901708602905273\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 24, batch train loss: 2.5291922092437744\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 25, batch train loss: 1.8129396438598633\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 26, batch train loss: 1.8666778802871704\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 27, batch train loss: 1.768497109413147\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 28, batch train loss: 2.480746030807495\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 29, batch train loss: 2.5269134044647217\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 30, batch train loss: 2.1359751224517822\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 31, batch train loss: 1.6954072713851929\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 32, batch train loss: 1.2166446447372437\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 33, batch train loss: 1.7635011672973633\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 34, batch train loss: 2.8954508304595947\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 35, batch train loss: 2.968036651611328\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 36, batch train loss: 3.7049031257629395\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 37, batch train loss: 2.6449718475341797\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 38, batch train loss: 3.1023402214050293\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 39, batch train loss: 2.565136671066284\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 40, batch train loss: 3.9924726486206055\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 41, batch train loss: 2.050358533859253\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 42, batch train loss: 1.8520513772964478\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 43, batch train loss: 1.6863008737564087\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 44, batch train loss: 1.7242399454116821\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 45, batch train loss: 2.3022351264953613\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 46, batch train loss: 1.801839828491211\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 47, batch train loss: 1.7608084678649902\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 48, batch train loss: 1.5076773166656494\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 49, batch train loss: 1.8422237634658813\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 50, batch train loss: 2.2855451107025146\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 51, batch train loss: 1.8208760023117065\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 52, batch train loss: 1.918226957321167\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 53, batch train loss: 3.131554365158081\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 54, batch train loss: 2.5304925441741943\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 55, batch train loss: 2.6533334255218506\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 56, batch train loss: 1.6589703559875488\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 57, batch train loss: 1.6531939506530762\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 58, batch train loss: 2.0609333515167236\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 59, batch train loss: 2.156344413757324\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 60, batch train loss: 1.6224437952041626\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 61, batch train loss: 1.40328848361969\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 62, batch train loss: 1.5339984893798828\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 63, batch train loss: 1.570001244544983\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 64, batch train loss: 1.5732026100158691\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 65, batch train loss: 1.2716705799102783\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 66, batch train loss: 1.388243317604065\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 67, batch train loss: 1.3708534240722656\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 68, batch train loss: 1.7967039346694946\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 69, batch train loss: 2.303891897201538\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 70, batch train loss: 1.676007866859436\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 71, batch train loss: 1.5992263555526733\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 72, batch train loss: 1.4880763292312622\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 73, batch train loss: 1.6137560606002808\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 74, batch train loss: 1.4530011415481567\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 75, batch train loss: 1.357757568359375\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 76, batch train loss: 2.0063233375549316\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 77, batch train loss: 1.3635493516921997\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 78, batch train loss: 1.559078574180603\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 79, batch train loss: 1.5102945566177368\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 80, batch train loss: 1.2016539573669434\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 81, batch train loss: 1.3478260040283203\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 82, batch train loss: 2.500201940536499\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 83, batch train loss: 1.5073795318603516\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 84, batch train loss: 1.5736496448516846\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 85, batch train loss: 3.2268004417419434\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 86, batch train loss: 1.7556754350662231\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 87, batch train loss: 2.125741481781006\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 88, batch train loss: 1.6007256507873535\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 89, batch train loss: 2.063462495803833\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 90, batch train loss: 1.833825707435608\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 91, batch train loss: 2.2099759578704834\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 92, batch train loss: 2.1502275466918945\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 93, batch train loss: 1.564760684967041\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 94, batch train loss: 2.0784785747528076\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 95, batch train loss: 1.58050537109375\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 96, batch train loss: 1.8389207124710083\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 97, batch train loss: 1.6607437133789062\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 98, batch train loss: 2.32187819480896\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 99, batch train loss: 1.65522038936615\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 100, batch train loss: 2.0345590114593506\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 101, batch train loss: 1.465149164199829\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 102, batch train loss: 1.6394660472869873\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 103, batch train loss: 1.745008111000061\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 104, batch train loss: 1.7813622951507568\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 105, batch train loss: 1.8589560985565186\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 106, batch train loss: 1.4018968343734741\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 107, batch train loss: 1.0930753946304321\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 108, batch train loss: 2.6471633911132812\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 109, batch train loss: 2.663896083831787\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 110, batch train loss: 2.0678539276123047\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 111, batch train loss: 1.4644488096237183\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 112, batch train loss: 2.0711631774902344\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 113, batch train loss: 2.4139983654022217\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 114, batch train loss: 2.999088764190674\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 115, batch train loss: 1.9919726848602295\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 116, batch train loss: 2.545661687850952\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 117, batch train loss: 2.3704235553741455\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 118, batch train loss: 1.844756841659546\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 119, batch train loss: 1.2783045768737793\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 120, batch train loss: 2.8129000663757324\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 121, batch train loss: 2.344087839126587\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 122, batch train loss: 3.0568466186523438\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 123, batch train loss: 2.617915153503418\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 124, batch train loss: 1.7779974937438965\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 125, batch train loss: 2.020429849624634\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 126, batch train loss: 1.7856101989746094\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 127, batch train loss: 1.6266968250274658\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59, batch_id: 128, batch train loss: 1.8859604597091675\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 129, batch train loss: 1.9427087306976318\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 130, batch train loss: 1.9444427490234375\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 131, batch train loss: 2.0534729957580566\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 132, batch train loss: 2.155251979827881\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 133, batch train loss: 2.092562198638916\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 134, batch train loss: 1.6433104276657104\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 135, batch train loss: 1.9470080137252808\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 136, batch train loss: 1.606020450592041\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 137, batch train loss: 1.4970941543579102\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 138, batch train loss: 1.5406347513198853\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 139, batch train loss: 1.5212907791137695\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 140, batch train loss: 1.8783442974090576\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 141, batch train loss: 1.5524946451187134\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 142, batch train loss: 1.5113071203231812\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 143, batch train loss: 1.4461860656738281\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 144, batch train loss: 1.510401725769043\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 145, batch train loss: 1.3425997495651245\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 146, batch train loss: 1.3680521249771118\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 147, batch train loss: 1.1102896928787231\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 148, batch train loss: 1.4452338218688965\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 149, batch train loss: 1.3193520307540894\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 150, batch train loss: 1.4695667028427124\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 151, batch train loss: 1.788072943687439\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 152, batch train loss: 1.3181802034378052\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 153, batch train loss: 1.3534464836120605\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 154, batch train loss: 1.1797140836715698\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 155, batch train loss: 1.243754267692566\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 156, batch train loss: 1.1993834972381592\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 157, batch train loss: 1.5676662921905518\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 158, batch train loss: 1.299122929573059\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 159, batch train loss: 1.3273613452911377\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 160, batch train loss: 1.2332582473754883\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 161, batch train loss: 1.4862669706344604\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 162, batch train loss: 1.602062702178955\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 163, batch train loss: 2.1796395778656006\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 164, batch train loss: 1.8429726362228394\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 165, batch train loss: 1.2631995677947998\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 166, batch train loss: 1.8429772853851318\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 167, batch train loss: 1.6490964889526367\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 168, batch train loss: 2.5783064365386963\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 169, batch train loss: 2.1875431537628174\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 170, batch train loss: 1.7097294330596924\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 171, batch train loss: 2.013698101043701\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 172, batch train loss: 2.231544256210327\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 173, batch train loss: 2.376178741455078\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 174, batch train loss: 3.3826258182525635\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 175, batch train loss: 2.776266574859619\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 176, batch train loss: 2.414884328842163\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 177, batch train loss: 3.720247507095337\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 178, batch train loss: 2.14915132522583\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 179, batch train loss: 1.7887449264526367\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 180, batch train loss: 1.999820590019226\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 181, batch train loss: 1.9345996379852295\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 182, batch train loss: 1.582451343536377\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 183, batch train loss: 1.9566826820373535\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 184, batch train loss: 2.0252323150634766\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 185, batch train loss: 1.8888555765151978\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 186, batch train loss: 1.9797481298446655\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 187, batch train loss: 2.5868184566497803\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 188, batch train loss: 1.913465142250061\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 189, batch train loss: 1.8327778577804565\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 190, batch train loss: 1.5551645755767822\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 191, batch train loss: 1.7249585390090942\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 192, batch train loss: 2.592055559158325\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 193, batch train loss: 2.5430078506469727\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 194, batch train loss: 2.196824550628662\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 195, batch train loss: 2.0198781490325928\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 196, batch train loss: 2.238936424255371\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 197, batch train loss: 1.809230923652649\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 198, batch train loss: 2.659332275390625\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 199, batch train loss: 1.7543487548828125\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 200, batch train loss: 1.6318039894104004\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 201, batch train loss: 1.8221303224563599\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 202, batch train loss: 1.5019264221191406\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 203, batch train loss: 1.8477425575256348\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 204, batch train loss: 1.992796778678894\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 205, batch train loss: 2.654890537261963\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 206, batch train loss: 1.6740025281906128\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 207, batch train loss: 1.818963646888733\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 208, batch train loss: 2.077662229537964\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 209, batch train loss: 2.1101317405700684\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 210, batch train loss: 2.568061113357544\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 211, batch train loss: 2.7555928230285645\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 212, batch train loss: 1.8770360946655273\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 213, batch train loss: 2.4457027912139893\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 214, batch train loss: 2.597357988357544\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 215, batch train loss: 1.9583158493041992\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 216, batch train loss: 3.115574359893799\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 217, batch train loss: 3.121457099914551\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 218, batch train loss: 2.24855899810791\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 219, batch train loss: 3.05928111076355\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 220, batch train loss: 2.5456321239471436\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 221, batch train loss: 2.1546976566314697\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 222, batch train loss: 2.825906276702881\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 223, batch train loss: 2.293180227279663\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 224, batch train loss: 2.5496010780334473\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 225, batch train loss: 2.888814687728882\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 226, batch train loss: 2.2205419540405273\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 227, batch train loss: 3.087238311767578\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 228, batch train loss: 2.4496383666992188\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 229, batch train loss: 2.0591256618499756\n",
      "\n",
      "\n",
      "Epoch: 59, batch_id: 230, batch train loss: 2.027878522872925\n",
      "\n",
      "\n",
      "Epoch: 59/ 100, Loss: 1.9808396344599517\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:24<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 Validation Loss: 2.23324103752772\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, batch_id: 1, batch train loss: 2.2064619064331055\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 2, batch train loss: 1.5535619258880615\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 3, batch train loss: 2.327080726623535\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 4, batch train loss: 2.00966477394104\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 5, batch train loss: 1.9320684671401978\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 6, batch train loss: 1.505151629447937\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 7, batch train loss: 1.6110951900482178\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 8, batch train loss: 1.6713095903396606\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 9, batch train loss: 1.559171438217163\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 10, batch train loss: 1.8074939250946045\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 11, batch train loss: 1.8363428115844727\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 12, batch train loss: 3.049725294113159\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 13, batch train loss: 2.068207263946533\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 14, batch train loss: 2.3450067043304443\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 15, batch train loss: 2.1816139221191406\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 16, batch train loss: 1.931861400604248\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 17, batch train loss: 2.382213830947876\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 18, batch train loss: 2.676872730255127\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 19, batch train loss: 1.559902310371399\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 20, batch train loss: 3.4852733612060547\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 21, batch train loss: 2.977004051208496\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 22, batch train loss: 2.2388975620269775\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 23, batch train loss: 1.9984973669052124\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 24, batch train loss: 1.7541385889053345\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 25, batch train loss: 1.9180188179016113\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 26, batch train loss: 1.7983968257904053\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 27, batch train loss: 1.9076091051101685\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 28, batch train loss: 2.6905343532562256\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 29, batch train loss: 1.9630435705184937\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 30, batch train loss: 1.8810056447982788\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 31, batch train loss: 1.1939135789871216\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 32, batch train loss: 1.9335538148880005\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 33, batch train loss: 1.5493121147155762\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 34, batch train loss: 2.84014892578125\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 35, batch train loss: 2.061586618423462\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 36, batch train loss: 1.875210165977478\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 37, batch train loss: 2.116316318511963\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 38, batch train loss: 1.8654125928878784\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 39, batch train loss: 1.921183705329895\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 40, batch train loss: 2.503365993499756\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 41, batch train loss: 2.1289896965026855\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 42, batch train loss: 1.764919400215149\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 43, batch train loss: 1.800065517425537\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 44, batch train loss: 1.3689554929733276\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 45, batch train loss: 1.7517253160476685\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 46, batch train loss: 2.0135254859924316\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 47, batch train loss: 1.854549527168274\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 48, batch train loss: 1.665532112121582\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 49, batch train loss: 2.1719167232513428\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 50, batch train loss: 1.5483309030532837\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 51, batch train loss: 2.067586660385132\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 52, batch train loss: 1.525773286819458\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 53, batch train loss: 2.8240809440612793\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 54, batch train loss: 1.7964868545532227\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 55, batch train loss: 2.043313503265381\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 56, batch train loss: 1.875678300857544\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 57, batch train loss: 2.0885772705078125\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 58, batch train loss: 2.602370500564575\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 59, batch train loss: 2.6718411445617676\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 60, batch train loss: 1.4114967584609985\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 61, batch train loss: 1.8070751428604126\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 62, batch train loss: 2.8965625762939453\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 63, batch train loss: 2.4053738117218018\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 64, batch train loss: 2.252373456954956\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 65, batch train loss: 2.280616283416748\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 66, batch train loss: 1.7509456872940063\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 67, batch train loss: 2.718311309814453\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 68, batch train loss: 1.9112353324890137\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 69, batch train loss: 2.002162218093872\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 70, batch train loss: 1.9460477828979492\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 71, batch train loss: 1.6108036041259766\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 72, batch train loss: 1.2776681184768677\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 73, batch train loss: 1.6121573448181152\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 74, batch train loss: 1.6325000524520874\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 75, batch train loss: 2.8135714530944824\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 76, batch train loss: 1.7003017663955688\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 77, batch train loss: 1.9811991453170776\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 78, batch train loss: 1.5490139722824097\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 79, batch train loss: 2.3593196868896484\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 80, batch train loss: 2.3184149265289307\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 81, batch train loss: 2.1878175735473633\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 82, batch train loss: 1.5947532653808594\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 83, batch train loss: 1.447679877281189\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 84, batch train loss: 1.690304160118103\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 85, batch train loss: 1.7752363681793213\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 86, batch train loss: 1.8477685451507568\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 87, batch train loss: 1.7294400930404663\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 88, batch train loss: 1.3226174116134644\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 89, batch train loss: 1.4468786716461182\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 90, batch train loss: 2.0323047637939453\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 91, batch train loss: 1.7959208488464355\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 92, batch train loss: 2.134641408920288\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 93, batch train loss: 1.8887211084365845\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 94, batch train loss: 2.6535866260528564\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 95, batch train loss: 2.1272568702697754\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 96, batch train loss: 2.4641449451446533\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 97, batch train loss: 2.6520488262176514\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 98, batch train loss: 2.326359272003174\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 99, batch train loss: 2.232628107070923\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 100, batch train loss: 2.4639952182769775\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 101, batch train loss: 1.6792640686035156\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 102, batch train loss: 1.0823029279708862\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 103, batch train loss: 2.546208381652832\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 104, batch train loss: 1.9387972354888916\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 105, batch train loss: 2.0953681468963623\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 106, batch train loss: 1.323764681816101\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 107, batch train loss: 1.3965641260147095\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 108, batch train loss: 1.8100907802581787\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 109, batch train loss: 1.3380438089370728\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 110, batch train loss: 1.9658966064453125\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 111, batch train loss: 1.4768496751785278\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 112, batch train loss: 1.4756568670272827\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 113, batch train loss: 2.0034353733062744\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 114, batch train loss: 2.1565184593200684\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 115, batch train loss: 1.8179540634155273\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 116, batch train loss: 1.9447499513626099\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 117, batch train loss: 1.9993587732315063\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 118, batch train loss: 1.6254220008850098\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 119, batch train loss: 1.5008313655853271\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 120, batch train loss: 1.4168157577514648\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 121, batch train loss: 1.6765514612197876\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 122, batch train loss: 1.3422943353652954\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 123, batch train loss: 1.6613142490386963\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 124, batch train loss: 1.459051251411438\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 125, batch train loss: 1.6563092470169067\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 126, batch train loss: 1.3675695657730103\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 127, batch train loss: 1.6416164636611938\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 128, batch train loss: 1.7776659727096558\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 129, batch train loss: 1.5820726156234741\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, batch_id: 130, batch train loss: 1.470090389251709\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 131, batch train loss: 1.2634142637252808\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 132, batch train loss: 1.7307881116867065\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 133, batch train loss: 1.6704506874084473\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 134, batch train loss: 1.5643105506896973\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 135, batch train loss: 1.731119990348816\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 136, batch train loss: 2.203611135482788\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 137, batch train loss: 1.6583969593048096\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 138, batch train loss: 2.6263203620910645\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 139, batch train loss: 1.828887939453125\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 140, batch train loss: 2.4142796993255615\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 141, batch train loss: 2.501168727874756\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 142, batch train loss: 1.7000681161880493\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 143, batch train loss: 2.331908941268921\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 144, batch train loss: 2.010927438735962\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 145, batch train loss: 2.2836050987243652\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 146, batch train loss: 2.1892569065093994\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 147, batch train loss: 4.039606094360352\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 148, batch train loss: 2.0442988872528076\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 149, batch train loss: 2.039142370223999\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 150, batch train loss: 2.015920400619507\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 151, batch train loss: 2.3601880073547363\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 152, batch train loss: 2.59653639793396\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 153, batch train loss: 2.3049323558807373\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 154, batch train loss: 2.007344961166382\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 155, batch train loss: 1.8247225284576416\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 156, batch train loss: 2.5118939876556396\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 157, batch train loss: 1.8298232555389404\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 158, batch train loss: 3.0063066482543945\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 159, batch train loss: 2.0774085521698\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 160, batch train loss: 1.9230456352233887\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 161, batch train loss: 2.5908384323120117\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 162, batch train loss: 1.8774662017822266\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 163, batch train loss: 2.3436920642852783\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 164, batch train loss: 1.5713635683059692\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 165, batch train loss: 1.5164074897766113\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 166, batch train loss: 1.657410979270935\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 167, batch train loss: 1.7108687162399292\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 168, batch train loss: 1.976582407951355\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 169, batch train loss: 1.7347627878189087\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 170, batch train loss: 1.690363883972168\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 171, batch train loss: 2.1074318885803223\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 172, batch train loss: 1.6297143697738647\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 173, batch train loss: 1.7755279541015625\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 174, batch train loss: 1.5716221332550049\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 175, batch train loss: 1.8474714756011963\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 176, batch train loss: 1.8799562454223633\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 177, batch train loss: 1.633278250694275\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 178, batch train loss: 1.8493914604187012\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 179, batch train loss: 1.7734417915344238\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 180, batch train loss: 1.661592960357666\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 181, batch train loss: 1.7552604675292969\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 182, batch train loss: 1.5454704761505127\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 183, batch train loss: 1.8630428314208984\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 184, batch train loss: 1.7176352739334106\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 185, batch train loss: 2.2666707038879395\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 186, batch train loss: 1.6826152801513672\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 187, batch train loss: 1.8721442222595215\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 188, batch train loss: 1.5616796016693115\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 189, batch train loss: 1.6628714799880981\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 190, batch train loss: 1.7736660242080688\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 191, batch train loss: 1.5224679708480835\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 192, batch train loss: 1.8999743461608887\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 193, batch train loss: 1.9347741603851318\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 194, batch train loss: 2.2505016326904297\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 195, batch train loss: 1.5911717414855957\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 196, batch train loss: 1.9186291694641113\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 197, batch train loss: 2.2631638050079346\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 198, batch train loss: 1.569158911705017\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 199, batch train loss: 1.4640295505523682\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 200, batch train loss: 2.0987236499786377\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 201, batch train loss: 1.2095328569412231\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 202, batch train loss: 1.365789532661438\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 203, batch train loss: 1.7481539249420166\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 204, batch train loss: 1.4874577522277832\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 205, batch train loss: 1.5837801694869995\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 206, batch train loss: 1.3838298320770264\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 207, batch train loss: 1.0249443054199219\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 208, batch train loss: 1.439355731010437\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 209, batch train loss: 1.8098502159118652\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 210, batch train loss: 1.3074344396591187\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 211, batch train loss: 1.4387648105621338\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 212, batch train loss: 1.8624259233474731\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 213, batch train loss: 1.147686243057251\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 214, batch train loss: 2.0782394409179688\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 215, batch train loss: 1.4818699359893799\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 216, batch train loss: 1.4528124332427979\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 217, batch train loss: 2.208928108215332\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 218, batch train loss: 1.8552536964416504\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 219, batch train loss: 1.6722017526626587\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 220, batch train loss: 1.8806040287017822\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 221, batch train loss: 2.823448657989502\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 222, batch train loss: 1.9227228164672852\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 223, batch train loss: 1.3862167596817017\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 224, batch train loss: 2.0271599292755127\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 225, batch train loss: 2.031841993331909\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 226, batch train loss: 2.3224217891693115\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 227, batch train loss: 1.4493803977966309\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 228, batch train loss: 1.5917763710021973\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 229, batch train loss: 1.4003087282180786\n",
      "\n",
      "\n",
      "Epoch: 60, batch_id: 230, batch train loss: 1.3854185342788696\n",
      "\n",
      "\n",
      "Epoch: 60/ 100, Loss: 1.9096228827600894\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:31<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60 Validation Loss: 1.2630064090092976\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Model Saved\n",
      "Epoch: 61, batch_id: 1, batch train loss: 1.2234848737716675\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 2, batch train loss: 1.130257248878479\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 3, batch train loss: 1.1979382038116455\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 4, batch train loss: 1.4058046340942383\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 5, batch train loss: 1.4588710069656372\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 6, batch train loss: 1.4919503927230835\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 7, batch train loss: 1.1978799104690552\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 8, batch train loss: 1.762511968612671\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 9, batch train loss: 1.3776594400405884\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 10, batch train loss: 1.211437702178955\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 11, batch train loss: 1.1860417127609253\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 12, batch train loss: 1.3305851221084595\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 13, batch train loss: 1.993449330329895\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 14, batch train loss: 1.5326932668685913\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 15, batch train loss: 1.5259690284729004\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 16, batch train loss: 1.4039400815963745\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 17, batch train loss: 2.0408942699432373\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 18, batch train loss: 1.596895456314087\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 19, batch train loss: 1.6764198541641235\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 20, batch train loss: 2.2471466064453125\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 21, batch train loss: 3.5553572177886963\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 22, batch train loss: 2.2000203132629395\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 23, batch train loss: 3.1716601848602295\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 24, batch train loss: 2.2947893142700195\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 25, batch train loss: 2.0795607566833496\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 26, batch train loss: 2.5497019290924072\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 27, batch train loss: 1.9796631336212158\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 28, batch train loss: 2.115196943283081\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 29, batch train loss: 2.9542171955108643\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 30, batch train loss: 2.4350926876068115\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 31, batch train loss: 1.4741138219833374\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 32, batch train loss: 2.3788416385650635\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 33, batch train loss: 1.837331771850586\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 34, batch train loss: 2.417250394821167\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 35, batch train loss: 3.795144557952881\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 36, batch train loss: 2.7836384773254395\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 37, batch train loss: 4.972618579864502\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 38, batch train loss: 5.155817031860352\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 39, batch train loss: 3.0182716846466064\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 40, batch train loss: 2.827357292175293\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 41, batch train loss: 1.842775821685791\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 42, batch train loss: 3.4450619220733643\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 43, batch train loss: 3.171257257461548\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 44, batch train loss: 4.0267157554626465\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 45, batch train loss: 2.8230345249176025\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 46, batch train loss: 2.372051477432251\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 47, batch train loss: 1.6227730512619019\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 48, batch train loss: 1.8538662195205688\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 49, batch train loss: 2.3274905681610107\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 50, batch train loss: 2.4080774784088135\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 51, batch train loss: 2.6284286975860596\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 52, batch train loss: 3.7109391689300537\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 53, batch train loss: 1.6741267442703247\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 54, batch train loss: 2.171100616455078\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 55, batch train loss: 2.728381872177124\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 56, batch train loss: 2.111672878265381\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 57, batch train loss: 2.2896106243133545\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 58, batch train loss: 2.919771194458008\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 59, batch train loss: 1.7943195104599\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 60, batch train loss: 2.3495705127716064\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 61, batch train loss: 3.1012611389160156\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 62, batch train loss: 2.3880529403686523\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 63, batch train loss: 2.200960397720337\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 64, batch train loss: 1.9004185199737549\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 65, batch train loss: 2.28975772857666\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 66, batch train loss: 2.1148688793182373\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 67, batch train loss: 1.8066970109939575\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 68, batch train loss: 1.643652319908142\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 69, batch train loss: 1.6098965406417847\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 70, batch train loss: 1.6528127193450928\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 71, batch train loss: 1.5075935125350952\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 72, batch train loss: 1.7808640003204346\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 73, batch train loss: 1.2307342290878296\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 74, batch train loss: 1.3061749935150146\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 75, batch train loss: 1.448191523551941\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 76, batch train loss: 1.8282350301742554\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 77, batch train loss: 1.4766968488693237\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 78, batch train loss: 1.2823984622955322\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 79, batch train loss: 1.3238085508346558\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 80, batch train loss: 1.3573709726333618\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 81, batch train loss: 1.2709887027740479\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 82, batch train loss: 1.2686004638671875\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 83, batch train loss: 1.6357076168060303\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 84, batch train loss: 1.4569531679153442\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 85, batch train loss: 1.5191951990127563\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 86, batch train loss: 1.4529579877853394\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 87, batch train loss: 1.9136625528335571\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 88, batch train loss: 1.7345092296600342\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 89, batch train loss: 1.9088163375854492\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 90, batch train loss: 1.7739312648773193\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 91, batch train loss: 1.547500729560852\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 92, batch train loss: 1.2378919124603271\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 93, batch train loss: 1.2070775032043457\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 94, batch train loss: 1.431397795677185\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 95, batch train loss: 1.2929877042770386\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 96, batch train loss: 2.097834587097168\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 97, batch train loss: 1.7918894290924072\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 98, batch train loss: 1.714927315711975\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 99, batch train loss: 2.138693332672119\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 100, batch train loss: 2.3172194957733154\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 101, batch train loss: 2.3295576572418213\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 102, batch train loss: 2.450885534286499\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 103, batch train loss: 1.946115493774414\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 104, batch train loss: 1.3817157745361328\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 105, batch train loss: 1.2719639539718628\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 106, batch train loss: 1.2735931873321533\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 107, batch train loss: 1.660357117652893\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 108, batch train loss: 1.3423693180084229\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 109, batch train loss: 2.8000924587249756\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 110, batch train loss: 1.6454676389694214\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 111, batch train loss: 2.1929075717926025\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 112, batch train loss: 2.1854259967803955\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 113, batch train loss: 1.619996428489685\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 114, batch train loss: 1.628191351890564\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 115, batch train loss: 1.6082370281219482\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 116, batch train loss: 1.6002931594848633\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 117, batch train loss: 1.8691786527633667\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 118, batch train loss: 1.479643702507019\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 119, batch train loss: 1.5761315822601318\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 120, batch train loss: 1.4635672569274902\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 121, batch train loss: 1.6029952764511108\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 122, batch train loss: 1.628711223602295\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 123, batch train loss: 1.4858494997024536\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 124, batch train loss: 1.4522327184677124\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 125, batch train loss: 1.5724337100982666\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 126, batch train loss: 1.264396071434021\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 127, batch train loss: 1.252742052078247\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61, batch_id: 128, batch train loss: 1.2823848724365234\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 129, batch train loss: 1.8730998039245605\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 130, batch train loss: 1.6279963254928589\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 131, batch train loss: 1.5585899353027344\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 132, batch train loss: 1.3421125411987305\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 133, batch train loss: 1.3585506677627563\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 134, batch train loss: 1.516154170036316\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 135, batch train loss: 1.2827928066253662\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 136, batch train loss: 1.6882306337356567\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 137, batch train loss: 1.126875877380371\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 138, batch train loss: 1.8883709907531738\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 139, batch train loss: 1.3830015659332275\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 140, batch train loss: 1.736871361732483\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 141, batch train loss: 1.3926608562469482\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 142, batch train loss: 1.570593237876892\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 143, batch train loss: 1.9463893175125122\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 144, batch train loss: 1.6266708374023438\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 145, batch train loss: 2.5607833862304688\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 146, batch train loss: 1.7789795398712158\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 147, batch train loss: 1.6349740028381348\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 148, batch train loss: 1.3646434545516968\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 149, batch train loss: 1.812089204788208\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 150, batch train loss: 2.600391387939453\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 151, batch train loss: 1.6594882011413574\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 152, batch train loss: 1.8359472751617432\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 153, batch train loss: 1.6446740627288818\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 154, batch train loss: 2.092759609222412\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 155, batch train loss: 1.729539155960083\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 156, batch train loss: 1.9341546297073364\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 157, batch train loss: 1.5398391485214233\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 158, batch train loss: 1.3689818382263184\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 159, batch train loss: 1.4198709726333618\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 160, batch train loss: 1.936949610710144\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 161, batch train loss: 1.6283625364303589\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 162, batch train loss: 1.734928846359253\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 163, batch train loss: 1.5626320838928223\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 164, batch train loss: 1.3662384748458862\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 165, batch train loss: 1.6601386070251465\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 166, batch train loss: 1.420266032218933\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 167, batch train loss: 2.337197780609131\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 168, batch train loss: 2.5124006271362305\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 169, batch train loss: 2.2164318561553955\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 170, batch train loss: 2.0191972255706787\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 171, batch train loss: 2.326982021331787\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 172, batch train loss: 1.9280202388763428\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 173, batch train loss: 1.5462933778762817\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 174, batch train loss: 1.9635355472564697\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 175, batch train loss: 1.8614892959594727\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 176, batch train loss: 1.7535754442214966\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 177, batch train loss: 1.6388546228408813\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 178, batch train loss: 1.6501203775405884\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 179, batch train loss: 1.5435386896133423\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 180, batch train loss: 1.322269320487976\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 181, batch train loss: 1.7165316343307495\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 182, batch train loss: 1.4607700109481812\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 183, batch train loss: 1.7892236709594727\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 184, batch train loss: 1.4099435806274414\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 185, batch train loss: 1.6198089122772217\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 186, batch train loss: 1.764120101928711\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 187, batch train loss: 1.8075852394104004\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 188, batch train loss: 1.5268301963806152\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 189, batch train loss: 1.634124755859375\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 190, batch train loss: 1.798048496246338\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 191, batch train loss: 1.7406420707702637\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 192, batch train loss: 1.620498538017273\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 193, batch train loss: 1.8697319030761719\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 194, batch train loss: 1.74427330493927\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 195, batch train loss: 1.5829107761383057\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 196, batch train loss: 1.5179082155227661\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 197, batch train loss: 1.174628734588623\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 198, batch train loss: 1.6974914073944092\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 199, batch train loss: 1.492802381515503\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 200, batch train loss: 1.7334485054016113\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 201, batch train loss: 2.221322774887085\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 202, batch train loss: 1.5864983797073364\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 203, batch train loss: 1.4391862154006958\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 204, batch train loss: 1.8493560552597046\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 205, batch train loss: 2.5515682697296143\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 206, batch train loss: 2.269770860671997\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 207, batch train loss: 1.884562373161316\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 208, batch train loss: 2.004863977432251\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 209, batch train loss: 2.5003600120544434\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 210, batch train loss: 1.7570984363555908\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 211, batch train loss: 1.8111751079559326\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 212, batch train loss: 2.0057504177093506\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 213, batch train loss: 2.4657788276672363\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 214, batch train loss: 1.5406889915466309\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 215, batch train loss: 1.4514364004135132\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 216, batch train loss: 2.4511756896972656\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 217, batch train loss: 1.9721262454986572\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 218, batch train loss: 1.960211992263794\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 219, batch train loss: 2.0365424156188965\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 220, batch train loss: 1.7570406198501587\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 221, batch train loss: 1.2888346910476685\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 222, batch train loss: 1.5778393745422363\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 223, batch train loss: 1.657305359840393\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 224, batch train loss: 1.5216467380523682\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 225, batch train loss: 1.4138436317443848\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 226, batch train loss: 1.4344347715377808\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 227, batch train loss: 1.5335586071014404\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 228, batch train loss: 1.2521603107452393\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 229, batch train loss: 1.9871163368225098\n",
      "\n",
      "\n",
      "Epoch: 61, batch_id: 230, batch train loss: 1.6825870275497437\n",
      "\n",
      "\n",
      "Epoch: 61/ 100, Loss: 1.8629642984141475\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:31<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 Validation Loss: 2.1654872993628183\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, batch_id: 1, batch train loss: 2.0968563556671143\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 2, batch train loss: 1.3603637218475342\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 3, batch train loss: 1.4720499515533447\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 4, batch train loss: 2.2184395790100098\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 5, batch train loss: 3.395709753036499\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 6, batch train loss: 3.2804226875305176\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 7, batch train loss: 2.278756618499756\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 8, batch train loss: 4.436567783355713\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 9, batch train loss: 4.265406608581543\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 10, batch train loss: 2.4909675121307373\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 11, batch train loss: 2.406914472579956\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 12, batch train loss: 6.4746198654174805\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 13, batch train loss: 4.967694282531738\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 14, batch train loss: 3.4270548820495605\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 15, batch train loss: 3.1390540599823\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 16, batch train loss: 3.978914499282837\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 17, batch train loss: 4.033472061157227\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 18, batch train loss: 2.4711050987243652\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 19, batch train loss: 3.748934268951416\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 20, batch train loss: 4.065508842468262\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 21, batch train loss: 2.6089775562286377\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 22, batch train loss: 1.8825150728225708\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 23, batch train loss: 3.0118892192840576\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 24, batch train loss: 1.64940345287323\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 25, batch train loss: 1.6253116130828857\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 26, batch train loss: 2.493931770324707\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 27, batch train loss: 1.5795117616653442\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 28, batch train loss: 1.7069014310836792\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 29, batch train loss: 1.9631744623184204\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 30, batch train loss: 2.223973274230957\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 31, batch train loss: 2.635855197906494\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 32, batch train loss: 2.194812297821045\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 33, batch train loss: 2.5864322185516357\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 34, batch train loss: 2.0748748779296875\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 35, batch train loss: 1.7366540431976318\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 36, batch train loss: 1.927553653717041\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 37, batch train loss: 1.864512324333191\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 38, batch train loss: 1.3342808485031128\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 39, batch train loss: 1.2985469102859497\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 40, batch train loss: 1.3195346593856812\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 41, batch train loss: 1.4225213527679443\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 42, batch train loss: 1.2839784622192383\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 43, batch train loss: 1.3338305950164795\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 44, batch train loss: 1.5632076263427734\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 45, batch train loss: 2.1041500568389893\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 46, batch train loss: 1.7380149364471436\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 47, batch train loss: 1.8735642433166504\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 48, batch train loss: 1.4354541301727295\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 49, batch train loss: 1.7366656064987183\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 50, batch train loss: 1.3125349283218384\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 51, batch train loss: 1.9238802194595337\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 52, batch train loss: 2.621722459793091\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 53, batch train loss: 1.7206931114196777\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 54, batch train loss: 2.4361398220062256\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 55, batch train loss: 1.8579312562942505\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 56, batch train loss: 1.6078081130981445\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 57, batch train loss: 1.7254728078842163\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 58, batch train loss: 2.4970126152038574\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 59, batch train loss: 2.3934664726257324\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 60, batch train loss: 2.5652191638946533\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 61, batch train loss: 2.0178775787353516\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 62, batch train loss: 2.5635690689086914\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 63, batch train loss: 1.772161841392517\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 64, batch train loss: 1.7577983140945435\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 65, batch train loss: 2.2203333377838135\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 66, batch train loss: 2.4831666946411133\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 67, batch train loss: 2.0977137088775635\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 68, batch train loss: 1.8625445365905762\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 69, batch train loss: 1.8343353271484375\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 70, batch train loss: 3.253307342529297\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 71, batch train loss: 1.8054581880569458\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 72, batch train loss: 2.17192006111145\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 73, batch train loss: 1.7253212928771973\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 74, batch train loss: 1.7032188177108765\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 75, batch train loss: 1.8539129495620728\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 76, batch train loss: 2.3051867485046387\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 77, batch train loss: 1.7124979496002197\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 78, batch train loss: 1.7407869100570679\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 79, batch train loss: 1.887465000152588\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 80, batch train loss: 2.44439697265625\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 81, batch train loss: 2.2035562992095947\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 82, batch train loss: 1.6227787733078003\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 83, batch train loss: 3.0129194259643555\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 84, batch train loss: 2.5718371868133545\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 85, batch train loss: 1.8209245204925537\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 86, batch train loss: 2.2558722496032715\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 87, batch train loss: 1.9239311218261719\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 88, batch train loss: 2.231945514678955\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 89, batch train loss: 1.6405928134918213\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 90, batch train loss: 1.5398633480072021\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 91, batch train loss: 1.7136621475219727\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 92, batch train loss: 2.08038067817688\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 93, batch train loss: 1.69916832447052\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 94, batch train loss: 1.7633394002914429\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 95, batch train loss: 1.6442004442214966\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 96, batch train loss: 1.459804892539978\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 97, batch train loss: 1.810397744178772\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 98, batch train loss: 1.64008367061615\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 99, batch train loss: 1.2946817874908447\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 100, batch train loss: 1.6000049114227295\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 101, batch train loss: 1.522122859954834\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 102, batch train loss: 1.3178874254226685\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 103, batch train loss: 1.2667633295059204\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 104, batch train loss: 1.3610581159591675\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 105, batch train loss: 1.3413153886795044\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 106, batch train loss: 1.4851027727127075\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 107, batch train loss: 2.384664535522461\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 108, batch train loss: 1.3768701553344727\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 109, batch train loss: 1.4700390100479126\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 110, batch train loss: 1.516915202140808\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 111, batch train loss: 1.9037922620773315\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 112, batch train loss: 1.7341089248657227\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 113, batch train loss: 1.7463819980621338\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 114, batch train loss: 1.4535465240478516\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 115, batch train loss: 1.1575629711151123\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 116, batch train loss: 1.879683017730713\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 117, batch train loss: 1.5472863912582397\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 118, batch train loss: 1.5442535877227783\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 119, batch train loss: 1.2786192893981934\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 120, batch train loss: 1.990596890449524\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 121, batch train loss: 3.261784553527832\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 122, batch train loss: 2.319993495941162\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 123, batch train loss: 2.7544195652008057\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 124, batch train loss: 1.949432373046875\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 125, batch train loss: 1.9763643741607666\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 126, batch train loss: 3.248642921447754\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 127, batch train loss: 3.326085329055786\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 128, batch train loss: 1.8813220262527466\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 129, batch train loss: 1.7397469282150269\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62, batch_id: 130, batch train loss: 2.1510515213012695\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 131, batch train loss: 2.5825490951538086\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 132, batch train loss: 2.066983461380005\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 133, batch train loss: 2.6019182205200195\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 134, batch train loss: 1.7299267053604126\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 135, batch train loss: 1.4637482166290283\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 136, batch train loss: 2.0177903175354004\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 137, batch train loss: 1.9541078805923462\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 138, batch train loss: 1.7191884517669678\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 139, batch train loss: 1.7779667377471924\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 140, batch train loss: 1.462049126625061\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 141, batch train loss: 1.5334962606430054\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 142, batch train loss: 1.807671308517456\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 143, batch train loss: 2.207184076309204\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 144, batch train loss: 2.7071313858032227\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 145, batch train loss: 2.111640691757202\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 146, batch train loss: 1.711094617843628\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 147, batch train loss: 3.95890736579895\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 148, batch train loss: 2.851508378982544\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 149, batch train loss: 2.5647366046905518\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 150, batch train loss: 3.7876415252685547\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 151, batch train loss: 4.280433654785156\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 152, batch train loss: 2.4419970512390137\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 153, batch train loss: 3.3597214221954346\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 154, batch train loss: 5.1645355224609375\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 155, batch train loss: 3.481498956680298\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 156, batch train loss: 2.2403759956359863\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 157, batch train loss: 2.795600652694702\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 158, batch train loss: 2.179854154586792\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 159, batch train loss: 1.877714991569519\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 160, batch train loss: 2.3468270301818848\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 161, batch train loss: 1.9383020401000977\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 162, batch train loss: 1.9390201568603516\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 163, batch train loss: 1.9176993370056152\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 164, batch train loss: 1.6785823106765747\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 165, batch train loss: 1.784047245979309\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 166, batch train loss: 1.8344773054122925\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 167, batch train loss: 1.8486112356185913\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 168, batch train loss: 1.8973010778427124\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 169, batch train loss: 1.6964558362960815\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 170, batch train loss: 1.7555440664291382\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 171, batch train loss: 2.693931818008423\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 172, batch train loss: 2.1610326766967773\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 173, batch train loss: 1.9193446636199951\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 174, batch train loss: 2.1844983100891113\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 175, batch train loss: 1.5870112180709839\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 176, batch train loss: 1.88264000415802\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 177, batch train loss: 1.7196640968322754\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 178, batch train loss: 1.5986907482147217\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 179, batch train loss: 1.5545560121536255\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 180, batch train loss: 1.595531940460205\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 181, batch train loss: 1.780367374420166\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 182, batch train loss: 1.8555536270141602\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 183, batch train loss: 1.8192417621612549\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 184, batch train loss: 1.5301936864852905\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 185, batch train loss: 1.1465297937393188\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 186, batch train loss: 1.8692874908447266\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 187, batch train loss: 1.633123517036438\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 188, batch train loss: 1.4560086727142334\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 189, batch train loss: 1.4399206638336182\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 190, batch train loss: 1.275728464126587\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 191, batch train loss: 2.3214902877807617\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 192, batch train loss: 1.608967661857605\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 193, batch train loss: 1.9339101314544678\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 194, batch train loss: 1.800073266029358\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 195, batch train loss: 1.6690773963928223\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 196, batch train loss: 1.384602427482605\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 197, batch train loss: 1.3694919347763062\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 198, batch train loss: 1.3933154344558716\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 199, batch train loss: 1.5306211709976196\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 200, batch train loss: 1.746820330619812\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 201, batch train loss: 1.6485950946807861\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 202, batch train loss: 1.6839548349380493\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 203, batch train loss: 1.7721946239471436\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 204, batch train loss: 1.5937912464141846\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 205, batch train loss: 1.9096852540969849\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 206, batch train loss: 1.4229719638824463\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 207, batch train loss: 1.578657627105713\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 208, batch train loss: 1.6989777088165283\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 209, batch train loss: 1.318626880645752\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 210, batch train loss: 1.591883897781372\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 211, batch train loss: 1.6251962184906006\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 212, batch train loss: 1.631222128868103\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 213, batch train loss: 2.065173864364624\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 214, batch train loss: 1.6610398292541504\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 215, batch train loss: 1.6609752178192139\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 216, batch train loss: 1.4943127632141113\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 217, batch train loss: 1.2135727405548096\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 218, batch train loss: 1.3007190227508545\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 219, batch train loss: 1.2419037818908691\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 220, batch train loss: 1.7381067276000977\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 221, batch train loss: 1.5995668172836304\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 222, batch train loss: 2.0268940925598145\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 223, batch train loss: 2.0977416038513184\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 224, batch train loss: 1.8021191358566284\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 225, batch train loss: 1.5220507383346558\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 226, batch train loss: 1.6483721733093262\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 227, batch train loss: 1.3292616605758667\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 228, batch train loss: 1.6765856742858887\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 229, batch train loss: 1.4719914197921753\n",
      "\n",
      "\n",
      "Epoch: 62, batch_id: 230, batch train loss: 1.633947491645813\n",
      "\n",
      "\n",
      "Epoch: 62/ 100, Loss: 2.0465574715448462\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:28<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 Validation Loss: 1.3928005715211234\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63, batch_id: 1, batch train loss: 1.4373836517333984\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 2, batch train loss: 1.3696397542953491\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 3, batch train loss: 1.168581485748291\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 4, batch train loss: 1.4452966451644897\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 5, batch train loss: 1.5056449174880981\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 6, batch train loss: 1.769161343574524\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 7, batch train loss: 1.4560000896453857\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 8, batch train loss: 1.359283208847046\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 9, batch train loss: 1.292798399925232\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 10, batch train loss: 1.7229427099227905\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 11, batch train loss: 1.5574840307235718\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 12, batch train loss: 1.470402479171753\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 13, batch train loss: 1.325471043586731\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 14, batch train loss: 0.9762623906135559\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 15, batch train loss: 1.3437494039535522\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 16, batch train loss: 1.3240609169006348\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 17, batch train loss: 1.4223748445510864\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 18, batch train loss: 1.659455418586731\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 19, batch train loss: 1.6012520790100098\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 20, batch train loss: 1.515525460243225\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 21, batch train loss: 2.302819013595581\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 22, batch train loss: 1.8035249710083008\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 23, batch train loss: 2.1872658729553223\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 24, batch train loss: 1.9783148765563965\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 25, batch train loss: 1.7098815441131592\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 26, batch train loss: 2.2419939041137695\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 27, batch train loss: 2.1965112686157227\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 28, batch train loss: 2.1111249923706055\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 29, batch train loss: 4.766096115112305\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 30, batch train loss: 5.564467430114746\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 31, batch train loss: 2.2306230068206787\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 32, batch train loss: 4.024456977844238\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 33, batch train loss: 3.2810537815093994\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 34, batch train loss: 2.806544303894043\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 35, batch train loss: 5.190090656280518\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 36, batch train loss: 5.585995197296143\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 37, batch train loss: 4.560839653015137\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 38, batch train loss: 2.704936981201172\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 39, batch train loss: 5.226860046386719\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 40, batch train loss: 4.826505661010742\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 41, batch train loss: 2.4155948162078857\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 42, batch train loss: 2.8112926483154297\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 43, batch train loss: 3.492814540863037\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 44, batch train loss: 2.1929781436920166\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 45, batch train loss: 2.810225486755371\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 46, batch train loss: 2.9555087089538574\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 47, batch train loss: 2.6097676753997803\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 48, batch train loss: 3.491893768310547\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 49, batch train loss: 2.029735803604126\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 50, batch train loss: 1.573854684829712\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 51, batch train loss: 2.348294258117676\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 52, batch train loss: 2.7287118434906006\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 53, batch train loss: 2.303989887237549\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 54, batch train loss: 2.266542434692383\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 55, batch train loss: 1.5730587244033813\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 56, batch train loss: 1.9667913913726807\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 57, batch train loss: 2.062870740890503\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 58, batch train loss: 1.8945139646530151\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 59, batch train loss: 2.3748090267181396\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 60, batch train loss: 2.1804513931274414\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 61, batch train loss: 2.416613817214966\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 62, batch train loss: 2.29223895072937\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 63, batch train loss: 1.8553884029388428\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 64, batch train loss: 1.9974831342697144\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 65, batch train loss: 1.664032220840454\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 66, batch train loss: 1.741505742073059\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 67, batch train loss: 1.6089937686920166\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 68, batch train loss: 1.4732786417007446\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 69, batch train loss: 1.8317657709121704\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 70, batch train loss: 1.8811149597167969\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 71, batch train loss: 1.9959163665771484\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 72, batch train loss: 1.8814815282821655\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 73, batch train loss: 1.8036452531814575\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 74, batch train loss: 1.6546483039855957\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 75, batch train loss: 1.9139004945755005\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 76, batch train loss: 1.4982777833938599\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 77, batch train loss: 1.7417688369750977\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 78, batch train loss: 2.0350892543792725\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 79, batch train loss: 2.172241687774658\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 80, batch train loss: 1.771348237991333\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 81, batch train loss: 1.9656884670257568\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 82, batch train loss: 2.0948588848114014\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 83, batch train loss: 1.6818182468414307\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 84, batch train loss: 2.1385855674743652\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 85, batch train loss: 1.8181132078170776\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 86, batch train loss: 1.9934285879135132\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 87, batch train loss: 1.8351218700408936\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 88, batch train loss: 1.6847593784332275\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 89, batch train loss: 1.590425968170166\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 90, batch train loss: 1.462459921836853\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 91, batch train loss: 1.5859735012054443\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 92, batch train loss: 1.819576621055603\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 93, batch train loss: 1.5054574012756348\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 94, batch train loss: 2.000964879989624\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 95, batch train loss: 1.4528619050979614\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 96, batch train loss: 1.9731600284576416\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 97, batch train loss: 3.047316789627075\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 98, batch train loss: 2.8550240993499756\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 99, batch train loss: 3.177700996398926\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 100, batch train loss: 1.6970127820968628\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 101, batch train loss: 2.553074359893799\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 102, batch train loss: 1.8315696716308594\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 103, batch train loss: 2.1627466678619385\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 104, batch train loss: 1.784986972808838\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 105, batch train loss: 1.8971281051635742\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 106, batch train loss: 1.9121798276901245\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 107, batch train loss: 1.7253690958023071\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 108, batch train loss: 1.4779537916183472\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 109, batch train loss: 2.0628929138183594\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 110, batch train loss: 2.3197896480560303\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 111, batch train loss: 2.095883846282959\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 112, batch train loss: 2.1091058254241943\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 113, batch train loss: 1.7275358438491821\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 114, batch train loss: 1.8555269241333008\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 115, batch train loss: 2.1922953128814697\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 116, batch train loss: 1.8870210647583008\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 117, batch train loss: 2.207207679748535\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 118, batch train loss: 2.077280044555664\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 119, batch train loss: 1.9998447895050049\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 120, batch train loss: 2.128002643585205\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 121, batch train loss: 1.8035699129104614\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 122, batch train loss: 2.0149834156036377\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 123, batch train loss: 2.09698486328125\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 124, batch train loss: 1.3649953603744507\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 125, batch train loss: 2.6035077571868896\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 126, batch train loss: 2.0288352966308594\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 127, batch train loss: 1.7449212074279785\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 128, batch train loss: 2.125396966934204\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 129, batch train loss: 1.5593345165252686\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63, batch_id: 130, batch train loss: 1.9366127252578735\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 131, batch train loss: 1.704448938369751\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 132, batch train loss: 1.4925872087478638\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 133, batch train loss: 1.2833274602890015\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 134, batch train loss: 1.5722798109054565\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 135, batch train loss: 1.3869413137435913\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 136, batch train loss: 1.6577882766723633\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 137, batch train loss: 1.3607914447784424\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 138, batch train loss: 1.6630871295928955\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 139, batch train loss: 1.5997804403305054\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 140, batch train loss: 1.2848907709121704\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 141, batch train loss: 1.2217501401901245\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 142, batch train loss: 1.5183628797531128\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 143, batch train loss: 1.4504574537277222\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 144, batch train loss: 1.5191874504089355\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 145, batch train loss: 1.4948821067810059\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 146, batch train loss: 1.775023341178894\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 147, batch train loss: 1.4566924571990967\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 148, batch train loss: 1.2247886657714844\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 149, batch train loss: 1.2064998149871826\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 150, batch train loss: 1.3623510599136353\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 151, batch train loss: 1.1978768110275269\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 152, batch train loss: 1.39071524143219\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 153, batch train loss: 2.457190752029419\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 154, batch train loss: 1.7604156732559204\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 155, batch train loss: 1.4602329730987549\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 156, batch train loss: 1.4687316417694092\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 157, batch train loss: 1.7286566495895386\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 158, batch train loss: 1.5677025318145752\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 159, batch train loss: 3.1654295921325684\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 160, batch train loss: 2.067673683166504\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 161, batch train loss: 2.5325655937194824\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 162, batch train loss: 3.233633518218994\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 163, batch train loss: 1.558397650718689\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 164, batch train loss: 2.3763997554779053\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 165, batch train loss: 1.8172014951705933\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 166, batch train loss: 1.2212374210357666\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 167, batch train loss: 1.397529125213623\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 168, batch train loss: 1.4618393182754517\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 169, batch train loss: 1.4615908861160278\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 170, batch train loss: 1.4736534357070923\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 171, batch train loss: 1.0154058933258057\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 172, batch train loss: 1.2211366891860962\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 173, batch train loss: 1.1399134397506714\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 174, batch train loss: 1.3492655754089355\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 175, batch train loss: 1.6176912784576416\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 176, batch train loss: 1.6143379211425781\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 177, batch train loss: 1.936137080192566\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 178, batch train loss: 1.5040867328643799\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 179, batch train loss: 1.558627724647522\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 180, batch train loss: 1.3501403331756592\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 181, batch train loss: 1.50180983543396\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 182, batch train loss: 1.313897967338562\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 183, batch train loss: 1.2707351446151733\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 184, batch train loss: 1.8623319864273071\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 185, batch train loss: 1.4017564058303833\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 186, batch train loss: 1.5403406620025635\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 187, batch train loss: 1.315699815750122\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 188, batch train loss: 1.3154444694519043\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 189, batch train loss: 1.7853091955184937\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 190, batch train loss: 2.1332805156707764\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 191, batch train loss: 1.4200533628463745\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 192, batch train loss: 1.8421382904052734\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 193, batch train loss: 1.4649516344070435\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 194, batch train loss: 1.7629307508468628\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 195, batch train loss: 1.5486626625061035\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 196, batch train loss: 1.725366234779358\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 197, batch train loss: 1.5828126668930054\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 198, batch train loss: 1.6218531131744385\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 199, batch train loss: 1.5218286514282227\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 200, batch train loss: 1.4071377515792847\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 201, batch train loss: 2.089414119720459\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 202, batch train loss: 1.7068806886672974\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 203, batch train loss: 1.6326725482940674\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 204, batch train loss: 1.5603053569793701\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 205, batch train loss: 1.2928273677825928\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 206, batch train loss: 1.4281959533691406\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 207, batch train loss: 1.6627408266067505\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 208, batch train loss: 1.6874881982803345\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 209, batch train loss: 1.6774259805679321\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 210, batch train loss: 2.057065010070801\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 211, batch train loss: 1.711666226387024\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 212, batch train loss: 1.5623538494110107\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 213, batch train loss: 1.9260720014572144\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 214, batch train loss: 1.5158202648162842\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 215, batch train loss: 1.827640175819397\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 216, batch train loss: 1.4731602668762207\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 217, batch train loss: 1.3537894487380981\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 218, batch train loss: 1.2426403760910034\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 219, batch train loss: 1.2871837615966797\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 220, batch train loss: 1.2661975622177124\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 221, batch train loss: 1.0914740562438965\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 222, batch train loss: 1.6811984777450562\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 223, batch train loss: 1.6972112655639648\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 224, batch train loss: 1.3354780673980713\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 225, batch train loss: 1.4026035070419312\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 226, batch train loss: 1.2875874042510986\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 227, batch train loss: 1.3182833194732666\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 228, batch train loss: 1.4123778343200684\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 229, batch train loss: 1.3246893882751465\n",
      "\n",
      "\n",
      "Epoch: 63, batch_id: 230, batch train loss: 1.5016595125198364\n",
      "\n",
      "\n",
      "Epoch: 63/ 100, Loss: 1.9030336273753126\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:30<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63 Validation Loss: 1.3030506292978923\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64, batch_id: 1, batch train loss: 1.3083964586257935\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 2, batch train loss: 1.9401224851608276\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 3, batch train loss: 1.4292305707931519\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 4, batch train loss: 1.661777377128601\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 5, batch train loss: 1.3258056640625\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 6, batch train loss: 1.4813361167907715\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 7, batch train loss: 1.2981165647506714\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 8, batch train loss: 1.5030663013458252\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 9, batch train loss: 1.3519954681396484\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 10, batch train loss: 1.5586652755737305\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 11, batch train loss: 1.5430008172988892\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 12, batch train loss: 1.5114790201187134\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 13, batch train loss: 1.353158712387085\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 14, batch train loss: 1.3082001209259033\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 15, batch train loss: 1.877238154411316\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 16, batch train loss: 0.984967052936554\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 17, batch train loss: 1.2674427032470703\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 18, batch train loss: 1.8186545372009277\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 19, batch train loss: 1.5257989168167114\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 20, batch train loss: 1.6823478937149048\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 21, batch train loss: 1.5619126558303833\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 22, batch train loss: 1.2948708534240723\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 23, batch train loss: 1.239673137664795\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 24, batch train loss: 1.074013113975525\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 25, batch train loss: 1.7483131885528564\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 26, batch train loss: 1.3097835779190063\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 27, batch train loss: 1.4191166162490845\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 28, batch train loss: 1.176284909248352\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 29, batch train loss: 1.155281662940979\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 30, batch train loss: 1.3486649990081787\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 31, batch train loss: 1.9825186729431152\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 32, batch train loss: 1.6807126998901367\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 33, batch train loss: 1.8133732080459595\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 34, batch train loss: 1.8626025915145874\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 35, batch train loss: 1.8443135023117065\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 36, batch train loss: 1.4551796913146973\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 37, batch train loss: 1.5029982328414917\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 38, batch train loss: 1.533130168914795\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 39, batch train loss: 1.6683403253555298\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 40, batch train loss: 1.4506713151931763\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 41, batch train loss: 1.6667052507400513\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 42, batch train loss: 1.304653286933899\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 43, batch train loss: 1.959978461265564\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 44, batch train loss: 1.6785824298858643\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 45, batch train loss: 2.2435855865478516\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 46, batch train loss: 1.794836401939392\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 47, batch train loss: 1.4548492431640625\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 48, batch train loss: 2.2750322818756104\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 49, batch train loss: 2.2473037242889404\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 50, batch train loss: 2.1677048206329346\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 51, batch train loss: 1.843526840209961\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 52, batch train loss: 2.1289331912994385\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 53, batch train loss: 1.6888158321380615\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 54, batch train loss: 2.5190436840057373\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 55, batch train loss: 1.9418948888778687\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 56, batch train loss: 3.515610456466675\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 57, batch train loss: 2.1629159450531006\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 58, batch train loss: 1.4998137950897217\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 59, batch train loss: 3.0891382694244385\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 60, batch train loss: 1.5577207803726196\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 61, batch train loss: 1.817931890487671\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 62, batch train loss: 1.6710671186447144\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 63, batch train loss: 1.5902736186981201\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 64, batch train loss: 1.4072929620742798\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 65, batch train loss: 2.0007081031799316\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 66, batch train loss: 1.6464495658874512\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 67, batch train loss: 1.4228801727294922\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 68, batch train loss: 1.4677085876464844\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 69, batch train loss: 1.2803245782852173\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 70, batch train loss: 1.4302548170089722\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 71, batch train loss: 1.40718674659729\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 72, batch train loss: 1.397717833518982\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 73, batch train loss: 1.9081772565841675\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 74, batch train loss: 1.7126108407974243\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 75, batch train loss: 2.159520149230957\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 76, batch train loss: 1.5691386461257935\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 77, batch train loss: 1.9146822690963745\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 78, batch train loss: 1.7709563970565796\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 79, batch train loss: 1.3692638874053955\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 80, batch train loss: 1.7993491888046265\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 81, batch train loss: 1.8215980529785156\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 82, batch train loss: 2.2860283851623535\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 83, batch train loss: 2.079324245452881\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 84, batch train loss: 1.7162622213363647\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 85, batch train loss: 2.1773884296417236\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 86, batch train loss: 1.8722180128097534\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 87, batch train loss: 2.1850481033325195\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 88, batch train loss: 2.7050669193267822\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 89, batch train loss: 1.4643211364746094\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 90, batch train loss: 2.67811918258667\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 91, batch train loss: 1.7768079042434692\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 92, batch train loss: 1.8249015808105469\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 93, batch train loss: 3.241741418838501\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 94, batch train loss: 2.554827928543091\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 95, batch train loss: 1.906145453453064\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 96, batch train loss: 3.3562703132629395\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 97, batch train loss: 1.7771304845809937\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 98, batch train loss: 2.3740432262420654\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 99, batch train loss: 4.871718883514404\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 100, batch train loss: 1.789003849029541\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 101, batch train loss: 2.4825377464294434\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 102, batch train loss: 3.1117215156555176\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 103, batch train loss: 2.2605481147766113\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 104, batch train loss: 2.9548416137695312\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 105, batch train loss: 3.5989623069763184\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 106, batch train loss: 1.6570727825164795\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 107, batch train loss: 1.9127225875854492\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 108, batch train loss: 2.6131510734558105\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 109, batch train loss: 2.3562018871307373\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 110, batch train loss: 2.2409584522247314\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 111, batch train loss: 2.4651551246643066\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 112, batch train loss: 2.5585193634033203\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 113, batch train loss: 2.1241581439971924\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 114, batch train loss: 3.0449163913726807\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 115, batch train loss: 2.755551815032959\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 116, batch train loss: 2.0385053157806396\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 117, batch train loss: 2.393282651901245\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 118, batch train loss: 2.7386107444763184\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 119, batch train loss: 3.3854711055755615\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 120, batch train loss: 4.1793413162231445\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 121, batch train loss: 3.1533753871917725\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 122, batch train loss: 2.2251358032226562\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 123, batch train loss: 2.042470693588257\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 124, batch train loss: 3.9991707801818848\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 125, batch train loss: 2.551039934158325\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 126, batch train loss: 1.8485020399093628\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 127, batch train loss: 4.303345203399658\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 128, batch train loss: 4.824409008026123\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 129, batch train loss: 1.8601731061935425\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64, batch_id: 130, batch train loss: 4.774657726287842\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 131, batch train loss: 5.87838077545166\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 132, batch train loss: 6.679327011108398\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 133, batch train loss: 2.3712899684906006\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 134, batch train loss: 4.015791416168213\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 135, batch train loss: 4.570319652557373\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 136, batch train loss: 3.162013292312622\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 137, batch train loss: 2.364638328552246\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 138, batch train loss: 3.3468496799468994\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 139, batch train loss: 4.101248741149902\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 140, batch train loss: 1.9752726554870605\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 141, batch train loss: 4.417341232299805\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 142, batch train loss: 5.086984634399414\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 143, batch train loss: 2.9999639987945557\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 144, batch train loss: 4.217521667480469\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 145, batch train loss: 5.465439796447754\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 146, batch train loss: 4.330427169799805\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 147, batch train loss: 2.728999137878418\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 148, batch train loss: 2.379002094268799\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 149, batch train loss: 1.2278108596801758\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 150, batch train loss: 2.851283073425293\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 151, batch train loss: 3.150693416595459\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 152, batch train loss: 2.863248109817505\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 153, batch train loss: 2.372403144836426\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 154, batch train loss: 2.113637924194336\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 155, batch train loss: 1.57463800907135\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 156, batch train loss: 3.0529158115386963\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 157, batch train loss: 1.678595781326294\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 158, batch train loss: 1.3616431951522827\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 159, batch train loss: 1.9594793319702148\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 160, batch train loss: 1.4704481363296509\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 161, batch train loss: 2.01282000541687\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 162, batch train loss: 1.6689441204071045\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 163, batch train loss: 1.2643109560012817\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 164, batch train loss: 1.5362697839736938\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 165, batch train loss: 1.682719111442566\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 166, batch train loss: 1.773756742477417\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 167, batch train loss: 1.4510715007781982\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 168, batch train loss: 1.3496299982070923\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 169, batch train loss: 1.4565093517303467\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 170, batch train loss: 1.246917486190796\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 171, batch train loss: 1.5714861154556274\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 172, batch train loss: 2.711458206176758\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 173, batch train loss: 2.2304770946502686\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 174, batch train loss: 1.927757740020752\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 175, batch train loss: 2.101149320602417\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 176, batch train loss: 1.702752709388733\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 177, batch train loss: 1.6579550504684448\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 178, batch train loss: 1.4223358631134033\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 179, batch train loss: 2.5163328647613525\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 180, batch train loss: 4.242990016937256\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 181, batch train loss: 2.163498640060425\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 182, batch train loss: 2.5663235187530518\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 183, batch train loss: 2.0014045238494873\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 184, batch train loss: 2.1062681674957275\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 185, batch train loss: 2.7127013206481934\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 186, batch train loss: 2.0081288814544678\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 187, batch train loss: 3.3673274517059326\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 188, batch train loss: 2.251474618911743\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 189, batch train loss: 2.540912628173828\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 190, batch train loss: 2.540296792984009\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 191, batch train loss: 2.114394187927246\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 192, batch train loss: 2.2632980346679688\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 193, batch train loss: 2.015840768814087\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 194, batch train loss: 1.9560209512710571\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 195, batch train loss: 1.8123281002044678\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 196, batch train loss: 1.3830466270446777\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 197, batch train loss: 2.142439365386963\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 198, batch train loss: 1.3220809698104858\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 199, batch train loss: 1.997842788696289\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 200, batch train loss: 1.6155571937561035\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 201, batch train loss: 2.104707956314087\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 202, batch train loss: 1.7678816318511963\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 203, batch train loss: 1.7802083492279053\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 204, batch train loss: 1.4006754159927368\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 205, batch train loss: 1.8283286094665527\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 206, batch train loss: 2.4280853271484375\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 207, batch train loss: 2.445748805999756\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 208, batch train loss: 2.2141239643096924\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 209, batch train loss: 2.454800844192505\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 210, batch train loss: 1.6282620429992676\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 211, batch train loss: 1.9498077630996704\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 212, batch train loss: 1.8317787647247314\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 213, batch train loss: 1.4444485902786255\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 214, batch train loss: 1.9993516206741333\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 215, batch train loss: 1.605795979499817\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 216, batch train loss: 1.7921407222747803\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 217, batch train loss: 1.693467378616333\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 218, batch train loss: 2.0335896015167236\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 219, batch train loss: 2.3678016662597656\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 220, batch train loss: 2.121682643890381\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 221, batch train loss: 1.6416335105895996\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 222, batch train loss: 1.432687520980835\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 223, batch train loss: 1.8020917177200317\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 224, batch train loss: 1.8099629878997803\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 225, batch train loss: 3.2758123874664307\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 226, batch train loss: 2.5057973861694336\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 227, batch train loss: 1.8066471815109253\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 228, batch train loss: 3.3411366939544678\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 229, batch train loss: 1.6511238813400269\n",
      "\n",
      "\n",
      "Epoch: 64, batch_id: 230, batch train loss: 2.1099066734313965\n",
      "\n",
      "\n",
      "Epoch: 64/ 100, Loss: 2.1769351992918096\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:20<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64 Validation Loss: 1.8921135107676188\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65, batch_id: 1, batch train loss: 1.6077687740325928\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 2, batch train loss: 1.9070910215377808\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 3, batch train loss: 1.7760804891586304\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 4, batch train loss: 1.5984660387039185\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 5, batch train loss: 1.9506568908691406\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 6, batch train loss: 1.6594668626785278\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 7, batch train loss: 1.373020887374878\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 8, batch train loss: 1.584416151046753\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 9, batch train loss: 1.988073706626892\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 10, batch train loss: 3.007443904876709\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 11, batch train loss: 3.0056302547454834\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 12, batch train loss: 1.79443359375\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 13, batch train loss: 1.653376817703247\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 14, batch train loss: 2.1401422023773193\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 15, batch train loss: 2.1925694942474365\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 16, batch train loss: 1.9478000402450562\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 17, batch train loss: 1.9668540954589844\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 18, batch train loss: 2.0465786457061768\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 19, batch train loss: 1.7337712049484253\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 20, batch train loss: 2.145970344543457\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 21, batch train loss: 2.3671960830688477\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 22, batch train loss: 2.2037880420684814\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 23, batch train loss: 1.4142868518829346\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 24, batch train loss: 2.952136754989624\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 25, batch train loss: 3.2460737228393555\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 26, batch train loss: 2.710423469543457\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 27, batch train loss: 1.7794305086135864\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 28, batch train loss: 1.7109273672103882\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 29, batch train loss: 1.5737828016281128\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 30, batch train loss: 1.659493088722229\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 31, batch train loss: 2.185487985610962\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 32, batch train loss: 2.1324658393859863\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 33, batch train loss: 2.888432025909424\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 34, batch train loss: 1.358907699584961\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 35, batch train loss: 1.028828501701355\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 36, batch train loss: 1.4084844589233398\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 37, batch train loss: 1.84559166431427\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 38, batch train loss: 1.8438671827316284\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 39, batch train loss: 2.2417752742767334\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 40, batch train loss: 1.8036409616470337\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 41, batch train loss: 1.572731614112854\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 42, batch train loss: 1.167953372001648\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 43, batch train loss: 2.995622158050537\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 44, batch train loss: 2.588062047958374\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 45, batch train loss: 2.148164749145508\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 46, batch train loss: 1.7071948051452637\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 47, batch train loss: 1.6523160934448242\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 48, batch train loss: 1.988294243812561\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 49, batch train loss: 1.6651029586791992\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 50, batch train loss: 1.4610626697540283\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 51, batch train loss: 1.5550707578659058\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 52, batch train loss: 1.2962937355041504\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 53, batch train loss: 1.1857937574386597\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 54, batch train loss: 1.374459981918335\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 55, batch train loss: 1.379572868347168\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 56, batch train loss: 1.269321322441101\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 57, batch train loss: 1.3233108520507812\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 58, batch train loss: 1.5892475843429565\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 59, batch train loss: 1.3920162916183472\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 60, batch train loss: 1.4815183877944946\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 61, batch train loss: 1.4457197189331055\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 62, batch train loss: 1.2073372602462769\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 63, batch train loss: 1.2077716588974\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 64, batch train loss: 1.2450395822525024\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 65, batch train loss: 1.0260437726974487\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 66, batch train loss: 1.3658826351165771\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 67, batch train loss: 1.7141789197921753\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 68, batch train loss: 1.2998121976852417\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 69, batch train loss: 1.3185524940490723\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 70, batch train loss: 1.462179183959961\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 71, batch train loss: 1.6234570741653442\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 72, batch train loss: 1.5232311487197876\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 73, batch train loss: 1.380704641342163\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 74, batch train loss: 1.2976436614990234\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 75, batch train loss: 1.1510380506515503\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 76, batch train loss: 1.2913620471954346\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 77, batch train loss: 1.748512625694275\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 78, batch train loss: 1.535277247428894\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 79, batch train loss: 2.0957884788513184\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 80, batch train loss: 2.080559015274048\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 81, batch train loss: 1.994462251663208\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 82, batch train loss: 1.8986295461654663\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 83, batch train loss: 2.0804362297058105\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 84, batch train loss: 1.744775414466858\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 85, batch train loss: 1.4921343326568604\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 86, batch train loss: 1.652670979499817\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 87, batch train loss: 1.3818036317825317\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 88, batch train loss: 1.729582667350769\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 89, batch train loss: 2.1521098613739014\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 90, batch train loss: 1.5625354051589966\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 91, batch train loss: 1.9833327531814575\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 92, batch train loss: 1.3446002006530762\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 93, batch train loss: 1.2786680459976196\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 94, batch train loss: 2.056166172027588\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 95, batch train loss: 1.5209999084472656\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 96, batch train loss: 1.284664511680603\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 97, batch train loss: 1.1380298137664795\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 98, batch train loss: 1.3169622421264648\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 99, batch train loss: 1.7319087982177734\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 100, batch train loss: 1.6174238920211792\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 101, batch train loss: 3.645298957824707\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 102, batch train loss: 2.7776601314544678\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 103, batch train loss: 1.6146601438522339\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 104, batch train loss: 2.2748072147369385\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 105, batch train loss: 2.234905958175659\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 106, batch train loss: 1.6599159240722656\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 107, batch train loss: 2.873732805252075\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 108, batch train loss: 2.4469223022460938\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 109, batch train loss: 2.1531898975372314\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 110, batch train loss: 2.9005520343780518\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 111, batch train loss: 1.5287014245986938\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 112, batch train loss: 2.1999893188476562\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 113, batch train loss: 2.0839555263519287\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 114, batch train loss: 2.037114143371582\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 115, batch train loss: 3.2723548412323\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 116, batch train loss: 3.627465009689331\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 117, batch train loss: 2.062359094619751\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 118, batch train loss: 2.6096320152282715\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 119, batch train loss: 2.198779344558716\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 120, batch train loss: 3.109060525894165\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 121, batch train loss: 2.186446189880371\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 122, batch train loss: 5.446232318878174\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 123, batch train loss: 6.285290718078613\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 124, batch train loss: 3.197556257247925\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 125, batch train loss: 3.8174707889556885\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 126, batch train loss: 3.2404205799102783\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 127, batch train loss: 3.3758385181427\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 128, batch train loss: 2.0627381801605225\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 129, batch train loss: 3.177119731903076\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65, batch_id: 130, batch train loss: 3.283759117126465\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 131, batch train loss: 3.4506795406341553\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 132, batch train loss: 3.4506571292877197\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 133, batch train loss: 4.465861797332764\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 134, batch train loss: 3.029855966567993\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 135, batch train loss: 2.7212023735046387\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 136, batch train loss: 2.603137254714966\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 137, batch train loss: 1.4703857898712158\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 138, batch train loss: 2.122779607772827\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 139, batch train loss: 1.664217233657837\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 140, batch train loss: 2.3530397415161133\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 141, batch train loss: 1.7299346923828125\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 142, batch train loss: 2.5853078365325928\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 143, batch train loss: 1.5212502479553223\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 144, batch train loss: 1.6998109817504883\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 145, batch train loss: 1.3218255043029785\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 146, batch train loss: 1.1661584377288818\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 147, batch train loss: 2.3054304122924805\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 148, batch train loss: 1.745765209197998\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 149, batch train loss: 1.7514740228652954\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 150, batch train loss: 1.315954566001892\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 151, batch train loss: 1.4666410684585571\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 152, batch train loss: 1.5604392290115356\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 153, batch train loss: 1.6972941160202026\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 154, batch train loss: 2.285292148590088\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 155, batch train loss: 1.5027409791946411\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 156, batch train loss: 2.2207624912261963\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 157, batch train loss: 1.637046456336975\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 158, batch train loss: 2.0869357585906982\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 159, batch train loss: 2.1139748096466064\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 160, batch train loss: 1.282114863395691\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 161, batch train loss: 2.3842878341674805\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 162, batch train loss: 1.837059736251831\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 163, batch train loss: 3.15104603767395\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 164, batch train loss: 2.9633419513702393\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 165, batch train loss: 1.9957188367843628\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 166, batch train loss: 2.5493197441101074\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 167, batch train loss: 2.2321627140045166\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 168, batch train loss: 2.119823455810547\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 169, batch train loss: 1.9602327346801758\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 170, batch train loss: 2.165407419204712\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 171, batch train loss: 1.8162133693695068\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 172, batch train loss: 1.8426969051361084\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 173, batch train loss: 2.3795833587646484\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 174, batch train loss: 1.9816246032714844\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 175, batch train loss: 2.103760242462158\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 176, batch train loss: 1.5954933166503906\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 177, batch train loss: 1.6889582872390747\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 178, batch train loss: 1.6653640270233154\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 179, batch train loss: 1.6074936389923096\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 180, batch train loss: 2.2782511711120605\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 181, batch train loss: 1.8742761611938477\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 182, batch train loss: 1.701246976852417\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 183, batch train loss: 1.935709834098816\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 184, batch train loss: 3.529837131500244\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 185, batch train loss: 2.882566213607788\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 186, batch train loss: 2.247929096221924\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 187, batch train loss: 2.6816177368164062\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 188, batch train loss: 2.3796823024749756\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 189, batch train loss: 1.4330588579177856\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 190, batch train loss: 3.4863204956054688\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 191, batch train loss: 3.238332509994507\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 192, batch train loss: 1.8459924459457397\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 193, batch train loss: 2.280942678451538\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 194, batch train loss: 3.21162486076355\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 195, batch train loss: 2.2384378910064697\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 196, batch train loss: 3.7838797569274902\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 197, batch train loss: 3.2162163257598877\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 198, batch train loss: 2.7468700408935547\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 199, batch train loss: 1.881012201309204\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 200, batch train loss: 3.922179698944092\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 201, batch train loss: 3.9022562503814697\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 202, batch train loss: 2.299076795578003\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 203, batch train loss: 3.91408371925354\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 204, batch train loss: 4.405907154083252\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 205, batch train loss: 2.314317226409912\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 206, batch train loss: 1.5790566205978394\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 207, batch train loss: 2.907689094543457\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 208, batch train loss: 2.76651668548584\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 209, batch train loss: 1.4434235095977783\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 210, batch train loss: 1.654422640800476\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 211, batch train loss: 2.034062385559082\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 212, batch train loss: 1.4830341339111328\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 213, batch train loss: 1.481560468673706\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 214, batch train loss: 2.0477213859558105\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 215, batch train loss: 1.6987342834472656\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 216, batch train loss: 1.607087254524231\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 217, batch train loss: 2.193368434906006\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 218, batch train loss: 1.4690145254135132\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 219, batch train loss: 1.5155011415481567\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 220, batch train loss: 1.616364598274231\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 221, batch train loss: 2.230940341949463\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 222, batch train loss: 1.8906168937683105\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 223, batch train loss: 2.336740255355835\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 224, batch train loss: 2.193258762359619\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 225, batch train loss: 1.7412935495376587\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 226, batch train loss: 1.4015004634857178\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 227, batch train loss: 1.2687289714813232\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 228, batch train loss: 3.141289472579956\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 229, batch train loss: 2.11664080619812\n",
      "\n",
      "\n",
      "Epoch: 65, batch_id: 230, batch train loss: 1.8764021396636963\n",
      "\n",
      "\n",
      "Epoch: 65/ 100, Loss: 2.0925557038058407\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:29<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65 Validation Loss: 2.1062975505987804\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, batch_id: 1, batch train loss: 2.0537686347961426\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 2, batch train loss: 1.9520816802978516\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 3, batch train loss: 2.548222541809082\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 4, batch train loss: 2.1170144081115723\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 5, batch train loss: 1.7845458984375\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 6, batch train loss: 2.368297815322876\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 7, batch train loss: 2.791365385055542\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 8, batch train loss: 3.3326706886291504\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 9, batch train loss: 2.5906822681427\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 10, batch train loss: 1.7220330238342285\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 11, batch train loss: 1.6376214027404785\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 12, batch train loss: 2.473005771636963\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 13, batch train loss: 2.722791910171509\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 14, batch train loss: 2.600338935852051\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 15, batch train loss: 3.1633810997009277\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 16, batch train loss: 2.3620574474334717\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 17, batch train loss: 2.4454987049102783\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 18, batch train loss: 3.4401791095733643\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 19, batch train loss: 2.54604172706604\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 20, batch train loss: 2.664644956588745\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 21, batch train loss: 2.824092388153076\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 22, batch train loss: 2.707061290740967\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 23, batch train loss: 1.8413523435592651\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 24, batch train loss: 3.6265738010406494\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 25, batch train loss: 7.9335808753967285\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 26, batch train loss: 2.7635884284973145\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 27, batch train loss: 2.9192497730255127\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 28, batch train loss: 4.237588882446289\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 29, batch train loss: 4.157217979431152\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 30, batch train loss: 2.3382601737976074\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 31, batch train loss: 2.7528045177459717\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 32, batch train loss: 3.091301202774048\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 33, batch train loss: 3.1603071689605713\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 34, batch train loss: 2.2072949409484863\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 35, batch train loss: 6.012094020843506\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 36, batch train loss: 3.7007319927215576\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 37, batch train loss: 2.4586405754089355\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 38, batch train loss: 2.561843156814575\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 39, batch train loss: 2.4804790019989014\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 40, batch train loss: 2.3966667652130127\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 41, batch train loss: 2.061800956726074\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 42, batch train loss: 2.9780023097991943\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 43, batch train loss: 1.7281640768051147\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 44, batch train loss: 1.5394423007965088\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 45, batch train loss: 2.106548309326172\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 46, batch train loss: 1.8098034858703613\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 47, batch train loss: 1.7552369832992554\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 48, batch train loss: 2.3376903533935547\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 49, batch train loss: 1.4861171245574951\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 50, batch train loss: 1.54300057888031\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 51, batch train loss: 1.4040064811706543\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 52, batch train loss: 1.9540085792541504\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 53, batch train loss: 2.9429855346679688\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 54, batch train loss: 3.176027536392212\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 55, batch train loss: 4.880677700042725\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 56, batch train loss: 4.130713939666748\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 57, batch train loss: 2.5396366119384766\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 58, batch train loss: 3.796086311340332\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 59, batch train loss: 2.912458896636963\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 60, batch train loss: 1.9412988424301147\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 61, batch train loss: 3.043586254119873\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 62, batch train loss: 2.0798568725585938\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 63, batch train loss: 2.019885778427124\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 64, batch train loss: 3.4335408210754395\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 65, batch train loss: 1.9090087413787842\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 66, batch train loss: 2.047959566116333\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 67, batch train loss: 4.312303066253662\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 68, batch train loss: 3.1480798721313477\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 69, batch train loss: 3.388334035873413\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 70, batch train loss: 4.2676825523376465\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 71, batch train loss: 2.037627696990967\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 72, batch train loss: 2.7415049076080322\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 73, batch train loss: 6.663409233093262\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 74, batch train loss: 2.7591142654418945\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 75, batch train loss: 1.5538372993469238\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 76, batch train loss: 1.7164994478225708\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 77, batch train loss: 1.6706948280334473\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 78, batch train loss: 2.897264003753662\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 79, batch train loss: 2.7551188468933105\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 80, batch train loss: 2.533170461654663\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 81, batch train loss: 1.7480828762054443\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 82, batch train loss: 1.8632135391235352\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 83, batch train loss: 3.149815559387207\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 84, batch train loss: 2.910780668258667\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 85, batch train loss: 4.548151969909668\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 86, batch train loss: 2.188131332397461\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 87, batch train loss: 2.303987979888916\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 88, batch train loss: 2.8367743492126465\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 89, batch train loss: 2.391270399093628\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 90, batch train loss: 2.053196907043457\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 91, batch train loss: 1.4762625694274902\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 92, batch train loss: 3.0512070655822754\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 93, batch train loss: 2.0652310848236084\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 94, batch train loss: 2.4855587482452393\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 95, batch train loss: 2.303504467010498\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 96, batch train loss: 1.5745588541030884\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 97, batch train loss: 2.4857077598571777\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 98, batch train loss: 1.7886481285095215\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 99, batch train loss: 2.376589059829712\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 100, batch train loss: 1.8212707042694092\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 101, batch train loss: 1.6800572872161865\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 102, batch train loss: 2.2142550945281982\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 103, batch train loss: 1.2746689319610596\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 104, batch train loss: 1.5655595064163208\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 105, batch train loss: 1.705386996269226\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 106, batch train loss: 2.0433850288391113\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 107, batch train loss: 1.9563875198364258\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 108, batch train loss: 1.8168894052505493\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 109, batch train loss: 2.070333957672119\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 110, batch train loss: 1.970578670501709\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 111, batch train loss: 1.5939699411392212\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 112, batch train loss: 2.0334417819976807\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 113, batch train loss: 2.3557469844818115\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 114, batch train loss: 4.3086676597595215\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 115, batch train loss: 4.705775737762451\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 116, batch train loss: 6.391332626342773\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 117, batch train loss: 5.392970561981201\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 118, batch train loss: 5.482667446136475\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 119, batch train loss: 3.360433340072632\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 120, batch train loss: 4.876668930053711\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 121, batch train loss: 3.322240114212036\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 122, batch train loss: 3.1888887882232666\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 123, batch train loss: 3.561859130859375\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 124, batch train loss: 3.4868130683898926\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 125, batch train loss: 3.008082628250122\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 126, batch train loss: 3.9663546085357666\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 127, batch train loss: 7.331754684448242\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 128, batch train loss: 6.259312152862549\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 129, batch train loss: 6.1133551597595215\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66, batch_id: 130, batch train loss: 5.60000467300415\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 131, batch train loss: 10.644556045532227\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 132, batch train loss: 6.485494136810303\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 133, batch train loss: 9.385453224182129\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 134, batch train loss: 6.7424187660217285\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 135, batch train loss: 4.0186872482299805\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 136, batch train loss: 2.97481107711792\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 137, batch train loss: 6.865038871765137\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 138, batch train loss: 7.168856620788574\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 139, batch train loss: 6.706267356872559\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 140, batch train loss: 5.485228061676025\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 141, batch train loss: 4.2706990242004395\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 142, batch train loss: 6.135373115539551\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 143, batch train loss: 3.754223585128784\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 144, batch train loss: 4.468809604644775\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 145, batch train loss: 4.132977485656738\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 146, batch train loss: 4.872828960418701\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 147, batch train loss: 4.93734884262085\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 148, batch train loss: 4.01859188079834\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 149, batch train loss: 4.618699550628662\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 150, batch train loss: 3.944338083267212\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 151, batch train loss: 3.4754419326782227\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 152, batch train loss: 3.907365322113037\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 153, batch train loss: 2.9006478786468506\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 154, batch train loss: 3.4799458980560303\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 155, batch train loss: 2.9693069458007812\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 156, batch train loss: 3.205934762954712\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 157, batch train loss: 2.974217653274536\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 158, batch train loss: 2.9346542358398438\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 159, batch train loss: 2.803227424621582\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 160, batch train loss: 2.4369072914123535\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 161, batch train loss: 5.326700210571289\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 162, batch train loss: 4.0432963371276855\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 163, batch train loss: 3.1460835933685303\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 164, batch train loss: 2.863274097442627\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 165, batch train loss: 3.916890859603882\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 166, batch train loss: 3.418653964996338\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 167, batch train loss: 2.624917507171631\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 168, batch train loss: 3.9400808811187744\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 169, batch train loss: 3.3468685150146484\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 170, batch train loss: 4.743706703186035\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 171, batch train loss: 7.68792724609375\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 172, batch train loss: 6.270958423614502\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 173, batch train loss: 5.638047695159912\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 174, batch train loss: 7.612138748168945\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 175, batch train loss: 8.006753921508789\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 176, batch train loss: 6.568415641784668\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 177, batch train loss: 6.584506034851074\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 178, batch train loss: 5.9524431228637695\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 179, batch train loss: 5.441241264343262\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 180, batch train loss: 6.546268939971924\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 181, batch train loss: 6.0061492919921875\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 182, batch train loss: 4.847353458404541\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 183, batch train loss: 4.851539134979248\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 184, batch train loss: 4.684294700622559\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 185, batch train loss: 4.418728828430176\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 186, batch train loss: 4.093017101287842\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 187, batch train loss: 4.690117359161377\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 188, batch train loss: 4.0508503913879395\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 189, batch train loss: 4.152462482452393\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 190, batch train loss: 4.149196624755859\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 191, batch train loss: 4.067534923553467\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 192, batch train loss: 4.959346294403076\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 193, batch train loss: 4.386266231536865\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 194, batch train loss: 4.58349084854126\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 195, batch train loss: 5.1565985679626465\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 196, batch train loss: 4.613780498504639\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 197, batch train loss: 4.435315132141113\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 198, batch train loss: 4.437707901000977\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 199, batch train loss: 3.826627492904663\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 200, batch train loss: 4.270452976226807\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 201, batch train loss: 5.479762554168701\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 202, batch train loss: 4.405190467834473\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 203, batch train loss: 4.082315444946289\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 204, batch train loss: 4.850804328918457\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 205, batch train loss: 3.855609893798828\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 206, batch train loss: 4.543307781219482\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 207, batch train loss: 5.109935283660889\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 208, batch train loss: 3.9298088550567627\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 209, batch train loss: 3.7102303504943848\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 210, batch train loss: 3.795117139816284\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 211, batch train loss: 6.048655033111572\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 212, batch train loss: 5.962441444396973\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 213, batch train loss: 6.855140686035156\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 214, batch train loss: 5.931342124938965\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 215, batch train loss: 7.642773628234863\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 216, batch train loss: 7.915628433227539\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 217, batch train loss: 7.628724098205566\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 218, batch train loss: 6.593520164489746\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 219, batch train loss: 6.590278148651123\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 220, batch train loss: 5.876406192779541\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 221, batch train loss: 6.007441997528076\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 222, batch train loss: 6.63976526260376\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 223, batch train loss: 5.233244895935059\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 224, batch train loss: 5.842633247375488\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 225, batch train loss: 4.406126976013184\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 226, batch train loss: 4.626842021942139\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 227, batch train loss: 5.910552501678467\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 228, batch train loss: 7.005282402038574\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 229, batch train loss: 8.054883003234863\n",
      "\n",
      "\n",
      "Epoch: 66, batch_id: 230, batch train loss: 9.658343315124512\n",
      "\n",
      "\n",
      "Epoch: 66/ 100, Loss: 3.8470409004584605\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:13<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 Validation Loss: 10.498546457290649\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67, batch_id: 1, batch train loss: 11.727315902709961\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 2, batch train loss: 10.948554039001465\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 3, batch train loss: 13.513067245483398\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 4, batch train loss: 9.242618560791016\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 5, batch train loss: 8.354406356811523\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 6, batch train loss: 6.097647666931152\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 7, batch train loss: 4.913514137268066\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 8, batch train loss: 8.672255516052246\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 9, batch train loss: 8.31417179107666\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 10, batch train loss: 5.075929164886475\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 11, batch train loss: 6.982168197631836\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 12, batch train loss: 7.044047832489014\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 13, batch train loss: 7.478739261627197\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 14, batch train loss: 4.7702202796936035\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 15, batch train loss: 6.3805365562438965\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 16, batch train loss: 10.3930082321167\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 17, batch train loss: 4.91365909576416\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 18, batch train loss: 4.333963394165039\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 19, batch train loss: 5.046329975128174\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 20, batch train loss: 4.0638556480407715\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 21, batch train loss: 4.416241645812988\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 22, batch train loss: 4.300927639007568\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 23, batch train loss: 4.388631343841553\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 24, batch train loss: 4.7753586769104\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 25, batch train loss: 4.217761516571045\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 26, batch train loss: 4.482058525085449\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 27, batch train loss: 3.4703612327575684\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 28, batch train loss: 4.169028282165527\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 29, batch train loss: 5.8612165451049805\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 30, batch train loss: 5.150854587554932\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 31, batch train loss: 4.4601359367370605\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 32, batch train loss: 4.978590488433838\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 33, batch train loss: 9.953290939331055\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 34, batch train loss: 8.025256156921387\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 35, batch train loss: 8.336722373962402\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 36, batch train loss: 7.149190902709961\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 37, batch train loss: 6.668262958526611\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 38, batch train loss: 7.93510103225708\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 39, batch train loss: 8.371191024780273\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 40, batch train loss: 10.949416160583496\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 41, batch train loss: 11.126144409179688\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 42, batch train loss: 12.002896308898926\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 43, batch train loss: 13.362848281860352\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 44, batch train loss: 10.78282642364502\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 45, batch train loss: 16.158138275146484\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 46, batch train loss: 13.126296997070312\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 47, batch train loss: 8.314408302307129\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 48, batch train loss: 11.683887481689453\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 49, batch train loss: 15.423022270202637\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 50, batch train loss: 8.385156631469727\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 51, batch train loss: 9.653528213500977\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 52, batch train loss: 9.896249771118164\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 53, batch train loss: 6.668632507324219\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 54, batch train loss: 6.576208591461182\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 55, batch train loss: 6.318877220153809\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 56, batch train loss: 6.62851095199585\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 57, batch train loss: 6.31369161605835\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 58, batch train loss: 6.999277114868164\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 59, batch train loss: 7.27567720413208\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 60, batch train loss: 4.743785858154297\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 61, batch train loss: 9.981775283813477\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 62, batch train loss: 9.65668773651123\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 63, batch train loss: 8.709210395812988\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 64, batch train loss: 9.12976360321045\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 65, batch train loss: 7.532431602478027\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 66, batch train loss: 12.5649995803833\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 67, batch train loss: 10.2822847366333\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 68, batch train loss: 9.782554626464844\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 69, batch train loss: 10.97512435913086\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 70, batch train loss: 6.957722187042236\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 71, batch train loss: 10.403573036193848\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 72, batch train loss: 11.97000503540039\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 73, batch train loss: 10.375253677368164\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 74, batch train loss: 9.615666389465332\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 75, batch train loss: 14.060498237609863\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 76, batch train loss: 14.896272659301758\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 77, batch train loss: 9.062894821166992\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 78, batch train loss: 20.90104866027832\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 79, batch train loss: 20.373554229736328\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 80, batch train loss: 12.161154747009277\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 81, batch train loss: 9.772421836853027\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 82, batch train loss: 13.931781768798828\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 83, batch train loss: 16.804651260375977\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 84, batch train loss: 12.106914520263672\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 85, batch train loss: 9.678733825683594\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 86, batch train loss: 9.396957397460938\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 87, batch train loss: 12.220067024230957\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 88, batch train loss: 11.320291519165039\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 89, batch train loss: 8.920184135437012\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 90, batch train loss: 8.021352767944336\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 91, batch train loss: 6.56972599029541\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 92, batch train loss: 7.132310390472412\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 93, batch train loss: 6.119075775146484\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 94, batch train loss: 6.36864709854126\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 95, batch train loss: 6.661705493927002\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 96, batch train loss: 7.663808822631836\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 97, batch train loss: 5.700465679168701\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 98, batch train loss: 4.617363929748535\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 99, batch train loss: 5.6421427726745605\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 100, batch train loss: 5.872506618499756\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 101, batch train loss: 5.632765293121338\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 102, batch train loss: 5.166281223297119\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 103, batch train loss: 6.256857395172119\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 104, batch train loss: 5.598779201507568\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 105, batch train loss: 5.77511739730835\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 106, batch train loss: 5.9180378913879395\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 107, batch train loss: 5.411477088928223\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 108, batch train loss: 6.167125701904297\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 109, batch train loss: 6.236048221588135\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 110, batch train loss: 5.618218421936035\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 111, batch train loss: 9.318273544311523\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 112, batch train loss: 7.670473575592041\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 113, batch train loss: 6.902453422546387\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 114, batch train loss: 8.685665130615234\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 115, batch train loss: 6.3572258949279785\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 116, batch train loss: 5.813450813293457\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 117, batch train loss: 6.337780952453613\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 118, batch train loss: 5.884020805358887\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 119, batch train loss: 5.614028453826904\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 120, batch train loss: 5.252260684967041\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 121, batch train loss: 4.926487445831299\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 122, batch train loss: 3.912429094314575\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 123, batch train loss: 4.044975757598877\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 124, batch train loss: 6.998331546783447\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 125, batch train loss: 6.181351184844971\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 126, batch train loss: 6.7374420166015625\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 127, batch train loss: 5.161437034606934\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 128, batch train loss: 6.061199188232422\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 129, batch train loss: 5.25161600112915\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 130, batch train loss: 6.719127655029297\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67, batch_id: 131, batch train loss: 4.083027362823486\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 132, batch train loss: 4.379382610321045\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 133, batch train loss: 4.024752140045166\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 134, batch train loss: 4.894822120666504\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 135, batch train loss: 5.471487045288086\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 136, batch train loss: 7.150562286376953\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 137, batch train loss: 4.500312805175781\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 138, batch train loss: 3.022733449935913\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 139, batch train loss: 4.692844867706299\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 140, batch train loss: 3.7409932613372803\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 141, batch train loss: 4.348013401031494\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 142, batch train loss: 4.166610240936279\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 143, batch train loss: 3.8765902519226074\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 144, batch train loss: 3.440579891204834\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 145, batch train loss: 3.9607205390930176\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 146, batch train loss: 3.236278533935547\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 147, batch train loss: 4.814404487609863\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 148, batch train loss: 5.691043853759766\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 149, batch train loss: 8.200299263000488\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 150, batch train loss: 7.819876194000244\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 151, batch train loss: 6.830519199371338\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 152, batch train loss: 9.607666015625\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 153, batch train loss: 11.665555953979492\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 154, batch train loss: 10.552434921264648\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 155, batch train loss: 12.331435203552246\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 156, batch train loss: 11.314123153686523\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 157, batch train loss: 12.846992492675781\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 158, batch train loss: 10.425222396850586\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 159, batch train loss: 8.406253814697266\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 160, batch train loss: 8.700844764709473\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 161, batch train loss: 8.58541488647461\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 162, batch train loss: 8.537384033203125\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 163, batch train loss: 8.903460502624512\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 164, batch train loss: 13.933135032653809\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 165, batch train loss: 13.844077110290527\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 166, batch train loss: 13.543869972229004\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 167, batch train loss: 12.689739227294922\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 168, batch train loss: 17.885175704956055\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 169, batch train loss: 11.507777214050293\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 170, batch train loss: 12.031935691833496\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 171, batch train loss: 11.687957763671875\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 172, batch train loss: 13.475543975830078\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 173, batch train loss: 10.9105863571167\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 174, batch train loss: 19.80797576904297\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 175, batch train loss: 10.346057891845703\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 176, batch train loss: 12.981302261352539\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 177, batch train loss: 13.570441246032715\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 178, batch train loss: 14.6744384765625\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 179, batch train loss: 15.412249565124512\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 180, batch train loss: 13.396026611328125\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 181, batch train loss: 14.205745697021484\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 182, batch train loss: 15.644339561462402\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 183, batch train loss: 18.167097091674805\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 184, batch train loss: 11.664945602416992\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 185, batch train loss: 8.699207305908203\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 186, batch train loss: 13.87939453125\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 187, batch train loss: 15.817877769470215\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 188, batch train loss: 8.249783515930176\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 189, batch train loss: 7.970491409301758\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 190, batch train loss: 8.41370677947998\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 191, batch train loss: 7.258540630340576\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 192, batch train loss: 7.189338207244873\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 193, batch train loss: 5.724440097808838\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 194, batch train loss: 7.199328422546387\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 195, batch train loss: 7.668238162994385\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 196, batch train loss: 5.897129535675049\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 197, batch train loss: 6.7588348388671875\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 198, batch train loss: 5.669540882110596\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 199, batch train loss: 10.1581449508667\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 200, batch train loss: 8.096240043640137\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 201, batch train loss: 8.115982055664062\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 202, batch train loss: 6.184685707092285\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 203, batch train loss: 5.764498233795166\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 204, batch train loss: 5.804366588592529\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 205, batch train loss: 6.504701137542725\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 206, batch train loss: 6.05402946472168\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 207, batch train loss: 5.731853008270264\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 208, batch train loss: 4.6207122802734375\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 209, batch train loss: 6.1369757652282715\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 210, batch train loss: 4.625421524047852\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 211, batch train loss: 10.080652236938477\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 212, batch train loss: 14.911930084228516\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 213, batch train loss: 12.562655448913574\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 214, batch train loss: 17.749052047729492\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 215, batch train loss: 14.325963973999023\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 216, batch train loss: 10.687893867492676\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 217, batch train loss: 11.507943153381348\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 218, batch train loss: 10.28079605102539\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 219, batch train loss: 10.22099494934082\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 220, batch train loss: 11.326507568359375\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 221, batch train loss: 11.78751277923584\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 222, batch train loss: 11.540771484375\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 223, batch train loss: 8.810993194580078\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 224, batch train loss: 9.159269332885742\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 225, batch train loss: 9.250502586364746\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 226, batch train loss: 10.664811134338379\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 227, batch train loss: 9.9941987991333\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 228, batch train loss: 8.878908157348633\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 229, batch train loss: 8.812223434448242\n",
      "\n",
      "\n",
      "Epoch: 67, batch_id: 230, batch train loss: 10.25278091430664\n",
      "\n",
      "\n",
      "Epoch: 67/ 100, Loss: 8.608229901479637\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:08<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 Validation Loss: 10.05223650932312\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, batch_id: 1, batch train loss: 10.089770317077637\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 2, batch train loss: 10.873199462890625\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 3, batch train loss: 8.79098129272461\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 4, batch train loss: 9.875875473022461\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 5, batch train loss: 9.090677261352539\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 6, batch train loss: 8.727397918701172\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 7, batch train loss: 7.225642681121826\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 8, batch train loss: 6.528234481811523\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 9, batch train loss: 7.786312580108643\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 10, batch train loss: 6.424166679382324\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 11, batch train loss: 5.34768533706665\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 12, batch train loss: 5.4690961837768555\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 13, batch train loss: 5.205899238586426\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 14, batch train loss: 3.9670777320861816\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 15, batch train loss: 4.433895587921143\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 16, batch train loss: 4.764411449432373\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 17, batch train loss: 4.64474630355835\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 18, batch train loss: 4.238674640655518\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 19, batch train loss: 6.417354106903076\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 20, batch train loss: 7.3150529861450195\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 21, batch train loss: 6.069930076599121\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 22, batch train loss: 5.632506370544434\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 23, batch train loss: 5.042613983154297\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 24, batch train loss: 4.648580551147461\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 25, batch train loss: 4.776019096374512\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 26, batch train loss: 4.472489356994629\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 27, batch train loss: 4.089000701904297\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 28, batch train loss: 4.9660797119140625\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 29, batch train loss: 4.153510570526123\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 30, batch train loss: 5.226613998413086\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 31, batch train loss: 5.722657203674316\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 32, batch train loss: 5.505227565765381\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 33, batch train loss: 4.545811176300049\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 34, batch train loss: 5.495625972747803\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 35, batch train loss: 5.222838401794434\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 36, batch train loss: 3.563636541366577\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 37, batch train loss: 7.162656307220459\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 38, batch train loss: 5.287135124206543\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 39, batch train loss: 5.025672435760498\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 40, batch train loss: 5.730669021606445\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 41, batch train loss: 3.891528367996216\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 42, batch train loss: 5.061945915222168\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 43, batch train loss: 4.522757053375244\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 44, batch train loss: 3.2561771869659424\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 45, batch train loss: 6.150592803955078\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 46, batch train loss: 13.795822143554688\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 47, batch train loss: 7.716993808746338\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 48, batch train loss: 7.324162006378174\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 49, batch train loss: 9.431644439697266\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 50, batch train loss: 9.8110990524292\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 51, batch train loss: 8.6321439743042\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 52, batch train loss: 6.680635929107666\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 53, batch train loss: 8.732401847839355\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 54, batch train loss: 6.160895824432373\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 55, batch train loss: 6.715671062469482\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 56, batch train loss: 8.957718849182129\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 57, batch train loss: 7.568446636199951\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 58, batch train loss: 7.072234630584717\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 59, batch train loss: 9.517224311828613\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 60, batch train loss: 6.862267017364502\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 61, batch train loss: 6.884939670562744\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 62, batch train loss: 7.457799434661865\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 63, batch train loss: 4.708134651184082\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 64, batch train loss: 11.088469505310059\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 65, batch train loss: 6.014289379119873\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 66, batch train loss: 5.033370018005371\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 67, batch train loss: 8.531377792358398\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 68, batch train loss: 10.827864646911621\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 69, batch train loss: 5.9967570304870605\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 70, batch train loss: 7.124434471130371\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 71, batch train loss: 5.714239597320557\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 72, batch train loss: 8.345041275024414\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 73, batch train loss: 9.006739616394043\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 74, batch train loss: 4.952412128448486\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 75, batch train loss: 8.474458694458008\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 76, batch train loss: 6.771831035614014\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 77, batch train loss: 7.283390998840332\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 78, batch train loss: 6.484955310821533\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 79, batch train loss: 6.696743011474609\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 80, batch train loss: 6.37185001373291\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 81, batch train loss: 6.658435344696045\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 82, batch train loss: 6.43131160736084\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 83, batch train loss: 6.235782146453857\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 84, batch train loss: 5.013362407684326\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 85, batch train loss: 4.679471015930176\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 86, batch train loss: 5.25326681137085\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 87, batch train loss: 5.077170372009277\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 88, batch train loss: 4.1391167640686035\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 89, batch train loss: 3.4410502910614014\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 90, batch train loss: 3.4549553394317627\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 91, batch train loss: 3.5854790210723877\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 92, batch train loss: 2.9378511905670166\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 93, batch train loss: 4.27963399887085\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 94, batch train loss: 4.945291996002197\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 95, batch train loss: 3.9999918937683105\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 96, batch train loss: 3.906040906906128\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 97, batch train loss: 4.29502534866333\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 98, batch train loss: 3.884258985519409\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 99, batch train loss: 4.23997688293457\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 100, batch train loss: 3.1881027221679688\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 101, batch train loss: 2.8545713424682617\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 102, batch train loss: 2.7545979022979736\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 103, batch train loss: 2.6730246543884277\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 104, batch train loss: 3.2478690147399902\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 105, batch train loss: 3.246591806411743\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 106, batch train loss: 2.757807731628418\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 107, batch train loss: 3.3776330947875977\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 108, batch train loss: 2.560472011566162\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 109, batch train loss: 2.8169825077056885\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 110, batch train loss: 2.660527229309082\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 111, batch train loss: 2.170424461364746\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 112, batch train loss: 2.6918249130249023\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 113, batch train loss: 2.5053610801696777\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 114, batch train loss: 2.5359318256378174\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 115, batch train loss: 2.700273275375366\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 116, batch train loss: 2.360494613647461\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 117, batch train loss: 3.0842111110687256\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 118, batch train loss: 3.056514024734497\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 119, batch train loss: 2.4091806411743164\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 120, batch train loss: 2.21986985206604\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 121, batch train loss: 3.009075403213501\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 122, batch train loss: 2.4369418621063232\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 123, batch train loss: 3.3502254486083984\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 124, batch train loss: 2.7465827465057373\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 125, batch train loss: 3.6567671298980713\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 126, batch train loss: 3.5009396076202393\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 127, batch train loss: 2.1663408279418945\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 128, batch train loss: 2.2922372817993164\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 129, batch train loss: 2.691354751586914\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 130, batch train loss: 4.097283840179443\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68, batch_id: 131, batch train loss: 3.365995407104492\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 132, batch train loss: 3.219815731048584\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 133, batch train loss: 4.779303550720215\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 134, batch train loss: 3.3693978786468506\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 135, batch train loss: 3.3069138526916504\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 136, batch train loss: 4.070620059967041\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 137, batch train loss: 4.921238899230957\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 138, batch train loss: 4.702779769897461\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 139, batch train loss: 4.569213390350342\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 140, batch train loss: 4.0190205574035645\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 141, batch train loss: 4.302981853485107\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 142, batch train loss: 4.4107584953308105\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 143, batch train loss: 4.4472551345825195\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 144, batch train loss: 4.8234543800354\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 145, batch train loss: 4.952417850494385\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 146, batch train loss: 5.046125411987305\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 147, batch train loss: 4.974951267242432\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 148, batch train loss: 5.460902214050293\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 149, batch train loss: 5.139780044555664\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 150, batch train loss: 5.364487648010254\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 151, batch train loss: 6.278260231018066\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 152, batch train loss: 5.492964267730713\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 153, batch train loss: 4.784322261810303\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 154, batch train loss: 5.369688987731934\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 155, batch train loss: 5.590884208679199\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 156, batch train loss: 5.017593860626221\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 157, batch train loss: 5.56147575378418\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 158, batch train loss: 4.995331287384033\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 159, batch train loss: 5.475866317749023\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 160, batch train loss: 4.878544330596924\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 161, batch train loss: 5.25639009475708\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 162, batch train loss: 5.376115798950195\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 163, batch train loss: 5.233802318572998\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 164, batch train loss: 5.257674217224121\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 165, batch train loss: 4.81692361831665\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 166, batch train loss: 4.703528881072998\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 167, batch train loss: 4.7057976722717285\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 168, batch train loss: 4.948350429534912\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 169, batch train loss: 5.455705165863037\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 170, batch train loss: 4.575923919677734\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 171, batch train loss: 4.792163848876953\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 172, batch train loss: 4.751162528991699\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 173, batch train loss: 4.406668663024902\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 174, batch train loss: 5.138631820678711\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 175, batch train loss: 4.731391429901123\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 176, batch train loss: 5.0313005447387695\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 177, batch train loss: 4.529863357543945\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 178, batch train loss: 4.370742321014404\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 179, batch train loss: 4.4358110427856445\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 180, batch train loss: 4.203607559204102\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 181, batch train loss: 5.599315643310547\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 182, batch train loss: 5.477982044219971\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 183, batch train loss: 5.031238555908203\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 184, batch train loss: 4.5448408126831055\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 185, batch train loss: 4.12100076675415\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 186, batch train loss: 3.9781932830810547\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 187, batch train loss: 4.7792792320251465\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 188, batch train loss: 4.978869915008545\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 189, batch train loss: 5.140596866607666\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 190, batch train loss: 4.194967269897461\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 191, batch train loss: 3.9701573848724365\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 192, batch train loss: 4.113821506500244\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 193, batch train loss: 4.357712745666504\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 194, batch train loss: 4.5557861328125\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 195, batch train loss: 4.649465560913086\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 196, batch train loss: 4.588883399963379\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 197, batch train loss: 4.443454742431641\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 198, batch train loss: 4.259142875671387\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 199, batch train loss: 4.2430877685546875\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 200, batch train loss: 4.738330841064453\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 201, batch train loss: 4.659963607788086\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 202, batch train loss: 4.22882604598999\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 203, batch train loss: 4.359466075897217\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 204, batch train loss: 3.6780216693878174\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 205, batch train loss: 4.331472396850586\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 206, batch train loss: 4.478034973144531\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 207, batch train loss: 4.407393455505371\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 208, batch train loss: 3.7681820392608643\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 209, batch train loss: 3.8713362216949463\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 210, batch train loss: 3.997021436691284\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 211, batch train loss: 3.9010655879974365\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 212, batch train loss: 3.823136329650879\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 213, batch train loss: 4.513705253601074\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 214, batch train loss: 4.141472339630127\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 215, batch train loss: 4.0031561851501465\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 216, batch train loss: 3.2933406829833984\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 217, batch train loss: 3.9480819702148438\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 218, batch train loss: 3.649106502532959\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 219, batch train loss: 3.293374538421631\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 220, batch train loss: 2.715587615966797\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 221, batch train loss: 3.2855758666992188\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 222, batch train loss: 2.977898120880127\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 223, batch train loss: 3.6053922176361084\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 224, batch train loss: 3.5201187133789062\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 225, batch train loss: 3.6975016593933105\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 226, batch train loss: 3.3050360679626465\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 227, batch train loss: 2.906611680984497\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 228, batch train loss: 3.878815174102783\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 229, batch train loss: 3.2340328693389893\n",
      "\n",
      "\n",
      "Epoch: 68, batch_id: 230, batch train loss: 3.6946980953216553\n",
      "\n",
      "\n",
      "Epoch: 68/ 100, Loss: 4.999181856279788\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:11<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 Validation Loss: 3.8614782174428304\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, batch_id: 1, batch train loss: 4.5025634765625\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 2, batch train loss: 3.6913387775421143\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 3, batch train loss: 3.4694697856903076\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 4, batch train loss: 3.3075613975524902\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 5, batch train loss: 3.1482272148132324\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 6, batch train loss: 3.777496337890625\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 7, batch train loss: 4.1564106941223145\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 8, batch train loss: 3.6209683418273926\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 9, batch train loss: 4.1193366050720215\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 10, batch train loss: 3.6538684368133545\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 11, batch train loss: 3.967987537384033\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 12, batch train loss: 3.743795871734619\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 13, batch train loss: 4.206296920776367\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 14, batch train loss: 4.505920886993408\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 15, batch train loss: 3.687670946121216\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 16, batch train loss: 3.5930025577545166\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 17, batch train loss: 4.3577561378479\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 18, batch train loss: 4.609671115875244\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 19, batch train loss: 4.916111469268799\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 20, batch train loss: 4.831668853759766\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 21, batch train loss: 4.6715803146362305\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 22, batch train loss: 4.281931400299072\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 23, batch train loss: 3.9283268451690674\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 24, batch train loss: 4.183925151824951\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 25, batch train loss: 3.682086944580078\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 26, batch train loss: 3.5712592601776123\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 27, batch train loss: 4.409197807312012\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 28, batch train loss: 3.649099111557007\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 29, batch train loss: 3.4493160247802734\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 30, batch train loss: 3.3190009593963623\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 31, batch train loss: 3.492431640625\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 32, batch train loss: 3.517151355743408\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 33, batch train loss: 3.484874963760376\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 34, batch train loss: 3.349421501159668\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 35, batch train loss: 2.8885185718536377\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 36, batch train loss: 3.280054807662964\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 37, batch train loss: 4.460886001586914\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 38, batch train loss: 3.776083469390869\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 39, batch train loss: 3.8566830158233643\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 40, batch train loss: 4.097362995147705\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 41, batch train loss: 4.185999870300293\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 42, batch train loss: 4.744140148162842\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 43, batch train loss: 3.6281824111938477\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 44, batch train loss: 4.206763744354248\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 45, batch train loss: 4.913161277770996\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 46, batch train loss: 4.321862697601318\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 47, batch train loss: 4.785398960113525\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 48, batch train loss: 6.197014331817627\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 49, batch train loss: 5.372299671173096\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 50, batch train loss: 4.346218109130859\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 51, batch train loss: 4.642675876617432\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 52, batch train loss: 5.599373817443848\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 53, batch train loss: 4.700953960418701\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 54, batch train loss: 4.5779571533203125\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 55, batch train loss: 4.562845230102539\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 56, batch train loss: 4.429662227630615\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 57, batch train loss: 4.585824012756348\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 58, batch train loss: 5.292072296142578\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 59, batch train loss: 4.19899845123291\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 60, batch train loss: 4.4373016357421875\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 61, batch train loss: 5.738818168640137\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 62, batch train loss: 5.051912307739258\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 63, batch train loss: 4.689452171325684\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 64, batch train loss: 3.9212307929992676\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 65, batch train loss: 3.806957960128784\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 66, batch train loss: 3.3828811645507812\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 67, batch train loss: 3.5222830772399902\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 68, batch train loss: 4.118261337280273\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 69, batch train loss: 3.507674217224121\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 70, batch train loss: 3.224808692932129\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 71, batch train loss: 2.7394235134124756\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 72, batch train loss: 2.44994854927063\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 73, batch train loss: 2.1860015392303467\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 74, batch train loss: 2.045029640197754\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 75, batch train loss: 2.76822829246521\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 76, batch train loss: 2.869197130203247\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 77, batch train loss: 2.208517551422119\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 78, batch train loss: 2.4892170429229736\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 79, batch train loss: 2.7178573608398438\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 80, batch train loss: 3.004737377166748\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 81, batch train loss: 2.7364652156829834\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 82, batch train loss: 3.2723045349121094\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 83, batch train loss: 2.8872311115264893\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 84, batch train loss: 3.3335771560668945\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 85, batch train loss: 3.0736517906188965\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 86, batch train loss: 2.8093879222869873\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 87, batch train loss: 2.7778515815734863\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 88, batch train loss: 2.8910250663757324\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 89, batch train loss: 2.6088271141052246\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 90, batch train loss: 2.7252607345581055\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 91, batch train loss: 2.6814124584198\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 92, batch train loss: 2.329373836517334\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 93, batch train loss: 2.3409152030944824\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 94, batch train loss: 2.5074477195739746\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 95, batch train loss: 2.9299402236938477\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 96, batch train loss: 2.2990481853485107\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 97, batch train loss: 1.887205958366394\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 98, batch train loss: 2.115813970565796\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 99, batch train loss: 1.7920981645584106\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 100, batch train loss: 1.8105820417404175\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 101, batch train loss: 2.5663278102874756\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 102, batch train loss: 2.760303258895874\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 103, batch train loss: 2.529726266860962\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 104, batch train loss: 2.517533779144287\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 105, batch train loss: 2.2025134563446045\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 106, batch train loss: 1.9992235898971558\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 107, batch train loss: 2.52612566947937\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 108, batch train loss: 2.251018762588501\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 109, batch train loss: 1.9998024702072144\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 110, batch train loss: 2.2589590549468994\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 111, batch train loss: 1.686669111251831\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 112, batch train loss: 1.6003031730651855\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 113, batch train loss: 2.006857395172119\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 114, batch train loss: 2.8463802337646484\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 115, batch train loss: 5.424905776977539\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 116, batch train loss: 7.503605842590332\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 117, batch train loss: 8.088035583496094\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 118, batch train loss: 7.750093460083008\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 119, batch train loss: 7.443680763244629\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 120, batch train loss: 7.630865097045898\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 121, batch train loss: 5.132067680358887\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 122, batch train loss: 7.125192165374756\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 123, batch train loss: 7.024752616882324\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 124, batch train loss: 7.201287269592285\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 125, batch train loss: 7.570274829864502\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 126, batch train loss: 6.359458923339844\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 127, batch train loss: 6.404399871826172\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 128, batch train loss: 7.0740203857421875\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 129, batch train loss: 7.326009750366211\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 130, batch train loss: 8.342293739318848\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69, batch_id: 131, batch train loss: 7.496882915496826\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 132, batch train loss: 7.620757579803467\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 133, batch train loss: 7.741891384124756\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 134, batch train loss: 8.262688636779785\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 135, batch train loss: 9.69210433959961\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 136, batch train loss: 8.323424339294434\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 137, batch train loss: 9.090902328491211\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 138, batch train loss: 8.851300239562988\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 139, batch train loss: 8.234183311462402\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 140, batch train loss: 10.29724407196045\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 141, batch train loss: 9.319313049316406\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 142, batch train loss: 9.61194896697998\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 143, batch train loss: 9.25971794128418\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 144, batch train loss: 8.585454940795898\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 145, batch train loss: 8.578883171081543\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 146, batch train loss: 9.12081241607666\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 147, batch train loss: 8.045679092407227\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 148, batch train loss: 9.244894027709961\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 149, batch train loss: 7.403404235839844\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 150, batch train loss: 8.979754447937012\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 151, batch train loss: 7.932469844818115\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 152, batch train loss: 8.005061149597168\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 153, batch train loss: 8.574176788330078\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 154, batch train loss: 8.746750831604004\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 155, batch train loss: 7.6367082595825195\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 156, batch train loss: 7.7488322257995605\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 157, batch train loss: 5.9305901527404785\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 158, batch train loss: 5.556877613067627\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 159, batch train loss: 9.163387298583984\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 160, batch train loss: 4.680493354797363\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 161, batch train loss: 6.522179126739502\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 162, batch train loss: 6.755472183227539\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 163, batch train loss: 3.714548349380493\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 164, batch train loss: 5.157035827636719\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 165, batch train loss: 4.310009956359863\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 166, batch train loss: 4.927229881286621\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 167, batch train loss: 5.616950511932373\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 168, batch train loss: 4.752974033355713\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 169, batch train loss: 4.597366809844971\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 170, batch train loss: 3.920722723007202\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 171, batch train loss: 2.9100515842437744\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 172, batch train loss: 3.943937063217163\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 173, batch train loss: 4.668480396270752\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 174, batch train loss: 3.74582839012146\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 175, batch train loss: 3.2423739433288574\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 176, batch train loss: 3.472513437271118\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 177, batch train loss: 3.4803972244262695\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 178, batch train loss: 3.7198548316955566\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 179, batch train loss: 2.979907512664795\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 180, batch train loss: 3.1698570251464844\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 181, batch train loss: 3.044654369354248\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 182, batch train loss: 3.5334224700927734\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 183, batch train loss: 3.8461661338806152\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 184, batch train loss: 3.36331844329834\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 185, batch train loss: 2.744114398956299\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 186, batch train loss: 2.795652389526367\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 187, batch train loss: 3.8081393241882324\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 188, batch train loss: 3.5711209774017334\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 189, batch train loss: 2.6608524322509766\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 190, batch train loss: 2.4841198921203613\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 191, batch train loss: 3.4350194931030273\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 192, batch train loss: 2.5947816371917725\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 193, batch train loss: 3.4798567295074463\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 194, batch train loss: 4.227397918701172\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 195, batch train loss: 2.910937786102295\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 196, batch train loss: 3.4343740940093994\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 197, batch train loss: 3.5218570232391357\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 198, batch train loss: 3.572512626647949\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 199, batch train loss: 5.377786159515381\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 200, batch train loss: 3.4220032691955566\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 201, batch train loss: 3.2304530143737793\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 202, batch train loss: 2.5299088954925537\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 203, batch train loss: 3.453786611557007\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 204, batch train loss: 3.4979093074798584\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 205, batch train loss: 3.9106478691101074\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 206, batch train loss: 2.9957406520843506\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 207, batch train loss: 3.9943840503692627\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 208, batch train loss: 3.023744583129883\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 209, batch train loss: 3.363734245300293\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 210, batch train loss: 3.5447311401367188\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 211, batch train loss: 4.680382251739502\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 212, batch train loss: 3.5520272254943848\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 213, batch train loss: 3.554457187652588\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 214, batch train loss: 3.7605957984924316\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 215, batch train loss: 3.3047869205474854\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 216, batch train loss: 3.7813174724578857\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 217, batch train loss: 6.121997356414795\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 218, batch train loss: 3.0238187313079834\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 219, batch train loss: 3.519334316253662\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 220, batch train loss: 4.392751693725586\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 221, batch train loss: 5.852626323699951\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 222, batch train loss: 5.197362422943115\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 223, batch train loss: 3.8518688678741455\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 224, batch train loss: 3.7020339965820312\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 225, batch train loss: 2.7102506160736084\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 226, batch train loss: 3.048520803451538\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 227, batch train loss: 3.328035593032837\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 228, batch train loss: 2.453835964202881\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 229, batch train loss: 2.289900779724121\n",
      "\n",
      "\n",
      "Epoch: 69, batch_id: 230, batch train loss: 3.73508620262146\n",
      "\n",
      "\n",
      "Epoch: 69/ 100, Loss: 4.447512892536495\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:14<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 Validation Loss: 2.3899471084276835\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, batch_id: 1, batch train loss: 2.0543205738067627\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 2, batch train loss: 2.1503372192382812\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 3, batch train loss: 2.6895477771759033\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 4, batch train loss: 2.8540711402893066\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 5, batch train loss: 2.492913007736206\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 6, batch train loss: 2.5126965045928955\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 7, batch train loss: 2.308175563812256\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 8, batch train loss: 2.5271029472351074\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 9, batch train loss: 2.7667758464813232\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 10, batch train loss: 2.965395212173462\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 11, batch train loss: 2.3240294456481934\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 12, batch train loss: 3.446978807449341\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 13, batch train loss: 3.8228447437286377\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 14, batch train loss: 4.806173324584961\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 15, batch train loss: 5.2982563972473145\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 16, batch train loss: 4.614218235015869\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 17, batch train loss: 2.932739734649658\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 18, batch train loss: 4.147908687591553\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 19, batch train loss: 4.611184120178223\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 20, batch train loss: 6.0735182762146\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 21, batch train loss: 5.212991237640381\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 22, batch train loss: 5.017315864562988\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 23, batch train loss: 5.435237407684326\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 24, batch train loss: 8.56555461883545\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 25, batch train loss: 5.662901878356934\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 26, batch train loss: 9.138041496276855\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 27, batch train loss: 7.662503242492676\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 28, batch train loss: 7.995972633361816\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 29, batch train loss: 9.458423614501953\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 30, batch train loss: 7.565495491027832\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 31, batch train loss: 10.496030807495117\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 32, batch train loss: 10.636353492736816\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 33, batch train loss: 11.843331336975098\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 34, batch train loss: 12.621126174926758\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 35, batch train loss: 12.764872550964355\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 36, batch train loss: 14.375755310058594\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 37, batch train loss: 10.651930809020996\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 38, batch train loss: 12.527506828308105\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 39, batch train loss: 11.70656967163086\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 40, batch train loss: 10.877965927124023\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 41, batch train loss: 12.687895774841309\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 42, batch train loss: 12.612366676330566\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 43, batch train loss: 9.874738693237305\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 44, batch train loss: 13.147268295288086\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 45, batch train loss: 12.488577842712402\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 46, batch train loss: 9.975528717041016\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 47, batch train loss: 11.141525268554688\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 48, batch train loss: 10.81675910949707\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 49, batch train loss: 8.810530662536621\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 50, batch train loss: 9.302120208740234\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 51, batch train loss: 8.541498184204102\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 52, batch train loss: 7.826442718505859\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 53, batch train loss: 9.092185020446777\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 54, batch train loss: 7.463969707489014\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 55, batch train loss: 7.241548538208008\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 56, batch train loss: 6.629185199737549\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 57, batch train loss: 5.71688985824585\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 58, batch train loss: 6.894099712371826\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 59, batch train loss: 7.365761756896973\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 60, batch train loss: 5.4908976554870605\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 61, batch train loss: 5.368086338043213\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 62, batch train loss: 5.278480052947998\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 63, batch train loss: 5.7283759117126465\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 64, batch train loss: 5.208186626434326\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 65, batch train loss: 4.678904056549072\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 66, batch train loss: 5.239022254943848\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 67, batch train loss: 4.544865608215332\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 68, batch train loss: 4.396544456481934\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 69, batch train loss: 4.394011974334717\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 70, batch train loss: 4.233736991882324\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 71, batch train loss: 4.062091827392578\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 72, batch train loss: 3.6774964332580566\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 73, batch train loss: 3.540457248687744\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 74, batch train loss: 4.141211986541748\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 75, batch train loss: 4.329279899597168\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 76, batch train loss: 3.5644359588623047\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 77, batch train loss: 2.9562184810638428\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 78, batch train loss: 2.801753044128418\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 79, batch train loss: 3.4169299602508545\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 80, batch train loss: 3.967395067214966\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 81, batch train loss: 2.9787542819976807\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 82, batch train loss: 3.400829792022705\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 83, batch train loss: 2.8962063789367676\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 84, batch train loss: 3.843440294265747\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 85, batch train loss: 3.7648062705993652\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 86, batch train loss: 3.6400043964385986\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 87, batch train loss: 3.709480047225952\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 88, batch train loss: 3.5822412967681885\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 89, batch train loss: 2.945169448852539\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 90, batch train loss: 3.340503454208374\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 91, batch train loss: 3.062814712524414\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 92, batch train loss: 2.8207404613494873\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 93, batch train loss: 3.121903657913208\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 94, batch train loss: 3.7725117206573486\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 95, batch train loss: 3.7535970211029053\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 96, batch train loss: 2.818901300430298\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 97, batch train loss: 3.2544620037078857\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 98, batch train loss: 3.182765483856201\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 99, batch train loss: 4.072057247161865\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 100, batch train loss: 4.455467224121094\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 101, batch train loss: 4.60698938369751\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 102, batch train loss: 4.961482524871826\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 103, batch train loss: 5.630467891693115\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 104, batch train loss: 4.731492042541504\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 105, batch train loss: 6.468742847442627\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 106, batch train loss: 6.134391784667969\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 107, batch train loss: 7.046485424041748\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 108, batch train loss: 5.618525981903076\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 109, batch train loss: 5.520410060882568\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 110, batch train loss: 6.006107330322266\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 111, batch train loss: 5.864640235900879\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 112, batch train loss: 6.600010871887207\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 113, batch train loss: 6.552661418914795\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 114, batch train loss: 7.904679298400879\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 115, batch train loss: 7.0692458152771\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 116, batch train loss: 7.288104057312012\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 117, batch train loss: 6.33066987991333\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 118, batch train loss: 6.899204730987549\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 119, batch train loss: 6.9380950927734375\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 120, batch train loss: 6.82181978225708\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 121, batch train loss: 6.738467693328857\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 122, batch train loss: 7.042369842529297\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 123, batch train loss: 7.873955249786377\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 124, batch train loss: 7.766002655029297\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 125, batch train loss: 7.7974724769592285\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 126, batch train loss: 7.203256607055664\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 127, batch train loss: 8.365374565124512\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 128, batch train loss: 8.692695617675781\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 129, batch train loss: 8.423120498657227\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 130, batch train loss: 8.360881805419922\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, batch_id: 131, batch train loss: 8.184284210205078\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 132, batch train loss: 8.202451705932617\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 133, batch train loss: 8.222954750061035\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 134, batch train loss: 7.376420021057129\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 135, batch train loss: 7.628292560577393\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 136, batch train loss: 7.595369338989258\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 137, batch train loss: 6.204277515411377\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 138, batch train loss: 7.397899627685547\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 139, batch train loss: 7.039539337158203\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 140, batch train loss: 6.673686981201172\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 141, batch train loss: 6.209754467010498\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 142, batch train loss: 6.996305465698242\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 143, batch train loss: 8.042106628417969\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 144, batch train loss: 5.401349067687988\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 145, batch train loss: 6.135261058807373\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 146, batch train loss: 6.349707126617432\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 147, batch train loss: 6.2548508644104\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 148, batch train loss: 6.405888557434082\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 149, batch train loss: 5.187774658203125\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 150, batch train loss: 6.905190467834473\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 151, batch train loss: 6.5194292068481445\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 152, batch train loss: 5.382991313934326\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 153, batch train loss: 4.664830684661865\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 154, batch train loss: 5.6164374351501465\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 155, batch train loss: 8.185399055480957\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 156, batch train loss: 5.887319087982178\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 157, batch train loss: 6.464634418487549\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 158, batch train loss: 4.839240074157715\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 159, batch train loss: 5.869624614715576\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 160, batch train loss: 5.727771282196045\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 161, batch train loss: 6.662238121032715\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 162, batch train loss: 5.6428351402282715\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 163, batch train loss: 4.500050067901611\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 164, batch train loss: 5.114579200744629\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 165, batch train loss: 4.937400817871094\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 166, batch train loss: 5.471749782562256\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 167, batch train loss: 5.017687797546387\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 168, batch train loss: 4.091466426849365\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 169, batch train loss: 4.382447242736816\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 170, batch train loss: 3.8416357040405273\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 171, batch train loss: 3.9205362796783447\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 172, batch train loss: 4.229779243469238\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 173, batch train loss: 4.370589256286621\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 174, batch train loss: 4.460048198699951\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 175, batch train loss: 3.8455166816711426\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 176, batch train loss: 3.3850419521331787\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 177, batch train loss: 3.9209065437316895\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 178, batch train loss: 3.2118606567382812\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 179, batch train loss: 3.9926528930664062\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 180, batch train loss: 3.352396249771118\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 181, batch train loss: 3.770660877227783\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 182, batch train loss: 3.076873779296875\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 183, batch train loss: 3.2684290409088135\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 184, batch train loss: 2.4494998455047607\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 185, batch train loss: 3.086775541305542\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 186, batch train loss: 3.585256814956665\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 187, batch train loss: 3.1215431690216064\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 188, batch train loss: 2.9555232524871826\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 189, batch train loss: 3.3979833126068115\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 190, batch train loss: 2.839444875717163\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 191, batch train loss: 3.490780830383301\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 192, batch train loss: 5.340143203735352\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 193, batch train loss: 2.514561414718628\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 194, batch train loss: 4.504884719848633\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 195, batch train loss: 3.846919059753418\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 196, batch train loss: 3.369105815887451\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 197, batch train loss: 3.121887683868408\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 198, batch train loss: 5.7912278175354\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 199, batch train loss: 2.3773255348205566\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 200, batch train loss: 3.1209917068481445\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 201, batch train loss: 4.093255043029785\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 202, batch train loss: 2.6934878826141357\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 203, batch train loss: 3.818547010421753\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 204, batch train loss: 4.489835262298584\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 205, batch train loss: 5.070688247680664\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 206, batch train loss: 3.764468193054199\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 207, batch train loss: 3.7475314140319824\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 208, batch train loss: 3.359034776687622\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 209, batch train loss: 3.4014511108398438\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 210, batch train loss: 3.440154552459717\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 211, batch train loss: 2.472970724105835\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 212, batch train loss: 2.9888951778411865\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 213, batch train loss: 3.578206777572632\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 214, batch train loss: 2.988485336303711\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 215, batch train loss: 2.9390649795532227\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 216, batch train loss: 3.2538862228393555\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 217, batch train loss: 3.050009250640869\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 218, batch train loss: 3.014493465423584\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 219, batch train loss: 3.3760836124420166\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 220, batch train loss: 2.9651682376861572\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 221, batch train loss: 2.4190003871917725\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 222, batch train loss: 2.970961332321167\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 223, batch train loss: 2.2197799682617188\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 224, batch train loss: 2.523805856704712\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 225, batch train loss: 2.325535774230957\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 226, batch train loss: 2.4970312118530273\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 227, batch train loss: 2.2834646701812744\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 228, batch train loss: 2.445671558380127\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 229, batch train loss: 2.3512213230133057\n",
      "\n",
      "\n",
      "Epoch: 70, batch_id: 230, batch train loss: 2.5353927612304688\n",
      "\n",
      "\n",
      "Epoch: 70/ 100, Loss: 5.417246443292369\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:11<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70 Validation Loss: 2.3414855817953746\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71, batch_id: 1, batch train loss: 1.8292152881622314\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 2, batch train loss: 2.857553005218506\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 3, batch train loss: 3.0609099864959717\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 4, batch train loss: 2.203601598739624\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 5, batch train loss: 2.779717206954956\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 6, batch train loss: 3.231827735900879\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 7, batch train loss: 4.129422187805176\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 8, batch train loss: 4.876719951629639\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 9, batch train loss: 3.898444890975952\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 10, batch train loss: 3.2770726680755615\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 11, batch train loss: 3.213498115539551\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 12, batch train loss: 3.3933799266815186\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 13, batch train loss: 2.4911067485809326\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 14, batch train loss: 2.9485855102539062\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 15, batch train loss: 3.9612374305725098\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 16, batch train loss: 3.188908815383911\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 17, batch train loss: 2.5545473098754883\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 18, batch train loss: 2.660224676132202\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 19, batch train loss: 2.0301520824432373\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 20, batch train loss: 2.1312217712402344\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 21, batch train loss: 1.9788786172866821\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 22, batch train loss: 2.022686243057251\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 23, batch train loss: 4.903990268707275\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 24, batch train loss: 4.034467697143555\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 25, batch train loss: 3.3214049339294434\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 26, batch train loss: 2.971287250518799\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 27, batch train loss: 3.209362745285034\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 28, batch train loss: 3.9785587787628174\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 29, batch train loss: 2.348841428756714\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 30, batch train loss: 2.9389021396636963\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 31, batch train loss: 2.9032280445098877\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 32, batch train loss: 1.8938134908676147\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 33, batch train loss: 2.4328081607818604\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 34, batch train loss: 2.9436604976654053\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 35, batch train loss: 2.241609811782837\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 36, batch train loss: 2.4106500148773193\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 37, batch train loss: 2.014655828475952\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 38, batch train loss: 1.9452394247055054\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 39, batch train loss: 2.3101491928100586\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 40, batch train loss: 1.9558268785476685\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 41, batch train loss: 2.3089725971221924\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 42, batch train loss: 2.589146375656128\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 43, batch train loss: 1.909666895866394\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 44, batch train loss: 1.48453688621521\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 45, batch train loss: 2.520458698272705\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 46, batch train loss: 2.1508569717407227\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 47, batch train loss: 2.1513428688049316\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 48, batch train loss: 2.5832996368408203\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 49, batch train loss: 1.7170217037200928\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 50, batch train loss: 1.8334451913833618\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 51, batch train loss: 1.6977348327636719\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 52, batch train loss: 1.9368774890899658\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 53, batch train loss: 2.069730281829834\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 54, batch train loss: 1.6920833587646484\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 55, batch train loss: 1.9533109664916992\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 56, batch train loss: 1.9573317766189575\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 57, batch train loss: 2.402590274810791\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 58, batch train loss: 1.8976680040359497\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 59, batch train loss: 2.204296350479126\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 60, batch train loss: 2.225677490234375\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 61, batch train loss: 1.5876368284225464\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 62, batch train loss: 1.810289740562439\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 63, batch train loss: 2.036771535873413\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 64, batch train loss: 1.9588466882705688\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 65, batch train loss: 2.073723554611206\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 66, batch train loss: 2.3065905570983887\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 67, batch train loss: 1.7457104921340942\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 68, batch train loss: 2.723939895629883\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 69, batch train loss: 2.2727668285369873\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 70, batch train loss: 2.0646674633026123\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 71, batch train loss: 2.465787172317505\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 72, batch train loss: 1.7771151065826416\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 73, batch train loss: 1.836698055267334\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 74, batch train loss: 2.4585492610931396\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 75, batch train loss: 1.8298720121383667\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 76, batch train loss: 1.8049863576889038\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 77, batch train loss: 1.4710935354232788\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 78, batch train loss: 1.6376394033432007\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 79, batch train loss: 1.6754313707351685\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 80, batch train loss: 2.0588488578796387\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 81, batch train loss: 2.231264352798462\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 82, batch train loss: 2.1054022312164307\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 83, batch train loss: 2.445812225341797\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 84, batch train loss: 2.438716411590576\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 85, batch train loss: 4.039047718048096\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 86, batch train loss: 2.156209707260132\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 87, batch train loss: 3.7105257511138916\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 88, batch train loss: 4.551848411560059\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 89, batch train loss: 2.7828404903411865\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 90, batch train loss: 3.814696788787842\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 91, batch train loss: 3.8239498138427734\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 92, batch train loss: 3.3523108959198\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 93, batch train loss: 2.766756296157837\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 94, batch train loss: 2.637645721435547\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 95, batch train loss: 6.403512477874756\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 96, batch train loss: 5.009792804718018\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 97, batch train loss: 3.134140729904175\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 98, batch train loss: 5.943950176239014\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 99, batch train loss: 7.709379196166992\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 100, batch train loss: 9.58858585357666\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 101, batch train loss: 10.842965126037598\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 102, batch train loss: 7.284641742706299\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 103, batch train loss: 9.014042854309082\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 104, batch train loss: 9.818249702453613\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 105, batch train loss: 18.006641387939453\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 106, batch train loss: 22.352367401123047\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 107, batch train loss: 30.80735969543457\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 108, batch train loss: 7.49922513961792\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 109, batch train loss: 24.551136016845703\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 110, batch train loss: 7.048216342926025\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 111, batch train loss: 27.949264526367188\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 112, batch train loss: 19.64128875732422\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 113, batch train loss: 26.71593475341797\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 114, batch train loss: 21.919038772583008\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 115, batch train loss: 14.962418556213379\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 116, batch train loss: 18.88385009765625\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 117, batch train loss: 30.132923126220703\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 118, batch train loss: 15.3136568069458\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 119, batch train loss: 19.27167320251465\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 120, batch train loss: 9.927494049072266\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 121, batch train loss: 6.988071441650391\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 122, batch train loss: 10.00383472442627\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 123, batch train loss: 6.857638359069824\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 124, batch train loss: 12.779719352722168\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 125, batch train loss: 11.25763988494873\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 126, batch train loss: 8.084359169006348\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 127, batch train loss: 16.669530868530273\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 128, batch train loss: 6.401378154754639\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 129, batch train loss: 6.145418167114258\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71, batch_id: 130, batch train loss: 7.49776029586792\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 131, batch train loss: 7.54506254196167\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 132, batch train loss: 6.2451324462890625\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 133, batch train loss: 6.098833084106445\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 134, batch train loss: 6.289066791534424\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 135, batch train loss: 6.797426223754883\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 136, batch train loss: 3.8975796699523926\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 137, batch train loss: 4.249574661254883\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 138, batch train loss: 5.129714012145996\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 139, batch train loss: 6.724130153656006\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 140, batch train loss: 5.666532039642334\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 141, batch train loss: 4.353609561920166\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 142, batch train loss: 6.979425430297852\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 143, batch train loss: 4.275911331176758\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 144, batch train loss: 12.731060028076172\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 145, batch train loss: 11.255624771118164\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 146, batch train loss: 11.172093391418457\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 147, batch train loss: 8.586938858032227\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 148, batch train loss: 7.849152088165283\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 149, batch train loss: 10.950957298278809\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 150, batch train loss: 7.637385845184326\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 151, batch train loss: 8.44438362121582\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 152, batch train loss: 6.719226837158203\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 153, batch train loss: 11.345444679260254\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 154, batch train loss: 14.654451370239258\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 155, batch train loss: 19.789302825927734\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 156, batch train loss: 27.3170108795166\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 157, batch train loss: 18.243663787841797\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 158, batch train loss: 15.859399795532227\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 159, batch train loss: 23.219797134399414\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 160, batch train loss: 27.778039932250977\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 161, batch train loss: 40.50460433959961\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 162, batch train loss: 28.906139373779297\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 163, batch train loss: 36.1323127746582\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 164, batch train loss: 25.140670776367188\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 165, batch train loss: 36.1823616027832\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 166, batch train loss: 23.30655860900879\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 167, batch train loss: 24.386245727539062\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 168, batch train loss: 38.12019729614258\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 169, batch train loss: 24.4481258392334\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 170, batch train loss: 18.511648178100586\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 171, batch train loss: 23.013261795043945\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 172, batch train loss: 23.192031860351562\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 173, batch train loss: 21.092670440673828\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 174, batch train loss: 19.26435661315918\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 175, batch train loss: 21.679960250854492\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 176, batch train loss: 14.637578010559082\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 177, batch train loss: 14.866402626037598\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 178, batch train loss: 14.192065238952637\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 179, batch train loss: 14.595977783203125\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 180, batch train loss: 16.071800231933594\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 181, batch train loss: 8.636338233947754\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 182, batch train loss: 13.791816711425781\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 183, batch train loss: 14.385390281677246\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 184, batch train loss: 12.19647216796875\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 185, batch train loss: 9.285707473754883\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 186, batch train loss: 9.509162902832031\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 187, batch train loss: 9.712284088134766\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 188, batch train loss: 8.110342979431152\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 189, batch train loss: 8.639302253723145\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 190, batch train loss: 8.686041831970215\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 191, batch train loss: 10.184234619140625\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 192, batch train loss: 9.899291038513184\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 193, batch train loss: 7.790984630584717\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 194, batch train loss: 12.43923568725586\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 195, batch train loss: 8.352733612060547\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 196, batch train loss: 9.35534381866455\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 197, batch train loss: 8.27403736114502\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 198, batch train loss: 7.959044456481934\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 199, batch train loss: 7.685486793518066\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 200, batch train loss: 8.480428695678711\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 201, batch train loss: 5.984611988067627\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 202, batch train loss: 6.243231773376465\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 203, batch train loss: 6.272693634033203\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 204, batch train loss: 7.231843948364258\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 205, batch train loss: 6.594714641571045\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 206, batch train loss: 10.179036140441895\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 207, batch train loss: 8.145858764648438\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 208, batch train loss: 7.179478168487549\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 209, batch train loss: 7.606344223022461\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 210, batch train loss: 8.569680213928223\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 211, batch train loss: 15.653626441955566\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 212, batch train loss: 10.675387382507324\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 213, batch train loss: 13.996440887451172\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 214, batch train loss: 15.170612335205078\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 215, batch train loss: 20.22237777709961\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 216, batch train loss: 29.643291473388672\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 217, batch train loss: 36.43533706665039\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 218, batch train loss: 63.706661224365234\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 219, batch train loss: 55.76377487182617\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 220, batch train loss: 67.363037109375\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 221, batch train loss: 67.45260620117188\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 222, batch train loss: 91.18087768554688\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 223, batch train loss: 90.9134521484375\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 224, batch train loss: 90.88687133789062\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 225, batch train loss: 114.064453125\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 226, batch train loss: 124.40608215332031\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 227, batch train loss: 80.93392944335938\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 228, batch train loss: 120.27820587158203\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 229, batch train loss: 139.7041473388672\n",
      "\n",
      "\n",
      "Epoch: 71, batch_id: 230, batch train loss: 126.53919219970703\n",
      "\n",
      "\n",
      "Epoch: 71/ 100, Loss: 13.73937802573909\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:17<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71 Validation Loss: 101.24610214233398\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, batch_id: 1, batch train loss: 96.58515930175781\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 2, batch train loss: 127.9281234741211\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 3, batch train loss: 116.78992462158203\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 4, batch train loss: 116.13253784179688\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 5, batch train loss: 79.56339263916016\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 6, batch train loss: 111.25102996826172\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 7, batch train loss: 94.72535705566406\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 8, batch train loss: 115.5068359375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 9, batch train loss: 94.1627426147461\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 10, batch train loss: 94.10336303710938\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 11, batch train loss: 82.60797882080078\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 12, batch train loss: 93.53726196289062\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 13, batch train loss: 108.10806274414062\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 14, batch train loss: 76.3897933959961\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 15, batch train loss: 83.65072631835938\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 16, batch train loss: 80.44670104980469\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 17, batch train loss: 72.76144409179688\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 18, batch train loss: 82.13297271728516\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 19, batch train loss: 74.09091186523438\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 20, batch train loss: 74.83558654785156\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 21, batch train loss: 55.273712158203125\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 22, batch train loss: 66.13809967041016\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 23, batch train loss: 66.97530364990234\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 24, batch train loss: 60.491966247558594\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 25, batch train loss: 49.162498474121094\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 26, batch train loss: 63.3601188659668\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 27, batch train loss: 49.63217544555664\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 28, batch train loss: 60.368534088134766\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 29, batch train loss: 49.465633392333984\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 30, batch train loss: 51.43633270263672\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 31, batch train loss: 44.4028434753418\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 32, batch train loss: 63.51399230957031\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 33, batch train loss: 31.237272262573242\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 34, batch train loss: 45.289241790771484\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 35, batch train loss: 61.095428466796875\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 36, batch train loss: 40.05255126953125\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 37, batch train loss: 42.05922317504883\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 38, batch train loss: 34.42696762084961\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 39, batch train loss: 48.658546447753906\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 40, batch train loss: 37.05308151245117\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 41, batch train loss: 37.64563751220703\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 42, batch train loss: 38.69798278808594\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 43, batch train loss: 30.571836471557617\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 44, batch train loss: 32.67058181762695\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 45, batch train loss: 34.358787536621094\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 46, batch train loss: 30.031490325927734\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 47, batch train loss: 32.264549255371094\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 48, batch train loss: 23.512285232543945\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 49, batch train loss: 29.21995735168457\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 50, batch train loss: 32.384925842285156\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 51, batch train loss: 35.04529571533203\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 52, batch train loss: 22.720796585083008\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 53, batch train loss: 36.558956146240234\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 54, batch train loss: 27.712858200073242\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 55, batch train loss: 32.843997955322266\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 56, batch train loss: 25.075178146362305\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 57, batch train loss: 30.977731704711914\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 58, batch train loss: 16.354999542236328\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 59, batch train loss: 28.544811248779297\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 60, batch train loss: 28.965770721435547\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 61, batch train loss: 24.101552963256836\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 62, batch train loss: 26.688791275024414\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 63, batch train loss: 20.642559051513672\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 64, batch train loss: 36.6322021484375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 65, batch train loss: 30.261972427368164\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 66, batch train loss: 21.5252742767334\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 67, batch train loss: 28.201641082763672\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 68, batch train loss: 20.949108123779297\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 69, batch train loss: 28.85626983642578\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 70, batch train loss: 21.241670608520508\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 71, batch train loss: 30.158170700073242\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 72, batch train loss: 20.464935302734375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 73, batch train loss: 21.40709114074707\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 74, batch train loss: 28.138704299926758\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 75, batch train loss: 31.673301696777344\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 76, batch train loss: 18.673765182495117\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 77, batch train loss: 22.395246505737305\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 78, batch train loss: 24.859180450439453\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 79, batch train loss: 18.624507904052734\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 80, batch train loss: 17.385799407958984\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 81, batch train loss: 21.532272338867188\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 82, batch train loss: 22.80577850341797\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 83, batch train loss: 14.8410005569458\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 84, batch train loss: 22.534507751464844\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 85, batch train loss: 16.058732986450195\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 86, batch train loss: 24.695514678955078\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 87, batch train loss: 22.35676383972168\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 88, batch train loss: 17.945222854614258\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 89, batch train loss: 17.8359375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 90, batch train loss: 18.03268814086914\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 91, batch train loss: 25.828548431396484\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 92, batch train loss: 18.02667236328125\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 93, batch train loss: 15.788161277770996\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 94, batch train loss: 22.200366973876953\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 95, batch train loss: 15.487058639526367\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 96, batch train loss: 25.876808166503906\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 97, batch train loss: 28.794967651367188\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 98, batch train loss: 18.3231143951416\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 99, batch train loss: 32.23727798461914\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 100, batch train loss: 26.178691864013672\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 101, batch train loss: 20.38836669921875\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 102, batch train loss: 25.602561950683594\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 103, batch train loss: 25.362838745117188\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 104, batch train loss: 16.970773696899414\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 105, batch train loss: 24.69458770751953\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 106, batch train loss: 25.39008140563965\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 107, batch train loss: 18.862619400024414\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 108, batch train loss: 20.33300018310547\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 109, batch train loss: 24.358991622924805\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 110, batch train loss: 17.830047607421875\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 111, batch train loss: 25.133533477783203\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 112, batch train loss: 18.84552001953125\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 113, batch train loss: 22.73356056213379\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 114, batch train loss: 23.9483699798584\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 115, batch train loss: 18.77500343322754\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 116, batch train loss: 17.720232009887695\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 117, batch train loss: 20.598236083984375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 118, batch train loss: 21.1484375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 119, batch train loss: 15.982901573181152\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 120, batch train loss: 14.86002254486084\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 121, batch train loss: 17.539033889770508\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 122, batch train loss: 19.2496280670166\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 123, batch train loss: 19.85968017578125\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 124, batch train loss: 16.439924240112305\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 125, batch train loss: 17.57390594482422\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 126, batch train loss: 15.50950813293457\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 127, batch train loss: 18.862987518310547\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 128, batch train loss: 15.9026517868042\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 129, batch train loss: 16.63737678527832\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 130, batch train loss: 20.684860229492188\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, batch_id: 131, batch train loss: 16.06970977783203\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 132, batch train loss: 17.14563751220703\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 133, batch train loss: 15.596578598022461\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 134, batch train loss: 21.543216705322266\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 135, batch train loss: 19.454750061035156\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 136, batch train loss: 13.943212509155273\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 137, batch train loss: 15.44942569732666\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 138, batch train loss: 20.785003662109375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 139, batch train loss: 18.51537322998047\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 140, batch train loss: 20.025686264038086\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 141, batch train loss: 17.045454025268555\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 142, batch train loss: 21.77194595336914\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 143, batch train loss: 21.975433349609375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 144, batch train loss: 18.592557907104492\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 145, batch train loss: 19.70694923400879\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 146, batch train loss: 19.534984588623047\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 147, batch train loss: 19.823732376098633\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 148, batch train loss: 18.115140914916992\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 149, batch train loss: 17.6547794342041\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 150, batch train loss: 20.719335556030273\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 151, batch train loss: 27.441226959228516\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 152, batch train loss: 30.99696922302246\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 153, batch train loss: 26.479360580444336\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 154, batch train loss: 39.19906997680664\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 155, batch train loss: 28.784902572631836\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 156, batch train loss: 33.791107177734375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 157, batch train loss: 27.979887008666992\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 158, batch train loss: 34.98274230957031\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 159, batch train loss: 31.88197898864746\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 160, batch train loss: 28.145755767822266\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 161, batch train loss: 31.86393928527832\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 162, batch train loss: 22.784717559814453\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 163, batch train loss: 30.834501266479492\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 164, batch train loss: 26.951007843017578\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 165, batch train loss: 24.678443908691406\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 166, batch train loss: 25.621124267578125\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 167, batch train loss: 32.19405746459961\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 168, batch train loss: 25.643836975097656\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 169, batch train loss: 26.109724044799805\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 170, batch train loss: 29.56673240661621\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 171, batch train loss: 25.84103012084961\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 172, batch train loss: 24.627126693725586\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 173, batch train loss: 26.535905838012695\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 174, batch train loss: 26.13469696044922\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 175, batch train loss: 23.08843994140625\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 176, batch train loss: 22.63004493713379\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 177, batch train loss: 25.224218368530273\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 178, batch train loss: 18.70464324951172\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 179, batch train loss: 22.68401336669922\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 180, batch train loss: 19.277816772460938\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 181, batch train loss: 21.516794204711914\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 182, batch train loss: 19.439006805419922\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 183, batch train loss: 18.803468704223633\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 184, batch train loss: 18.464868545532227\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 185, batch train loss: 21.372364044189453\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 186, batch train loss: 17.97980499267578\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 187, batch train loss: 21.090618133544922\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 188, batch train loss: 16.922077178955078\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 189, batch train loss: 21.05722999572754\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 190, batch train loss: 18.46823501586914\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 191, batch train loss: 19.88112449645996\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 192, batch train loss: 21.117063522338867\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 193, batch train loss: 20.939619064331055\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 194, batch train loss: 21.090341567993164\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 195, batch train loss: 20.14031219482422\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 196, batch train loss: 19.860706329345703\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 197, batch train loss: 17.0823917388916\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 198, batch train loss: 15.192147254943848\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 199, batch train loss: 16.935287475585938\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 200, batch train loss: 14.939462661743164\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 201, batch train loss: 16.08913803100586\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 202, batch train loss: 14.32650089263916\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 203, batch train loss: 14.377490043640137\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 204, batch train loss: 18.03944969177246\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 205, batch train loss: 16.924283981323242\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 206, batch train loss: 14.26416015625\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 207, batch train loss: 17.546804428100586\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 208, batch train loss: 14.790081024169922\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 209, batch train loss: 13.650554656982422\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 210, batch train loss: 13.829493522644043\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 211, batch train loss: 14.048066139221191\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 212, batch train loss: 17.19329833984375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 213, batch train loss: 16.213836669921875\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 214, batch train loss: 14.771730422973633\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 215, batch train loss: 14.40567684173584\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 216, batch train loss: 14.341907501220703\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 217, batch train loss: 14.030913352966309\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 218, batch train loss: 13.246434211730957\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 219, batch train loss: 12.968353271484375\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 220, batch train loss: 13.569796562194824\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 221, batch train loss: 12.783041954040527\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 222, batch train loss: 12.0097017288208\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 223, batch train loss: 14.36504077911377\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 224, batch train loss: 14.25584602355957\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 225, batch train loss: 13.467537879943848\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 226, batch train loss: 16.143678665161133\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 227, batch train loss: 14.661752700805664\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 228, batch train loss: 14.182175636291504\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 229, batch train loss: 15.1399564743042\n",
      "\n",
      "\n",
      "Epoch: 72, batch_id: 230, batch train loss: 12.571267127990723\n",
      "\n",
      "\n",
      "Epoch: 72/ 100, Loss: 30.58379024008046\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:09<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72 Validation Loss: 15.090144443511964\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, batch_id: 1, batch train loss: 13.007701873779297\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 2, batch train loss: 14.23511028289795\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 3, batch train loss: 13.73233699798584\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 4, batch train loss: 13.53938102722168\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 5, batch train loss: 13.25639820098877\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 6, batch train loss: 13.043682098388672\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 7, batch train loss: 15.045419692993164\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 8, batch train loss: 15.012425422668457\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 9, batch train loss: 12.806706428527832\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 10, batch train loss: 11.363946914672852\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 11, batch train loss: 14.299417495727539\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 12, batch train loss: 12.651104927062988\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 13, batch train loss: 15.374055862426758\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 14, batch train loss: 13.831298828125\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 15, batch train loss: 14.722792625427246\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 16, batch train loss: 15.186502456665039\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 17, batch train loss: 15.917415618896484\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 18, batch train loss: 14.770366668701172\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 19, batch train loss: 15.126570701599121\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 20, batch train loss: 13.533720970153809\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 21, batch train loss: 12.341899871826172\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 22, batch train loss: 14.189549446105957\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 23, batch train loss: 17.313098907470703\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 24, batch train loss: 12.674307823181152\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 25, batch train loss: 13.46737289428711\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 26, batch train loss: 16.511804580688477\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 27, batch train loss: 16.059120178222656\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 28, batch train loss: 12.381733894348145\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 29, batch train loss: 18.456092834472656\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 30, batch train loss: 19.111650466918945\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 31, batch train loss: 16.02046012878418\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 32, batch train loss: 17.589405059814453\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 33, batch train loss: 16.892623901367188\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 34, batch train loss: 15.992226600646973\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 35, batch train loss: 15.476093292236328\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 36, batch train loss: 13.799127578735352\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 37, batch train loss: 14.526963233947754\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 38, batch train loss: 16.200843811035156\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 39, batch train loss: 14.86478042602539\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 40, batch train loss: 13.837727546691895\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 41, batch train loss: 13.049993515014648\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 42, batch train loss: 15.865694999694824\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 43, batch train loss: 13.24242115020752\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 44, batch train loss: 13.568565368652344\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 45, batch train loss: 13.149574279785156\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 46, batch train loss: 12.898247718811035\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 47, batch train loss: 12.559466361999512\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 48, batch train loss: 11.15218734741211\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 49, batch train loss: 13.491623878479004\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 50, batch train loss: 11.557880401611328\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 51, batch train loss: 12.222330093383789\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 52, batch train loss: 11.599480628967285\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 53, batch train loss: 13.821894645690918\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 54, batch train loss: 13.168011665344238\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 55, batch train loss: 11.537155151367188\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 56, batch train loss: 11.187226295471191\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 57, batch train loss: 12.291919708251953\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 58, batch train loss: 10.613717079162598\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 59, batch train loss: 9.64328384399414\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 60, batch train loss: 11.656161308288574\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 61, batch train loss: 10.663714408874512\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 62, batch train loss: 10.057716369628906\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 63, batch train loss: 10.388381004333496\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 64, batch train loss: 11.049007415771484\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 65, batch train loss: 10.775022506713867\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 66, batch train loss: 10.006725311279297\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 67, batch train loss: 12.586113929748535\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 68, batch train loss: 10.343931198120117\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 69, batch train loss: 11.923491477966309\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 70, batch train loss: 10.790216445922852\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 71, batch train loss: 10.160449028015137\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 72, batch train loss: 12.943861961364746\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 73, batch train loss: 10.576814651489258\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 74, batch train loss: 10.612906455993652\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 75, batch train loss: 11.03003215789795\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 76, batch train loss: 11.379626274108887\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 77, batch train loss: 10.320226669311523\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 78, batch train loss: 11.191533088684082\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 79, batch train loss: 10.679588317871094\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 80, batch train loss: 10.019859313964844\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 81, batch train loss: 11.811750411987305\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 82, batch train loss: 10.423064231872559\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 83, batch train loss: 10.035619735717773\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 84, batch train loss: 10.34447956085205\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 85, batch train loss: 10.847801208496094\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 86, batch train loss: 10.94316291809082\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 87, batch train loss: 11.547743797302246\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 88, batch train loss: 10.729366302490234\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 89, batch train loss: 9.106374740600586\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 90, batch train loss: 9.736577987670898\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 91, batch train loss: 8.716849327087402\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 92, batch train loss: 11.09755802154541\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 93, batch train loss: 8.855887413024902\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 94, batch train loss: 9.153167724609375\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 95, batch train loss: 13.862744331359863\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 96, batch train loss: 11.718119621276855\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 97, batch train loss: 11.278995513916016\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 98, batch train loss: 9.260412216186523\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 99, batch train loss: 11.392976760864258\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 100, batch train loss: 11.133075714111328\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 101, batch train loss: 10.495469093322754\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 102, batch train loss: 10.921884536743164\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 103, batch train loss: 11.969701766967773\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 104, batch train loss: 13.101430892944336\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 105, batch train loss: 9.758377075195312\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 106, batch train loss: 12.000179290771484\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 107, batch train loss: 10.465517044067383\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 108, batch train loss: 11.639358520507812\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 109, batch train loss: 9.683629989624023\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 110, batch train loss: 9.115972518920898\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 111, batch train loss: 11.436984062194824\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 112, batch train loss: 9.8931303024292\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 113, batch train loss: 9.174947738647461\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 114, batch train loss: 8.959877967834473\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 115, batch train loss: 8.679198265075684\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 116, batch train loss: 9.991816520690918\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 117, batch train loss: 7.619470119476318\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 118, batch train loss: 8.552443504333496\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 119, batch train loss: 8.210420608520508\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 120, batch train loss: 8.50097370147705\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 121, batch train loss: 9.821595191955566\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 122, batch train loss: 6.860348224639893\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 123, batch train loss: 8.068228721618652\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 124, batch train loss: 6.778287887573242\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 125, batch train loss: 6.864178657531738\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 126, batch train loss: 7.23518705368042\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 127, batch train loss: 6.8353190422058105\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 128, batch train loss: 7.229111194610596\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 129, batch train loss: 6.62606954574585\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, batch_id: 130, batch train loss: 8.878859519958496\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 131, batch train loss: 6.333334922790527\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 132, batch train loss: 5.538547039031982\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 133, batch train loss: 6.759481430053711\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 134, batch train loss: 6.048734664916992\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 135, batch train loss: 5.90401029586792\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 136, batch train loss: 6.280139446258545\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 137, batch train loss: 7.344830513000488\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 138, batch train loss: 7.621710777282715\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 139, batch train loss: 7.972876071929932\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 140, batch train loss: 7.178592205047607\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 141, batch train loss: 5.821437358856201\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 142, batch train loss: 7.820221424102783\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 143, batch train loss: 5.672053813934326\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 144, batch train loss: 7.948124885559082\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 145, batch train loss: 6.8156328201293945\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 146, batch train loss: 7.604266166687012\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 147, batch train loss: 7.248305797576904\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 148, batch train loss: 7.665217876434326\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 149, batch train loss: 7.005887031555176\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 150, batch train loss: 5.5112104415893555\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 151, batch train loss: 7.516804218292236\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 152, batch train loss: 6.706244468688965\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 153, batch train loss: 7.742272853851318\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 154, batch train loss: 9.045666694641113\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 155, batch train loss: 7.25033712387085\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 156, batch train loss: 9.441064834594727\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 157, batch train loss: 7.01089334487915\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 158, batch train loss: 8.65242862701416\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 159, batch train loss: 7.052452087402344\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 160, batch train loss: 8.201798439025879\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 161, batch train loss: 7.487668514251709\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 162, batch train loss: 7.011837482452393\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 163, batch train loss: 6.446006774902344\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 164, batch train loss: 7.595098495483398\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 165, batch train loss: 6.0829057693481445\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 166, batch train loss: 6.3413987159729\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 167, batch train loss: 7.148929119110107\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 168, batch train loss: 6.885627269744873\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 169, batch train loss: 6.047718524932861\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 170, batch train loss: 6.91842794418335\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 171, batch train loss: 7.49672269821167\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 172, batch train loss: 6.36496114730835\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 173, batch train loss: 6.279030799865723\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 174, batch train loss: 5.760103225708008\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 175, batch train loss: 7.228591442108154\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 176, batch train loss: 6.3593244552612305\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 177, batch train loss: 5.702877521514893\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 178, batch train loss: 7.111067771911621\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 179, batch train loss: 6.133671760559082\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 180, batch train loss: 8.417305946350098\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 181, batch train loss: 6.229615688323975\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 182, batch train loss: 6.006272792816162\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 183, batch train loss: 5.545172691345215\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 184, batch train loss: 7.104023456573486\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 185, batch train loss: 7.984718322753906\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 186, batch train loss: 8.080550193786621\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 187, batch train loss: 7.4082489013671875\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 188, batch train loss: 7.2849650382995605\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 189, batch train loss: 7.020364761352539\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 190, batch train loss: 6.593221664428711\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 191, batch train loss: 7.616272926330566\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 192, batch train loss: 6.318935871124268\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 193, batch train loss: 7.1481242179870605\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 194, batch train loss: 8.429152488708496\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 195, batch train loss: 6.07335090637207\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 196, batch train loss: 7.953869819641113\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 197, batch train loss: 6.692955493927002\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 198, batch train loss: 8.051519393920898\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 199, batch train loss: 7.26414155960083\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 200, batch train loss: 7.894000053405762\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 201, batch train loss: 7.425650119781494\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 202, batch train loss: 5.781895637512207\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 203, batch train loss: 6.600634574890137\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 204, batch train loss: 8.030622482299805\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 205, batch train loss: 6.453755855560303\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 206, batch train loss: 6.837042808532715\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 207, batch train loss: 6.662962436676025\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 208, batch train loss: 6.317775249481201\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 209, batch train loss: 6.466623306274414\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 210, batch train loss: 6.531065464019775\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 211, batch train loss: 7.259842872619629\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 212, batch train loss: 6.208775997161865\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 213, batch train loss: 5.844197750091553\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 214, batch train loss: 4.8727312088012695\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 215, batch train loss: 5.605982303619385\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 216, batch train loss: 4.882701873779297\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 217, batch train loss: 4.828589916229248\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 218, batch train loss: 4.7055864334106445\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 219, batch train loss: 5.187834739685059\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 220, batch train loss: 6.008049011230469\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 221, batch train loss: 5.744534492492676\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 222, batch train loss: 6.234778881072998\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 223, batch train loss: 5.461116790771484\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 224, batch train loss: 6.382612705230713\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 225, batch train loss: 5.711915016174316\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 226, batch train loss: 6.2059197425842285\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 227, batch train loss: 4.548741340637207\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 228, batch train loss: 4.808900833129883\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 229, batch train loss: 6.249443531036377\n",
      "\n",
      "\n",
      "Epoch: 73, batch_id: 230, batch train loss: 6.000420570373535\n",
      "\n",
      "\n",
      "Epoch: 73/ 100, Loss: 9.623465305825938\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:18<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 Validation Loss: 6.3269600629806515\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74, batch_id: 1, batch train loss: 6.172639846801758\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 2, batch train loss: 7.843719005584717\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 3, batch train loss: 7.12973165512085\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 4, batch train loss: 6.058743476867676\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 5, batch train loss: 5.879271030426025\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 6, batch train loss: 4.919925212860107\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 7, batch train loss: 8.058150291442871\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 8, batch train loss: 7.330967426300049\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 9, batch train loss: 6.315225601196289\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 10, batch train loss: 6.456605911254883\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 11, batch train loss: 7.015148162841797\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 12, batch train loss: 6.971843242645264\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 13, batch train loss: 12.296860694885254\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 14, batch train loss: 7.903735160827637\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 15, batch train loss: 7.533745288848877\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 16, batch train loss: 6.177003383636475\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 17, batch train loss: 5.497271537780762\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 18, batch train loss: 5.277415752410889\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 19, batch train loss: 6.973082065582275\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 20, batch train loss: 7.333911895751953\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 21, batch train loss: 7.644391059875488\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 22, batch train loss: 10.226800918579102\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 23, batch train loss: 8.3921537399292\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 24, batch train loss: 5.9394850730896\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 25, batch train loss: 6.963111877441406\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 26, batch train loss: 8.750655174255371\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 27, batch train loss: 5.857630252838135\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 28, batch train loss: 8.041084289550781\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 29, batch train loss: 9.210198402404785\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 30, batch train loss: 4.332818984985352\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 31, batch train loss: 6.123376846313477\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 32, batch train loss: 5.723111629486084\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 33, batch train loss: 4.453726291656494\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 34, batch train loss: 4.965948104858398\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 35, batch train loss: 6.053727149963379\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 36, batch train loss: 4.888122081756592\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 37, batch train loss: 4.02939510345459\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 38, batch train loss: 4.393398761749268\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 39, batch train loss: 6.346473693847656\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 40, batch train loss: 3.678352117538452\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 41, batch train loss: 2.849808692932129\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 42, batch train loss: 3.0463905334472656\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 43, batch train loss: 3.1051199436187744\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 44, batch train loss: 5.581294059753418\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 45, batch train loss: 3.035839796066284\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 46, batch train loss: 3.4806692600250244\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 47, batch train loss: 4.546306133270264\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 48, batch train loss: 3.091167688369751\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 49, batch train loss: 4.780385971069336\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 50, batch train loss: 3.4691731929779053\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 51, batch train loss: 4.765194416046143\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 52, batch train loss: 4.1183576583862305\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 53, batch train loss: 3.6113147735595703\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 54, batch train loss: 4.3495073318481445\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 55, batch train loss: 3.617583751678467\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 56, batch train loss: 5.241480350494385\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 57, batch train loss: 5.623648166656494\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 58, batch train loss: 4.519368648529053\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 59, batch train loss: 5.797011375427246\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 60, batch train loss: 6.388558387756348\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 61, batch train loss: 3.8085625171661377\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 62, batch train loss: 2.9047422409057617\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 63, batch train loss: 7.80281400680542\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 64, batch train loss: 5.108102798461914\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 65, batch train loss: 4.4428205490112305\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 66, batch train loss: 5.180171012878418\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 67, batch train loss: 6.580263614654541\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 68, batch train loss: 4.129692554473877\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 69, batch train loss: 5.452247142791748\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 70, batch train loss: 5.6321587562561035\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 71, batch train loss: 8.41308307647705\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 72, batch train loss: 9.285950660705566\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 73, batch train loss: 9.557852745056152\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 74, batch train loss: 6.511061191558838\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 75, batch train loss: 6.199996471405029\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 76, batch train loss: 5.199683666229248\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 77, batch train loss: 6.567265510559082\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 78, batch train loss: 5.985086441040039\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 79, batch train loss: 6.642216205596924\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 80, batch train loss: 7.616632461547852\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 81, batch train loss: 5.219025135040283\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 82, batch train loss: 7.420381546020508\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 83, batch train loss: 5.542438983917236\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 84, batch train loss: 4.282484531402588\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 85, batch train loss: 5.2768402099609375\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 86, batch train loss: 3.3055076599121094\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 87, batch train loss: 3.5424723625183105\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 88, batch train loss: 5.1426544189453125\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 89, batch train loss: 4.0928053855896\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 90, batch train loss: 3.8344788551330566\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 91, batch train loss: 4.183101177215576\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 92, batch train loss: 3.0807387828826904\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 93, batch train loss: 3.7811343669891357\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 94, batch train loss: 7.166135311126709\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 95, batch train loss: 4.064822673797607\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 96, batch train loss: 5.551964282989502\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 97, batch train loss: 3.8353612422943115\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 98, batch train loss: 2.915532112121582\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 99, batch train loss: 4.4283976554870605\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 100, batch train loss: 2.6390771865844727\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 101, batch train loss: 4.40505838394165\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 102, batch train loss: 3.3415253162384033\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 103, batch train loss: 3.7560184001922607\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 104, batch train loss: 3.7215473651885986\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 105, batch train loss: 2.987318515777588\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 106, batch train loss: 3.8096625804901123\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 107, batch train loss: 3.077176809310913\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 108, batch train loss: 4.789860725402832\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 109, batch train loss: 4.292681694030762\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 110, batch train loss: 3.8475987911224365\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 111, batch train loss: 4.247114658355713\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 112, batch train loss: 3.3219335079193115\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 113, batch train loss: 3.7385151386260986\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 114, batch train loss: 2.5701119899749756\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 115, batch train loss: 3.8170247077941895\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 116, batch train loss: 2.9729130268096924\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 117, batch train loss: 4.966701507568359\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 118, batch train loss: 5.207311153411865\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 119, batch train loss: 4.5052032470703125\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 120, batch train loss: 7.276956558227539\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 121, batch train loss: 7.923663139343262\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 122, batch train loss: 3.81892991065979\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 123, batch train loss: 4.389522075653076\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 124, batch train loss: 6.688343524932861\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 125, batch train loss: 6.57514762878418\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 126, batch train loss: 4.379390239715576\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 127, batch train loss: 6.3723578453063965\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 128, batch train loss: 6.64959192276001\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 129, batch train loss: 7.574045181274414\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 130, batch train loss: 2.749784231185913\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74, batch_id: 131, batch train loss: 8.1547269821167\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 132, batch train loss: 8.951086044311523\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 133, batch train loss: 6.17182731628418\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 134, batch train loss: 3.588137149810791\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 135, batch train loss: 6.741905212402344\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 136, batch train loss: 6.965090274810791\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 137, batch train loss: 4.230031967163086\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 138, batch train loss: 5.448637962341309\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 139, batch train loss: 5.780542850494385\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 140, batch train loss: 3.714040517807007\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 141, batch train loss: 2.8219246864318848\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 142, batch train loss: 4.150205135345459\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 143, batch train loss: 3.7324137687683105\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 144, batch train loss: 3.739367723464966\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 145, batch train loss: 5.815679550170898\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 146, batch train loss: 4.092155933380127\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 147, batch train loss: 2.267014265060425\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 148, batch train loss: 4.589182376861572\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 149, batch train loss: 4.364408493041992\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 150, batch train loss: 2.663543939590454\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 151, batch train loss: 6.141270637512207\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 152, batch train loss: 3.471163272857666\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 153, batch train loss: 2.3530044555664062\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 154, batch train loss: 3.030172109603882\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 155, batch train loss: 2.858070135116577\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 156, batch train loss: 4.774980545043945\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 157, batch train loss: 4.536122798919678\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 158, batch train loss: 4.352563381195068\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 159, batch train loss: 2.877639055252075\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 160, batch train loss: 3.1174755096435547\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 161, batch train loss: 2.454291343688965\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 162, batch train loss: 4.9079461097717285\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 163, batch train loss: 3.3552451133728027\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 164, batch train loss: 2.839635133743286\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 165, batch train loss: 4.204598426818848\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 166, batch train loss: 4.383976459503174\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 167, batch train loss: 5.009304046630859\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 168, batch train loss: 4.817226886749268\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 169, batch train loss: 3.404303789138794\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 170, batch train loss: 4.230181694030762\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 171, batch train loss: 6.941801071166992\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 172, batch train loss: 6.7630462646484375\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 173, batch train loss: 5.681133270263672\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 174, batch train loss: 5.760663032531738\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 175, batch train loss: 5.396355152130127\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 176, batch train loss: 6.215444087982178\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 177, batch train loss: 6.413370132446289\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 178, batch train loss: 7.315992832183838\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 179, batch train loss: 4.883081912994385\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 180, batch train loss: 6.1705169677734375\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 181, batch train loss: 7.171591758728027\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 182, batch train loss: 5.702200889587402\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 183, batch train loss: 4.9522809982299805\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 184, batch train loss: 4.890296459197998\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 185, batch train loss: 6.649862289428711\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 186, batch train loss: 4.40620231628418\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 187, batch train loss: 3.717836856842041\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 188, batch train loss: 3.8725638389587402\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 189, batch train loss: 6.2880401611328125\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 190, batch train loss: 5.642926216125488\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 191, batch train loss: 5.317654132843018\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 192, batch train loss: 5.326491355895996\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 193, batch train loss: 6.113882064819336\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 194, batch train loss: 4.892392158508301\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 195, batch train loss: 5.076108455657959\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 196, batch train loss: 6.220972061157227\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 197, batch train loss: 5.395623683929443\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 198, batch train loss: 4.981350898742676\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 199, batch train loss: 5.936718940734863\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 200, batch train loss: 4.9474778175354\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 201, batch train loss: 7.168389320373535\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 202, batch train loss: 4.928731441497803\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 203, batch train loss: 4.50529146194458\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 204, batch train loss: 4.114956378936768\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 205, batch train loss: 6.26528263092041\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 206, batch train loss: 4.2870941162109375\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 207, batch train loss: 4.244414806365967\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 208, batch train loss: 6.10864782333374\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 209, batch train loss: 4.260790824890137\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 210, batch train loss: 5.990602493286133\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 211, batch train loss: 5.1583571434021\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 212, batch train loss: 5.671473979949951\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 213, batch train loss: 5.308395862579346\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 214, batch train loss: 6.718130111694336\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 215, batch train loss: 4.89794921875\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 216, batch train loss: 4.638874530792236\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 217, batch train loss: 5.622578144073486\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 218, batch train loss: 6.037463188171387\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 219, batch train loss: 4.3398308753967285\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 220, batch train loss: 5.729752540588379\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 221, batch train loss: 5.988234519958496\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 222, batch train loss: 5.912342071533203\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 223, batch train loss: 5.135514736175537\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 224, batch train loss: 6.093335151672363\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 225, batch train loss: 5.23749303817749\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 226, batch train loss: 5.814455509185791\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 227, batch train loss: 5.564742088317871\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 228, batch train loss: 5.006178379058838\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 229, batch train loss: 6.147886753082275\n",
      "\n",
      "\n",
      "Epoch: 74, batch_id: 230, batch train loss: 5.3489670753479\n",
      "\n",
      "\n",
      "Epoch: 74/ 100, Loss: 5.246378404161204\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:09<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74 Validation Loss: 4.542301587263743\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75, batch_id: 1, batch train loss: 3.893519401550293\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 2, batch train loss: 6.771198272705078\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 3, batch train loss: 4.4063544273376465\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 4, batch train loss: 3.656216621398926\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 5, batch train loss: 5.20390510559082\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 6, batch train loss: 4.64643669128418\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 7, batch train loss: 4.845001697540283\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 8, batch train loss: 4.104752063751221\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 9, batch train loss: 4.0060133934021\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 10, batch train loss: 5.01495885848999\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 11, batch train loss: 4.798487663269043\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 12, batch train loss: 3.9176456928253174\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 13, batch train loss: 3.627532958984375\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 14, batch train loss: 4.52256965637207\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 15, batch train loss: 3.9313623905181885\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 16, batch train loss: 5.614381313323975\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 17, batch train loss: 5.0639328956604\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 18, batch train loss: 3.278510808944702\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 19, batch train loss: 3.734630823135376\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 20, batch train loss: 3.4306657314300537\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 21, batch train loss: 3.5345523357391357\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 22, batch train loss: 3.927161931991577\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 23, batch train loss: 3.5721096992492676\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 24, batch train loss: 3.342139482498169\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 25, batch train loss: 4.702633857727051\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 26, batch train loss: 3.5607028007507324\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 27, batch train loss: 4.882315158843994\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 28, batch train loss: 3.822911024093628\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 29, batch train loss: 4.172330379486084\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 30, batch train loss: 4.835557460784912\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 31, batch train loss: 3.6618587970733643\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 32, batch train loss: 6.025171756744385\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 33, batch train loss: 4.889117240905762\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 34, batch train loss: 4.519189834594727\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 35, batch train loss: 5.4342427253723145\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 36, batch train loss: 4.068702220916748\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 37, batch train loss: 3.5550248622894287\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 38, batch train loss: 4.774753570556641\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 39, batch train loss: 3.998771905899048\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 40, batch train loss: 4.939337253570557\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 41, batch train loss: 3.4968531131744385\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 42, batch train loss: 3.377087116241455\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 43, batch train loss: 5.101677417755127\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 44, batch train loss: 5.3549089431762695\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 45, batch train loss: 3.9500410556793213\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 46, batch train loss: 8.65564250946045\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 47, batch train loss: 4.490362167358398\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 48, batch train loss: 3.5470614433288574\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 49, batch train loss: 3.3343005180358887\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 50, batch train loss: 2.955066442489624\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 51, batch train loss: 3.7167766094207764\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 52, batch train loss: 3.7301151752471924\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 53, batch train loss: 4.1118364334106445\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 54, batch train loss: 10.812616348266602\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 55, batch train loss: 7.736088752746582\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 56, batch train loss: 3.9731123447418213\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 57, batch train loss: 3.247008800506592\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 58, batch train loss: 3.8157849311828613\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 59, batch train loss: 4.414209842681885\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 60, batch train loss: 4.255529880523682\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 61, batch train loss: 4.160254001617432\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 62, batch train loss: 4.855719089508057\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 63, batch train loss: 3.6218395233154297\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 64, batch train loss: 4.800219535827637\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 65, batch train loss: 3.7311670780181885\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 66, batch train loss: 5.773509502410889\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 67, batch train loss: 3.6125190258026123\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 68, batch train loss: 3.17521595954895\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 69, batch train loss: 2.564800262451172\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 70, batch train loss: 4.231119155883789\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 71, batch train loss: 3.7719192504882812\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 72, batch train loss: 4.81405782699585\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 73, batch train loss: 4.385159969329834\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 74, batch train loss: 3.2641854286193848\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 75, batch train loss: 3.71305251121521\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 76, batch train loss: 6.241167068481445\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 77, batch train loss: 3.798251152038574\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 78, batch train loss: 4.821368217468262\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 79, batch train loss: 5.582955837249756\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 80, batch train loss: 4.363970756530762\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 81, batch train loss: 3.065721035003662\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 82, batch train loss: 3.3556551933288574\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 83, batch train loss: 5.669659614562988\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 84, batch train loss: 8.07470703125\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 85, batch train loss: 6.061635494232178\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 86, batch train loss: 5.203429222106934\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 87, batch train loss: 5.034204006195068\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 88, batch train loss: 5.01934814453125\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 89, batch train loss: 11.1096830368042\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 90, batch train loss: 7.790144920349121\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 91, batch train loss: 5.21412467956543\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 92, batch train loss: 7.427036762237549\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 93, batch train loss: 7.109456539154053\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 94, batch train loss: 7.020695686340332\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 95, batch train loss: 6.618425369262695\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 96, batch train loss: 7.837981700897217\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 97, batch train loss: 7.328714370727539\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 98, batch train loss: 5.297211647033691\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 99, batch train loss: 4.969306468963623\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 100, batch train loss: 7.925266265869141\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 101, batch train loss: 6.616528511047363\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 102, batch train loss: 6.643413543701172\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 103, batch train loss: 7.316576957702637\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 104, batch train loss: 8.40062141418457\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 105, batch train loss: 7.37791109085083\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 106, batch train loss: 6.091924667358398\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 107, batch train loss: 8.337178230285645\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 108, batch train loss: 7.310415267944336\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 109, batch train loss: 7.439177989959717\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 110, batch train loss: 7.530819416046143\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 111, batch train loss: 6.372824192047119\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 112, batch train loss: 6.373173236846924\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 113, batch train loss: 5.646742820739746\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 114, batch train loss: 3.935396671295166\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 115, batch train loss: 5.200033187866211\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 116, batch train loss: 6.523705005645752\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 117, batch train loss: 4.24132776260376\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 118, batch train loss: 3.8574185371398926\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 119, batch train loss: 6.859748363494873\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 120, batch train loss: 4.812788963317871\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 121, batch train loss: 4.434715747833252\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 122, batch train loss: 4.5667314529418945\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 123, batch train loss: 4.5652241706848145\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 124, batch train loss: 5.190474510192871\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 125, batch train loss: 4.5219407081604\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 126, batch train loss: 4.464795112609863\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 127, batch train loss: 6.128422260284424\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 128, batch train loss: 5.426199913024902\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 129, batch train loss: 8.444607734680176\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 130, batch train loss: 6.260484218597412\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75, batch_id: 131, batch train loss: 8.544809341430664\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 132, batch train loss: 6.723254203796387\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 133, batch train loss: 4.748597621917725\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 134, batch train loss: 9.915796279907227\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 135, batch train loss: 8.789121627807617\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 136, batch train loss: 5.626219749450684\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 137, batch train loss: 6.85092306137085\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 138, batch train loss: 11.215925216674805\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 139, batch train loss: 7.587323188781738\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 140, batch train loss: 5.566743850708008\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 141, batch train loss: 7.219016075134277\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 142, batch train loss: 8.83840274810791\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 143, batch train loss: 4.787107467651367\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 144, batch train loss: 5.6904401779174805\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 145, batch train loss: 5.427812576293945\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 146, batch train loss: 4.041995525360107\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 147, batch train loss: 5.190921306610107\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 148, batch train loss: 6.004007339477539\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 149, batch train loss: 5.540677547454834\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 150, batch train loss: 6.33911657333374\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 151, batch train loss: 5.436131477355957\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 152, batch train loss: 3.7383928298950195\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 153, batch train loss: 7.191844940185547\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 154, batch train loss: 4.3434247970581055\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 155, batch train loss: 5.496976852416992\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 156, batch train loss: 5.923224925994873\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 157, batch train loss: 4.341882705688477\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 158, batch train loss: 5.299825191497803\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 159, batch train loss: 6.622161388397217\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 160, batch train loss: 4.613729476928711\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 161, batch train loss: 4.165194034576416\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 162, batch train loss: 8.402945518493652\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 163, batch train loss: 3.9212899208068848\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 164, batch train loss: 5.910097599029541\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 165, batch train loss: 5.224026203155518\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 166, batch train loss: 6.119284152984619\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 167, batch train loss: 3.715625524520874\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 168, batch train loss: 4.047840595245361\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 169, batch train loss: 4.233536720275879\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 170, batch train loss: 6.28781270980835\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 171, batch train loss: 5.250250816345215\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 172, batch train loss: 4.767621994018555\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 173, batch train loss: 3.83139967918396\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 174, batch train loss: 3.7656314373016357\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 175, batch train loss: 4.37825870513916\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 176, batch train loss: 4.131401538848877\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 177, batch train loss: 2.794973850250244\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 178, batch train loss: 4.915241241455078\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 179, batch train loss: 3.55470871925354\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 180, batch train loss: 3.1217808723449707\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 181, batch train loss: 2.551532506942749\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 182, batch train loss: 3.0962226390838623\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 183, batch train loss: 3.330341100692749\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 184, batch train loss: 4.178768634796143\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 185, batch train loss: 3.006929397583008\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 186, batch train loss: 3.8899474143981934\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 187, batch train loss: 3.656113386154175\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 188, batch train loss: 3.5251803398132324\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 189, batch train loss: 3.1782052516937256\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 190, batch train loss: 3.5068089962005615\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 191, batch train loss: 3.5841541290283203\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 192, batch train loss: 3.070829391479492\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 193, batch train loss: 2.804069995880127\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 194, batch train loss: 5.283419132232666\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 195, batch train loss: 8.40190315246582\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 196, batch train loss: 3.767188310623169\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 197, batch train loss: 4.2107439041137695\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 198, batch train loss: 5.67787504196167\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 199, batch train loss: 5.320544242858887\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 200, batch train loss: 4.097687244415283\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 201, batch train loss: 4.846753120422363\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 202, batch train loss: 4.611122131347656\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 203, batch train loss: 3.299964666366577\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 204, batch train loss: 3.891407012939453\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 205, batch train loss: 3.5198910236358643\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 206, batch train loss: 2.9637081623077393\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 207, batch train loss: 7.0646257400512695\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 208, batch train loss: 4.622297763824463\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 209, batch train loss: 3.988616466522217\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 210, batch train loss: 4.660309791564941\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 211, batch train loss: 3.960238456726074\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 212, batch train loss: 3.0511839389801025\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 213, batch train loss: 2.9250967502593994\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 214, batch train loss: 5.260595321655273\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 215, batch train loss: 4.553558826446533\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 216, batch train loss: 4.006659030914307\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 217, batch train loss: 4.940832614898682\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 218, batch train loss: 2.4600632190704346\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 219, batch train loss: 2.4308929443359375\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 220, batch train loss: 2.833451509475708\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 221, batch train loss: 3.2526023387908936\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 222, batch train loss: 3.1970603466033936\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 223, batch train loss: 2.842477321624756\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 224, batch train loss: 1.9497289657592773\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 225, batch train loss: 4.184209823608398\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 226, batch train loss: 3.2028026580810547\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 227, batch train loss: 3.2510979175567627\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 228, batch train loss: 3.2059895992279053\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 229, batch train loss: 2.2487494945526123\n",
      "\n",
      "\n",
      "Epoch: 75, batch_id: 230, batch train loss: 2.656759023666382\n",
      "\n",
      "\n",
      "Epoch: 75/ 100, Loss: 4.922977646537449\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:06<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 Validation Loss: 3.356240928173065\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76, batch_id: 1, batch train loss: 3.3752336502075195\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 2, batch train loss: 3.817735195159912\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 3, batch train loss: 2.0258359909057617\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 4, batch train loss: 3.0057153701782227\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 5, batch train loss: 4.059932708740234\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 6, batch train loss: 2.9633595943450928\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 7, batch train loss: 3.1265709400177\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 8, batch train loss: 2.9351508617401123\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 9, batch train loss: 3.6404964923858643\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 10, batch train loss: 3.0424273014068604\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 11, batch train loss: 2.9581639766693115\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 12, batch train loss: 2.9378585815429688\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 13, batch train loss: 4.13370943069458\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 14, batch train loss: 2.9820902347564697\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 15, batch train loss: 3.4332327842712402\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 16, batch train loss: 3.5664429664611816\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 17, batch train loss: 3.441403865814209\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 18, batch train loss: 2.973614454269409\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 19, batch train loss: 3.312978506088257\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 20, batch train loss: 2.8038439750671387\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 21, batch train loss: 3.4478752613067627\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 22, batch train loss: 2.850928544998169\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 23, batch train loss: 3.956840753555298\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 24, batch train loss: 3.9697859287261963\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 25, batch train loss: 2.692943811416626\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 26, batch train loss: 4.646021366119385\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 27, batch train loss: 4.428308486938477\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 28, batch train loss: 3.877873182296753\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 29, batch train loss: 2.9022297859191895\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 30, batch train loss: 4.468071460723877\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 31, batch train loss: 2.946401596069336\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 32, batch train loss: 2.7850515842437744\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 33, batch train loss: 2.7947137355804443\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 34, batch train loss: 3.5012047290802\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 35, batch train loss: 3.4348738193511963\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 36, batch train loss: 3.6044938564300537\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 37, batch train loss: 3.3404605388641357\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 38, batch train loss: 4.128216743469238\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 39, batch train loss: 3.724198818206787\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 40, batch train loss: 3.185260772705078\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 41, batch train loss: 2.1816329956054688\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 42, batch train loss: 3.6781582832336426\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 43, batch train loss: 2.723968982696533\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 44, batch train loss: 4.036142826080322\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 45, batch train loss: 3.0901665687561035\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 46, batch train loss: 3.9441919326782227\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 47, batch train loss: 3.8055896759033203\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 48, batch train loss: 3.0830600261688232\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 49, batch train loss: 2.4069101810455322\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 50, batch train loss: 2.5584139823913574\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 51, batch train loss: 3.4896504878997803\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 52, batch train loss: 3.438141345977783\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 53, batch train loss: 3.8092293739318848\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 54, batch train loss: 2.9366047382354736\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 55, batch train loss: 2.897376775741577\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 56, batch train loss: 2.683811902999878\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 57, batch train loss: 3.1163229942321777\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 58, batch train loss: 2.985475778579712\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 59, batch train loss: 4.890522480010986\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 60, batch train loss: 2.4733099937438965\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 61, batch train loss: 3.1369261741638184\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 62, batch train loss: 2.8540494441986084\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 63, batch train loss: 2.7746944427490234\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 64, batch train loss: 3.314281702041626\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 65, batch train loss: 3.8931262493133545\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 66, batch train loss: 3.824460029602051\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 67, batch train loss: 2.8880553245544434\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 68, batch train loss: 2.7048275470733643\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 69, batch train loss: 4.296535015106201\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 70, batch train loss: 2.896890163421631\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 71, batch train loss: 2.6217758655548096\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 72, batch train loss: 3.1406679153442383\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 73, batch train loss: 3.2911245822906494\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 74, batch train loss: 3.010303020477295\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 75, batch train loss: 4.169897556304932\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 76, batch train loss: 3.699295997619629\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 77, batch train loss: 2.9297492504119873\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 78, batch train loss: 3.099606513977051\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 79, batch train loss: 3.395590305328369\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 80, batch train loss: 2.8996336460113525\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 81, batch train loss: 3.5739493370056152\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 82, batch train loss: 3.216303825378418\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 83, batch train loss: 2.6982433795928955\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 84, batch train loss: 2.880120277404785\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 85, batch train loss: 2.7749316692352295\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 86, batch train loss: 2.9629549980163574\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 87, batch train loss: 2.6709392070770264\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 88, batch train loss: 2.6875691413879395\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 89, batch train loss: 3.7914741039276123\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 90, batch train loss: 3.651094675064087\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 91, batch train loss: 3.057786703109741\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 92, batch train loss: 2.4924817085266113\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 93, batch train loss: 2.9698097705841064\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 94, batch train loss: 3.071833848953247\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 95, batch train loss: 4.263759136199951\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 96, batch train loss: 2.344106912612915\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 97, batch train loss: 3.874382734298706\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 98, batch train loss: 3.421827793121338\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 99, batch train loss: 4.667784214019775\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 100, batch train loss: 3.7699711322784424\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 101, batch train loss: 3.4979171752929688\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 102, batch train loss: 3.9165408611297607\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 103, batch train loss: 3.3991494178771973\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 104, batch train loss: 2.657994508743286\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 105, batch train loss: 4.317490100860596\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 106, batch train loss: 6.311663627624512\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 107, batch train loss: 3.784822940826416\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 108, batch train loss: 4.542616367340088\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 109, batch train loss: 5.377140998840332\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 110, batch train loss: 4.433399200439453\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 111, batch train loss: 3.3773245811462402\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 112, batch train loss: 5.174190998077393\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 113, batch train loss: 4.8624587059021\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 114, batch train loss: 3.9584903717041016\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 115, batch train loss: 3.0087759494781494\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 116, batch train loss: 3.939591407775879\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 117, batch train loss: 3.556063652038574\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 118, batch train loss: 4.947414875030518\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 119, batch train loss: 2.884516716003418\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 120, batch train loss: 3.695310354232788\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 121, batch train loss: 3.0983994007110596\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 122, batch train loss: 2.43155837059021\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 123, batch train loss: 4.290595531463623\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 124, batch train loss: 2.5448782444000244\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 125, batch train loss: 2.999955415725708\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 126, batch train loss: 3.435596227645874\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 127, batch train loss: 3.1920039653778076\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 128, batch train loss: 3.656926155090332\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 129, batch train loss: 3.059553384780884\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76, batch_id: 130, batch train loss: 4.344156742095947\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 131, batch train loss: 3.9948315620422363\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 132, batch train loss: 2.680018901824951\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 133, batch train loss: 3.2617835998535156\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 134, batch train loss: 3.500558614730835\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 135, batch train loss: 3.2893848419189453\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 136, batch train loss: 4.61372184753418\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 137, batch train loss: 2.855409860610962\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 138, batch train loss: 3.6114859580993652\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 139, batch train loss: 2.814328193664551\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 140, batch train loss: 2.696721076965332\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 141, batch train loss: 3.115068197250366\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 142, batch train loss: 4.420488357543945\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 143, batch train loss: 2.559873580932617\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 144, batch train loss: 2.766184091567993\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 145, batch train loss: 2.9344990253448486\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 146, batch train loss: 3.351881742477417\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 147, batch train loss: 3.021698236465454\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 148, batch train loss: 2.1606128215789795\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 149, batch train loss: 3.417862892150879\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 150, batch train loss: 2.892125129699707\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 151, batch train loss: 4.781013011932373\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 152, batch train loss: 4.207179546356201\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 153, batch train loss: 3.1688382625579834\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 154, batch train loss: 2.310666561126709\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 155, batch train loss: 2.3947691917419434\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 156, batch train loss: 5.349055767059326\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 157, batch train loss: 3.7714502811431885\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 158, batch train loss: 3.0222909450531006\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 159, batch train loss: 4.655105113983154\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 160, batch train loss: 3.982187509536743\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 161, batch train loss: 4.934729099273682\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 162, batch train loss: 4.914772033691406\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 163, batch train loss: 4.340211391448975\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 164, batch train loss: 3.9839529991149902\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 165, batch train loss: 2.9220499992370605\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 166, batch train loss: 4.669064998626709\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 167, batch train loss: 2.481431245803833\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 168, batch train loss: 2.927140235900879\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 169, batch train loss: 2.963956594467163\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 170, batch train loss: 3.0864646434783936\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 171, batch train loss: 3.3001084327697754\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 172, batch train loss: 3.1345646381378174\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 173, batch train loss: 2.5108554363250732\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 174, batch train loss: 3.556354284286499\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 175, batch train loss: 3.40301513671875\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 176, batch train loss: 2.518744468688965\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 177, batch train loss: 3.800930976867676\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 178, batch train loss: 3.5276639461517334\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 179, batch train loss: 3.2595322132110596\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 180, batch train loss: 2.4303531646728516\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 181, batch train loss: 3.4717607498168945\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 182, batch train loss: 3.132169485092163\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 183, batch train loss: 2.6082048416137695\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 184, batch train loss: 3.318248748779297\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 185, batch train loss: 2.300723075866699\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 186, batch train loss: 2.500211477279663\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 187, batch train loss: 2.233137845993042\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 188, batch train loss: 3.1150765419006348\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 189, batch train loss: 2.661370038986206\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 190, batch train loss: 2.4412968158721924\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 191, batch train loss: 3.770604133605957\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 192, batch train loss: 1.8953908681869507\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 193, batch train loss: 2.3372507095336914\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 194, batch train loss: 2.7036383152008057\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 195, batch train loss: 4.045944690704346\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 196, batch train loss: 3.8998849391937256\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 197, batch train loss: 3.5136849880218506\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 198, batch train loss: 2.5005242824554443\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 199, batch train loss: 3.267528772354126\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 200, batch train loss: 2.414116621017456\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 201, batch train loss: 2.4802699089050293\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 202, batch train loss: 3.3646621704101562\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 203, batch train loss: 2.634685754776001\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 204, batch train loss: 2.272614002227783\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 205, batch train loss: 2.658217668533325\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 206, batch train loss: 2.3591878414154053\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 207, batch train loss: 2.319127082824707\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 208, batch train loss: 2.8658957481384277\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 209, batch train loss: 2.075178861618042\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 210, batch train loss: 2.3136255741119385\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 211, batch train loss: 1.875166654586792\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 212, batch train loss: 1.974464774131775\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 213, batch train loss: 2.5122921466827393\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 214, batch train loss: 3.0133063793182373\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 215, batch train loss: 3.174402952194214\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 216, batch train loss: 3.7259154319763184\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 217, batch train loss: 2.867039680480957\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 218, batch train loss: 4.6893157958984375\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 219, batch train loss: 2.904658317565918\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 220, batch train loss: 3.6049089431762695\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 221, batch train loss: 2.292703151702881\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 222, batch train loss: 3.128784656524658\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 223, batch train loss: 4.508443832397461\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 224, batch train loss: 3.4453728199005127\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 225, batch train loss: 3.508495330810547\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 226, batch train loss: 2.510314702987671\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 227, batch train loss: 2.8687784671783447\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 228, batch train loss: 2.9432482719421387\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 229, batch train loss: 4.263910293579102\n",
      "\n",
      "\n",
      "Epoch: 76, batch_id: 230, batch train loss: 3.576343536376953\n",
      "\n",
      "\n",
      "Epoch: 76/ 100, Loss: 3.308515799563864\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:07<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76 Validation Loss: 3.06454621553421\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77, batch_id: 1, batch train loss: 3.2603960037231445\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 2, batch train loss: 3.535504102706909\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 3, batch train loss: 2.6957039833068848\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 4, batch train loss: 3.0151424407958984\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 5, batch train loss: 3.327224016189575\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 6, batch train loss: 4.655330657958984\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 7, batch train loss: 4.8783345222473145\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 8, batch train loss: 3.397932767868042\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 9, batch train loss: 3.9630537033081055\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 10, batch train loss: 3.961569309234619\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 11, batch train loss: 2.6241955757141113\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 12, batch train loss: 3.770193576812744\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 13, batch train loss: 2.991032361984253\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 14, batch train loss: 3.644240617752075\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 15, batch train loss: 3.862473964691162\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 16, batch train loss: 3.243690013885498\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 17, batch train loss: 2.7106847763061523\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 18, batch train loss: 3.2360339164733887\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 19, batch train loss: 2.3799264430999756\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 20, batch train loss: 4.1360368728637695\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 21, batch train loss: 2.561751365661621\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 22, batch train loss: 3.006448268890381\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 23, batch train loss: 2.140394687652588\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 24, batch train loss: 3.412522792816162\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 25, batch train loss: 2.812966823577881\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 26, batch train loss: 2.7151601314544678\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 27, batch train loss: 2.305912971496582\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 28, batch train loss: 2.9651243686676025\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 29, batch train loss: 2.436537504196167\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 30, batch train loss: 2.7187917232513428\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 31, batch train loss: 2.667299747467041\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 32, batch train loss: 2.7062301635742188\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 33, batch train loss: 3.713831901550293\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 34, batch train loss: 3.3146369457244873\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 35, batch train loss: 1.946903109550476\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 36, batch train loss: 1.8501757383346558\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 37, batch train loss: 3.5988948345184326\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 38, batch train loss: 2.2806410789489746\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 39, batch train loss: 3.497096061706543\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 40, batch train loss: 2.538213014602661\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 41, batch train loss: 3.15535569190979\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 42, batch train loss: 3.526426076889038\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 43, batch train loss: 3.5767252445220947\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 44, batch train loss: 3.2280185222625732\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 45, batch train loss: 3.4387366771698\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 46, batch train loss: 4.17080545425415\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 47, batch train loss: 3.782855272293091\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 48, batch train loss: 3.0377357006073\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 49, batch train loss: 2.918860673904419\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 50, batch train loss: 2.8434813022613525\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 51, batch train loss: 3.2723236083984375\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 52, batch train loss: 3.8537533283233643\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 53, batch train loss: 3.2201898097991943\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 54, batch train loss: 4.176337718963623\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 55, batch train loss: 2.830778121948242\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 56, batch train loss: 3.6190900802612305\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 57, batch train loss: 2.7637813091278076\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 58, batch train loss: 3.1070730686187744\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 59, batch train loss: 3.8812952041625977\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 60, batch train loss: 2.636631727218628\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 61, batch train loss: 2.7507848739624023\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 62, batch train loss: 3.981613874435425\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 63, batch train loss: 2.0397067070007324\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 64, batch train loss: 2.0032050609588623\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 65, batch train loss: 2.377636194229126\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 66, batch train loss: 3.9298148155212402\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 67, batch train loss: 2.5382168292999268\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 68, batch train loss: 2.5458028316497803\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 69, batch train loss: 2.118475914001465\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 70, batch train loss: 3.0698485374450684\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 71, batch train loss: 4.128103256225586\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 72, batch train loss: 3.199918270111084\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 73, batch train loss: 2.7628328800201416\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 74, batch train loss: 1.928635835647583\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 75, batch train loss: 1.941385269165039\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 76, batch train loss: 2.5254838466644287\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 77, batch train loss: 2.4661552906036377\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 78, batch train loss: 2.2242884635925293\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 79, batch train loss: 2.377345323562622\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 80, batch train loss: 2.5954203605651855\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 81, batch train loss: 3.06014347076416\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 82, batch train loss: 2.456277370452881\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 83, batch train loss: 2.135558605194092\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 84, batch train loss: 2.499985456466675\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 85, batch train loss: 1.8569303750991821\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 86, batch train loss: 2.0934338569641113\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 87, batch train loss: 2.4515113830566406\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 88, batch train loss: 2.0358922481536865\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 89, batch train loss: 1.9833731651306152\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 90, batch train loss: 2.0075843334198\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 91, batch train loss: 2.7715868949890137\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 92, batch train loss: 1.932661771774292\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 93, batch train loss: 2.246811628341675\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 94, batch train loss: 2.163321018218994\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 95, batch train loss: 2.292649745941162\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 96, batch train loss: 2.5793404579162598\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 97, batch train loss: 3.6146552562713623\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 98, batch train loss: 2.640768527984619\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 99, batch train loss: 2.9536361694335938\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 100, batch train loss: 2.6510350704193115\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 101, batch train loss: 3.072791576385498\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 102, batch train loss: 3.496504306793213\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 103, batch train loss: 2.4900588989257812\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 104, batch train loss: 3.0111348628997803\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 105, batch train loss: 3.2320313453674316\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 106, batch train loss: 2.9037511348724365\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 107, batch train loss: 2.9497647285461426\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 108, batch train loss: 2.758488655090332\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 109, batch train loss: 2.7345707416534424\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 110, batch train loss: 3.961707353591919\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 111, batch train loss: 2.8792359828948975\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 112, batch train loss: 3.553561210632324\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 113, batch train loss: 4.201159477233887\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 114, batch train loss: 3.44529128074646\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 115, batch train loss: 3.309572696685791\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 116, batch train loss: 4.314605712890625\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 117, batch train loss: 5.021499156951904\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 118, batch train loss: 2.5618536472320557\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 119, batch train loss: 5.738699913024902\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 120, batch train loss: 4.176368713378906\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 121, batch train loss: 4.313263893127441\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 122, batch train loss: 3.814708948135376\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 123, batch train loss: 4.068631172180176\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 124, batch train loss: 5.690535545349121\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 125, batch train loss: 3.5101168155670166\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 126, batch train loss: 8.539698600769043\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 127, batch train loss: 5.375236988067627\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 128, batch train loss: 4.081943035125732\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 129, batch train loss: 6.075196266174316\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77, batch_id: 130, batch train loss: 5.606563091278076\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 131, batch train loss: 7.111608028411865\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 132, batch train loss: 7.666913986206055\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 133, batch train loss: 9.509259223937988\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 134, batch train loss: 8.768902778625488\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 135, batch train loss: 5.802938938140869\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 136, batch train loss: 4.833031177520752\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 137, batch train loss: 8.231327056884766\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 138, batch train loss: 7.080812931060791\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 139, batch train loss: 5.318435192108154\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 140, batch train loss: 6.564876079559326\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 141, batch train loss: 7.542763710021973\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 142, batch train loss: 5.817930221557617\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 143, batch train loss: 4.655686855316162\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 144, batch train loss: 6.7430572509765625\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 145, batch train loss: 6.237452030181885\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 146, batch train loss: 4.268270969390869\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 147, batch train loss: 7.676792621612549\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 148, batch train loss: 6.374265193939209\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 149, batch train loss: 3.7613167762756348\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 150, batch train loss: 4.36549711227417\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 151, batch train loss: 5.350515842437744\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 152, batch train loss: 4.275883197784424\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 153, batch train loss: 5.304320335388184\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 154, batch train loss: 3.7003369331359863\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 155, batch train loss: 3.1987533569335938\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 156, batch train loss: 5.256493091583252\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 157, batch train loss: 5.301824569702148\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 158, batch train loss: 5.498687744140625\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 159, batch train loss: 5.39994478225708\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 160, batch train loss: 4.135340690612793\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 161, batch train loss: 4.226494312286377\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 162, batch train loss: 5.794065952301025\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 163, batch train loss: 5.7422590255737305\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 164, batch train loss: 6.001260757446289\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 165, batch train loss: 5.131290912628174\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 166, batch train loss: 4.829544544219971\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 167, batch train loss: 5.054616451263428\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 168, batch train loss: 5.134422779083252\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 169, batch train loss: 5.446193218231201\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 170, batch train loss: 4.337528228759766\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 171, batch train loss: 5.165751934051514\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 172, batch train loss: 3.621786594390869\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 173, batch train loss: 4.146119117736816\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 174, batch train loss: 5.846286773681641\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 175, batch train loss: 3.5530436038970947\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 176, batch train loss: 5.111655235290527\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 177, batch train loss: 4.209580898284912\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 178, batch train loss: 3.532034397125244\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 179, batch train loss: 5.200201034545898\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 180, batch train loss: 4.264217853546143\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 181, batch train loss: 3.363408088684082\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 182, batch train loss: 2.73146915435791\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 183, batch train loss: 6.513061046600342\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 184, batch train loss: 4.603200912475586\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 185, batch train loss: 6.32066011428833\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 186, batch train loss: 6.794612407684326\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 187, batch train loss: 11.85292911529541\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 188, batch train loss: 11.208914756774902\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 189, batch train loss: 8.315828323364258\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 190, batch train loss: 6.993036270141602\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 191, batch train loss: 10.76719856262207\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 192, batch train loss: 5.778152942657471\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 193, batch train loss: 5.356228828430176\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 194, batch train loss: 5.856785297393799\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 195, batch train loss: 9.176807403564453\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 196, batch train loss: 7.750765800476074\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 197, batch train loss: 5.9862518310546875\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 198, batch train loss: 5.517335891723633\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 199, batch train loss: 9.761482238769531\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 200, batch train loss: 6.2660112380981445\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 201, batch train loss: 6.628774166107178\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 202, batch train loss: 6.043308258056641\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 203, batch train loss: 6.935909748077393\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 204, batch train loss: 5.296851634979248\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 205, batch train loss: 5.125565052032471\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 206, batch train loss: 4.563728332519531\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 207, batch train loss: 5.238459587097168\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 208, batch train loss: 4.757265090942383\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 209, batch train loss: 3.1686065196990967\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 210, batch train loss: 4.90956449508667\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 211, batch train loss: 3.36043119430542\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 212, batch train loss: 3.7874748706817627\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 213, batch train loss: 4.00951623916626\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 214, batch train loss: 3.8282227516174316\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 215, batch train loss: 3.6776325702667236\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 216, batch train loss: 2.9491190910339355\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 217, batch train loss: 3.6242198944091797\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 218, batch train loss: 4.35329532623291\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 219, batch train loss: 3.780200958251953\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 220, batch train loss: 3.0071818828582764\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 221, batch train loss: 4.435957431793213\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 222, batch train loss: 4.167769432067871\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 223, batch train loss: 3.0289480686187744\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 224, batch train loss: 2.397416830062866\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 225, batch train loss: 4.565227508544922\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 226, batch train loss: 3.161203622817993\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 227, batch train loss: 3.3832898139953613\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 228, batch train loss: 2.7703511714935303\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 229, batch train loss: 3.0398223400115967\n",
      "\n",
      "\n",
      "Epoch: 77, batch_id: 230, batch train loss: 3.120363473892212\n",
      "\n",
      "\n",
      "Epoch: 77/ 100, Loss: 4.132479453605154\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77 Validation Loss: 3.072926660378774\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, batch_id: 1, batch train loss: 3.161284923553467\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 2, batch train loss: 2.7490808963775635\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 3, batch train loss: 2.843975782394409\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 4, batch train loss: 2.4904963970184326\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 5, batch train loss: 2.803349018096924\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 6, batch train loss: 4.358972549438477\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 7, batch train loss: 3.166213274002075\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 8, batch train loss: 3.991422176361084\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 9, batch train loss: 3.6208324432373047\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 10, batch train loss: 3.597945213317871\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 11, batch train loss: 3.82830810546875\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 12, batch train loss: 3.3115782737731934\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 13, batch train loss: 3.6843578815460205\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 14, batch train loss: 4.762439727783203\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 15, batch train loss: 2.9057083129882812\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 16, batch train loss: 4.4791412353515625\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 17, batch train loss: 2.9705772399902344\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 18, batch train loss: 2.585526466369629\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 19, batch train loss: 3.533681631088257\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 20, batch train loss: 2.810046434402466\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 21, batch train loss: 2.773857355117798\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 22, batch train loss: 3.75053334236145\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 23, batch train loss: 2.897498846054077\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 24, batch train loss: 3.4026107788085938\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 25, batch train loss: 3.7170348167419434\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 26, batch train loss: 2.517275810241699\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 27, batch train loss: 3.836477756500244\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 28, batch train loss: 2.9275240898132324\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 29, batch train loss: 2.889052152633667\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 30, batch train loss: 2.675903081893921\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 31, batch train loss: 3.671280860900879\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 32, batch train loss: 3.359715700149536\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 33, batch train loss: 2.799130439758301\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 34, batch train loss: 2.787862777709961\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 35, batch train loss: 2.732328414916992\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 36, batch train loss: 3.6013472080230713\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 37, batch train loss: 3.9372355937957764\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 38, batch train loss: 4.120866298675537\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 39, batch train loss: 4.055005073547363\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 40, batch train loss: 2.76249623298645\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 41, batch train loss: 4.011257171630859\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 42, batch train loss: 3.5214884281158447\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 43, batch train loss: 3.964451789855957\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 44, batch train loss: 2.507197618484497\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 45, batch train loss: 4.197060585021973\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 46, batch train loss: 2.9281961917877197\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 47, batch train loss: 3.8380794525146484\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 48, batch train loss: 4.45854377746582\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 49, batch train loss: 3.7625732421875\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 50, batch train loss: 3.0895955562591553\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 51, batch train loss: 4.584301471710205\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 52, batch train loss: 4.160775661468506\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 53, batch train loss: 4.409292221069336\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 54, batch train loss: 2.870091438293457\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 55, batch train loss: 2.7618489265441895\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 56, batch train loss: 3.573284387588501\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 57, batch train loss: 4.159450054168701\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 58, batch train loss: 3.776540517807007\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 59, batch train loss: 5.368943214416504\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 60, batch train loss: 3.904224157333374\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 61, batch train loss: 4.1960248947143555\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 62, batch train loss: 2.4381415843963623\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 63, batch train loss: 6.409914493560791\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 64, batch train loss: 4.556601524353027\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 65, batch train loss: 3.719198703765869\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 66, batch train loss: 3.467846155166626\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 67, batch train loss: 5.830196857452393\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 68, batch train loss: 3.8510026931762695\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 69, batch train loss: 6.477464199066162\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 70, batch train loss: 3.996025323867798\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 71, batch train loss: 5.12293815612793\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 72, batch train loss: 4.729620456695557\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 73, batch train loss: 4.537875175476074\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 74, batch train loss: 5.9477314949035645\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 75, batch train loss: 4.917268753051758\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 76, batch train loss: 3.632580041885376\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 77, batch train loss: 2.584949493408203\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 78, batch train loss: 4.376997947692871\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 79, batch train loss: 4.148463726043701\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 80, batch train loss: 3.284860610961914\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 81, batch train loss: 4.886877536773682\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 82, batch train loss: 4.066317081451416\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 83, batch train loss: 3.1737289428710938\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 84, batch train loss: 3.8663363456726074\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 85, batch train loss: 4.434497833251953\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 86, batch train loss: 3.2058000564575195\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 87, batch train loss: 3.872460126876831\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 88, batch train loss: 4.3271894454956055\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 89, batch train loss: 3.1973671913146973\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 90, batch train loss: 3.32188081741333\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 91, batch train loss: 5.275096416473389\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 92, batch train loss: 4.726702690124512\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 93, batch train loss: 3.85848069190979\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 94, batch train loss: 3.310182809829712\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 95, batch train loss: 3.8778719902038574\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 96, batch train loss: 3.936044931411743\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 97, batch train loss: 3.383232831954956\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 98, batch train loss: 3.923220157623291\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 99, batch train loss: 4.111398220062256\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 100, batch train loss: 2.805400848388672\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 101, batch train loss: 3.9050915241241455\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 102, batch train loss: 3.7295544147491455\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 103, batch train loss: 3.3923704624176025\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 104, batch train loss: 3.514651298522949\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 105, batch train loss: 3.906540632247925\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 106, batch train loss: 2.5152740478515625\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 107, batch train loss: 3.447782278060913\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 108, batch train loss: 3.024899959564209\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 109, batch train loss: 3.3108232021331787\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 110, batch train loss: 2.966346502304077\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 111, batch train loss: 2.9696052074432373\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 112, batch train loss: 3.6986243724823\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 113, batch train loss: 3.164853811264038\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 114, batch train loss: 3.1316206455230713\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 115, batch train loss: 2.8971543312072754\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 116, batch train loss: 3.5242269039154053\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 117, batch train loss: 2.2414968013763428\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 118, batch train loss: 2.424445867538452\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 119, batch train loss: 4.379101753234863\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 120, batch train loss: 2.848825216293335\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 121, batch train loss: 2.670718193054199\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 122, batch train loss: 2.7856080532073975\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 123, batch train loss: 3.4421157836914062\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 124, batch train loss: 2.783379077911377\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 125, batch train loss: 2.9561262130737305\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 126, batch train loss: 2.6879515647888184\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 127, batch train loss: 4.484178066253662\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 128, batch train loss: 3.969006299972534\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 129, batch train loss: 3.0582456588745117\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 130, batch train loss: 4.529971122741699\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, batch_id: 131, batch train loss: 3.655313730239868\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 132, batch train loss: 3.101837635040283\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 133, batch train loss: 4.780068397521973\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 134, batch train loss: 3.239088535308838\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 135, batch train loss: 3.072664260864258\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 136, batch train loss: 3.168935537338257\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 137, batch train loss: 2.8805627822875977\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 138, batch train loss: 3.028895139694214\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 139, batch train loss: 3.0750484466552734\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 140, batch train loss: 3.791355848312378\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 141, batch train loss: 2.771836519241333\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 142, batch train loss: 2.476743459701538\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 143, batch train loss: 3.257760763168335\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 144, batch train loss: 4.853039741516113\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 145, batch train loss: 2.17952036857605\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 146, batch train loss: 3.618293523788452\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 147, batch train loss: 3.165956497192383\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 148, batch train loss: 3.0631163120269775\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 149, batch train loss: 3.4473559856414795\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 150, batch train loss: 3.406609296798706\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 151, batch train loss: 3.0418334007263184\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 152, batch train loss: 3.004795789718628\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 153, batch train loss: 2.7027642726898193\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 154, batch train loss: 2.7284157276153564\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 155, batch train loss: 3.1564648151397705\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 156, batch train loss: 2.596877336502075\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 157, batch train loss: 2.502488613128662\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 158, batch train loss: 2.5524237155914307\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 159, batch train loss: 2.432830333709717\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 160, batch train loss: 2.8914148807525635\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 161, batch train loss: 2.0440428256988525\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 162, batch train loss: 1.7005784511566162\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 163, batch train loss: 3.1110458374023438\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 164, batch train loss: 2.9318766593933105\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 165, batch train loss: 2.3685483932495117\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 166, batch train loss: 2.4198882579803467\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 167, batch train loss: 2.5182130336761475\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 168, batch train loss: 3.0165023803710938\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 169, batch train loss: 2.230031967163086\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 170, batch train loss: 2.747929573059082\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 171, batch train loss: 2.0438263416290283\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 172, batch train loss: 2.437288522720337\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 173, batch train loss: 2.904172658920288\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 174, batch train loss: 2.034433603286743\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 175, batch train loss: 2.6726608276367188\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 176, batch train loss: 3.299177885055542\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 177, batch train loss: 2.080700397491455\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 178, batch train loss: 3.332587480545044\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 179, batch train loss: 2.9153945446014404\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 180, batch train loss: 2.8146440982818604\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 181, batch train loss: 3.1688616275787354\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 182, batch train loss: 2.7953901290893555\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 183, batch train loss: 6.035958766937256\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 184, batch train loss: 3.1242640018463135\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 185, batch train loss: 2.8431780338287354\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 186, batch train loss: 2.870650053024292\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 187, batch train loss: 2.505873680114746\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 188, batch train loss: 2.9225471019744873\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 189, batch train loss: 2.490279197692871\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 190, batch train loss: 2.431565999984741\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 191, batch train loss: 3.156559467315674\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 192, batch train loss: 2.84648060798645\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 193, batch train loss: 2.4056291580200195\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 194, batch train loss: 2.770137071609497\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 195, batch train loss: 2.2583398818969727\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 196, batch train loss: 2.323247194290161\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 197, batch train loss: 3.0214779376983643\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 198, batch train loss: 3.311108350753784\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 199, batch train loss: 2.744410991668701\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 200, batch train loss: 2.76640248298645\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 201, batch train loss: 2.936549186706543\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 202, batch train loss: 2.9043242931365967\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 203, batch train loss: 2.732192039489746\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 204, batch train loss: 2.5616204738616943\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 205, batch train loss: 1.9555859565734863\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 206, batch train loss: 2.21309757232666\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 207, batch train loss: 2.3740274906158447\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 208, batch train loss: 2.2963004112243652\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 209, batch train loss: 2.246596097946167\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 210, batch train loss: 2.9763801097869873\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 211, batch train loss: 2.1403844356536865\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 212, batch train loss: 2.253504753112793\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 213, batch train loss: 2.301875114440918\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 214, batch train loss: 2.6145598888397217\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 215, batch train loss: 2.246661901473999\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 216, batch train loss: 2.0939340591430664\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 217, batch train loss: 2.506368637084961\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 218, batch train loss: 2.1099536418914795\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 219, batch train loss: 2.433635711669922\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 220, batch train loss: 3.4997127056121826\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 221, batch train loss: 2.8397903442382812\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 222, batch train loss: 2.050171375274658\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 223, batch train loss: 2.1967523097991943\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 224, batch train loss: 2.9455299377441406\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 225, batch train loss: 2.093245506286621\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 226, batch train loss: 2.7034451961517334\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 227, batch train loss: 2.559211492538452\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 228, batch train loss: 3.212975025177002\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 229, batch train loss: 2.6772453784942627\n",
      "\n",
      "\n",
      "Epoch: 78, batch_id: 230, batch train loss: 3.134734630584717\n",
      "\n",
      "\n",
      "Epoch: 78/ 100, Loss: 3.2727570948393447\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:14<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78 Validation Loss: 3.2515675107638042\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79, batch_id: 1, batch train loss: 3.4136853218078613\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 2, batch train loss: 3.420109748840332\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 3, batch train loss: 2.8322808742523193\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 4, batch train loss: 2.1137895584106445\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 5, batch train loss: 3.383424997329712\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 6, batch train loss: 3.9765923023223877\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 7, batch train loss: 3.6155831813812256\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 8, batch train loss: 2.9878315925598145\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 9, batch train loss: 2.567532777786255\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 10, batch train loss: 2.2637033462524414\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 11, batch train loss: 3.084764003753662\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 12, batch train loss: 2.681321144104004\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 13, batch train loss: 2.241022825241089\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 14, batch train loss: 2.738421678543091\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 15, batch train loss: 2.6645681858062744\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 16, batch train loss: 2.161731481552124\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 17, batch train loss: 1.9093648195266724\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 18, batch train loss: 5.794950485229492\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 19, batch train loss: 2.8064000606536865\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 20, batch train loss: 3.6404759883880615\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 21, batch train loss: 3.1196019649505615\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 22, batch train loss: 2.8499507904052734\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 23, batch train loss: 4.53263521194458\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 24, batch train loss: 3.324934244155884\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 25, batch train loss: 3.075641393661499\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 26, batch train loss: 5.349309921264648\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 27, batch train loss: 2.374985456466675\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 28, batch train loss: 4.188822269439697\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 29, batch train loss: 3.3456482887268066\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 30, batch train loss: 4.560606479644775\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 31, batch train loss: 4.413053512573242\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 32, batch train loss: 5.261228561401367\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 33, batch train loss: 3.7569684982299805\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 34, batch train loss: 4.331521987915039\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 35, batch train loss: 4.08868932723999\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 36, batch train loss: 2.9681167602539062\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 37, batch train loss: 4.157725811004639\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 38, batch train loss: 3.7007203102111816\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 39, batch train loss: 2.7186479568481445\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 40, batch train loss: 2.636366128921509\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 41, batch train loss: 2.440603256225586\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 42, batch train loss: 2.6777212619781494\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 43, batch train loss: 3.2671926021575928\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 44, batch train loss: 2.0823657512664795\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 45, batch train loss: 2.1579134464263916\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 46, batch train loss: 2.1745002269744873\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 47, batch train loss: 1.955826997756958\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 48, batch train loss: 4.701764106750488\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 49, batch train loss: 2.7643468379974365\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 50, batch train loss: 2.4973371028900146\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 51, batch train loss: 1.9403156042099\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 52, batch train loss: 2.464357376098633\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 53, batch train loss: 2.464292287826538\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 54, batch train loss: 2.134960412979126\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 55, batch train loss: 2.636671781539917\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 56, batch train loss: 2.290027618408203\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 57, batch train loss: 2.866912364959717\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 58, batch train loss: 2.304518222808838\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 59, batch train loss: 2.864072799682617\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 60, batch train loss: 2.6548986434936523\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 61, batch train loss: 2.1940536499023438\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 62, batch train loss: 3.028667688369751\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 63, batch train loss: 1.9719494581222534\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 64, batch train loss: 1.840558648109436\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 65, batch train loss: 1.962531328201294\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 66, batch train loss: 2.235788583755493\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 67, batch train loss: 2.714531898498535\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 68, batch train loss: 2.062309503555298\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 69, batch train loss: 3.6623783111572266\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 70, batch train loss: 1.5015678405761719\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 71, batch train loss: 2.586562395095825\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 72, batch train loss: 1.8863154649734497\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 73, batch train loss: 3.0696139335632324\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 74, batch train loss: 3.2477545738220215\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 75, batch train loss: 2.251713752746582\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 76, batch train loss: 2.442504405975342\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 77, batch train loss: 2.6962602138519287\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 78, batch train loss: 2.7949671745300293\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 79, batch train loss: 2.039963960647583\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 80, batch train loss: 2.387249231338501\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 81, batch train loss: 2.700040578842163\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 82, batch train loss: 2.309133291244507\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 83, batch train loss: 2.282477855682373\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 84, batch train loss: 2.188673973083496\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 85, batch train loss: 2.171957492828369\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 86, batch train loss: 2.164415121078491\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 87, batch train loss: 2.2526869773864746\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 88, batch train loss: 3.0701613426208496\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 89, batch train loss: 2.9502077102661133\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 90, batch train loss: 3.455791473388672\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 91, batch train loss: 4.310878753662109\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 92, batch train loss: 3.467783212661743\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 93, batch train loss: 3.4720299243927\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 94, batch train loss: 3.544059991836548\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 95, batch train loss: 2.7368648052215576\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 96, batch train loss: 2.377023935317993\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 97, batch train loss: 1.8935927152633667\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 98, batch train loss: 2.345012664794922\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 99, batch train loss: 1.933726191520691\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 100, batch train loss: 2.2398340702056885\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 101, batch train loss: 3.2229421138763428\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 102, batch train loss: 3.680044651031494\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 103, batch train loss: 3.503598690032959\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 104, batch train loss: 4.172569274902344\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 105, batch train loss: 4.303036689758301\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 106, batch train loss: 3.535623073577881\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 107, batch train loss: 3.4598019123077393\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 108, batch train loss: 2.9148099422454834\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 109, batch train loss: 3.5740039348602295\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 110, batch train loss: 4.392524242401123\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 111, batch train loss: 3.0627434253692627\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 112, batch train loss: 5.405472755432129\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 113, batch train loss: 3.616650342941284\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 114, batch train loss: 5.578612327575684\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 115, batch train loss: 5.777510166168213\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 116, batch train loss: 4.686747074127197\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 117, batch train loss: 3.766619920730591\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 118, batch train loss: 4.890832424163818\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 119, batch train loss: 3.7319083213806152\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 120, batch train loss: 2.376476764678955\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 121, batch train loss: 3.394773244857788\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 122, batch train loss: 2.678480625152588\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 123, batch train loss: 7.211572170257568\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 124, batch train loss: 3.7255260944366455\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 125, batch train loss: 5.956720352172852\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 126, batch train loss: 3.9030070304870605\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 127, batch train loss: 3.3256709575653076\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 128, batch train loss: 2.4746406078338623\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 129, batch train loss: 2.333798885345459\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79, batch_id: 130, batch train loss: 2.2776293754577637\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 131, batch train loss: 2.5469987392425537\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 132, batch train loss: 4.245950698852539\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 133, batch train loss: 3.683107852935791\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 134, batch train loss: 4.172779083251953\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 135, batch train loss: 3.505298614501953\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 136, batch train loss: 2.500572919845581\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 137, batch train loss: 3.5166869163513184\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 138, batch train loss: 4.069088935852051\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 139, batch train loss: 2.390599012374878\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 140, batch train loss: 3.474667549133301\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 141, batch train loss: 2.8219215869903564\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 142, batch train loss: 2.379805088043213\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 143, batch train loss: 2.6366071701049805\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 144, batch train loss: 2.9715521335601807\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 145, batch train loss: 3.0535898208618164\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 146, batch train loss: 4.387928485870361\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 147, batch train loss: 3.312459707260132\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 148, batch train loss: 2.579387664794922\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 149, batch train loss: 2.612924098968506\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 150, batch train loss: 3.023674726486206\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 151, batch train loss: 2.961888313293457\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 152, batch train loss: 3.2762951850891113\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 153, batch train loss: 2.7443039417266846\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 154, batch train loss: 3.289259433746338\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 155, batch train loss: 4.549030780792236\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 156, batch train loss: 4.424864292144775\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 157, batch train loss: 3.4220616817474365\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 158, batch train loss: 2.4720282554626465\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 159, batch train loss: 3.1527111530303955\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 160, batch train loss: 2.7433834075927734\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 161, batch train loss: 3.3427295684814453\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 162, batch train loss: 2.2252159118652344\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 163, batch train loss: 2.990919589996338\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 164, batch train loss: 3.8730428218841553\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 165, batch train loss: 3.418203830718994\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 166, batch train loss: 2.6401736736297607\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 167, batch train loss: 3.910792350769043\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 168, batch train loss: 2.66918683052063\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 169, batch train loss: 3.0280191898345947\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 170, batch train loss: 3.5299718379974365\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 171, batch train loss: 2.668020009994507\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 172, batch train loss: 2.5920941829681396\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 173, batch train loss: 2.762570381164551\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 174, batch train loss: 2.9832069873809814\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 175, batch train loss: 2.6955323219299316\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 176, batch train loss: 2.7552177906036377\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 177, batch train loss: 3.3605098724365234\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 178, batch train loss: 3.2153282165527344\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 179, batch train loss: 3.8648617267608643\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 180, batch train loss: 4.731723785400391\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 181, batch train loss: 3.9562337398529053\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 182, batch train loss: 2.9009933471679688\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 183, batch train loss: 3.3332972526550293\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 184, batch train loss: 3.4683845043182373\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 185, batch train loss: 4.178784370422363\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 186, batch train loss: 3.2372851371765137\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 187, batch train loss: 3.464200496673584\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 188, batch train loss: 3.196688413619995\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 189, batch train loss: 3.113809585571289\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 190, batch train loss: 4.256161212921143\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 191, batch train loss: 2.827357530593872\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 192, batch train loss: 3.3273558616638184\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 193, batch train loss: 3.049051523208618\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 194, batch train loss: 2.9494051933288574\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 195, batch train loss: 3.526245594024658\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 196, batch train loss: 4.072021961212158\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 197, batch train loss: 2.9041318893432617\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 198, batch train loss: 4.383618354797363\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 199, batch train loss: 3.931239366531372\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 200, batch train loss: 4.144692897796631\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 201, batch train loss: 4.325468063354492\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 202, batch train loss: 5.26094913482666\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 203, batch train loss: 5.595021724700928\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 204, batch train loss: 6.133702754974365\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 205, batch train loss: 8.753503799438477\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 206, batch train loss: 4.492252826690674\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 207, batch train loss: 4.4698615074157715\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 208, batch train loss: 4.7407684326171875\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 209, batch train loss: 3.7434186935424805\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 210, batch train loss: 5.215567111968994\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 211, batch train loss: 5.195331573486328\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 212, batch train loss: 5.632008075714111\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 213, batch train loss: 5.757834434509277\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 214, batch train loss: 7.101598262786865\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 215, batch train loss: 8.85566520690918\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 216, batch train loss: 12.13809585571289\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 217, batch train loss: 6.364905834197998\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 218, batch train loss: 6.042826175689697\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 219, batch train loss: 6.976754665374756\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 220, batch train loss: 6.980096817016602\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 221, batch train loss: 6.04644250869751\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 222, batch train loss: 5.765861988067627\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 223, batch train loss: 6.820955753326416\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 224, batch train loss: 6.42025899887085\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 225, batch train loss: 3.607698678970337\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 226, batch train loss: 8.570965766906738\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 227, batch train loss: 7.574368476867676\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 228, batch train loss: 6.615878105163574\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 229, batch train loss: 5.911738395690918\n",
      "\n",
      "\n",
      "Epoch: 79, batch_id: 230, batch train loss: 4.203860759735107\n",
      "\n",
      "\n",
      "Epoch: 79/ 100, Loss: 3.571672331250232\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:12<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79 Validation Loss: 6.097962852319082\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, batch_id: 1, batch train loss: 7.056025981903076\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 2, batch train loss: 4.251548767089844\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 3, batch train loss: 6.731227874755859\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 4, batch train loss: 6.239346027374268\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 5, batch train loss: 5.136875629425049\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 6, batch train loss: 6.23310661315918\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 7, batch train loss: 7.293471813201904\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 8, batch train loss: 14.83311653137207\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 9, batch train loss: 8.699301719665527\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 10, batch train loss: 6.361248970031738\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 11, batch train loss: 6.636000633239746\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 12, batch train loss: 8.086029052734375\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 13, batch train loss: 6.596385478973389\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 14, batch train loss: 6.336945056915283\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 15, batch train loss: 7.983680725097656\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 16, batch train loss: 8.473226547241211\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 17, batch train loss: 6.68289041519165\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 18, batch train loss: 4.689828395843506\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 19, batch train loss: 9.192959785461426\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 20, batch train loss: 4.8935441970825195\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 21, batch train loss: 7.433624744415283\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 22, batch train loss: 4.8447136878967285\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 23, batch train loss: 9.225244522094727\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 24, batch train loss: 5.070838928222656\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 25, batch train loss: 6.5746541023254395\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 26, batch train loss: 9.718002319335938\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 27, batch train loss: 6.746422290802002\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 28, batch train loss: 3.9709548950195312\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 29, batch train loss: 5.269834995269775\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 30, batch train loss: 5.5630950927734375\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 31, batch train loss: 6.369580268859863\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 32, batch train loss: 4.8622727394104\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 33, batch train loss: 5.715381622314453\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 34, batch train loss: 6.463840961456299\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 35, batch train loss: 6.517177104949951\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 36, batch train loss: 4.727115631103516\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 37, batch train loss: 5.176735877990723\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 38, batch train loss: 4.755985736846924\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 39, batch train loss: 4.299984455108643\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 40, batch train loss: 5.796189785003662\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 41, batch train loss: 3.665802001953125\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 42, batch train loss: 4.4596967697143555\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 43, batch train loss: 3.2817513942718506\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 44, batch train loss: 5.190167427062988\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 45, batch train loss: 3.812727928161621\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 46, batch train loss: 4.405655860900879\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 47, batch train loss: 4.26785135269165\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 48, batch train loss: 4.4252424240112305\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 49, batch train loss: 5.384372711181641\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 50, batch train loss: 3.872664451599121\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 51, batch train loss: 4.104105472564697\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 52, batch train loss: 4.207540988922119\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 53, batch train loss: 5.215813636779785\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 54, batch train loss: 5.311359882354736\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 55, batch train loss: 5.373283863067627\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 56, batch train loss: 5.621212482452393\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 57, batch train loss: 5.046500205993652\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 58, batch train loss: 5.1280059814453125\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 59, batch train loss: 4.586859703063965\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 60, batch train loss: 4.374088287353516\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 61, batch train loss: 4.160030364990234\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 62, batch train loss: 4.558067321777344\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 63, batch train loss: 4.227858066558838\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 64, batch train loss: 5.919404983520508\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 65, batch train loss: 4.238223552703857\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 66, batch train loss: 4.617181301116943\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 67, batch train loss: 6.058440208435059\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 68, batch train loss: 5.393953323364258\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 69, batch train loss: 4.528128147125244\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 70, batch train loss: 5.469419956207275\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 71, batch train loss: 4.77340841293335\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 72, batch train loss: 4.494224548339844\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 73, batch train loss: 4.130198955535889\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 74, batch train loss: 5.692727565765381\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 75, batch train loss: 4.343196392059326\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 76, batch train loss: 4.035705089569092\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 77, batch train loss: 4.304661273956299\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 78, batch train loss: 4.673431873321533\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 79, batch train loss: 4.952495098114014\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 80, batch train loss: 4.2235846519470215\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 81, batch train loss: 6.671583652496338\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 82, batch train loss: 5.367547512054443\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 83, batch train loss: 5.554590702056885\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 84, batch train loss: 4.852717876434326\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 85, batch train loss: 7.391486167907715\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 86, batch train loss: 5.179720401763916\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 87, batch train loss: 5.8678297996521\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 88, batch train loss: 5.522664546966553\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 89, batch train loss: 5.613152027130127\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 90, batch train loss: 5.158177852630615\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 91, batch train loss: 5.679502010345459\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 92, batch train loss: 4.598970890045166\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 93, batch train loss: 5.698105335235596\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 94, batch train loss: 5.125598430633545\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 95, batch train loss: 4.055761337280273\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 96, batch train loss: 5.832215785980225\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 97, batch train loss: 5.501792907714844\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 98, batch train loss: 4.000644683837891\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 99, batch train loss: 4.869591236114502\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 100, batch train loss: 4.351688861846924\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 101, batch train loss: 6.985317230224609\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 102, batch train loss: 5.399840354919434\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 103, batch train loss: 3.7831196784973145\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 104, batch train loss: 6.795058727264404\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 105, batch train loss: 6.799368381500244\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 106, batch train loss: 6.704695701599121\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 107, batch train loss: 5.217245101928711\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 108, batch train loss: 5.409402847290039\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 109, batch train loss: 7.912899494171143\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 110, batch train loss: 5.650887489318848\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 111, batch train loss: 4.16642427444458\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 112, batch train loss: 6.773051738739014\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 113, batch train loss: 5.420050621032715\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 114, batch train loss: 5.939075946807861\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 115, batch train loss: 6.1933207511901855\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 116, batch train loss: 5.83640718460083\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 117, batch train loss: 6.36757230758667\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 118, batch train loss: 4.990041732788086\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 119, batch train loss: 5.376993179321289\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 120, batch train loss: 7.1547112464904785\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 121, batch train loss: 5.126239776611328\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 122, batch train loss: 5.494754314422607\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 123, batch train loss: 6.007680892944336\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 124, batch train loss: 7.1417741775512695\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 125, batch train loss: 5.906144618988037\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 126, batch train loss: 7.751095294952393\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 127, batch train loss: 5.433964729309082\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 128, batch train loss: 5.693121910095215\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 129, batch train loss: 6.685463905334473\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 130, batch train loss: 5.055353164672852\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, batch_id: 131, batch train loss: 7.405513286590576\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 132, batch train loss: 6.033856391906738\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 133, batch train loss: 5.844255447387695\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 134, batch train loss: 4.833376407623291\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 135, batch train loss: 5.460978031158447\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 136, batch train loss: 5.814252853393555\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 137, batch train loss: 6.6918110847473145\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 138, batch train loss: 5.538933277130127\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 139, batch train loss: 6.2072038650512695\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 140, batch train loss: 6.006300926208496\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 141, batch train loss: 4.588292598724365\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 142, batch train loss: 9.346281051635742\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 143, batch train loss: 5.585102558135986\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 144, batch train loss: 6.511074066162109\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 145, batch train loss: 5.723814964294434\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 146, batch train loss: 8.582236289978027\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 147, batch train loss: 6.7664031982421875\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 148, batch train loss: 6.0827717781066895\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 149, batch train loss: 6.621894836425781\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 150, batch train loss: 8.049101829528809\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 151, batch train loss: 6.53936767578125\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 152, batch train loss: 7.277763843536377\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 153, batch train loss: 7.963405132293701\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 154, batch train loss: 5.775329113006592\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 155, batch train loss: 8.829002380371094\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 156, batch train loss: 6.872004508972168\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 157, batch train loss: 7.998175621032715\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 158, batch train loss: 8.51364517211914\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 159, batch train loss: 7.8129143714904785\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 160, batch train loss: 7.455341815948486\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 161, batch train loss: 8.56283187866211\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 162, batch train loss: 5.430091381072998\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 163, batch train loss: 7.801246643066406\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 164, batch train loss: 9.126800537109375\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 165, batch train loss: 7.100004196166992\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 166, batch train loss: 9.256431579589844\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 167, batch train loss: 6.308174133300781\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 168, batch train loss: 7.507688999176025\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 169, batch train loss: 11.022697448730469\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 170, batch train loss: 6.774832725524902\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 171, batch train loss: 5.9077911376953125\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 172, batch train loss: 6.432782173156738\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 173, batch train loss: 5.559150218963623\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 174, batch train loss: 6.7677106857299805\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 175, batch train loss: 6.085855007171631\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 176, batch train loss: 6.4672627449035645\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 177, batch train loss: 9.127744674682617\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 178, batch train loss: 6.360081195831299\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 179, batch train loss: 6.4113054275512695\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 180, batch train loss: 8.349175453186035\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 181, batch train loss: 8.005324363708496\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 182, batch train loss: 6.379476547241211\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 183, batch train loss: 5.72116231918335\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 184, batch train loss: 4.775858402252197\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 185, batch train loss: 8.911971092224121\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 186, batch train loss: 7.282291889190674\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 187, batch train loss: 8.943841934204102\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 188, batch train loss: 5.1090874671936035\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 189, batch train loss: 9.292328834533691\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 190, batch train loss: 8.671228408813477\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 191, batch train loss: 5.938867568969727\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 192, batch train loss: 7.680351734161377\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 193, batch train loss: 6.929056644439697\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 194, batch train loss: 8.297371864318848\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 195, batch train loss: 5.858329772949219\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 196, batch train loss: 4.505892753601074\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 197, batch train loss: 7.722150802612305\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 198, batch train loss: 5.572940349578857\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 199, batch train loss: 7.087267875671387\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 200, batch train loss: 5.118626117706299\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 201, batch train loss: 5.844424247741699\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 202, batch train loss: 6.964093208312988\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 203, batch train loss: 7.522512435913086\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 204, batch train loss: 5.205914497375488\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 205, batch train loss: 6.084954738616943\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 206, batch train loss: 6.116271018981934\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 207, batch train loss: 6.55514669418335\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 208, batch train loss: 4.798374176025391\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 209, batch train loss: 4.670907497406006\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 210, batch train loss: 5.321664810180664\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 211, batch train loss: 5.392800807952881\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 212, batch train loss: 4.3352813720703125\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 213, batch train loss: 6.509593486785889\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 214, batch train loss: 4.558651447296143\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 215, batch train loss: 5.621662616729736\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 216, batch train loss: 3.890437364578247\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 217, batch train loss: 4.921451091766357\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 218, batch train loss: 6.67818021774292\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 219, batch train loss: 5.470298767089844\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 220, batch train loss: 5.0760321617126465\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 221, batch train loss: 5.956038951873779\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 222, batch train loss: 5.406917095184326\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 223, batch train loss: 4.727368354797363\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 224, batch train loss: 4.99221658706665\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 225, batch train loss: 5.204400062561035\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 226, batch train loss: 5.6108245849609375\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 227, batch train loss: 6.724327564239502\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 228, batch train loss: 4.134286403656006\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 229, batch train loss: 4.711076736450195\n",
      "\n",
      "\n",
      "Epoch: 80, batch_id: 230, batch train loss: 6.167016983032227\n",
      "\n",
      "\n",
      "Epoch: 80/ 100, Loss: 6.026819513155067\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:28<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80 Validation Loss: 6.508078408241272\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81, batch_id: 1, batch train loss: 5.953105926513672\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 2, batch train loss: 6.1167192459106445\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 3, batch train loss: 5.551304340362549\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 4, batch train loss: 5.574516773223877\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 5, batch train loss: 7.408950328826904\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 6, batch train loss: 6.1493964195251465\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 7, batch train loss: 5.454624176025391\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 8, batch train loss: 4.048632621765137\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 9, batch train loss: 8.283859252929688\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 10, batch train loss: 7.732386112213135\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 11, batch train loss: 7.650269985198975\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 12, batch train loss: 6.623711109161377\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 13, batch train loss: 6.812140941619873\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 14, batch train loss: 5.830617904663086\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 15, batch train loss: 5.634721279144287\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 16, batch train loss: 5.520804405212402\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 17, batch train loss: 6.541388511657715\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 18, batch train loss: 4.751825332641602\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 19, batch train loss: 4.844937324523926\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 20, batch train loss: 6.310453414916992\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 21, batch train loss: 5.2571282386779785\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 22, batch train loss: 5.372522830963135\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 23, batch train loss: 5.763807773590088\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 24, batch train loss: 4.971164703369141\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 25, batch train loss: 4.009571552276611\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 26, batch train loss: 4.348465442657471\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 27, batch train loss: 3.39123797416687\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 28, batch train loss: 4.154170989990234\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 29, batch train loss: 3.7887048721313477\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 30, batch train loss: 3.0593409538269043\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 31, batch train loss: 3.671142101287842\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 32, batch train loss: 3.632723093032837\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 33, batch train loss: 4.176025867462158\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 34, batch train loss: 4.123196601867676\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 35, batch train loss: 4.027651309967041\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 36, batch train loss: 3.1875431537628174\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 37, batch train loss: 4.117590427398682\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 38, batch train loss: 4.6595611572265625\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 39, batch train loss: 4.045507907867432\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 40, batch train loss: 3.677234649658203\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 41, batch train loss: 4.1429762840271\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 42, batch train loss: 5.3888421058654785\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 43, batch train loss: 3.414501905441284\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 44, batch train loss: 5.256075859069824\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 45, batch train loss: 4.409817695617676\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 46, batch train loss: 3.546074151992798\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 47, batch train loss: 4.325204849243164\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 48, batch train loss: 4.11024808883667\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 49, batch train loss: 3.57916259765625\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 50, batch train loss: 3.7976534366607666\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 51, batch train loss: 4.874967575073242\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 52, batch train loss: 4.458198070526123\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 53, batch train loss: 2.7987515926361084\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 54, batch train loss: 3.0608632564544678\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 55, batch train loss: 3.4522433280944824\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 56, batch train loss: 4.038598537445068\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 57, batch train loss: 4.185672760009766\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 58, batch train loss: 3.650294303894043\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 59, batch train loss: 4.070773601531982\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 60, batch train loss: 2.809098720550537\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 61, batch train loss: 5.699187278747559\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 62, batch train loss: 3.8808393478393555\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 63, batch train loss: 3.6836612224578857\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 64, batch train loss: 3.943601369857788\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 65, batch train loss: 2.9892544746398926\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 66, batch train loss: 4.940852642059326\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 67, batch train loss: 2.9374210834503174\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 68, batch train loss: 3.5163540840148926\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 69, batch train loss: 3.2136261463165283\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 70, batch train loss: 4.131916522979736\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 71, batch train loss: 3.8134424686431885\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 72, batch train loss: 4.138304233551025\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 73, batch train loss: 4.267384052276611\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 74, batch train loss: 5.550148963928223\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 75, batch train loss: 3.9500715732574463\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 76, batch train loss: 2.834929943084717\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 77, batch train loss: 6.234460830688477\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 78, batch train loss: 4.472693920135498\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 79, batch train loss: 5.366688251495361\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 80, batch train loss: 5.199039936065674\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 81, batch train loss: 3.873427629470825\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 82, batch train loss: 5.828896999359131\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 83, batch train loss: 6.4626007080078125\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 84, batch train loss: 4.503641128540039\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 85, batch train loss: 3.390000104904175\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 86, batch train loss: 4.819115161895752\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 87, batch train loss: 4.451693058013916\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 88, batch train loss: 3.905904531478882\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 89, batch train loss: 3.760516405105591\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 90, batch train loss: 4.1025238037109375\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 91, batch train loss: 3.2921805381774902\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 92, batch train loss: 2.415708541870117\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 93, batch train loss: 2.807218551635742\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 94, batch train loss: 2.546348810195923\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 95, batch train loss: 5.731837272644043\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 96, batch train loss: 3.12733793258667\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 97, batch train loss: 4.567145347595215\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 98, batch train loss: 3.295438528060913\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 99, batch train loss: 3.0739572048187256\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 100, batch train loss: 4.6356964111328125\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 101, batch train loss: 2.9649956226348877\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 102, batch train loss: 5.641569137573242\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 103, batch train loss: 4.8110222816467285\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 104, batch train loss: 3.6116483211517334\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 105, batch train loss: 4.659240245819092\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 106, batch train loss: 4.122485160827637\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 107, batch train loss: 3.1176388263702393\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 108, batch train loss: 3.3806495666503906\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 109, batch train loss: 2.9287500381469727\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 110, batch train loss: 3.7394702434539795\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 111, batch train loss: 3.1463379859924316\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 112, batch train loss: 4.718662738800049\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 113, batch train loss: 4.819519519805908\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 114, batch train loss: 4.103901386260986\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 115, batch train loss: 3.7684707641601562\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 116, batch train loss: 2.6886355876922607\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 117, batch train loss: 4.189534664154053\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 118, batch train loss: 4.175047397613525\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 119, batch train loss: 4.006496906280518\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 120, batch train loss: 3.247016668319702\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 121, batch train loss: 2.9374470710754395\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 122, batch train loss: 4.430911540985107\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 123, batch train loss: 2.9465270042419434\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 124, batch train loss: 4.382908344268799\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 125, batch train loss: 3.797750234603882\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 126, batch train loss: 3.1471052169799805\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 127, batch train loss: 4.009337425231934\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 128, batch train loss: 4.346382141113281\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 129, batch train loss: 3.990222692489624\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 130, batch train loss: 4.358944892883301\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81, batch_id: 131, batch train loss: 3.956458330154419\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 132, batch train loss: 4.147242546081543\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 133, batch train loss: 3.8452327251434326\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 134, batch train loss: 5.495510101318359\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 135, batch train loss: 4.768343448638916\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 136, batch train loss: 5.026257514953613\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 137, batch train loss: 4.2125396728515625\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 138, batch train loss: 3.7643887996673584\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 139, batch train loss: 4.305029392242432\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 140, batch train loss: 4.148233890533447\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 141, batch train loss: 4.0504374504089355\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 142, batch train loss: 4.316230297088623\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 143, batch train loss: 4.178414344787598\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 144, batch train loss: 6.454095363616943\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 145, batch train loss: 4.364952087402344\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 146, batch train loss: 3.682880163192749\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 147, batch train loss: 6.16830587387085\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 148, batch train loss: 3.3053882122039795\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 149, batch train loss: 3.863328456878662\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 150, batch train loss: 3.8473591804504395\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 151, batch train loss: 3.8643431663513184\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 152, batch train loss: 3.5966577529907227\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 153, batch train loss: 3.4945857524871826\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 154, batch train loss: 4.492122173309326\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 155, batch train loss: 4.024268627166748\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 156, batch train loss: 3.534045457839966\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 157, batch train loss: 4.276196479797363\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 158, batch train loss: 4.447134017944336\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 159, batch train loss: 4.46691370010376\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 160, batch train loss: 3.586050271987915\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 161, batch train loss: 3.7228479385375977\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 162, batch train loss: 4.696041584014893\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 163, batch train loss: 4.198976993560791\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 164, batch train loss: 4.594146251678467\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 165, batch train loss: 6.422765254974365\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 166, batch train loss: 5.7286057472229\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 167, batch train loss: 3.5491206645965576\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 168, batch train loss: 5.4032745361328125\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 169, batch train loss: 10.41952133178711\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 170, batch train loss: 5.347312927246094\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 171, batch train loss: 5.615982532501221\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 172, batch train loss: 6.890437602996826\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 173, batch train loss: 4.853229999542236\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 174, batch train loss: 6.672282695770264\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 175, batch train loss: 5.736730098724365\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 176, batch train loss: 5.817512035369873\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 177, batch train loss: 4.341100215911865\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 178, batch train loss: 3.831226348876953\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 179, batch train loss: 4.048201084136963\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 180, batch train loss: 6.042408466339111\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 181, batch train loss: 3.477790594100952\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 182, batch train loss: 5.197226524353027\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 183, batch train loss: 5.502331733703613\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 184, batch train loss: 4.036821365356445\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 185, batch train loss: 3.883861780166626\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 186, batch train loss: 4.175526142120361\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 187, batch train loss: 4.503200531005859\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 188, batch train loss: 5.652896404266357\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 189, batch train loss: 3.9073197841644287\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 190, batch train loss: 5.49801778793335\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 191, batch train loss: 5.242678642272949\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 192, batch train loss: 5.1918044090271\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 193, batch train loss: 5.763026714324951\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 194, batch train loss: 5.015610218048096\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 195, batch train loss: 4.487998962402344\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 196, batch train loss: 4.319436073303223\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 197, batch train loss: 4.7172698974609375\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 198, batch train loss: 4.2499895095825195\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 199, batch train loss: 4.869208812713623\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 200, batch train loss: 4.881382465362549\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 201, batch train loss: 3.6003832817077637\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 202, batch train loss: 4.6796674728393555\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 203, batch train loss: 5.505709648132324\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 204, batch train loss: 4.2920308113098145\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 205, batch train loss: 3.8643693923950195\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 206, batch train loss: 4.420095443725586\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 207, batch train loss: 3.9582722187042236\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 208, batch train loss: 3.996497869491577\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 209, batch train loss: 4.367861747741699\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 210, batch train loss: 4.668645858764648\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 211, batch train loss: 3.1881208419799805\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 212, batch train loss: 4.693624019622803\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 213, batch train loss: 3.2895913124084473\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 214, batch train loss: 2.663215398788452\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 215, batch train loss: 2.4380972385406494\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 216, batch train loss: 3.016568183898926\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 217, batch train loss: 1.9051049947738647\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 218, batch train loss: 2.573556661605835\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 219, batch train loss: 3.5072550773620605\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 220, batch train loss: 4.404216289520264\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 221, batch train loss: 3.1377928256988525\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 222, batch train loss: 3.4235904216766357\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 223, batch train loss: 2.459733486175537\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 224, batch train loss: 1.9458986520767212\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 225, batch train loss: 2.342362880706787\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 226, batch train loss: 3.177769422531128\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 227, batch train loss: 3.1878747940063477\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 228, batch train loss: 3.4308576583862305\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 229, batch train loss: 3.401426076889038\n",
      "\n",
      "\n",
      "Epoch: 81, batch_id: 230, batch train loss: 3.0293965339660645\n",
      "\n",
      "\n",
      "Epoch: 81/ 100, Loss: 4.356087073035862\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:21<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81 Validation Loss: 2.985875900586446\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82, batch_id: 1, batch train loss: 3.494429111480713\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 2, batch train loss: 2.7024426460266113\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 3, batch train loss: 2.7676827907562256\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 4, batch train loss: 2.3549482822418213\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 5, batch train loss: 2.374828338623047\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 6, batch train loss: 4.242127418518066\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 7, batch train loss: 3.646651268005371\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 8, batch train loss: 2.2173619270324707\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 9, batch train loss: 2.6853365898132324\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 10, batch train loss: 2.353189706802368\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 11, batch train loss: 2.3408420085906982\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 12, batch train loss: 2.9669880867004395\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 13, batch train loss: 1.630854845046997\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 14, batch train loss: 2.864028215408325\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 15, batch train loss: 2.25020694732666\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 16, batch train loss: 3.143929958343506\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 17, batch train loss: 2.1735305786132812\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 18, batch train loss: 3.009782552719116\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 19, batch train loss: 3.5011343955993652\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 20, batch train loss: 3.457122802734375\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 21, batch train loss: 2.882488489151001\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 22, batch train loss: 2.837592363357544\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 23, batch train loss: 2.1336822509765625\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 24, batch train loss: 2.4050867557525635\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 25, batch train loss: 2.8391165733337402\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 26, batch train loss: 2.857755422592163\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 27, batch train loss: 2.23506236076355\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 28, batch train loss: 4.005511283874512\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 29, batch train loss: 3.5160820484161377\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 30, batch train loss: 3.2789461612701416\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 31, batch train loss: 2.6398699283599854\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 32, batch train loss: 2.5921761989593506\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 33, batch train loss: 1.9779980182647705\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 34, batch train loss: 2.7754263877868652\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 35, batch train loss: 2.9336588382720947\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 36, batch train loss: 3.080620527267456\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 37, batch train loss: 3.3960673809051514\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 38, batch train loss: 2.8499295711517334\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 39, batch train loss: 2.917259693145752\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 40, batch train loss: 2.6925644874572754\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 41, batch train loss: 1.6956257820129395\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 42, batch train loss: 1.8277140855789185\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 43, batch train loss: 3.6179935932159424\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 44, batch train loss: 2.6485936641693115\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 45, batch train loss: 4.865822792053223\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 46, batch train loss: 2.9547271728515625\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 47, batch train loss: 3.0480542182922363\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 48, batch train loss: 4.396090984344482\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 49, batch train loss: 3.915339469909668\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 50, batch train loss: 3.8777339458465576\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 51, batch train loss: 3.348383903503418\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 52, batch train loss: 2.989825963973999\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 53, batch train loss: 4.107507705688477\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 54, batch train loss: 3.106454610824585\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 55, batch train loss: 3.536027431488037\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 56, batch train loss: 5.020595073699951\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 57, batch train loss: 5.250256061553955\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 58, batch train loss: 3.804328203201294\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 59, batch train loss: 4.340100288391113\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 60, batch train loss: 3.090102434158325\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 61, batch train loss: 3.0511746406555176\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 62, batch train loss: 2.312403678894043\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 63, batch train loss: 3.953925848007202\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 64, batch train loss: 3.455754280090332\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 65, batch train loss: 3.061410665512085\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 66, batch train loss: 2.921250104904175\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 67, batch train loss: 3.0969507694244385\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 68, batch train loss: 2.9266881942749023\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 69, batch train loss: 3.4407925605773926\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 70, batch train loss: 4.30344295501709\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 71, batch train loss: 4.472428321838379\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 72, batch train loss: 2.58430552482605\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 73, batch train loss: 1.7341902256011963\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 74, batch train loss: 1.9812532663345337\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 75, batch train loss: 5.713244438171387\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 76, batch train loss: 3.9729995727539062\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 77, batch train loss: 4.254835605621338\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 78, batch train loss: 4.548003196716309\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 79, batch train loss: 4.251369476318359\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 80, batch train loss: 4.016355991363525\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 81, batch train loss: 4.7289252281188965\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 82, batch train loss: 4.281302452087402\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 83, batch train loss: 3.0051207542419434\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 84, batch train loss: 4.9674763679504395\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 85, batch train loss: 2.9823577404022217\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 86, batch train loss: 3.0700411796569824\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 87, batch train loss: 3.9148921966552734\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 88, batch train loss: 4.271599292755127\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 89, batch train loss: 3.9435834884643555\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 90, batch train loss: 4.715282917022705\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 91, batch train loss: 5.367952346801758\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 92, batch train loss: 4.308105945587158\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 93, batch train loss: 3.844623565673828\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 94, batch train loss: 3.2817511558532715\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 95, batch train loss: 4.115551948547363\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 96, batch train loss: 3.6467602252960205\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 97, batch train loss: 4.108144283294678\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 98, batch train loss: 3.1599130630493164\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 99, batch train loss: 2.4905104637145996\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 100, batch train loss: 3.1248300075531006\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 101, batch train loss: 3.482010841369629\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 102, batch train loss: 4.005039691925049\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 103, batch train loss: 3.385242223739624\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 104, batch train loss: 2.971684455871582\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 105, batch train loss: 4.69101095199585\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 106, batch train loss: 4.450223922729492\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 107, batch train loss: 2.766188621520996\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 108, batch train loss: 2.5653669834136963\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 109, batch train loss: 6.062857151031494\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 110, batch train loss: 5.214806079864502\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 111, batch train loss: 4.455395698547363\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 112, batch train loss: 4.078195571899414\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 113, batch train loss: 4.018148422241211\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 114, batch train loss: 3.1072685718536377\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 115, batch train loss: 3.722787618637085\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 116, batch train loss: 3.4326090812683105\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 117, batch train loss: 3.230473518371582\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 118, batch train loss: 4.389454364776611\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 119, batch train loss: 4.172231674194336\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 120, batch train loss: 2.5963611602783203\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 121, batch train loss: 1.9848964214324951\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 122, batch train loss: 2.6886110305786133\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 123, batch train loss: 3.030750036239624\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 124, batch train loss: 4.202551364898682\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 125, batch train loss: 4.689199924468994\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 126, batch train loss: 5.442474365234375\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 127, batch train loss: 5.464728832244873\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 128, batch train loss: 4.462651252746582\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 129, batch train loss: 5.4633636474609375\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82, batch_id: 130, batch train loss: 4.509670257568359\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 131, batch train loss: 4.8070807456970215\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 132, batch train loss: 6.593965530395508\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 133, batch train loss: 6.3511061668396\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 134, batch train loss: 5.090539932250977\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 135, batch train loss: 5.064203262329102\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 136, batch train loss: 7.153329849243164\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 137, batch train loss: 5.92814302444458\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 138, batch train loss: 6.704948902130127\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 139, batch train loss: 6.508446216583252\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 140, batch train loss: 5.781943321228027\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 141, batch train loss: 5.282530307769775\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 142, batch train loss: 8.225763320922852\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 143, batch train loss: 4.797451496124268\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 144, batch train loss: 6.728541374206543\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 145, batch train loss: 6.411461353302002\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 146, batch train loss: 5.37472677230835\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 147, batch train loss: 5.145928859710693\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 148, batch train loss: 4.878054141998291\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 149, batch train loss: 5.819203853607178\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 150, batch train loss: 5.31447696685791\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 151, batch train loss: 4.464211463928223\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 152, batch train loss: 4.866638660430908\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 153, batch train loss: 6.597538471221924\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 154, batch train loss: 4.979486465454102\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 155, batch train loss: 5.24177885055542\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 156, batch train loss: 6.138322830200195\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 157, batch train loss: 5.605007171630859\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 158, batch train loss: 4.229776382446289\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 159, batch train loss: 4.571592807769775\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 160, batch train loss: 5.210715293884277\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 161, batch train loss: 5.601423263549805\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 162, batch train loss: 5.368723392486572\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 163, batch train loss: 5.7404279708862305\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 164, batch train loss: 5.710106372833252\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 165, batch train loss: 5.39955472946167\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 166, batch train loss: 5.34574556350708\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 167, batch train loss: 5.465698719024658\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 168, batch train loss: 4.468493461608887\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 169, batch train loss: 7.574213981628418\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 170, batch train loss: 4.799269676208496\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 171, batch train loss: 5.628236770629883\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 172, batch train loss: 5.576206684112549\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 173, batch train loss: 5.603032112121582\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 174, batch train loss: 4.156108379364014\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 175, batch train loss: 5.154262065887451\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 176, batch train loss: 4.6835198402404785\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 177, batch train loss: 7.41611909866333\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 178, batch train loss: 5.044946670532227\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 179, batch train loss: 7.9270524978637695\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 180, batch train loss: 5.507585525512695\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 181, batch train loss: 6.478409767150879\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 182, batch train loss: 5.3312153816223145\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 183, batch train loss: 4.070845127105713\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 184, batch train loss: 5.933389186859131\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 185, batch train loss: 7.100502967834473\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 186, batch train loss: 5.996391773223877\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 187, batch train loss: 6.482501029968262\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 188, batch train loss: 5.271973609924316\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 189, batch train loss: 6.506077289581299\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 190, batch train loss: 5.420581817626953\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 191, batch train loss: 9.06689167022705\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 192, batch train loss: 7.089488983154297\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 193, batch train loss: 5.196720600128174\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 194, batch train loss: 4.817365646362305\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 195, batch train loss: 7.558804512023926\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 196, batch train loss: 6.954962730407715\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 197, batch train loss: 8.211994171142578\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 198, batch train loss: 6.203794956207275\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 199, batch train loss: 9.034947395324707\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 200, batch train loss: 10.949075698852539\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 201, batch train loss: 8.984536170959473\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 202, batch train loss: 7.787230491638184\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 203, batch train loss: 7.003284454345703\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 204, batch train loss: 6.452133655548096\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 205, batch train loss: 7.824928283691406\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 206, batch train loss: 6.301833152770996\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 207, batch train loss: 5.573971748352051\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 208, batch train loss: 5.630821704864502\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 209, batch train loss: 5.850734233856201\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 210, batch train loss: 6.073136806488037\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 211, batch train loss: 5.788859844207764\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 212, batch train loss: 5.380339622497559\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 213, batch train loss: 5.847728252410889\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 214, batch train loss: 4.2260661125183105\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 215, batch train loss: 5.856349468231201\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 216, batch train loss: 6.247841835021973\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 217, batch train loss: 4.718461036682129\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 218, batch train loss: 5.35325813293457\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 219, batch train loss: 4.783731937408447\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 220, batch train loss: 4.954535484313965\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 221, batch train loss: 4.904158115386963\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 222, batch train loss: 4.730563163757324\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 223, batch train loss: 5.2524638175964355\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 224, batch train loss: 7.008206367492676\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 225, batch train loss: 4.195329666137695\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 226, batch train loss: 5.912930965423584\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 227, batch train loss: 5.130645275115967\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 228, batch train loss: 3.991494655609131\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 229, batch train loss: 3.809629201889038\n",
      "\n",
      "\n",
      "Epoch: 82, batch_id: 230, batch train loss: 4.4100022315979\n",
      "\n",
      "\n",
      "Epoch: 82/ 100, Loss: 4.505574474127396\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:22<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 Validation Loss: 5.3677085916201275\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83, batch_id: 1, batch train loss: 4.561965465545654\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 2, batch train loss: 4.0985426902771\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 3, batch train loss: 3.7077879905700684\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 4, batch train loss: 4.812045097351074\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 5, batch train loss: 4.216518402099609\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 6, batch train loss: 4.367002487182617\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 7, batch train loss: 3.833507537841797\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 8, batch train loss: 3.4004228115081787\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 9, batch train loss: 5.061803817749023\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 10, batch train loss: 5.035309314727783\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 11, batch train loss: 3.724196672439575\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 12, batch train loss: 4.3312458992004395\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 13, batch train loss: 3.6691882610321045\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 14, batch train loss: 4.532455921173096\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 15, batch train loss: 4.322744369506836\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 16, batch train loss: 4.139830112457275\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 17, batch train loss: 5.8158183097839355\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 18, batch train loss: 4.619163990020752\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 19, batch train loss: 3.824470281600952\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 20, batch train loss: 3.7812304496765137\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 21, batch train loss: 4.486427307128906\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 22, batch train loss: 3.7359859943389893\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 23, batch train loss: 4.138033390045166\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 24, batch train loss: 3.2070226669311523\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 25, batch train loss: 7.9437971115112305\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 26, batch train loss: 4.849457740783691\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 27, batch train loss: 4.865577220916748\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 28, batch train loss: 2.93906831741333\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 29, batch train loss: 6.661464691162109\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 30, batch train loss: 5.139777660369873\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 31, batch train loss: 4.909462928771973\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 32, batch train loss: 5.176058769226074\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 33, batch train loss: 4.788553714752197\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 34, batch train loss: 3.8418331146240234\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 35, batch train loss: 7.394759178161621\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 36, batch train loss: 4.992281913757324\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 37, batch train loss: 4.923150062561035\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 38, batch train loss: 3.884312629699707\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 39, batch train loss: 3.402118444442749\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 40, batch train loss: 4.627719402313232\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 41, batch train loss: 4.2277421951293945\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 42, batch train loss: 3.7573904991149902\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 43, batch train loss: 3.1413445472717285\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 44, batch train loss: 3.8885905742645264\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 45, batch train loss: 3.9021239280700684\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 46, batch train loss: 3.2652769088745117\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 47, batch train loss: 3.426197052001953\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 48, batch train loss: 3.8452742099761963\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 49, batch train loss: 5.256559371948242\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 50, batch train loss: 4.8531012535095215\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 51, batch train loss: 5.656219959259033\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 52, batch train loss: 6.446246147155762\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 53, batch train loss: 7.157713890075684\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 54, batch train loss: 4.805471897125244\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 55, batch train loss: 5.6459221839904785\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 56, batch train loss: 5.096181869506836\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 57, batch train loss: 7.239635467529297\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 58, batch train loss: 6.683850288391113\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 59, batch train loss: 4.637043476104736\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 60, batch train loss: 4.248805999755859\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 61, batch train loss: 4.199741840362549\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 62, batch train loss: 4.900586128234863\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 63, batch train loss: 4.115438938140869\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 64, batch train loss: 4.542886734008789\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 65, batch train loss: 3.6203083992004395\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 66, batch train loss: 4.465181827545166\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 67, batch train loss: 5.726827621459961\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 68, batch train loss: 5.66409969329834\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 69, batch train loss: 4.071630001068115\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 70, batch train loss: 5.490513324737549\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 71, batch train loss: 5.183149814605713\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 72, batch train loss: 5.596190929412842\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 73, batch train loss: 4.198520660400391\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 74, batch train loss: 3.8577404022216797\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 75, batch train loss: 4.15755558013916\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 76, batch train loss: 6.97709321975708\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 77, batch train loss: 4.13661527633667\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 78, batch train loss: 5.296245098114014\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 79, batch train loss: 4.837789535522461\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 80, batch train loss: 4.080057621002197\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 81, batch train loss: 3.913621425628662\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 82, batch train loss: 5.441418647766113\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 83, batch train loss: 4.126777648925781\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 84, batch train loss: 4.698523998260498\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 85, batch train loss: 5.101126670837402\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 86, batch train loss: 5.49810791015625\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 87, batch train loss: 3.0032312870025635\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 88, batch train loss: 3.936556100845337\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 89, batch train loss: 3.843067169189453\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 90, batch train loss: 2.8819069862365723\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 91, batch train loss: 4.385892391204834\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 92, batch train loss: 3.9048123359680176\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 93, batch train loss: 4.333578109741211\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 94, batch train loss: 4.639622211456299\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 95, batch train loss: 4.164959907531738\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 96, batch train loss: 2.94507098197937\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 97, batch train loss: 5.351598262786865\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 98, batch train loss: 4.759058475494385\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 99, batch train loss: 4.066595554351807\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 100, batch train loss: 3.8302433490753174\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 101, batch train loss: 3.5154638290405273\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 102, batch train loss: 4.349666118621826\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 103, batch train loss: 2.9187488555908203\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 104, batch train loss: 2.8577957153320312\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 105, batch train loss: 3.856935977935791\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 106, batch train loss: 4.099288463592529\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 107, batch train loss: 3.828587532043457\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 108, batch train loss: 4.363236904144287\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 109, batch train loss: 3.9850361347198486\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 110, batch train loss: 4.313482284545898\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 111, batch train loss: 4.81468391418457\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 112, batch train loss: 5.7395806312561035\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 113, batch train loss: 4.404319763183594\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 114, batch train loss: 5.609537124633789\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 115, batch train loss: 4.693862438201904\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 116, batch train loss: 4.16925573348999\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 117, batch train loss: 2.796144723892212\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 118, batch train loss: 3.9135494232177734\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 119, batch train loss: 4.686516284942627\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 120, batch train loss: 3.7482364177703857\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 121, batch train loss: 4.360830307006836\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 122, batch train loss: 3.712352752685547\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 123, batch train loss: 4.548890590667725\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 124, batch train loss: 4.049232006072998\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 125, batch train loss: 2.9235901832580566\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 126, batch train loss: 3.875180721282959\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 127, batch train loss: 4.918491363525391\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 128, batch train loss: 3.5513134002685547\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 129, batch train loss: 5.000611782073975\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 130, batch train loss: 5.463232040405273\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83, batch_id: 131, batch train loss: 4.207335472106934\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 132, batch train loss: 4.155704498291016\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 133, batch train loss: 5.935056209564209\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 134, batch train loss: 3.727874755859375\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 135, batch train loss: 5.816411972045898\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 136, batch train loss: 3.562565803527832\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 137, batch train loss: 3.2943286895751953\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 138, batch train loss: 5.1002349853515625\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 139, batch train loss: 5.203021049499512\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 140, batch train loss: 4.258803844451904\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 141, batch train loss: 4.3934550285339355\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 142, batch train loss: 4.305691719055176\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 143, batch train loss: 6.274913787841797\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 144, batch train loss: 4.101330280303955\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 145, batch train loss: 3.813854217529297\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 146, batch train loss: 4.154919624328613\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 147, batch train loss: 5.350539207458496\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 148, batch train loss: 4.217740535736084\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 149, batch train loss: 4.597902297973633\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 150, batch train loss: 3.8934972286224365\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 151, batch train loss: 5.427104473114014\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 152, batch train loss: 5.271706581115723\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 153, batch train loss: 4.467480659484863\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 154, batch train loss: 4.1319475173950195\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 155, batch train loss: 6.2420783042907715\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 156, batch train loss: 4.721790313720703\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 157, batch train loss: 4.802267551422119\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 158, batch train loss: 7.848719120025635\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 159, batch train loss: 5.659792423248291\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 160, batch train loss: 5.787517070770264\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 161, batch train loss: 6.42733907699585\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 162, batch train loss: 6.910864353179932\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 163, batch train loss: 6.076740741729736\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 164, batch train loss: 6.91013765335083\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 165, batch train loss: 9.161291122436523\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 166, batch train loss: 9.51481819152832\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 167, batch train loss: 9.802190780639648\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 168, batch train loss: 11.135285377502441\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 169, batch train loss: 10.396011352539062\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 170, batch train loss: 11.357219696044922\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 171, batch train loss: 8.193556785583496\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 172, batch train loss: 11.51244831085205\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 173, batch train loss: 10.065975189208984\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 174, batch train loss: 8.065537452697754\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 175, batch train loss: 11.083090782165527\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 176, batch train loss: 7.990198612213135\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 177, batch train loss: 10.566333770751953\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 178, batch train loss: 10.460833549499512\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 179, batch train loss: 9.644118309020996\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 180, batch train loss: 11.14382266998291\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 181, batch train loss: 10.786524772644043\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 182, batch train loss: 10.305398941040039\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 183, batch train loss: 9.343236923217773\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 184, batch train loss: 12.053018569946289\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 185, batch train loss: 12.108185768127441\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 186, batch train loss: 11.2234525680542\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 187, batch train loss: 11.181065559387207\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 188, batch train loss: 10.811850547790527\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 189, batch train loss: 11.240950584411621\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 190, batch train loss: 9.783249855041504\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 191, batch train loss: 9.673243522644043\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 192, batch train loss: 9.438751220703125\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 193, batch train loss: 8.746214866638184\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 194, batch train loss: 9.877606391906738\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 195, batch train loss: 9.579691886901855\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 196, batch train loss: 10.314004898071289\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 197, batch train loss: 10.325287818908691\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 198, batch train loss: 11.3815336227417\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 199, batch train loss: 10.72851276397705\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 200, batch train loss: 10.267410278320312\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 201, batch train loss: 11.090433120727539\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 202, batch train loss: 10.671486854553223\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 203, batch train loss: 10.929041862487793\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 204, batch train loss: 12.307353973388672\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 205, batch train loss: 10.989465713500977\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 206, batch train loss: 10.283638000488281\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 207, batch train loss: 10.323451042175293\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 208, batch train loss: 9.52873706817627\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 209, batch train loss: 8.9559965133667\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 210, batch train loss: 9.56724739074707\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 211, batch train loss: 9.367363929748535\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 212, batch train loss: 7.9494171142578125\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 213, batch train loss: 9.881178855895996\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 214, batch train loss: 7.699292182922363\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 215, batch train loss: 8.088520050048828\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 216, batch train loss: 9.620369911193848\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 217, batch train loss: 9.77638053894043\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 218, batch train loss: 7.821720600128174\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 219, batch train loss: 9.86491870880127\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 220, batch train loss: 7.845615386962891\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 221, batch train loss: 9.290560722351074\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 222, batch train loss: 7.831573963165283\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 223, batch train loss: 9.475099563598633\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 224, batch train loss: 8.210434913635254\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 225, batch train loss: 7.583524703979492\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 226, batch train loss: 9.714919090270996\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 227, batch train loss: 8.618794441223145\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 228, batch train loss: 7.131181716918945\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 229, batch train loss: 7.7547526359558105\n",
      "\n",
      "\n",
      "Epoch: 83, batch_id: 230, batch train loss: 7.551813125610352\n",
      "\n",
      "\n",
      "Epoch: 83/ 100, Loss: 6.086918580013773\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:26<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83 Validation Loss: 7.465348943074544\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84, batch_id: 1, batch train loss: 7.710292339324951\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 2, batch train loss: 6.269956588745117\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 3, batch train loss: 6.6253228187561035\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 4, batch train loss: 6.547961235046387\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 5, batch train loss: 7.767057418823242\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 6, batch train loss: 4.896574974060059\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 7, batch train loss: 7.5994391441345215\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 8, batch train loss: 8.169528007507324\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 9, batch train loss: 6.2738118171691895\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 10, batch train loss: 6.966977596282959\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 11, batch train loss: 7.007660388946533\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 12, batch train loss: 7.364018440246582\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 13, batch train loss: 6.069789886474609\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 14, batch train loss: 6.128665447235107\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 15, batch train loss: 6.641010284423828\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 16, batch train loss: 6.03994083404541\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 17, batch train loss: 5.5142645835876465\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 18, batch train loss: 6.51517915725708\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 19, batch train loss: 5.547971248626709\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 20, batch train loss: 5.874204635620117\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 21, batch train loss: 5.325516223907471\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 22, batch train loss: 4.408389568328857\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 23, batch train loss: 5.714230060577393\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 24, batch train loss: 5.355897903442383\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 25, batch train loss: 5.095551013946533\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 26, batch train loss: 5.017967224121094\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 27, batch train loss: 4.893278121948242\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 28, batch train loss: 4.620689392089844\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 29, batch train loss: 6.279135227203369\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 30, batch train loss: 4.582937240600586\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 31, batch train loss: 5.537683010101318\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 32, batch train loss: 4.9517927169799805\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 33, batch train loss: 4.222732067108154\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 34, batch train loss: 7.136569023132324\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 35, batch train loss: 4.934406757354736\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 36, batch train loss: 5.523538112640381\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 37, batch train loss: 5.739943981170654\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 38, batch train loss: 5.402596950531006\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 39, batch train loss: 6.70559024810791\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 40, batch train loss: 5.370771884918213\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 41, batch train loss: 6.549676418304443\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 42, batch train loss: 5.148082256317139\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 43, batch train loss: 4.933453559875488\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 44, batch train loss: 5.630128383636475\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 45, batch train loss: 6.131057262420654\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 46, batch train loss: 5.050282001495361\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 47, batch train loss: 6.302430152893066\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 48, batch train loss: 5.786633491516113\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 49, batch train loss: 6.011955738067627\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 50, batch train loss: 6.38804292678833\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 51, batch train loss: 7.336440563201904\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 52, batch train loss: 7.272678375244141\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 53, batch train loss: 4.591639995574951\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 54, batch train loss: 5.436626434326172\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 55, batch train loss: 7.027022361755371\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 56, batch train loss: 4.178720951080322\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 57, batch train loss: 4.965537071228027\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 58, batch train loss: 5.981976509094238\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 59, batch train loss: 5.034813404083252\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 60, batch train loss: 5.417636871337891\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 61, batch train loss: 6.1853790283203125\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 62, batch train loss: 8.943766593933105\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 63, batch train loss: 5.080672740936279\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 64, batch train loss: 5.518440246582031\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 65, batch train loss: 7.1473236083984375\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 66, batch train loss: 6.527100563049316\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 67, batch train loss: 6.545910358428955\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 68, batch train loss: 6.538044452667236\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 69, batch train loss: 5.687507629394531\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 70, batch train loss: 5.494899272918701\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 71, batch train loss: 4.459352016448975\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 72, batch train loss: 5.821140289306641\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 73, batch train loss: 5.444398403167725\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 74, batch train loss: 6.543211936950684\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 75, batch train loss: 5.388894081115723\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 76, batch train loss: 7.4995832443237305\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 77, batch train loss: 6.064135551452637\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 78, batch train loss: 4.62521505355835\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 79, batch train loss: 4.8784379959106445\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 80, batch train loss: 7.728420257568359\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 81, batch train loss: 6.882762908935547\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 82, batch train loss: 5.903771877288818\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 83, batch train loss: 7.322027206420898\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 84, batch train loss: 7.1509480476379395\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 85, batch train loss: 6.859864711761475\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 86, batch train loss: 5.666405200958252\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 87, batch train loss: 4.719670295715332\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 88, batch train loss: 6.155418872833252\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 89, batch train loss: 7.126621723175049\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 90, batch train loss: 8.08471393585205\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 91, batch train loss: 5.278678894042969\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 92, batch train loss: 5.461857318878174\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 93, batch train loss: 6.256367206573486\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 94, batch train loss: 6.146298408508301\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 95, batch train loss: 6.227140426635742\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 96, batch train loss: 5.4886603355407715\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 97, batch train loss: 5.652670383453369\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 98, batch train loss: 5.271592617034912\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 99, batch train loss: 5.185972690582275\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 100, batch train loss: 4.988924026489258\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 101, batch train loss: 3.6576693058013916\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 102, batch train loss: 4.202972412109375\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 103, batch train loss: 5.84528923034668\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 104, batch train loss: 5.399264335632324\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 105, batch train loss: 4.2633867263793945\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 106, batch train loss: 3.4254846572875977\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 107, batch train loss: 3.839353084564209\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 108, batch train loss: 3.8405282497406006\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 109, batch train loss: 4.854543209075928\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 110, batch train loss: 3.7017695903778076\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 111, batch train loss: 3.390878200531006\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 112, batch train loss: 4.1838555335998535\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 113, batch train loss: 3.7211551666259766\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 114, batch train loss: 3.5501508712768555\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 115, batch train loss: 3.668752431869507\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 116, batch train loss: 3.7885167598724365\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 117, batch train loss: 4.143326282501221\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 118, batch train loss: 3.7287211418151855\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 119, batch train loss: 4.149531364440918\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 120, batch train loss: 3.6733784675598145\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 121, batch train loss: 3.4473273754119873\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 122, batch train loss: 5.403226375579834\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 123, batch train loss: 3.9923393726348877\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 124, batch train loss: 3.672931432723999\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 125, batch train loss: 3.145073652267456\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 126, batch train loss: 4.829198360443115\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 127, batch train loss: 4.323991775512695\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 128, batch train loss: 4.517393112182617\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 129, batch train loss: 4.417889595031738\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 130, batch train loss: 4.680654525756836\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84, batch_id: 131, batch train loss: 4.601719856262207\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 132, batch train loss: 3.599292516708374\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 133, batch train loss: 3.6354427337646484\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 134, batch train loss: 4.194379806518555\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 135, batch train loss: 4.307804584503174\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 136, batch train loss: 4.153486728668213\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 137, batch train loss: 3.6480090618133545\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 138, batch train loss: 6.539016246795654\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 139, batch train loss: 4.16923189163208\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 140, batch train loss: 4.479271411895752\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 141, batch train loss: 4.076952934265137\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 142, batch train loss: 4.784447193145752\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 143, batch train loss: 3.961097002029419\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 144, batch train loss: 3.4392664432525635\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 145, batch train loss: 3.7689526081085205\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 146, batch train loss: 4.0429840087890625\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 147, batch train loss: 4.6665754318237305\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 148, batch train loss: 3.3265111446380615\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 149, batch train loss: 4.7602362632751465\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 150, batch train loss: 4.4831624031066895\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 151, batch train loss: 3.205472946166992\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 152, batch train loss: 4.607070446014404\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 153, batch train loss: 3.6922872066497803\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 154, batch train loss: 5.430904865264893\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 155, batch train loss: 4.05811882019043\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 156, batch train loss: 3.8375394344329834\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 157, batch train loss: 4.476571083068848\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 158, batch train loss: 4.909488201141357\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 159, batch train loss: 4.04065465927124\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 160, batch train loss: 5.058671951293945\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 161, batch train loss: 3.432893991470337\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 162, batch train loss: 3.40541672706604\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 163, batch train loss: 3.986011505126953\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 164, batch train loss: 4.437642574310303\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 165, batch train loss: 3.4357645511627197\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 166, batch train loss: 5.023036479949951\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 167, batch train loss: 3.734316825866699\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 168, batch train loss: 3.4878005981445312\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 169, batch train loss: 4.896596908569336\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 170, batch train loss: 4.348048210144043\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 171, batch train loss: 4.62407922744751\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 172, batch train loss: 3.303694725036621\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 173, batch train loss: 3.0195844173431396\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 174, batch train loss: 3.419541120529175\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 175, batch train loss: 3.1343867778778076\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 176, batch train loss: 3.198586940765381\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 177, batch train loss: 4.6421637535095215\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 178, batch train loss: 4.297249794006348\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 179, batch train loss: 4.007436752319336\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 180, batch train loss: 4.9638495445251465\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 181, batch train loss: 4.377778053283691\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 182, batch train loss: 4.407567501068115\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 183, batch train loss: 3.628237247467041\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 184, batch train loss: 4.202052593231201\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 185, batch train loss: 4.405970573425293\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 186, batch train loss: 3.873980760574341\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 187, batch train loss: 3.2687201499938965\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 188, batch train loss: 3.958691358566284\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 189, batch train loss: 4.002254009246826\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 190, batch train loss: 4.042210102081299\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 191, batch train loss: 4.350481986999512\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 192, batch train loss: 4.947749137878418\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 193, batch train loss: 3.736255645751953\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 194, batch train loss: 4.658289432525635\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 195, batch train loss: 4.241806983947754\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 196, batch train loss: 4.022737503051758\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 197, batch train loss: 3.5814669132232666\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 198, batch train loss: 3.159682273864746\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 199, batch train loss: 4.1852216720581055\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 200, batch train loss: 3.8916923999786377\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 201, batch train loss: 3.1397762298583984\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 202, batch train loss: 3.3590776920318604\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 203, batch train loss: 3.3869402408599854\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 204, batch train loss: 3.544079542160034\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 205, batch train loss: 3.906817674636841\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 206, batch train loss: 3.7617907524108887\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 207, batch train loss: 3.6832988262176514\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 208, batch train loss: 4.488650798797607\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 209, batch train loss: 3.9641406536102295\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 210, batch train loss: 4.63572883605957\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 211, batch train loss: 3.681022882461548\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 212, batch train loss: 3.973555088043213\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 213, batch train loss: 6.34445333480835\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 214, batch train loss: 4.732661724090576\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 215, batch train loss: 3.9946272373199463\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 216, batch train loss: 4.135904788970947\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 217, batch train loss: 4.956688404083252\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 218, batch train loss: 5.983276844024658\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 219, batch train loss: 4.0811967849731445\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 220, batch train loss: 3.6738080978393555\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 221, batch train loss: 6.211414337158203\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 222, batch train loss: 5.816967964172363\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 223, batch train loss: 4.736719608306885\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 224, batch train loss: 5.895622253417969\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 225, batch train loss: 5.0375494956970215\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 226, batch train loss: 4.772202014923096\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 227, batch train loss: 5.687499523162842\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 228, batch train loss: 5.461899280548096\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 229, batch train loss: 5.000831127166748\n",
      "\n",
      "\n",
      "Epoch: 84, batch_id: 230, batch train loss: 5.252586364746094\n",
      "\n",
      "\n",
      "Epoch: 84/ 100, Loss: 4.982307770977849\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:19<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84 Validation Loss: 5.80248377720515\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85, batch_id: 1, batch train loss: 6.375584125518799\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 2, batch train loss: 5.027467250823975\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 3, batch train loss: 4.906003475189209\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 4, batch train loss: 3.506662607192993\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 5, batch train loss: 3.0586893558502197\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 6, batch train loss: 3.3617494106292725\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 7, batch train loss: 4.0121002197265625\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 8, batch train loss: 3.5419721603393555\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 9, batch train loss: 3.418637275695801\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 10, batch train loss: 3.93092942237854\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 11, batch train loss: 2.825427770614624\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 12, batch train loss: 2.00347638130188\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 13, batch train loss: 3.932286262512207\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 14, batch train loss: 3.7037694454193115\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 15, batch train loss: 2.438901662826538\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 16, batch train loss: 3.5582926273345947\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 17, batch train loss: 3.106837034225464\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 18, batch train loss: 3.006714344024658\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 19, batch train loss: 2.67932391166687\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 20, batch train loss: 2.708085775375366\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 21, batch train loss: 2.6104464530944824\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 22, batch train loss: 2.5616066455841064\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 23, batch train loss: 2.2973363399505615\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 24, batch train loss: 2.5876424312591553\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 25, batch train loss: 2.5417985916137695\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 26, batch train loss: 2.6304893493652344\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 27, batch train loss: 2.8612923622131348\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 28, batch train loss: 2.592217206954956\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 29, batch train loss: 2.735279083251953\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 30, batch train loss: 2.260488986968994\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 31, batch train loss: 3.681140661239624\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 32, batch train loss: 3.0142953395843506\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 33, batch train loss: 4.31558895111084\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 34, batch train loss: 3.1034839153289795\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 35, batch train loss: 2.770951747894287\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 36, batch train loss: 4.646914482116699\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 37, batch train loss: 2.471386194229126\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 38, batch train loss: 2.3016715049743652\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 39, batch train loss: 3.2419795989990234\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 40, batch train loss: 2.9503469467163086\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 41, batch train loss: 3.05800199508667\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 42, batch train loss: 2.2922592163085938\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 43, batch train loss: 3.2278294563293457\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 44, batch train loss: 2.689028024673462\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 45, batch train loss: 3.5589115619659424\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 46, batch train loss: 2.5857133865356445\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 47, batch train loss: 3.600653886795044\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 48, batch train loss: 3.4377493858337402\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 49, batch train loss: 2.9990549087524414\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 50, batch train loss: 4.075162887573242\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 51, batch train loss: 3.584913730621338\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 52, batch train loss: 5.225640296936035\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 53, batch train loss: 3.113438606262207\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 54, batch train loss: 4.734918117523193\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 55, batch train loss: 4.525259017944336\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 56, batch train loss: 3.492043972015381\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 57, batch train loss: 4.422718524932861\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 58, batch train loss: 3.520426034927368\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 59, batch train loss: 5.4926886558532715\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 60, batch train loss: 3.538531541824341\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 61, batch train loss: 3.912379264831543\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 62, batch train loss: 2.6383986473083496\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 63, batch train loss: 3.063676118850708\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 64, batch train loss: 3.7131221294403076\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 65, batch train loss: 4.011806488037109\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 66, batch train loss: 3.9732186794281006\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 67, batch train loss: 4.706164360046387\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 68, batch train loss: 9.115269660949707\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 69, batch train loss: 4.36134672164917\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 70, batch train loss: 4.181284427642822\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 71, batch train loss: 4.843538284301758\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 72, batch train loss: 4.704587459564209\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 73, batch train loss: 4.658064365386963\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 74, batch train loss: 5.402610778808594\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 75, batch train loss: 4.3367156982421875\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 76, batch train loss: 3.7237846851348877\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 77, batch train loss: 5.691040992736816\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 78, batch train loss: 3.4780797958374023\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 79, batch train loss: 2.872983455657959\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 80, batch train loss: 7.7458648681640625\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 81, batch train loss: 3.423064708709717\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 82, batch train loss: 4.3320465087890625\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 83, batch train loss: 4.9681525230407715\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 84, batch train loss: 4.943312168121338\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 85, batch train loss: 5.993381500244141\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 86, batch train loss: 5.160931587219238\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 87, batch train loss: 4.817004680633545\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 88, batch train loss: 5.162374496459961\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 89, batch train loss: 3.974722385406494\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 90, batch train loss: 3.737828254699707\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 91, batch train loss: 5.647449970245361\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 92, batch train loss: 4.446834087371826\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 93, batch train loss: 4.921442985534668\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 94, batch train loss: 3.5438220500946045\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 95, batch train loss: 5.1377105712890625\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 96, batch train loss: 3.5180485248565674\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 97, batch train loss: 5.808274269104004\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 98, batch train loss: 4.543491363525391\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 99, batch train loss: 5.183016777038574\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 100, batch train loss: 5.4900383949279785\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 101, batch train loss: 4.916531562805176\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 102, batch train loss: 4.2641754150390625\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 103, batch train loss: 4.376486778259277\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 104, batch train loss: 5.046573162078857\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 105, batch train loss: 5.545007228851318\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 106, batch train loss: 5.5429229736328125\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 107, batch train loss: 5.1614155769348145\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 108, batch train loss: 4.78177547454834\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 109, batch train loss: 4.332194805145264\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 110, batch train loss: 5.346248149871826\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 111, batch train loss: 4.366400718688965\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 112, batch train loss: 5.167688846588135\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 113, batch train loss: 4.9659318923950195\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 114, batch train loss: 5.2545857429504395\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 115, batch train loss: 4.2364959716796875\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 116, batch train loss: 4.453913688659668\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 117, batch train loss: 4.790782451629639\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 118, batch train loss: 5.220963478088379\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 119, batch train loss: 3.882387638092041\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 120, batch train loss: 4.066208839416504\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 121, batch train loss: 4.032121658325195\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 122, batch train loss: 4.551953315734863\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 123, batch train loss: 4.297253608703613\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 124, batch train loss: 4.588777542114258\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 125, batch train loss: 3.5327723026275635\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 126, batch train loss: 4.002161026000977\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 127, batch train loss: 5.290073394775391\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 128, batch train loss: 3.488293409347534\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 129, batch train loss: 3.232175588607788\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 130, batch train loss: 3.7556421756744385\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85, batch_id: 131, batch train loss: 3.39902925491333\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 132, batch train loss: 4.334621429443359\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 133, batch train loss: 4.992156982421875\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 134, batch train loss: 4.576900959014893\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 135, batch train loss: 3.574632167816162\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 136, batch train loss: 4.467171669006348\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 137, batch train loss: 3.490459680557251\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 138, batch train loss: 5.9701995849609375\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 139, batch train loss: 5.4391937255859375\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 140, batch train loss: 3.9848556518554688\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 141, batch train loss: 6.5582380294799805\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 142, batch train loss: 4.741373538970947\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 143, batch train loss: 4.105596542358398\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 144, batch train loss: 4.598169803619385\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 145, batch train loss: 4.541986465454102\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 146, batch train loss: 4.16973352432251\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 147, batch train loss: 4.192946910858154\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 148, batch train loss: 3.538039445877075\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 149, batch train loss: 3.088167667388916\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 150, batch train loss: 3.603618621826172\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 151, batch train loss: 3.266047477722168\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 152, batch train loss: 3.061075210571289\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 153, batch train loss: 4.457831382751465\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 154, batch train loss: 4.222444534301758\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 155, batch train loss: 3.9588420391082764\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 156, batch train loss: 5.389370441436768\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 157, batch train loss: 3.587477922439575\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 158, batch train loss: 3.76118540763855\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 159, batch train loss: 3.8394925594329834\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 160, batch train loss: 6.68385124206543\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 161, batch train loss: 5.100358963012695\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 162, batch train loss: 4.717158794403076\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 163, batch train loss: 4.486346244812012\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 164, batch train loss: 4.479492664337158\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 165, batch train loss: 4.097257137298584\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 166, batch train loss: 4.423675060272217\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 167, batch train loss: 5.078162670135498\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 168, batch train loss: 4.354182720184326\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 169, batch train loss: 5.283589839935303\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 170, batch train loss: 5.007791996002197\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 171, batch train loss: 5.3874945640563965\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 172, batch train loss: 5.9803242683410645\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 173, batch train loss: 7.434790134429932\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 174, batch train loss: 7.100320816040039\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 175, batch train loss: 5.673269748687744\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 176, batch train loss: 9.516613960266113\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 177, batch train loss: 6.46819543838501\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 178, batch train loss: 5.822691917419434\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 179, batch train loss: 6.725975036621094\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 180, batch train loss: 6.363944053649902\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 181, batch train loss: 7.229384899139404\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 182, batch train loss: 7.072787284851074\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 183, batch train loss: 5.996525287628174\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 184, batch train loss: 7.631980895996094\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 185, batch train loss: 8.132582664489746\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 186, batch train loss: 7.68211030960083\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 187, batch train loss: 8.438663482666016\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 188, batch train loss: 6.8769378662109375\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 189, batch train loss: 7.573699474334717\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 190, batch train loss: 7.984978675842285\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 191, batch train loss: 5.69803524017334\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 192, batch train loss: 5.6563401222229\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 193, batch train loss: 7.128501892089844\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 194, batch train loss: 8.223550796508789\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 195, batch train loss: 7.250073432922363\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 196, batch train loss: 10.666653633117676\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 197, batch train loss: 10.373846054077148\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 198, batch train loss: 10.600516319274902\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 199, batch train loss: 9.177749633789062\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 200, batch train loss: 7.748569488525391\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 201, batch train loss: 7.674691677093506\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 202, batch train loss: 7.670905590057373\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 203, batch train loss: 7.33883810043335\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 204, batch train loss: 7.255224704742432\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 205, batch train loss: 6.038386344909668\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 206, batch train loss: 7.901565074920654\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 207, batch train loss: 7.211204528808594\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 208, batch train loss: 7.697809219360352\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 209, batch train loss: 8.893540382385254\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 210, batch train loss: 6.949253082275391\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 211, batch train loss: 8.231677055358887\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 212, batch train loss: 8.719386100769043\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 213, batch train loss: 6.789992809295654\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 214, batch train loss: 7.803946018218994\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 215, batch train loss: 6.667250156402588\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 216, batch train loss: 7.264895915985107\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 217, batch train loss: 7.168728828430176\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 218, batch train loss: 8.239109992980957\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 219, batch train loss: 8.59916877746582\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 220, batch train loss: 7.010789394378662\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 221, batch train loss: 6.354767322540283\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 222, batch train loss: 7.2238850593566895\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 223, batch train loss: 7.517836093902588\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 224, batch train loss: 6.590549945831299\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 225, batch train loss: 6.067357540130615\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 226, batch train loss: 7.195429801940918\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 227, batch train loss: 7.25827169418335\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 228, batch train loss: 7.747429370880127\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 229, batch train loss: 7.733213901519775\n",
      "\n",
      "\n",
      "Epoch: 85, batch_id: 230, batch train loss: 7.658007621765137\n",
      "\n",
      "\n",
      "Epoch: 85/ 100, Loss: 4.989321543859399\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:28<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85 Validation Loss: 7.268208972613016\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86, batch_id: 1, batch train loss: 7.415532112121582\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 2, batch train loss: 6.283096790313721\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 3, batch train loss: 9.084251403808594\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 4, batch train loss: 10.11749267578125\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 5, batch train loss: 8.573196411132812\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 6, batch train loss: 12.350573539733887\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 7, batch train loss: 9.236166954040527\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 8, batch train loss: 8.732202529907227\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 9, batch train loss: 9.316176414489746\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 10, batch train loss: 8.767566680908203\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 11, batch train loss: 10.606241226196289\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 12, batch train loss: 14.574085235595703\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 13, batch train loss: 7.922544956207275\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 14, batch train loss: 7.589476108551025\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 15, batch train loss: 8.328907012939453\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 16, batch train loss: 9.147982597351074\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 17, batch train loss: 7.434939861297607\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 18, batch train loss: 7.591897964477539\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 19, batch train loss: 6.793445587158203\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 20, batch train loss: 8.386528015136719\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 21, batch train loss: 9.348334312438965\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 22, batch train loss: 7.563050270080566\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 23, batch train loss: 7.429825782775879\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 24, batch train loss: 6.596307754516602\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 25, batch train loss: 8.031533241271973\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 26, batch train loss: 7.4066033363342285\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 27, batch train loss: 8.592720031738281\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 28, batch train loss: 7.523656368255615\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 29, batch train loss: 7.583835601806641\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 30, batch train loss: 7.996175765991211\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 31, batch train loss: 8.049251556396484\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 32, batch train loss: 6.832605838775635\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 33, batch train loss: 8.055387496948242\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 34, batch train loss: 7.451028823852539\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 35, batch train loss: 6.959434986114502\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 36, batch train loss: 7.700319766998291\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 37, batch train loss: 8.192774772644043\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 38, batch train loss: 6.680044174194336\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 39, batch train loss: 7.2080159187316895\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 40, batch train loss: 7.126865863800049\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 41, batch train loss: 7.739427089691162\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 42, batch train loss: 6.759910583496094\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 43, batch train loss: 7.713141918182373\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 44, batch train loss: 5.765913009643555\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 45, batch train loss: 7.163264274597168\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 46, batch train loss: 6.8548903465271\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 47, batch train loss: 6.33883810043335\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 48, batch train loss: 6.657536029815674\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 49, batch train loss: 7.347337245941162\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 50, batch train loss: 5.786905288696289\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 51, batch train loss: 4.839015960693359\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 52, batch train loss: 8.940961837768555\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 53, batch train loss: 6.923369884490967\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 54, batch train loss: 6.930385589599609\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 55, batch train loss: 6.568297863006592\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 56, batch train loss: 5.914465427398682\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 57, batch train loss: 6.949234962463379\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 58, batch train loss: 6.541804313659668\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 59, batch train loss: 5.495204925537109\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 60, batch train loss: 4.609720706939697\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 61, batch train loss: 5.478434085845947\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 62, batch train loss: 5.3704376220703125\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 63, batch train loss: 6.108557224273682\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 64, batch train loss: 6.054322719573975\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 65, batch train loss: 6.672076225280762\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 66, batch train loss: 5.471653461456299\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 67, batch train loss: 5.682378768920898\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 68, batch train loss: 5.024584770202637\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 69, batch train loss: 5.289180278778076\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 70, batch train loss: 4.71131706237793\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 71, batch train loss: 4.727851390838623\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 72, batch train loss: 5.627237319946289\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 73, batch train loss: 5.331177711486816\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 74, batch train loss: 5.95025110244751\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 75, batch train loss: 6.539319038391113\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 76, batch train loss: 6.376316070556641\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 77, batch train loss: 4.828296661376953\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 78, batch train loss: 4.77714729309082\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 79, batch train loss: 4.072610855102539\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 80, batch train loss: 5.198018550872803\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 81, batch train loss: 5.163295269012451\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 82, batch train loss: 4.815098285675049\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 83, batch train loss: 6.009117603302002\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 84, batch train loss: 5.972422122955322\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 85, batch train loss: 5.844818592071533\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 86, batch train loss: 5.6992902755737305\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 87, batch train loss: 4.9406328201293945\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 88, batch train loss: 4.9531989097595215\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 89, batch train loss: 6.217260837554932\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 90, batch train loss: 5.032273292541504\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 91, batch train loss: 4.9342427253723145\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 92, batch train loss: 4.73932409286499\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 93, batch train loss: 4.119463920593262\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 94, batch train loss: 4.423746109008789\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 95, batch train loss: 4.906355857849121\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 96, batch train loss: 3.4806323051452637\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 97, batch train loss: 3.848500967025757\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 98, batch train loss: 5.370583534240723\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 99, batch train loss: 4.363365650177002\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 100, batch train loss: 4.275190353393555\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 101, batch train loss: 4.433674335479736\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 102, batch train loss: 4.096902847290039\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 103, batch train loss: 4.006150722503662\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 104, batch train loss: 3.7999539375305176\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 105, batch train loss: 4.084410667419434\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 106, batch train loss: 3.7497851848602295\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 107, batch train loss: 5.190605640411377\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 108, batch train loss: 3.2044005393981934\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 109, batch train loss: 3.439260721206665\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 110, batch train loss: 4.054620265960693\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 111, batch train loss: 3.868804454803467\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 112, batch train loss: 4.13266134262085\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 113, batch train loss: 3.8027539253234863\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 114, batch train loss: 3.888185977935791\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 115, batch train loss: 4.156714916229248\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 116, batch train loss: 4.535618782043457\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 117, batch train loss: 4.40522575378418\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 118, batch train loss: 5.2002716064453125\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 119, batch train loss: 4.947478771209717\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 120, batch train loss: 4.325987815856934\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 121, batch train loss: 4.065249443054199\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 122, batch train loss: 5.247589111328125\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 123, batch train loss: 4.536233425140381\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 124, batch train loss: 4.2048020362854\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 125, batch train loss: 4.7394514083862305\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 126, batch train loss: 4.190496444702148\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 127, batch train loss: 4.314640045166016\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 128, batch train loss: 4.093770503997803\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 129, batch train loss: 3.952054738998413\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 130, batch train loss: 4.103509426116943\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86, batch_id: 131, batch train loss: 4.020479679107666\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 132, batch train loss: 4.524942398071289\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 133, batch train loss: 4.20158576965332\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 134, batch train loss: 4.435828685760498\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 135, batch train loss: 4.649975299835205\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 136, batch train loss: 4.079002857208252\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 137, batch train loss: 5.127671241760254\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 138, batch train loss: 3.569654941558838\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 139, batch train loss: 3.967446804046631\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 140, batch train loss: 3.7193055152893066\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 141, batch train loss: 4.388076305389404\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 142, batch train loss: 3.7044270038604736\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 143, batch train loss: 3.38932204246521\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 144, batch train loss: 5.171243667602539\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 145, batch train loss: 3.763753652572632\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 146, batch train loss: 4.1789984703063965\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 147, batch train loss: 4.1958394050598145\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 148, batch train loss: 4.011496543884277\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 149, batch train loss: 4.254669666290283\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 150, batch train loss: 3.959813117980957\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 151, batch train loss: 4.131507396697998\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 152, batch train loss: 4.6122870445251465\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 153, batch train loss: 4.639257907867432\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 154, batch train loss: 4.3212890625\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 155, batch train loss: 4.076318740844727\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 156, batch train loss: 4.72059440612793\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 157, batch train loss: 3.5278353691101074\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 158, batch train loss: 3.9199934005737305\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 159, batch train loss: 4.387704372406006\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 160, batch train loss: 4.3577399253845215\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 161, batch train loss: 3.5672237873077393\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 162, batch train loss: 5.028664588928223\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 163, batch train loss: 4.073399066925049\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 164, batch train loss: 4.461482524871826\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 165, batch train loss: 5.361022472381592\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 166, batch train loss: 3.5858654975891113\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 167, batch train loss: 3.435229539871216\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 168, batch train loss: 6.844742774963379\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 169, batch train loss: 4.187524795532227\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 170, batch train loss: 4.207129955291748\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 171, batch train loss: 4.287391185760498\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 172, batch train loss: 4.234823226928711\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 173, batch train loss: 4.817654609680176\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 174, batch train loss: 3.9424922466278076\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 175, batch train loss: 4.546580791473389\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 176, batch train loss: 3.9468977451324463\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 177, batch train loss: 4.294729232788086\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 178, batch train loss: 4.012129783630371\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 179, batch train loss: 3.7733845710754395\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 180, batch train loss: 3.736262559890747\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 181, batch train loss: 3.6250154972076416\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 182, batch train loss: 4.275477409362793\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 183, batch train loss: 3.736464738845825\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 184, batch train loss: 4.317640781402588\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 185, batch train loss: 3.968841552734375\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 186, batch train loss: 4.923532485961914\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 187, batch train loss: 3.8114371299743652\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 188, batch train loss: 4.354287147521973\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 189, batch train loss: 3.3363850116729736\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 190, batch train loss: 4.776013374328613\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 191, batch train loss: 4.249484539031982\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 192, batch train loss: 4.416351318359375\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 193, batch train loss: 4.044206142425537\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 194, batch train loss: 3.851792812347412\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 195, batch train loss: 4.553065776824951\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 196, batch train loss: 5.415832042694092\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 197, batch train loss: 4.197564125061035\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 198, batch train loss: 4.799315929412842\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 199, batch train loss: 5.1292829513549805\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 200, batch train loss: 5.1701507568359375\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 201, batch train loss: 3.408874988555908\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 202, batch train loss: 4.321948528289795\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 203, batch train loss: 5.215653419494629\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 204, batch train loss: 5.183536529541016\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 205, batch train loss: 5.207440376281738\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 206, batch train loss: 4.183446884155273\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 207, batch train loss: 4.177739143371582\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 208, batch train loss: 4.872935771942139\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 209, batch train loss: 5.0192389488220215\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 210, batch train loss: 4.960114002227783\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 211, batch train loss: 4.202696800231934\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 212, batch train loss: 4.272284984588623\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 213, batch train loss: 4.681519985198975\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 214, batch train loss: 5.158001899719238\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 215, batch train loss: 4.056844234466553\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 216, batch train loss: 4.134484767913818\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 217, batch train loss: 4.027311325073242\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 218, batch train loss: 4.646843433380127\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 219, batch train loss: 3.8787431716918945\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 220, batch train loss: 3.8868179321289062\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 221, batch train loss: 5.024550914764404\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 222, batch train loss: 4.089182376861572\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 223, batch train loss: 3.6778576374053955\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 224, batch train loss: 4.8560099601745605\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 225, batch train loss: 5.3730788230896\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 226, batch train loss: 4.204560279846191\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 227, batch train loss: 4.633951187133789\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 228, batch train loss: 4.276372909545898\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 229, batch train loss: 4.71107816696167\n",
      "\n",
      "\n",
      "Epoch: 86, batch_id: 230, batch train loss: 4.594310283660889\n",
      "\n",
      "\n",
      "Epoch: 86/ 100, Loss: 5.355796567253445\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:16<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86 Validation Loss: 3.815081898371379\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87, batch_id: 1, batch train loss: 3.4999148845672607\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 2, batch train loss: 3.783728837966919\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 3, batch train loss: 4.451286792755127\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 4, batch train loss: 3.904869318008423\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 5, batch train loss: 4.229990482330322\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 6, batch train loss: 4.651513576507568\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 7, batch train loss: 3.5767147541046143\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 8, batch train loss: 3.1404666900634766\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 9, batch train loss: 3.9857254028320312\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 10, batch train loss: 3.951810359954834\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 11, batch train loss: 4.200786113739014\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 12, batch train loss: 3.8551998138427734\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 13, batch train loss: 3.810509443283081\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 14, batch train loss: 3.6234982013702393\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 15, batch train loss: 3.4336397647857666\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 16, batch train loss: 5.079745292663574\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 17, batch train loss: 4.058085918426514\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 18, batch train loss: 3.7117631435394287\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 19, batch train loss: 4.481820583343506\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 20, batch train loss: 3.566243886947632\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 21, batch train loss: 3.7806856632232666\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 22, batch train loss: 5.743106365203857\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 23, batch train loss: 3.2615840435028076\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 24, batch train loss: 4.7468719482421875\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 25, batch train loss: 4.375394821166992\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 26, batch train loss: 4.049499034881592\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 27, batch train loss: 5.03790283203125\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 28, batch train loss: 4.073093891143799\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 29, batch train loss: 2.823322296142578\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 30, batch train loss: 5.048703670501709\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 31, batch train loss: 4.206738471984863\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 32, batch train loss: 4.512636661529541\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 33, batch train loss: 3.8132901191711426\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 34, batch train loss: 3.9195568561553955\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 35, batch train loss: 4.890745639801025\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 36, batch train loss: 3.5658602714538574\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 37, batch train loss: 3.2067067623138428\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 38, batch train loss: 4.226085662841797\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 39, batch train loss: 3.242856025695801\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 40, batch train loss: 3.6570663452148438\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 41, batch train loss: 3.849546194076538\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 42, batch train loss: 3.194570302963257\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 43, batch train loss: 3.686972141265869\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 44, batch train loss: 2.9111437797546387\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 45, batch train loss: 3.1181018352508545\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 46, batch train loss: 3.2409377098083496\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 47, batch train loss: 3.113346815109253\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 48, batch train loss: 3.453112840652466\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 49, batch train loss: 3.302229881286621\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 50, batch train loss: 2.651606321334839\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 51, batch train loss: 3.7007014751434326\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 52, batch train loss: 3.7370834350585938\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 53, batch train loss: 3.0918350219726562\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 54, batch train loss: 3.545614004135132\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 55, batch train loss: 3.400714874267578\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 56, batch train loss: 2.802981376647949\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 57, batch train loss: 4.234280586242676\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 58, batch train loss: 3.1787021160125732\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 59, batch train loss: 3.4085609912872314\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 60, batch train loss: 3.5531005859375\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 61, batch train loss: 2.7874443531036377\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 62, batch train loss: 2.962989330291748\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 63, batch train loss: 2.80613112449646\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 64, batch train loss: 2.7536823749542236\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 65, batch train loss: 2.953627824783325\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 66, batch train loss: 2.9141242504119873\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 67, batch train loss: 3.5748209953308105\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 68, batch train loss: 2.460852861404419\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 69, batch train loss: 3.540066719055176\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 70, batch train loss: 3.505213737487793\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 71, batch train loss: 3.3572752475738525\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 72, batch train loss: 3.9446308612823486\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 73, batch train loss: 3.6673836708068848\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 74, batch train loss: 3.3941850662231445\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 75, batch train loss: 3.6718692779541016\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 76, batch train loss: 3.3975398540496826\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 77, batch train loss: 4.254233360290527\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 78, batch train loss: 3.616070508956909\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 79, batch train loss: 3.293947458267212\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 80, batch train loss: 5.3257551193237305\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 81, batch train loss: 4.387874126434326\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 82, batch train loss: 4.618356227874756\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 83, batch train loss: 6.7673563957214355\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 84, batch train loss: 5.1601057052612305\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 85, batch train loss: 5.109626293182373\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 86, batch train loss: 5.526651859283447\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 87, batch train loss: 5.255419731140137\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 88, batch train loss: 4.590253829956055\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 89, batch train loss: 4.117374897003174\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 90, batch train loss: 4.808084011077881\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 91, batch train loss: 4.214772701263428\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 92, batch train loss: 6.580051898956299\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 93, batch train loss: 5.955533027648926\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 94, batch train loss: 3.871110439300537\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 95, batch train loss: 7.434002876281738\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 96, batch train loss: 5.624751091003418\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 97, batch train loss: 4.576368808746338\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 98, batch train loss: 5.605062484741211\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 99, batch train loss: 5.099429130554199\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 100, batch train loss: 5.811848163604736\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 101, batch train loss: 4.1877899169921875\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 102, batch train loss: 6.33140230178833\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 103, batch train loss: 5.765809535980225\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 104, batch train loss: 4.077505111694336\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 105, batch train loss: 6.437961101531982\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 106, batch train loss: 5.714666843414307\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 107, batch train loss: 5.107627868652344\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 108, batch train loss: 4.986306667327881\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 109, batch train loss: 5.8282151222229\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 110, batch train loss: 4.174867630004883\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 111, batch train loss: 5.449623107910156\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 112, batch train loss: 5.882624626159668\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 113, batch train loss: 4.000090599060059\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 114, batch train loss: 2.998016119003296\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 115, batch train loss: 5.9712724685668945\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 116, batch train loss: 4.700595855712891\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 117, batch train loss: 4.588166236877441\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 118, batch train loss: 4.114718437194824\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 119, batch train loss: 4.290455341339111\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 120, batch train loss: 3.658029794692993\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 121, batch train loss: 3.386697292327881\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 122, batch train loss: 4.489345550537109\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 123, batch train loss: 3.492483377456665\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 124, batch train loss: 3.3580074310302734\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 125, batch train loss: 4.68931770324707\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 126, batch train loss: 3.4801180362701416\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 127, batch train loss: 5.033348083496094\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 128, batch train loss: 4.649065017700195\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 129, batch train loss: 4.1405134201049805\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 130, batch train loss: 4.020030975341797\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87, batch_id: 131, batch train loss: 4.13754415512085\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 132, batch train loss: 4.78113317489624\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 133, batch train loss: 3.8631391525268555\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 134, batch train loss: 3.682605743408203\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 135, batch train loss: 4.256113529205322\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 136, batch train loss: 4.356557846069336\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 137, batch train loss: 4.122988700866699\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 138, batch train loss: 3.3596460819244385\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 139, batch train loss: 3.3946735858917236\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 140, batch train loss: 3.123605728149414\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 141, batch train loss: 3.0588133335113525\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 142, batch train loss: 5.8557024002075195\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 143, batch train loss: 3.6086933612823486\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 144, batch train loss: 4.266077041625977\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 145, batch train loss: 4.294288158416748\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 146, batch train loss: 3.0540060997009277\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 147, batch train loss: 2.546616315841675\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 148, batch train loss: 4.53696870803833\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 149, batch train loss: 3.5703771114349365\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 150, batch train loss: 3.710010290145874\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 151, batch train loss: 3.5262813568115234\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 152, batch train loss: 3.0912039279937744\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 153, batch train loss: 3.6962947845458984\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 154, batch train loss: 4.683056354522705\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 155, batch train loss: 4.753366947174072\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 156, batch train loss: 3.476940155029297\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 157, batch train loss: 3.808568000793457\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 158, batch train loss: 3.781737804412842\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 159, batch train loss: 3.3770651817321777\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 160, batch train loss: 3.992950916290283\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 161, batch train loss: 3.8473002910614014\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 162, batch train loss: 3.6187663078308105\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 163, batch train loss: 2.8248496055603027\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 164, batch train loss: 3.310856342315674\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 165, batch train loss: 3.0890913009643555\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 166, batch train loss: 2.835575580596924\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 167, batch train loss: 2.508406639099121\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 168, batch train loss: 2.779348850250244\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 169, batch train loss: 3.7484822273254395\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 170, batch train loss: 3.9359281063079834\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 171, batch train loss: 3.183797597885132\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 172, batch train loss: 4.130550861358643\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 173, batch train loss: 4.296479225158691\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 174, batch train loss: 4.366852283477783\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 175, batch train loss: 3.306572914123535\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 176, batch train loss: 2.65067195892334\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 177, batch train loss: 3.414283037185669\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 178, batch train loss: 2.4670653343200684\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 179, batch train loss: 4.366168022155762\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 180, batch train loss: 3.0371663570404053\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 181, batch train loss: 3.617809295654297\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 182, batch train loss: 3.975766658782959\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 183, batch train loss: 3.7700395584106445\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 184, batch train loss: 3.9965274333953857\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 185, batch train loss: 3.6656901836395264\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 186, batch train loss: 2.6347131729125977\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 187, batch train loss: 4.714626312255859\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 188, batch train loss: 4.4015655517578125\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 189, batch train loss: 3.481127977371216\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 190, batch train loss: 4.60312032699585\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 191, batch train loss: 3.039339065551758\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 192, batch train loss: 3.1539108753204346\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 193, batch train loss: 3.646658420562744\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 194, batch train loss: 3.688896894454956\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 195, batch train loss: 3.2031819820404053\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 196, batch train loss: 3.5363094806671143\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 197, batch train loss: 2.2420177459716797\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 198, batch train loss: 3.008683919906616\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 199, batch train loss: 2.460480213165283\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 200, batch train loss: 2.462326765060425\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 201, batch train loss: 2.7332282066345215\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 202, batch train loss: 2.383929967880249\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 203, batch train loss: 2.7159321308135986\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 204, batch train loss: 3.388065814971924\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 205, batch train loss: 3.228198289871216\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 206, batch train loss: 2.511040449142456\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 207, batch train loss: 3.0425477027893066\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 208, batch train loss: 2.630310535430908\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 209, batch train loss: 2.272371530532837\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 210, batch train loss: 2.2725296020507812\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 211, batch train loss: 2.155749797821045\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 212, batch train loss: 2.2378034591674805\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 213, batch train loss: 2.3107597827911377\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 214, batch train loss: 3.024524211883545\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 215, batch train loss: 2.1715476512908936\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 216, batch train loss: 2.138171434402466\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 217, batch train loss: 3.4803996086120605\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 218, batch train loss: 2.5646536350250244\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 219, batch train loss: 2.989398241043091\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 220, batch train loss: 3.380309581756592\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 221, batch train loss: 2.619811773300171\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 222, batch train loss: 2.506366014480591\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 223, batch train loss: 3.008852958679199\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 224, batch train loss: 2.991638660430908\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 225, batch train loss: 2.890774726867676\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 226, batch train loss: 3.035667896270752\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 227, batch train loss: 2.722829818725586\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 228, batch train loss: 3.1185758113861084\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 229, batch train loss: 3.2022225856781006\n",
      "\n",
      "\n",
      "Epoch: 87, batch_id: 230, batch train loss: 2.9729673862457275\n",
      "\n",
      "\n",
      "Epoch: 87/ 100, Loss: 3.8093214003936104\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:06<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87 Validation Loss: 2.8190231283505756\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88, batch_id: 1, batch train loss: 2.889470100402832\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 2, batch train loss: 2.554676055908203\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 3, batch train loss: 2.448568820953369\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 4, batch train loss: 2.489793300628662\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 5, batch train loss: 2.867663860321045\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 6, batch train loss: 2.610158681869507\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 7, batch train loss: 2.190922260284424\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 8, batch train loss: 2.4925243854522705\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 9, batch train loss: 2.3501906394958496\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 10, batch train loss: 2.708843231201172\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 11, batch train loss: 2.599954605102539\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 12, batch train loss: 2.2339296340942383\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 13, batch train loss: 2.8739612102508545\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 14, batch train loss: 2.475191354751587\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 15, batch train loss: 2.3743391036987305\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 16, batch train loss: 3.3296687602996826\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 17, batch train loss: 2.3286492824554443\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 18, batch train loss: 2.6739184856414795\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 19, batch train loss: 2.4396040439605713\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 20, batch train loss: 3.5114705562591553\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 21, batch train loss: 2.4515185356140137\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 22, batch train loss: 3.476773262023926\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 23, batch train loss: 2.5583794116973877\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 24, batch train loss: 2.9127206802368164\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 25, batch train loss: 2.833352565765381\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 26, batch train loss: 3.253903388977051\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 27, batch train loss: 2.9613425731658936\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 28, batch train loss: 2.795651912689209\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 29, batch train loss: 2.7134974002838135\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 30, batch train loss: 2.5627388954162598\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 31, batch train loss: 2.8222599029541016\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 32, batch train loss: 3.6852405071258545\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 33, batch train loss: 3.071481227874756\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 34, batch train loss: 3.2719390392303467\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 35, batch train loss: 3.0628771781921387\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 36, batch train loss: 3.5180976390838623\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 37, batch train loss: 2.651423454284668\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 38, batch train loss: 2.3279407024383545\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 39, batch train loss: 2.8329312801361084\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 40, batch train loss: 2.564229726791382\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 41, batch train loss: 2.0152082443237305\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 42, batch train loss: 2.8780651092529297\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 43, batch train loss: 2.304974317550659\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 44, batch train loss: 2.084516763687134\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 45, batch train loss: 2.318864107131958\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 46, batch train loss: 2.086855173110962\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 47, batch train loss: 2.529639720916748\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 48, batch train loss: 3.662506580352783\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 49, batch train loss: 2.54477858543396\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 50, batch train loss: 3.960575819015503\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 51, batch train loss: 3.4352147579193115\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 52, batch train loss: 3.0387864112854004\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 53, batch train loss: 4.864078998565674\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 54, batch train loss: 3.4531123638153076\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 55, batch train loss: 3.3158211708068848\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 56, batch train loss: 6.610357284545898\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 57, batch train loss: 3.1316659450531006\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 58, batch train loss: 3.5131404399871826\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 59, batch train loss: 4.66306734085083\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 60, batch train loss: 4.867684841156006\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 61, batch train loss: 5.029345512390137\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 62, batch train loss: 5.061975955963135\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 63, batch train loss: 4.729681968688965\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 64, batch train loss: 3.3425121307373047\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 65, batch train loss: 4.936746120452881\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 66, batch train loss: 4.794529438018799\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 67, batch train loss: 3.064323663711548\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 68, batch train loss: 4.066061973571777\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 69, batch train loss: 3.853600263595581\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 70, batch train loss: 3.1240978240966797\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 71, batch train loss: 3.3668367862701416\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 72, batch train loss: 2.8894295692443848\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 73, batch train loss: 3.222538471221924\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 74, batch train loss: 2.663649559020996\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 75, batch train loss: 3.6331982612609863\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 76, batch train loss: 3.38197922706604\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 77, batch train loss: 2.686884880065918\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 78, batch train loss: 5.208669662475586\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 79, batch train loss: 4.526752948760986\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 80, batch train loss: 3.7207658290863037\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 81, batch train loss: 5.4323272705078125\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 82, batch train loss: 3.9819555282592773\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 83, batch train loss: 3.905486583709717\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 84, batch train loss: 4.049623012542725\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 85, batch train loss: 3.416827917098999\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 86, batch train loss: 3.7176427841186523\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 87, batch train loss: 3.421872138977051\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 88, batch train loss: 4.312556266784668\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 89, batch train loss: 4.253713607788086\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 90, batch train loss: 3.052870273590088\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 91, batch train loss: 3.3321661949157715\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 92, batch train loss: 2.9104440212249756\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 93, batch train loss: 2.612086296081543\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 94, batch train loss: 2.9993364810943604\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 95, batch train loss: 2.6858553886413574\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 96, batch train loss: 2.6091666221618652\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 97, batch train loss: 2.884596347808838\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 98, batch train loss: 2.705826759338379\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 99, batch train loss: 3.2131593227386475\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 100, batch train loss: 2.8988804817199707\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 101, batch train loss: 2.712949514389038\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 102, batch train loss: 4.036473274230957\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 103, batch train loss: 3.0094454288482666\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 104, batch train loss: 3.503758192062378\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 105, batch train loss: 2.606849193572998\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 106, batch train loss: 2.5263705253601074\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 107, batch train loss: 2.1965904235839844\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 108, batch train loss: 2.692922592163086\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 109, batch train loss: 3.13220477104187\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 110, batch train loss: 2.3896002769470215\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 111, batch train loss: 3.5482311248779297\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 112, batch train loss: 2.707660675048828\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 113, batch train loss: 3.2273828983306885\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 114, batch train loss: 2.7039051055908203\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 115, batch train loss: 3.4345362186431885\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 116, batch train loss: 2.588719367980957\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 117, batch train loss: 2.7027511596679688\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 118, batch train loss: 4.073955059051514\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 119, batch train loss: 2.9868855476379395\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 120, batch train loss: 2.5846140384674072\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 121, batch train loss: 2.8558249473571777\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 122, batch train loss: 3.4984607696533203\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 123, batch train loss: 2.598236083984375\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 124, batch train loss: 3.328604221343994\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 125, batch train loss: 3.775738477706909\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 126, batch train loss: 2.8778624534606934\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 127, batch train loss: 3.015991449356079\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 128, batch train loss: 2.53281831741333\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 129, batch train loss: 3.130589485168457\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88, batch_id: 130, batch train loss: 3.6466121673583984\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 131, batch train loss: 3.1486573219299316\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 132, batch train loss: 3.2702417373657227\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 133, batch train loss: 3.289973258972168\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 134, batch train loss: 3.070951223373413\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 135, batch train loss: 3.568784236907959\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 136, batch train loss: 4.051675796508789\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 137, batch train loss: 2.5977189540863037\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 138, batch train loss: 2.636577844619751\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 139, batch train loss: 2.789114475250244\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 140, batch train loss: 4.171084403991699\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 141, batch train loss: 3.549125909805298\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 142, batch train loss: 3.5431387424468994\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 143, batch train loss: 3.4498047828674316\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 144, batch train loss: 3.569148302078247\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 145, batch train loss: 3.2106130123138428\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 146, batch train loss: 4.064192295074463\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 147, batch train loss: 3.4468445777893066\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 148, batch train loss: 3.1032495498657227\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 149, batch train loss: 2.7040634155273438\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 150, batch train loss: 2.6001133918762207\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 151, batch train loss: 2.870366096496582\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 152, batch train loss: 2.5259463787078857\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 153, batch train loss: 2.655339002609253\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 154, batch train loss: 2.6137259006500244\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 155, batch train loss: 5.244966983795166\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 156, batch train loss: 3.8787150382995605\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 157, batch train loss: 4.7008819580078125\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 158, batch train loss: 3.566527843475342\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 159, batch train loss: 2.3843812942504883\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 160, batch train loss: 4.387671947479248\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 161, batch train loss: 3.2420759201049805\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 162, batch train loss: 2.78328013420105\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 163, batch train loss: 2.8444623947143555\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 164, batch train loss: 2.7353293895721436\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 165, batch train loss: 2.832737922668457\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 166, batch train loss: 2.986471176147461\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 167, batch train loss: 2.859269857406616\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 168, batch train loss: 3.4241740703582764\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 169, batch train loss: 3.032680034637451\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 170, batch train loss: 3.6078410148620605\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 171, batch train loss: 3.828640937805176\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 172, batch train loss: 3.200793743133545\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 173, batch train loss: 2.742649555206299\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 174, batch train loss: 2.7736124992370605\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 175, batch train loss: 2.87105393409729\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 176, batch train loss: 2.9718806743621826\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 177, batch train loss: 2.4879331588745117\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 178, batch train loss: 2.9940502643585205\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 179, batch train loss: 2.7984766960144043\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 180, batch train loss: 2.296569585800171\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 181, batch train loss: 3.021522045135498\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 182, batch train loss: 2.141287326812744\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 183, batch train loss: 3.148301839828491\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 184, batch train loss: 2.310460090637207\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 185, batch train loss: 2.7270874977111816\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 186, batch train loss: 2.923281192779541\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 187, batch train loss: 2.637037992477417\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 188, batch train loss: 2.3779282569885254\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 189, batch train loss: 2.664708137512207\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 190, batch train loss: 2.2180354595184326\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 191, batch train loss: 1.9494950771331787\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 192, batch train loss: 3.0129318237304688\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 193, batch train loss: 2.7827954292297363\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 194, batch train loss: 2.214244842529297\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 195, batch train loss: 2.560819149017334\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 196, batch train loss: 2.5818889141082764\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 197, batch train loss: 3.21855092048645\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 198, batch train loss: 2.9411263465881348\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 199, batch train loss: 2.4102871417999268\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 200, batch train loss: 1.860927939414978\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 201, batch train loss: 2.7705838680267334\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 202, batch train loss: 2.6003453731536865\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 203, batch train loss: 2.5750060081481934\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 204, batch train loss: 2.8387415409088135\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 205, batch train loss: 2.5408506393432617\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 206, batch train loss: 2.664928913116455\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 207, batch train loss: 1.9401706457138062\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 208, batch train loss: 2.7995312213897705\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 209, batch train loss: 3.094839572906494\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 210, batch train loss: 2.9950859546661377\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 211, batch train loss: 3.234635829925537\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 212, batch train loss: 2.5394201278686523\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 213, batch train loss: 3.1312735080718994\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 214, batch train loss: 3.2964673042297363\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 215, batch train loss: 2.8627734184265137\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 216, batch train loss: 3.9226553440093994\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 217, batch train loss: 2.356278896331787\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 218, batch train loss: 2.4976158142089844\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 219, batch train loss: 2.543201208114624\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 220, batch train loss: 2.634554147720337\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 221, batch train loss: 2.8799502849578857\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 222, batch train loss: 2.9942855834960938\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 223, batch train loss: 2.874422073364258\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 224, batch train loss: 3.076392650604248\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 225, batch train loss: 2.5242440700531006\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 226, batch train loss: 2.777719020843506\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 227, batch train loss: 2.4886531829833984\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 228, batch train loss: 2.3150882720947266\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 229, batch train loss: 2.7763891220092773\n",
      "\n",
      "\n",
      "Epoch: 88, batch_id: 230, batch train loss: 2.964473009109497\n",
      "\n",
      "\n",
      "Epoch: 88/ 100, Loss: 3.085078701765641\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:06<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88 Validation Loss: 2.48127414782842\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89, batch_id: 1, batch train loss: 2.472484588623047\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 2, batch train loss: 3.5369718074798584\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 3, batch train loss: 2.5239522457122803\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 4, batch train loss: 2.9050869941711426\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 5, batch train loss: 2.7876365184783936\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 6, batch train loss: 2.830289840698242\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 7, batch train loss: 4.486777305603027\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 8, batch train loss: 2.797483444213867\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 9, batch train loss: 3.589973211288452\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 10, batch train loss: 1.9686858654022217\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 11, batch train loss: 3.2771623134613037\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 12, batch train loss: 3.234898567199707\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 13, batch train loss: 3.9016332626342773\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 14, batch train loss: 4.661290645599365\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 15, batch train loss: 3.645442008972168\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 16, batch train loss: 4.09926700592041\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 17, batch train loss: 2.471407413482666\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 18, batch train loss: 4.067167282104492\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 19, batch train loss: 3.587188720703125\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 20, batch train loss: 3.2152233123779297\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 21, batch train loss: 3.480518102645874\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 22, batch train loss: 2.7782368659973145\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 23, batch train loss: 2.886622428894043\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 24, batch train loss: 2.546835422515869\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 25, batch train loss: 3.1449801921844482\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 26, batch train loss: 3.4784281253814697\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 27, batch train loss: 3.275965452194214\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 28, batch train loss: 3.662759304046631\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 29, batch train loss: 3.0235843658447266\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 30, batch train loss: 2.9951584339141846\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 31, batch train loss: 3.214027166366577\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 32, batch train loss: 2.4875543117523193\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 33, batch train loss: 2.3040733337402344\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 34, batch train loss: 2.984478235244751\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 35, batch train loss: 2.9297919273376465\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 36, batch train loss: 3.3886055946350098\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 37, batch train loss: 4.020541191101074\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 38, batch train loss: 4.292252540588379\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 39, batch train loss: 2.881850481033325\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 40, batch train loss: 3.888364315032959\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 41, batch train loss: 3.950089454650879\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 42, batch train loss: 3.7184529304504395\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 43, batch train loss: 3.6409618854522705\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 44, batch train loss: 3.0656933784484863\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 45, batch train loss: 4.008238315582275\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 46, batch train loss: 4.695591449737549\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 47, batch train loss: 2.9573676586151123\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 48, batch train loss: 4.468520641326904\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 49, batch train loss: 2.8358564376831055\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 50, batch train loss: 3.638878107070923\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 51, batch train loss: 3.3317995071411133\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 52, batch train loss: 3.2289297580718994\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 53, batch train loss: 3.3784573078155518\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 54, batch train loss: 2.6572041511535645\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 55, batch train loss: 3.020634651184082\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 56, batch train loss: 2.972033739089966\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 57, batch train loss: 2.465459108352661\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 58, batch train loss: 3.280162811279297\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 59, batch train loss: 3.6284162998199463\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 60, batch train loss: 3.759350538253784\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 61, batch train loss: 2.6679694652557373\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 62, batch train loss: 2.9084115028381348\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 63, batch train loss: 3.0143725872039795\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 64, batch train loss: 3.2208971977233887\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 65, batch train loss: 3.423623561859131\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 66, batch train loss: 2.5168371200561523\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 67, batch train loss: 3.6277778148651123\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 68, batch train loss: 3.760998487472534\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 69, batch train loss: 3.6260745525360107\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 70, batch train loss: 3.325845241546631\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 71, batch train loss: 4.256701946258545\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 72, batch train loss: 4.260998725891113\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 73, batch train loss: 4.922224998474121\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 74, batch train loss: 3.7081527709960938\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 75, batch train loss: 3.2141506671905518\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 76, batch train loss: 3.6551928520202637\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 77, batch train loss: 3.6537163257598877\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 78, batch train loss: 3.2611143589019775\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 79, batch train loss: 2.9295268058776855\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 80, batch train loss: 2.6041877269744873\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 81, batch train loss: 2.756875991821289\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 82, batch train loss: 2.7898144721984863\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 83, batch train loss: 2.4535324573516846\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 84, batch train loss: 2.984830379486084\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 85, batch train loss: 2.453948497772217\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 86, batch train loss: 2.208228588104248\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 87, batch train loss: 2.5763261318206787\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 88, batch train loss: 3.1209373474121094\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 89, batch train loss: 3.048807144165039\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 90, batch train loss: 2.759509801864624\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 91, batch train loss: 2.5643324851989746\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 92, batch train loss: 2.825241804122925\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 93, batch train loss: 2.5776526927948\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 94, batch train loss: 3.0453596115112305\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 95, batch train loss: 3.289916753768921\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 96, batch train loss: 2.737755060195923\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 97, batch train loss: 2.9317398071289062\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 98, batch train loss: 2.8581624031066895\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 99, batch train loss: 3.0101065635681152\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 100, batch train loss: 4.382996559143066\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 101, batch train loss: 2.7132728099823\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 102, batch train loss: 2.758868932723999\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 103, batch train loss: 2.5110301971435547\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 104, batch train loss: 2.789480686187744\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 105, batch train loss: 2.5988924503326416\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 106, batch train loss: 3.280972719192505\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 107, batch train loss: 2.8193013668060303\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 108, batch train loss: 3.2717459201812744\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 109, batch train loss: 2.856275796890259\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 110, batch train loss: 2.6184003353118896\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 111, batch train loss: 3.5242371559143066\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 112, batch train loss: 3.179628610610962\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 113, batch train loss: 3.308039426803589\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 114, batch train loss: 2.8322954177856445\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 115, batch train loss: 2.9423463344573975\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 116, batch train loss: 2.7762937545776367\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 117, batch train loss: 3.6600003242492676\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 118, batch train loss: 2.838959217071533\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 119, batch train loss: 5.231260299682617\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 120, batch train loss: 3.2140090465545654\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 121, batch train loss: 3.469241142272949\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 122, batch train loss: 3.068258762359619\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 123, batch train loss: 3.209963083267212\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 124, batch train loss: 3.001157283782959\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 125, batch train loss: 3.0835773944854736\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 126, batch train loss: 3.214207649230957\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 127, batch train loss: 3.557577610015869\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 128, batch train loss: 3.206995725631714\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 129, batch train loss: 2.7383549213409424\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89, batch_id: 130, batch train loss: 2.8368866443634033\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 131, batch train loss: 2.8560233116149902\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 132, batch train loss: 2.9482312202453613\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 133, batch train loss: 2.981881618499756\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 134, batch train loss: 2.9236702919006348\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 135, batch train loss: 5.118175029754639\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 136, batch train loss: 2.914456605911255\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 137, batch train loss: 3.5884790420532227\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 138, batch train loss: 3.6255998611450195\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 139, batch train loss: 4.111529350280762\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 140, batch train loss: 3.3541131019592285\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 141, batch train loss: 3.315492868423462\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 142, batch train loss: 3.0594303607940674\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 143, batch train loss: 3.4146435260772705\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 144, batch train loss: 2.8852782249450684\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 145, batch train loss: 2.3058931827545166\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 146, batch train loss: 3.525132656097412\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 147, batch train loss: 3.4565820693969727\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 148, batch train loss: 3.4514379501342773\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 149, batch train loss: 3.792217254638672\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 150, batch train loss: 2.522394895553589\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 151, batch train loss: 3.716249942779541\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 152, batch train loss: 2.694106340408325\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 153, batch train loss: 3.125850200653076\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 154, batch train loss: 3.8567802906036377\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 155, batch train loss: 3.344658613204956\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 156, batch train loss: 3.0038697719573975\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 157, batch train loss: 3.7576537132263184\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 158, batch train loss: 3.1274139881134033\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 159, batch train loss: 2.9831013679504395\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 160, batch train loss: 3.2809395790100098\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 161, batch train loss: 2.590820550918579\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 162, batch train loss: 2.2677271366119385\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 163, batch train loss: 2.635716676712036\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 164, batch train loss: 2.5245673656463623\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 165, batch train loss: 2.739865303039551\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 166, batch train loss: 2.8401453495025635\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 167, batch train loss: 2.481783390045166\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 168, batch train loss: 2.584155559539795\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 169, batch train loss: 2.3556900024414062\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 170, batch train loss: 2.5096471309661865\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 171, batch train loss: 2.7123308181762695\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 172, batch train loss: 2.7657861709594727\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 173, batch train loss: 2.955655813217163\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 174, batch train loss: 2.6452858448028564\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 175, batch train loss: 2.4580273628234863\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 176, batch train loss: 2.22580623626709\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 177, batch train loss: 2.6603143215179443\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 178, batch train loss: 2.2836644649505615\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 179, batch train loss: 2.6531405448913574\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 180, batch train loss: 2.5813255310058594\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 181, batch train loss: 3.204967737197876\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 182, batch train loss: 2.0413148403167725\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 183, batch train loss: 2.534280776977539\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 184, batch train loss: 1.9472007751464844\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 185, batch train loss: 2.4215493202209473\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 186, batch train loss: 3.4698054790496826\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 187, batch train loss: 2.454894781112671\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 188, batch train loss: 2.921642780303955\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 189, batch train loss: 2.4297091960906982\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 190, batch train loss: 2.7463033199310303\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 191, batch train loss: 3.365919589996338\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 192, batch train loss: 2.9844279289245605\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 193, batch train loss: 3.1359314918518066\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 194, batch train loss: 4.101372241973877\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 195, batch train loss: 2.5239975452423096\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 196, batch train loss: 2.5317471027374268\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 197, batch train loss: 3.0318124294281006\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 198, batch train loss: 2.3435018062591553\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 199, batch train loss: 3.8260505199432373\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 200, batch train loss: 4.642895698547363\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 201, batch train loss: 3.7962071895599365\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 202, batch train loss: 3.9944422245025635\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 203, batch train loss: 2.9183146953582764\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 204, batch train loss: 2.8024322986602783\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 205, batch train loss: 2.590996265411377\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 206, batch train loss: 2.5260562896728516\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 207, batch train loss: 3.131640911102295\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 208, batch train loss: 4.249443531036377\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 209, batch train loss: 2.7004857063293457\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 210, batch train loss: 2.6367080211639404\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 211, batch train loss: 2.9800572395324707\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 212, batch train loss: 3.8769564628601074\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 213, batch train loss: 3.237907886505127\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 214, batch train loss: 2.8398592472076416\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 215, batch train loss: 3.1657543182373047\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 216, batch train loss: 3.069298505783081\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 217, batch train loss: 3.2405142784118652\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 218, batch train loss: 2.832984209060669\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 219, batch train loss: 2.972543478012085\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 220, batch train loss: 3.2286150455474854\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 221, batch train loss: 3.770428419113159\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 222, batch train loss: 3.368844509124756\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 223, batch train loss: 2.745363473892212\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 224, batch train loss: 2.7828667163848877\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 225, batch train loss: 2.9511499404907227\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 226, batch train loss: 3.2889060974121094\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 227, batch train loss: 2.9309604167938232\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 228, batch train loss: 3.174794912338257\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 229, batch train loss: 3.830188035964966\n",
      "\n",
      "\n",
      "Epoch: 89, batch_id: 230, batch train loss: 2.8450241088867188\n",
      "\n",
      "\n",
      "Epoch: 89/ 100, Loss: 3.13532582676929\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:05<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89 Validation Loss: 3.222777227560679\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, batch_id: 1, batch train loss: 3.0133109092712402\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 2, batch train loss: 3.011025905609131\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 3, batch train loss: 3.059462785720825\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 4, batch train loss: 2.976999282836914\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 5, batch train loss: 2.674691677093506\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 6, batch train loss: 2.8287134170532227\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 7, batch train loss: 2.5991880893707275\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 8, batch train loss: 3.1914784908294678\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 9, batch train loss: 3.326141357421875\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 10, batch train loss: 3.0086042881011963\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 11, batch train loss: 2.954223155975342\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 12, batch train loss: 2.810743570327759\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 13, batch train loss: 3.138375759124756\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 14, batch train loss: 3.219796657562256\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 15, batch train loss: 3.2419207096099854\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 16, batch train loss: 3.1061792373657227\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 17, batch train loss: 3.623589277267456\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 18, batch train loss: 3.1421234607696533\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 19, batch train loss: 3.170767307281494\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 20, batch train loss: 2.902440071105957\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 21, batch train loss: 3.283139705657959\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 22, batch train loss: 2.5261154174804688\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 23, batch train loss: 2.8943660259246826\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 24, batch train loss: 3.2220752239227295\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 25, batch train loss: 2.8251075744628906\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 26, batch train loss: 3.308380126953125\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 27, batch train loss: 3.2721967697143555\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 28, batch train loss: 3.0595149993896484\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 29, batch train loss: 3.195556402206421\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 30, batch train loss: 3.025815725326538\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 31, batch train loss: 3.0175068378448486\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 32, batch train loss: 3.955516815185547\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 33, batch train loss: 3.523550510406494\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 34, batch train loss: 4.114063262939453\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 35, batch train loss: 3.803983449935913\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 36, batch train loss: 3.5134379863739014\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 37, batch train loss: 3.6180436611175537\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 38, batch train loss: 3.241640567779541\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 39, batch train loss: 2.794064998626709\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 40, batch train loss: 3.346419334411621\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 41, batch train loss: 3.4051339626312256\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 42, batch train loss: 3.9508471488952637\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 43, batch train loss: 3.5141890048980713\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 44, batch train loss: 3.180114507675171\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 45, batch train loss: 3.228663206100464\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 46, batch train loss: 2.7334201335906982\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 47, batch train loss: 3.360713005065918\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 48, batch train loss: 3.1532812118530273\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 49, batch train loss: 3.203829050064087\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 50, batch train loss: 3.0802605152130127\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 51, batch train loss: 2.5640246868133545\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 52, batch train loss: 2.9821465015411377\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 53, batch train loss: 2.9976186752319336\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 54, batch train loss: 3.4794437885284424\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 55, batch train loss: 2.9935598373413086\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 56, batch train loss: 2.8040895462036133\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 57, batch train loss: 2.7818775177001953\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 58, batch train loss: 3.3781931400299072\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 59, batch train loss: 3.1058948040008545\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 60, batch train loss: 2.656095266342163\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 61, batch train loss: 2.5740866661071777\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 62, batch train loss: 3.474213123321533\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 63, batch train loss: 3.1093976497650146\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 64, batch train loss: 2.794981002807617\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 65, batch train loss: 2.704761266708374\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 66, batch train loss: 3.311107873916626\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 67, batch train loss: 2.859950304031372\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 68, batch train loss: 2.973905086517334\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 69, batch train loss: 3.133888006210327\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 70, batch train loss: 2.7189178466796875\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 71, batch train loss: 2.729900598526001\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 72, batch train loss: 3.3130135536193848\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 73, batch train loss: 2.9186270236968994\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 74, batch train loss: 2.6028990745544434\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 75, batch train loss: 3.5725390911102295\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 76, batch train loss: 4.3920674324035645\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 77, batch train loss: 3.7769343852996826\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 78, batch train loss: 4.408870220184326\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 79, batch train loss: 3.1471846103668213\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 80, batch train loss: 3.306295394897461\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 81, batch train loss: 3.450515031814575\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 82, batch train loss: 3.6277432441711426\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 83, batch train loss: 3.938365936279297\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 84, batch train loss: 2.258143186569214\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 85, batch train loss: 3.276172399520874\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 86, batch train loss: 2.8750836849212646\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 87, batch train loss: 2.6970837116241455\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 88, batch train loss: 2.527247905731201\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 89, batch train loss: 3.635697364807129\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 90, batch train loss: 4.9575958251953125\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 91, batch train loss: 3.040573835372925\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 92, batch train loss: 3.2045693397521973\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 93, batch train loss: 2.7028841972351074\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 94, batch train loss: 2.267522096633911\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 95, batch train loss: 2.8706343173980713\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 96, batch train loss: 3.1797521114349365\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 97, batch train loss: 3.0127146244049072\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 98, batch train loss: 3.117824077606201\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 99, batch train loss: 2.623789072036743\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 100, batch train loss: 3.0614283084869385\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 101, batch train loss: 3.3238813877105713\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 102, batch train loss: 2.3739209175109863\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 103, batch train loss: 3.760190486907959\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 104, batch train loss: 2.8003957271575928\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 105, batch train loss: 2.4177942276000977\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 106, batch train loss: 1.9517053365707397\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 107, batch train loss: 2.1269946098327637\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 108, batch train loss: 2.474869728088379\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 109, batch train loss: 2.4908227920532227\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 110, batch train loss: 2.344449996948242\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 111, batch train loss: 3.217489004135132\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 112, batch train loss: 1.9471737146377563\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 113, batch train loss: 2.2656872272491455\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 114, batch train loss: 2.312359094619751\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 115, batch train loss: 2.1723458766937256\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 116, batch train loss: 2.151632785797119\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 117, batch train loss: 2.74597430229187\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 118, batch train loss: 2.325605630874634\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 119, batch train loss: 2.5547258853912354\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 120, batch train loss: 2.3747899532318115\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 121, batch train loss: 2.174968719482422\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 122, batch train loss: 2.288715124130249\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 123, batch train loss: 2.3559720516204834\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 124, batch train loss: 3.4900588989257812\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 125, batch train loss: 2.343151807785034\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 126, batch train loss: 2.4766571521759033\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 127, batch train loss: 2.3524482250213623\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 128, batch train loss: 2.3589611053466797\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 129, batch train loss: 2.4942104816436768\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, batch_id: 130, batch train loss: 3.069733142852783\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 131, batch train loss: 2.9443254470825195\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 132, batch train loss: 2.4606363773345947\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 133, batch train loss: 1.9955974817276\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 134, batch train loss: 3.107717275619507\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 135, batch train loss: 1.9972628355026245\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 136, batch train loss: 2.690662145614624\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 137, batch train loss: 2.1159045696258545\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 138, batch train loss: 2.8453152179718018\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 139, batch train loss: 2.0995559692382812\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 140, batch train loss: 3.765888214111328\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 141, batch train loss: 2.4777798652648926\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 142, batch train loss: 2.9312844276428223\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 143, batch train loss: 4.008969783782959\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 144, batch train loss: 2.8183679580688477\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 145, batch train loss: 3.9225521087646484\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 146, batch train loss: 4.522331714630127\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 147, batch train loss: 3.729508876800537\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 148, batch train loss: 4.896542072296143\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 149, batch train loss: 6.4498491287231445\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 150, batch train loss: 3.975687265396118\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 151, batch train loss: 3.819035291671753\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 152, batch train loss: 6.412051200866699\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 153, batch train loss: 4.361955165863037\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 154, batch train loss: 5.047388553619385\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 155, batch train loss: 5.447293281555176\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 156, batch train loss: 5.916793346405029\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 157, batch train loss: 3.621690273284912\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 158, batch train loss: 2.604982852935791\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 159, batch train loss: 3.452472686767578\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 160, batch train loss: 3.636319160461426\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 161, batch train loss: 3.520033359527588\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 162, batch train loss: 3.3722569942474365\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 163, batch train loss: 3.786454200744629\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 164, batch train loss: 2.981602668762207\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 165, batch train loss: 2.6274914741516113\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 166, batch train loss: 2.6981868743896484\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 167, batch train loss: 3.4248645305633545\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 168, batch train loss: 3.3316872119903564\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 169, batch train loss: 2.6384341716766357\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 170, batch train loss: 3.1208536624908447\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 171, batch train loss: 2.593252658843994\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 172, batch train loss: 3.630580186843872\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 173, batch train loss: 3.002006769180298\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 174, batch train loss: 3.270923376083374\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 175, batch train loss: 3.0502922534942627\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 176, batch train loss: 2.339033603668213\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 177, batch train loss: 2.8680083751678467\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 178, batch train loss: 3.4976978302001953\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 179, batch train loss: 2.7309188842773438\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 180, batch train loss: 2.958057165145874\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 181, batch train loss: 3.0552148818969727\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 182, batch train loss: 2.460756778717041\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 183, batch train loss: 2.599346399307251\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 184, batch train loss: 2.132871389389038\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 185, batch train loss: 3.877047061920166\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 186, batch train loss: 3.6752734184265137\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 187, batch train loss: 2.190176486968994\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 188, batch train loss: 2.478721857070923\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 189, batch train loss: 2.224916458129883\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 190, batch train loss: 2.710568428039551\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 191, batch train loss: 2.298401117324829\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 192, batch train loss: 4.484527111053467\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 193, batch train loss: 2.4479482173919678\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 194, batch train loss: 1.8276461362838745\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 195, batch train loss: 4.777405738830566\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 196, batch train loss: 4.516298770904541\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 197, batch train loss: 2.6395950317382812\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 198, batch train loss: 2.8181421756744385\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 199, batch train loss: 2.6038882732391357\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 200, batch train loss: 2.67387318611145\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 201, batch train loss: 2.8339617252349854\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 202, batch train loss: 2.104628801345825\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 203, batch train loss: 1.928863525390625\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 204, batch train loss: 1.9294931888580322\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 205, batch train loss: 1.876545786857605\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 206, batch train loss: 3.206904172897339\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 207, batch train loss: 2.2049484252929688\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 208, batch train loss: 1.7971549034118652\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 209, batch train loss: 1.7184810638427734\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 210, batch train loss: 2.5562191009521484\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 211, batch train loss: 3.3202128410339355\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 212, batch train loss: 3.232586145401001\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 213, batch train loss: 3.523561954498291\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 214, batch train loss: 4.762338638305664\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 215, batch train loss: 3.3653483390808105\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 216, batch train loss: 2.1272714138031006\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 217, batch train loss: 4.346914291381836\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 218, batch train loss: 3.0252904891967773\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 219, batch train loss: 1.9459460973739624\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 220, batch train loss: 2.373936176300049\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 221, batch train loss: 2.5525999069213867\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 222, batch train loss: 1.8599432706832886\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 223, batch train loss: 3.5527164936065674\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 224, batch train loss: 2.4330246448516846\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 225, batch train loss: 3.2112321853637695\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 226, batch train loss: 2.3526480197906494\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 227, batch train loss: 2.012368679046631\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 228, batch train loss: 3.152747869491577\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 229, batch train loss: 4.981096267700195\n",
      "\n",
      "\n",
      "Epoch: 90, batch_id: 230, batch train loss: 2.194385528564453\n",
      "\n",
      "\n",
      "Epoch: 90/ 100, Loss: 3.0577155558959297\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:07<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 Validation Loss: 5.5394397934277855\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91, batch_id: 1, batch train loss: 4.758657455444336\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 2, batch train loss: 5.249876499176025\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 3, batch train loss: 3.7681925296783447\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 4, batch train loss: 2.5639970302581787\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 5, batch train loss: 5.126986026763916\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 6, batch train loss: 3.3023838996887207\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 7, batch train loss: 3.3613786697387695\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 8, batch train loss: 3.298755168914795\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 9, batch train loss: 2.5480964183807373\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 10, batch train loss: 2.039048194885254\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 11, batch train loss: 2.6797268390655518\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 12, batch train loss: 2.546952724456787\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 13, batch train loss: 3.422415018081665\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 14, batch train loss: 3.084456443786621\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 15, batch train loss: 2.4184670448303223\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 16, batch train loss: 3.403367280960083\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 17, batch train loss: 3.000955581665039\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 18, batch train loss: 2.0758399963378906\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 19, batch train loss: 2.8321261405944824\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 20, batch train loss: 3.549459218978882\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 21, batch train loss: 2.9443483352661133\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 22, batch train loss: 2.38493275642395\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 23, batch train loss: 2.507751941680908\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 24, batch train loss: 2.657743215560913\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 25, batch train loss: 2.3331804275512695\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 26, batch train loss: 2.011190414428711\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 27, batch train loss: 2.6424546241760254\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 28, batch train loss: 2.308760643005371\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 29, batch train loss: 2.575172185897827\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 30, batch train loss: 4.3624725341796875\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 31, batch train loss: 2.8949246406555176\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 32, batch train loss: 2.8432483673095703\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 33, batch train loss: 2.7974984645843506\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 34, batch train loss: 3.2242846488952637\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 35, batch train loss: 3.3832671642303467\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 36, batch train loss: 2.7273240089416504\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 37, batch train loss: 2.0223658084869385\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 38, batch train loss: 2.4423155784606934\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 39, batch train loss: 2.607847213745117\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 40, batch train loss: 2.647887945175171\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 41, batch train loss: 3.324843645095825\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 42, batch train loss: 3.897136688232422\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 43, batch train loss: 2.092552661895752\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 44, batch train loss: 4.249501705169678\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 45, batch train loss: 3.6168594360351562\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 46, batch train loss: 2.518872022628784\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 47, batch train loss: 1.986145257949829\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 48, batch train loss: 3.0595862865448\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 49, batch train loss: 2.4198434352874756\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 50, batch train loss: 2.178508758544922\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 51, batch train loss: 3.6102840900421143\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 52, batch train loss: 2.9838616847991943\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 53, batch train loss: 2.960688591003418\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 54, batch train loss: 2.4454591274261475\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 55, batch train loss: 5.680016040802002\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 56, batch train loss: 3.568203926086426\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 57, batch train loss: 2.7493162155151367\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 58, batch train loss: 3.4265217781066895\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 59, batch train loss: 3.7489306926727295\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 60, batch train loss: 2.1692774295806885\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 61, batch train loss: 1.6783443689346313\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 62, batch train loss: 2.547593832015991\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 63, batch train loss: 1.7353081703186035\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 64, batch train loss: 2.3339059352874756\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 65, batch train loss: 2.1349411010742188\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 66, batch train loss: 1.9983937740325928\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 67, batch train loss: 1.8469266891479492\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 68, batch train loss: 2.015886068344116\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 69, batch train loss: 3.105128288269043\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 70, batch train loss: 2.8094558715820312\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 71, batch train loss: 4.826046943664551\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 72, batch train loss: 2.4680893421173096\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 73, batch train loss: 2.4750466346740723\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 74, batch train loss: 2.6157281398773193\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 75, batch train loss: 2.2568888664245605\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 76, batch train loss: 2.19209885597229\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 77, batch train loss: 2.6883065700531006\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 78, batch train loss: 2.443340539932251\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 79, batch train loss: 2.139497995376587\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 80, batch train loss: 1.6785603761672974\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 81, batch train loss: 1.5999624729156494\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 82, batch train loss: 1.6808370351791382\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 83, batch train loss: 1.68183434009552\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 84, batch train loss: 1.9129523038864136\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 85, batch train loss: 1.9425616264343262\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 86, batch train loss: 1.785393476486206\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 87, batch train loss: 1.730224370956421\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 88, batch train loss: 2.2940738201141357\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 89, batch train loss: 1.514205813407898\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 90, batch train loss: 1.5647168159484863\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 91, batch train loss: 1.4107422828674316\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 92, batch train loss: 2.327836751937866\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 93, batch train loss: 2.2617244720458984\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 94, batch train loss: 2.8994674682617188\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 95, batch train loss: 1.912353515625\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 96, batch train loss: 2.456538200378418\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 97, batch train loss: 1.5379259586334229\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 98, batch train loss: 2.438401222229004\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 99, batch train loss: 2.463391065597534\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 100, batch train loss: 2.074798583984375\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 101, batch train loss: 2.0882039070129395\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 102, batch train loss: 1.3703088760375977\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 103, batch train loss: 1.7645819187164307\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 104, batch train loss: 2.077204704284668\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 105, batch train loss: 2.0485544204711914\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 106, batch train loss: 1.4041212797164917\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 107, batch train loss: 1.4421433210372925\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 108, batch train loss: 2.497467517852783\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 109, batch train loss: 1.9326180219650269\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 110, batch train loss: 2.176276206970215\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 111, batch train loss: 1.436267375946045\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 112, batch train loss: 2.407003164291382\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 113, batch train loss: 1.4118144512176514\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 114, batch train loss: 1.8476017713546753\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 115, batch train loss: 2.417555332183838\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 116, batch train loss: 2.008758068084717\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 117, batch train loss: 1.5119439363479614\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 118, batch train loss: 1.5978577136993408\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 119, batch train loss: 1.7289581298828125\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 120, batch train loss: 1.9448550939559937\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 121, batch train loss: 1.5450752973556519\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 122, batch train loss: 1.3071736097335815\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 123, batch train loss: 2.516437292098999\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 124, batch train loss: 2.031636953353882\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 125, batch train loss: 2.374295949935913\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 126, batch train loss: 1.9509559869766235\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 127, batch train loss: 2.235057830810547\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 128, batch train loss: 2.462350845336914\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 129, batch train loss: 1.4489967823028564\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91, batch_id: 130, batch train loss: 1.754150390625\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 131, batch train loss: 1.9909602403640747\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 132, batch train loss: 1.574573278427124\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 133, batch train loss: 2.46964955329895\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 134, batch train loss: 1.7283841371536255\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 135, batch train loss: 2.4688634872436523\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 136, batch train loss: 2.956981658935547\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 137, batch train loss: 1.8839267492294312\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 138, batch train loss: 3.6884443759918213\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 139, batch train loss: 1.983039140701294\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 140, batch train loss: 1.804104208946228\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 141, batch train loss: 2.2620441913604736\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 142, batch train loss: 2.9239258766174316\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 143, batch train loss: 4.263598442077637\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 144, batch train loss: 2.2530128955841064\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 145, batch train loss: 3.058004140853882\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 146, batch train loss: 2.618042230606079\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 147, batch train loss: 3.2793238162994385\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 148, batch train loss: 1.811156153678894\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 149, batch train loss: 3.0972864627838135\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 150, batch train loss: 3.1337313652038574\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 151, batch train loss: 1.8035537004470825\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 152, batch train loss: 2.313842296600342\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 153, batch train loss: 1.7608752250671387\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 154, batch train loss: 2.142906427383423\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 155, batch train loss: 2.3445043563842773\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 156, batch train loss: 1.9103755950927734\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 157, batch train loss: 2.3961215019226074\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 158, batch train loss: 1.2730138301849365\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 159, batch train loss: 1.5689771175384521\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 160, batch train loss: 2.5512075424194336\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 161, batch train loss: 2.231619119644165\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 162, batch train loss: 2.5669891834259033\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 163, batch train loss: 2.0825142860412598\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 164, batch train loss: 1.7124112844467163\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 165, batch train loss: 2.106692314147949\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 166, batch train loss: 2.3471662998199463\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 167, batch train loss: 2.3717033863067627\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 168, batch train loss: 2.0188798904418945\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 169, batch train loss: 2.8305530548095703\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 170, batch train loss: 1.851620078086853\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 171, batch train loss: 1.740217924118042\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 172, batch train loss: 2.2238929271698\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 173, batch train loss: 2.294053316116333\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 174, batch train loss: 3.691920518875122\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 175, batch train loss: 1.828776478767395\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 176, batch train loss: 2.8598921298980713\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 177, batch train loss: 3.198923110961914\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 178, batch train loss: 2.2863800525665283\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 179, batch train loss: 2.3591084480285645\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 180, batch train loss: 2.3672521114349365\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 181, batch train loss: 2.520076036453247\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 182, batch train loss: 2.9521658420562744\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 183, batch train loss: 3.596447229385376\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 184, batch train loss: 3.2887253761291504\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 185, batch train loss: 2.552917242050171\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 186, batch train loss: 2.080939531326294\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 187, batch train loss: 2.8312888145446777\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 188, batch train loss: 2.185056209564209\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 189, batch train loss: 2.6254043579101562\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 190, batch train loss: 2.589118242263794\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 191, batch train loss: 2.0567562580108643\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 192, batch train loss: 3.169774055480957\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 193, batch train loss: 3.4554104804992676\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 194, batch train loss: 3.32137131690979\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 195, batch train loss: 3.2929208278656006\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 196, batch train loss: 2.8673532009124756\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 197, batch train loss: 2.7775723934173584\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 198, batch train loss: 4.805662631988525\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 199, batch train loss: 2.9870314598083496\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 200, batch train loss: 3.4054341316223145\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 201, batch train loss: 4.512822151184082\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 202, batch train loss: 2.921743869781494\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 203, batch train loss: 2.277573823928833\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 204, batch train loss: 3.401094913482666\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 205, batch train loss: 2.770063638687134\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 206, batch train loss: 2.2266321182250977\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 207, batch train loss: 2.8936636447906494\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 208, batch train loss: 3.4401416778564453\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 209, batch train loss: 2.961775064468384\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 210, batch train loss: 3.190382480621338\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 211, batch train loss: 3.0312914848327637\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 212, batch train loss: 2.6924877166748047\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 213, batch train loss: 2.6009626388549805\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 214, batch train loss: 2.835069417953491\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 215, batch train loss: 2.2758588790893555\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 216, batch train loss: 5.303913593292236\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 217, batch train loss: 3.332575798034668\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 218, batch train loss: 4.093861103057861\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 219, batch train loss: 3.276113271713257\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 220, batch train loss: 3.3286783695220947\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 221, batch train loss: 3.856621026992798\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 222, batch train loss: 2.111511707305908\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 223, batch train loss: 2.7050657272338867\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 224, batch train loss: 2.8583338260650635\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 225, batch train loss: 2.4695117473602295\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 226, batch train loss: 2.1116464138031006\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 227, batch train loss: 2.7936317920684814\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 228, batch train loss: 1.821901798248291\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 229, batch train loss: 2.4969804286956787\n",
      "\n",
      "\n",
      "Epoch: 91, batch_id: 230, batch train loss: 2.7508578300476074\n",
      "\n",
      "\n",
      "Epoch: 91/ 100, Loss: 2.5793276703876\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:07<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91 Validation Loss: 2.466626461346944\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92, batch_id: 1, batch train loss: 3.408473014831543\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 2, batch train loss: 2.729043483734131\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 3, batch train loss: 3.943225860595703\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 4, batch train loss: 2.3588032722473145\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 5, batch train loss: 4.357229232788086\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 6, batch train loss: 4.278590202331543\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 7, batch train loss: 2.8778843879699707\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 8, batch train loss: 3.1189916133880615\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 9, batch train loss: 6.548116683959961\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 10, batch train loss: 4.168926239013672\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 11, batch train loss: 2.602733850479126\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 12, batch train loss: 4.426602840423584\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 13, batch train loss: 3.7250816822052\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 14, batch train loss: 2.506133556365967\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 15, batch train loss: 4.058779716491699\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 16, batch train loss: 4.050962924957275\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 17, batch train loss: 2.923588514328003\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 18, batch train loss: 3.8352432250976562\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 19, batch train loss: 3.2520461082458496\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 20, batch train loss: 2.4488515853881836\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 21, batch train loss: 4.070926666259766\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 22, batch train loss: 2.7132344245910645\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 23, batch train loss: 2.0033998489379883\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 24, batch train loss: 3.0370543003082275\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 25, batch train loss: 3.2653584480285645\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 26, batch train loss: 3.2706387042999268\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 27, batch train loss: 4.6547465324401855\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 28, batch train loss: 3.8234264850616455\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 29, batch train loss: 2.322392463684082\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 30, batch train loss: 3.095254421234131\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 31, batch train loss: 2.2531068325042725\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 32, batch train loss: 2.5103390216827393\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 33, batch train loss: 2.7609713077545166\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 34, batch train loss: 2.152820587158203\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 35, batch train loss: 2.0577783584594727\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 36, batch train loss: 1.8978124856948853\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 37, batch train loss: 2.6371688842773438\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 38, batch train loss: 2.2565183639526367\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 39, batch train loss: 2.874901294708252\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 40, batch train loss: 3.6993367671966553\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 41, batch train loss: 3.1162919998168945\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 42, batch train loss: 3.3670854568481445\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 43, batch train loss: 2.422933340072632\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 44, batch train loss: 2.6917052268981934\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 45, batch train loss: 2.2011184692382812\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 46, batch train loss: 2.353847026824951\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 47, batch train loss: 3.5389230251312256\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 48, batch train loss: 2.5533175468444824\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 49, batch train loss: 2.1145179271698\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 50, batch train loss: 1.610148310661316\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 51, batch train loss: 1.9892886877059937\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 52, batch train loss: 2.4704487323760986\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 53, batch train loss: 2.240849494934082\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 54, batch train loss: 2.325357675552368\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 55, batch train loss: 2.134782314300537\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 56, batch train loss: 2.3756392002105713\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 57, batch train loss: 3.861532688140869\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 58, batch train loss: 2.0238585472106934\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 59, batch train loss: 2.909832000732422\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 60, batch train loss: 2.727944850921631\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 61, batch train loss: 3.2201457023620605\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 62, batch train loss: 2.299349784851074\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 63, batch train loss: 1.9006074666976929\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 64, batch train loss: 2.0386581420898438\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 65, batch train loss: 2.278555393218994\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 66, batch train loss: 2.425776243209839\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 67, batch train loss: 2.1901159286499023\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 68, batch train loss: 2.3422932624816895\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 69, batch train loss: 2.432133674621582\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 70, batch train loss: 2.557976484298706\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 71, batch train loss: 2.3514769077301025\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 72, batch train loss: 2.6770968437194824\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 73, batch train loss: 2.802022933959961\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 74, batch train loss: 2.6139590740203857\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 75, batch train loss: 2.883180618286133\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 76, batch train loss: 2.8011860847473145\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 77, batch train loss: 2.099257469177246\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 78, batch train loss: 4.6678547859191895\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 79, batch train loss: 4.295674800872803\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 80, batch train loss: 3.7419450283050537\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 81, batch train loss: 4.72591495513916\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 82, batch train loss: 3.096034288406372\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 83, batch train loss: 2.5898749828338623\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 84, batch train loss: 2.335585832595825\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 85, batch train loss: 3.220109462738037\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 86, batch train loss: 2.9355413913726807\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 87, batch train loss: 3.0037689208984375\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 88, batch train loss: 3.4486238956451416\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 89, batch train loss: 2.344583749771118\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 90, batch train loss: 2.6073381900787354\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 91, batch train loss: 2.651007652282715\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 92, batch train loss: 2.2872977256774902\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 93, batch train loss: 2.3564321994781494\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 94, batch train loss: 2.140287160873413\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 95, batch train loss: 2.4359500408172607\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 96, batch train loss: 1.886728286743164\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 97, batch train loss: 2.1568753719329834\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 98, batch train loss: 1.8690022230148315\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 99, batch train loss: 1.9483516216278076\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 100, batch train loss: 2.6195011138916016\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 101, batch train loss: 3.1137049198150635\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 102, batch train loss: 2.4990808963775635\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 103, batch train loss: 2.261368751525879\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 104, batch train loss: 2.797454833984375\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 105, batch train loss: 1.8304176330566406\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 106, batch train loss: 2.4143574237823486\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 107, batch train loss: 3.2609827518463135\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 108, batch train loss: 3.067366123199463\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 109, batch train loss: 2.997164487838745\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 110, batch train loss: 2.180208683013916\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 111, batch train loss: 2.0607428550720215\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 112, batch train loss: 2.2179431915283203\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 113, batch train loss: 2.624438762664795\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 114, batch train loss: 2.5646867752075195\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 115, batch train loss: 2.5002448558807373\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 116, batch train loss: 2.193467140197754\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 117, batch train loss: 2.9425559043884277\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 118, batch train loss: 2.559725522994995\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 119, batch train loss: 3.7905077934265137\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 120, batch train loss: 2.342759609222412\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 121, batch train loss: 2.897798776626587\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 122, batch train loss: 3.034334897994995\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 123, batch train loss: 2.998696804046631\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 124, batch train loss: 2.485058546066284\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 125, batch train loss: 4.5661301612854\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 126, batch train loss: 4.157313823699951\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 127, batch train loss: 3.0849225521087646\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 128, batch train loss: 3.605935573577881\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 129, batch train loss: 3.4267139434814453\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92, batch_id: 130, batch train loss: 2.9769649505615234\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 131, batch train loss: 4.108438491821289\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 132, batch train loss: 4.9936957359313965\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 133, batch train loss: 3.9121508598327637\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 134, batch train loss: 3.559296131134033\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 135, batch train loss: 3.2312822341918945\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 136, batch train loss: 2.898237466812134\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 137, batch train loss: 4.289361000061035\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 138, batch train loss: 5.230624198913574\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 139, batch train loss: 3.682889699935913\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 140, batch train loss: 3.422734260559082\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 141, batch train loss: 3.275646209716797\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 142, batch train loss: 3.085979461669922\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 143, batch train loss: 3.2504186630249023\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 144, batch train loss: 3.112143039703369\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 145, batch train loss: 2.82295560836792\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 146, batch train loss: 2.784477949142456\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 147, batch train loss: 2.9957284927368164\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 148, batch train loss: 3.9333300590515137\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 149, batch train loss: 3.9273979663848877\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 150, batch train loss: 3.7353579998016357\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 151, batch train loss: 2.8376312255859375\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 152, batch train loss: 2.8606510162353516\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 153, batch train loss: 3.306971549987793\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 154, batch train loss: 3.828336477279663\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 155, batch train loss: 3.9460668563842773\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 156, batch train loss: 2.9338788986206055\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 157, batch train loss: 2.724485158920288\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 158, batch train loss: 2.4561941623687744\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 159, batch train loss: 2.5300493240356445\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 160, batch train loss: 2.3343665599823\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 161, batch train loss: 3.1559202671051025\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 162, batch train loss: 2.861370801925659\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 163, batch train loss: 3.227020502090454\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 164, batch train loss: 3.7443928718566895\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 165, batch train loss: 2.971313953399658\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 166, batch train loss: 2.696599006652832\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 167, batch train loss: 3.2684895992279053\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 168, batch train loss: 2.845421075820923\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 169, batch train loss: 2.959944009780884\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 170, batch train loss: 3.278806686401367\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 171, batch train loss: 3.036717176437378\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 172, batch train loss: 2.9645609855651855\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 173, batch train loss: 2.3202106952667236\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 174, batch train loss: 2.194483757019043\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 175, batch train loss: 3.6320629119873047\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 176, batch train loss: 3.4580862522125244\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 177, batch train loss: 2.7915592193603516\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 178, batch train loss: 3.8319616317749023\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 179, batch train loss: 2.410706043243408\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 180, batch train loss: 2.9498250484466553\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 181, batch train loss: 3.585655927658081\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 182, batch train loss: 3.5248827934265137\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 183, batch train loss: 5.158958435058594\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 184, batch train loss: 4.593538284301758\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 185, batch train loss: 2.9570791721343994\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 186, batch train loss: 3.3846590518951416\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 187, batch train loss: 4.366995334625244\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 188, batch train loss: 3.302192449569702\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 189, batch train loss: 2.8872218132019043\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 190, batch train loss: 3.6543498039245605\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 191, batch train loss: 4.499261379241943\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 192, batch train loss: 3.278367280960083\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 193, batch train loss: 3.4996395111083984\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 194, batch train loss: 3.4433255195617676\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 195, batch train loss: 3.381945848464966\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 196, batch train loss: 3.2298810482025146\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 197, batch train loss: 3.8775594234466553\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 198, batch train loss: 3.54801344871521\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 199, batch train loss: 4.527400016784668\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 200, batch train loss: 4.102433204650879\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 201, batch train loss: 3.6588871479034424\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 202, batch train loss: 3.672060489654541\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 203, batch train loss: 4.499917030334473\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 204, batch train loss: 3.5630056858062744\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 205, batch train loss: 3.5431017875671387\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 206, batch train loss: 2.746396780014038\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 207, batch train loss: 2.1851401329040527\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 208, batch train loss: 4.1335296630859375\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 209, batch train loss: 3.550898790359497\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 210, batch train loss: 3.276289463043213\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 211, batch train loss: 3.28867506980896\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 212, batch train loss: 2.548614978790283\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 213, batch train loss: 2.4490156173706055\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 214, batch train loss: 2.820840835571289\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 215, batch train loss: 2.6291913986206055\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 216, batch train loss: 2.6698505878448486\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 217, batch train loss: 4.5672688484191895\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 218, batch train loss: 2.5686721801757812\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 219, batch train loss: 3.4636390209198\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 220, batch train loss: 4.042825698852539\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 221, batch train loss: 2.4810357093811035\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 222, batch train loss: 3.748924493789673\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 223, batch train loss: 2.9897043704986572\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 224, batch train loss: 2.6375234127044678\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 225, batch train loss: 4.474759101867676\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 226, batch train loss: 3.7354466915130615\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 227, batch train loss: 2.550142526626587\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 228, batch train loss: 2.6009483337402344\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 229, batch train loss: 2.584791421890259\n",
      "\n",
      "\n",
      "Epoch: 92, batch_id: 230, batch train loss: 3.627897024154663\n",
      "\n",
      "\n",
      "Epoch: 92/ 100, Loss: 3.075911411513453\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:09<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92 Validation Loss: 4.721946402390798\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93, batch_id: 1, batch train loss: 7.711711406707764\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 2, batch train loss: 6.245285987854004\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 3, batch train loss: 3.327242136001587\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 4, batch train loss: 2.856968879699707\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 5, batch train loss: 3.195244550704956\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 6, batch train loss: 3.3057055473327637\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 7, batch train loss: 3.4282405376434326\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 8, batch train loss: 3.914107322692871\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 9, batch train loss: 4.431769371032715\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 10, batch train loss: 3.0464112758636475\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 11, batch train loss: 2.771376132965088\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 12, batch train loss: 2.193641185760498\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 13, batch train loss: 2.265934467315674\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 14, batch train loss: 2.590451240539551\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 15, batch train loss: 2.6064181327819824\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 16, batch train loss: 3.958847761154175\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 17, batch train loss: 2.5278103351593018\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 18, batch train loss: 3.0702013969421387\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 19, batch train loss: 3.4882609844207764\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 20, batch train loss: 3.176522970199585\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 21, batch train loss: 2.873190402984619\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 22, batch train loss: 2.7901101112365723\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 23, batch train loss: 2.3929972648620605\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 24, batch train loss: 2.759350061416626\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 25, batch train loss: 3.032782793045044\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 26, batch train loss: 2.637474298477173\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 27, batch train loss: 4.193385601043701\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 28, batch train loss: 3.312394618988037\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 29, batch train loss: 3.2972021102905273\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 30, batch train loss: 3.1376254558563232\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 31, batch train loss: 3.217921018600464\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 32, batch train loss: 3.1738691329956055\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 33, batch train loss: 5.06932258605957\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 34, batch train loss: 3.1887173652648926\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 35, batch train loss: 2.6131184101104736\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 36, batch train loss: 3.5090811252593994\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 37, batch train loss: 2.578268051147461\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 38, batch train loss: 3.348858594894409\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 39, batch train loss: 3.0148794651031494\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 40, batch train loss: 2.373797655105591\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 41, batch train loss: 2.3522791862487793\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 42, batch train loss: 2.353455066680908\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 43, batch train loss: 2.283552885055542\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 44, batch train loss: 3.4201152324676514\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 45, batch train loss: 3.0667717456817627\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 46, batch train loss: 2.458488702774048\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 47, batch train loss: 3.296003818511963\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 48, batch train loss: 2.489302635192871\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 49, batch train loss: 2.7636961936950684\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 50, batch train loss: 3.2100682258605957\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 51, batch train loss: 3.1185736656188965\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 52, batch train loss: 2.9098360538482666\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 53, batch train loss: 2.6577510833740234\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 54, batch train loss: 3.546907663345337\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 55, batch train loss: 2.8061697483062744\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 56, batch train loss: 3.1932554244995117\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 57, batch train loss: 2.706998825073242\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 58, batch train loss: 3.4275593757629395\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 59, batch train loss: 3.3754258155822754\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 60, batch train loss: 3.1853220462799072\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 61, batch train loss: 3.526926279067993\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 62, batch train loss: 6.173241138458252\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 63, batch train loss: 2.682966709136963\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 64, batch train loss: 3.0511038303375244\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 65, batch train loss: 2.8216135501861572\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 66, batch train loss: 2.401576280593872\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 67, batch train loss: 2.31583833694458\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 68, batch train loss: 2.5687034130096436\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 69, batch train loss: 2.810497999191284\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 70, batch train loss: 2.921066999435425\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 71, batch train loss: 3.000002861022949\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 72, batch train loss: 2.5185258388519287\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 73, batch train loss: 2.5420949459075928\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 74, batch train loss: 2.651620864868164\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 75, batch train loss: 2.440408945083618\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 76, batch train loss: 2.875230312347412\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 77, batch train loss: 3.2316551208496094\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 78, batch train loss: 2.079881191253662\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 79, batch train loss: 2.986090660095215\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 80, batch train loss: 2.2607483863830566\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 81, batch train loss: 2.0387275218963623\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 82, batch train loss: 3.6359472274780273\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 83, batch train loss: 2.1169464588165283\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 84, batch train loss: 1.8172523975372314\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 85, batch train loss: 1.8516428470611572\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 86, batch train loss: 2.019927978515625\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 87, batch train loss: 2.066742420196533\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 88, batch train loss: 2.2008771896362305\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 89, batch train loss: 2.432304620742798\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 90, batch train loss: 3.16457200050354\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 91, batch train loss: 3.2071900367736816\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 92, batch train loss: 2.953761100769043\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 93, batch train loss: 2.365180730819702\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 94, batch train loss: 2.290064811706543\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 95, batch train loss: 2.21878981590271\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 96, batch train loss: 2.8266830444335938\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 97, batch train loss: 2.2736711502075195\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 98, batch train loss: 2.401677131652832\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 99, batch train loss: 2.044893741607666\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 100, batch train loss: 2.386190891265869\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 101, batch train loss: 2.7847673892974854\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 102, batch train loss: 4.064300060272217\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 103, batch train loss: 2.377183675765991\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 104, batch train loss: 3.0408501625061035\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 105, batch train loss: 3.082881450653076\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 106, batch train loss: 2.3658015727996826\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 107, batch train loss: 2.719071388244629\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 108, batch train loss: 2.165496587753296\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 109, batch train loss: 2.318585157394409\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 110, batch train loss: 2.0774986743927\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 111, batch train loss: 2.5902769565582275\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 112, batch train loss: 2.7236034870147705\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 113, batch train loss: 2.637059211730957\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 114, batch train loss: 2.5077743530273438\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 115, batch train loss: 1.913712739944458\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 116, batch train loss: 2.5254392623901367\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 117, batch train loss: 2.160489559173584\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 118, batch train loss: 2.4851436614990234\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 119, batch train loss: 2.903552770614624\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 120, batch train loss: 2.7660067081451416\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 121, batch train loss: 2.676025867462158\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 122, batch train loss: 3.770733594894409\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 123, batch train loss: 2.6377108097076416\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 124, batch train loss: 2.835749864578247\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 125, batch train loss: 4.111178874969482\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 126, batch train loss: 2.920607089996338\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 127, batch train loss: 2.8660659790039062\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 128, batch train loss: 2.370995283126831\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 129, batch train loss: 2.2347168922424316\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93, batch_id: 130, batch train loss: 1.938960313796997\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 131, batch train loss: 2.753246545791626\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 132, batch train loss: 1.9583057165145874\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 133, batch train loss: 2.2284889221191406\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 134, batch train loss: 2.5533645153045654\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 135, batch train loss: 2.445145606994629\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 136, batch train loss: 2.935148239135742\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 137, batch train loss: 3.6808972358703613\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 138, batch train loss: 2.4351537227630615\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 139, batch train loss: 2.1230947971343994\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 140, batch train loss: 3.2692923545837402\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 141, batch train loss: 2.343637704849243\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 142, batch train loss: 3.746997117996216\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 143, batch train loss: 3.1620800495147705\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 144, batch train loss: 2.2402327060699463\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 145, batch train loss: 2.152031183242798\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 146, batch train loss: 2.24407696723938\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 147, batch train loss: 2.7072629928588867\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 148, batch train loss: 2.803462028503418\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 149, batch train loss: 2.608030080795288\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 150, batch train loss: 2.8047473430633545\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 151, batch train loss: 2.732555627822876\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 152, batch train loss: 2.643293619155884\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 153, batch train loss: 2.192462682723999\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 154, batch train loss: 3.0118627548217773\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 155, batch train loss: 2.3329288959503174\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 156, batch train loss: 2.335362195968628\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 157, batch train loss: 3.0708963871002197\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 158, batch train loss: 2.380772352218628\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 159, batch train loss: 2.654860734939575\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 160, batch train loss: 3.530020236968994\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 161, batch train loss: 2.448086738586426\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 162, batch train loss: 2.3225293159484863\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 163, batch train loss: 3.4638442993164062\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 164, batch train loss: 3.4818594455718994\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 165, batch train loss: 2.565150499343872\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 166, batch train loss: 2.3517560958862305\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 167, batch train loss: 3.3587987422943115\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 168, batch train loss: 2.1257100105285645\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 169, batch train loss: 3.7269115447998047\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 170, batch train loss: 2.4029626846313477\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 171, batch train loss: 2.328327178955078\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 172, batch train loss: 2.6080055236816406\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 173, batch train loss: 2.7674760818481445\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 174, batch train loss: 2.86578369140625\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 175, batch train loss: 2.901135206222534\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 176, batch train loss: 2.462691068649292\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 177, batch train loss: 2.141892671585083\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 178, batch train loss: 2.415311336517334\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 179, batch train loss: 2.5161187648773193\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 180, batch train loss: 2.715933322906494\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 181, batch train loss: 2.3262736797332764\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 182, batch train loss: 2.3916144371032715\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 183, batch train loss: 2.597100019454956\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 184, batch train loss: 2.1367862224578857\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 185, batch train loss: 2.804776668548584\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 186, batch train loss: 2.371162176132202\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 187, batch train loss: 2.518956422805786\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 188, batch train loss: 2.350318431854248\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 189, batch train loss: 2.562896251678467\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 190, batch train loss: 2.5973823070526123\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 191, batch train loss: 2.4315192699432373\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 192, batch train loss: 2.3881213665008545\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 193, batch train loss: 2.8894104957580566\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 194, batch train loss: 2.8234286308288574\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 195, batch train loss: 2.886826276779175\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 196, batch train loss: 2.624650478363037\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 197, batch train loss: 2.3584039211273193\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 198, batch train loss: 1.921675205230713\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 199, batch train loss: 1.738063931465149\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 200, batch train loss: 2.253694772720337\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 201, batch train loss: 3.6722705364227295\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 202, batch train loss: 2.6793582439422607\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 203, batch train loss: 2.4334681034088135\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 204, batch train loss: 1.8245832920074463\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 205, batch train loss: 2.3713834285736084\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 206, batch train loss: 2.6608946323394775\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 207, batch train loss: 2.402121067047119\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 208, batch train loss: 2.70646595954895\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 209, batch train loss: 2.327425956726074\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 210, batch train loss: 2.4427123069763184\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 211, batch train loss: 3.1782708168029785\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 212, batch train loss: 3.4675822257995605\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 213, batch train loss: 3.712087869644165\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 214, batch train loss: 4.475794315338135\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 215, batch train loss: 3.964637517929077\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 216, batch train loss: 3.4546613693237305\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 217, batch train loss: 3.3321995735168457\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 218, batch train loss: 2.718738317489624\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 219, batch train loss: 2.3914341926574707\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 220, batch train loss: 2.771115779876709\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 221, batch train loss: 6.544558048248291\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 222, batch train loss: 2.813830614089966\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 223, batch train loss: 2.6277904510498047\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 224, batch train loss: 2.5206549167633057\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 225, batch train loss: 2.3007962703704834\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 226, batch train loss: 4.219917297363281\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 227, batch train loss: 3.718181610107422\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 228, batch train loss: 2.684417724609375\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 229, batch train loss: 2.6602115631103516\n",
      "\n",
      "\n",
      "Epoch: 93, batch_id: 230, batch train loss: 2.0192792415618896\n",
      "\n",
      "\n",
      "Epoch: 93/ 100, Loss: 2.8352739437766696\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:09<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93 Validation Loss: 2.0294501543045045\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94, batch_id: 1, batch train loss: 2.0720837116241455\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 2, batch train loss: 2.1876654624938965\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 3, batch train loss: 2.058480978012085\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 4, batch train loss: 2.9774482250213623\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 5, batch train loss: 3.26446533203125\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 6, batch train loss: 2.894437789916992\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 7, batch train loss: 2.577042818069458\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 8, batch train loss: 2.4490113258361816\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 9, batch train loss: 2.3107433319091797\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 10, batch train loss: 1.9599326848983765\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 11, batch train loss: 2.68558669090271\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 12, batch train loss: 2.463773250579834\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 13, batch train loss: 2.694580078125\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 14, batch train loss: 3.0017635822296143\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 15, batch train loss: 3.573354482650757\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 16, batch train loss: 2.2837185859680176\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 17, batch train loss: 3.157655715942383\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 18, batch train loss: 2.3669817447662354\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 19, batch train loss: 2.3845808506011963\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 20, batch train loss: 3.7414793968200684\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 21, batch train loss: 2.2204105854034424\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 22, batch train loss: 2.297105312347412\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 23, batch train loss: 2.4328622817993164\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 24, batch train loss: 2.3473691940307617\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 25, batch train loss: 3.240168571472168\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 26, batch train loss: 3.24389386177063\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 27, batch train loss: 2.154541015625\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 28, batch train loss: 2.6794872283935547\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 29, batch train loss: 2.4326422214508057\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 30, batch train loss: 2.2678141593933105\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 31, batch train loss: 2.5091724395751953\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 32, batch train loss: 1.9470237493515015\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 33, batch train loss: 1.9856610298156738\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 34, batch train loss: 1.7771563529968262\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 35, batch train loss: 1.83311927318573\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 36, batch train loss: 2.5178215503692627\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 37, batch train loss: 1.9916139841079712\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 38, batch train loss: 1.8220312595367432\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 39, batch train loss: 2.262294292449951\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 40, batch train loss: 1.9192413091659546\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 41, batch train loss: 1.7061470746994019\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 42, batch train loss: 1.806219220161438\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 43, batch train loss: 1.9731491804122925\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 44, batch train loss: 1.8677546977996826\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 45, batch train loss: 1.8769997358322144\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 46, batch train loss: 2.529071569442749\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 47, batch train loss: 2.3901848793029785\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 48, batch train loss: 2.155010461807251\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 49, batch train loss: 3.3256468772888184\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 50, batch train loss: 2.0336005687713623\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 51, batch train loss: 2.659358501434326\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 52, batch train loss: 4.223778247833252\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 53, batch train loss: 4.656185150146484\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 54, batch train loss: 2.4349710941314697\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 55, batch train loss: 1.896559238433838\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 56, batch train loss: 3.013507604598999\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 57, batch train loss: 2.3785786628723145\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 58, batch train loss: 3.2614781856536865\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 59, batch train loss: 3.488492727279663\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 60, batch train loss: 2.337631940841675\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 61, batch train loss: 2.711414098739624\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 62, batch train loss: 3.169344663619995\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 63, batch train loss: 2.9111881256103516\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 64, batch train loss: 3.110635757446289\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 65, batch train loss: 2.825690269470215\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 66, batch train loss: 2.652688980102539\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 67, batch train loss: 2.09941029548645\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 68, batch train loss: 2.443662405014038\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 69, batch train loss: 3.5389437675476074\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 70, batch train loss: 3.707390546798706\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 71, batch train loss: 2.5068366527557373\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 72, batch train loss: 2.413186550140381\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 73, batch train loss: 1.9757388830184937\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 74, batch train loss: 1.8864270448684692\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 75, batch train loss: 2.9354593753814697\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 76, batch train loss: 2.440045118331909\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 77, batch train loss: 2.25347900390625\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 78, batch train loss: 2.0763182640075684\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 79, batch train loss: 2.1370389461517334\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 80, batch train loss: 2.0986316204071045\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 81, batch train loss: 1.976789951324463\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 82, batch train loss: 2.658931016921997\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 83, batch train loss: 2.601701498031616\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 84, batch train loss: 2.032914876937866\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 85, batch train loss: 2.27280592918396\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 86, batch train loss: 1.8231319189071655\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 87, batch train loss: 1.5813121795654297\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 88, batch train loss: 1.8642339706420898\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 89, batch train loss: 1.6325409412384033\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 90, batch train loss: 1.907280445098877\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 91, batch train loss: 2.1577649116516113\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 92, batch train loss: 2.4613735675811768\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 93, batch train loss: 2.2150676250457764\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 94, batch train loss: 2.1323068141937256\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 95, batch train loss: 2.039396047592163\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 96, batch train loss: 2.7115795612335205\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 97, batch train loss: 2.118093967437744\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 98, batch train loss: 2.078259229660034\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 99, batch train loss: 1.9152799844741821\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 100, batch train loss: 2.472785711288452\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 101, batch train loss: 1.884800672531128\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 102, batch train loss: 2.141245126724243\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 103, batch train loss: 2.5708699226379395\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 104, batch train loss: 2.001384973526001\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 105, batch train loss: 2.3426513671875\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 106, batch train loss: 1.9179011583328247\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 107, batch train loss: 2.20721697807312\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 108, batch train loss: 2.0853209495544434\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 109, batch train loss: 2.214174509048462\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 110, batch train loss: 2.31259822845459\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 111, batch train loss: 3.2494006156921387\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 112, batch train loss: 3.0041797161102295\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 113, batch train loss: 3.128039598464966\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 114, batch train loss: 2.442781686782837\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 115, batch train loss: 2.8842055797576904\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 116, batch train loss: 2.220470905303955\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 117, batch train loss: 1.8772441148757935\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 118, batch train loss: 3.6750223636627197\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 119, batch train loss: 2.1598379611968994\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 120, batch train loss: 1.8059163093566895\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 121, batch train loss: 2.1728498935699463\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 122, batch train loss: 3.039508104324341\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 123, batch train loss: 2.5829544067382812\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 124, batch train loss: 2.0477168560028076\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 125, batch train loss: 1.991491675376892\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 126, batch train loss: 2.0785043239593506\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 127, batch train loss: 1.9869555234909058\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 128, batch train loss: 2.6481246948242188\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 129, batch train loss: 2.206373691558838\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94, batch_id: 130, batch train loss: 2.695826530456543\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 131, batch train loss: 2.502139091491699\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 132, batch train loss: 2.0552098751068115\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 133, batch train loss: 2.1346988677978516\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 134, batch train loss: 2.916776657104492\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 135, batch train loss: 2.35518217086792\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 136, batch train loss: 2.218430757522583\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 137, batch train loss: 2.349790096282959\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 138, batch train loss: 1.9230470657348633\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 139, batch train loss: 2.970970392227173\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 140, batch train loss: 2.555971622467041\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 141, batch train loss: 3.944977283477783\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 142, batch train loss: 4.379638195037842\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 143, batch train loss: 2.8169708251953125\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 144, batch train loss: 4.681587219238281\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 145, batch train loss: 5.403546333312988\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 146, batch train loss: 3.9672887325286865\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 147, batch train loss: 2.4526450634002686\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 148, batch train loss: 3.2152132987976074\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 149, batch train loss: 3.4075658321380615\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 150, batch train loss: 2.6761083602905273\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 151, batch train loss: 3.361902952194214\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 152, batch train loss: 2.866400718688965\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 153, batch train loss: 2.384134292602539\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 154, batch train loss: 2.127150535583496\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 155, batch train loss: 2.717449426651001\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 156, batch train loss: 2.489337682723999\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 157, batch train loss: 2.5527400970458984\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 158, batch train loss: 2.479890823364258\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 159, batch train loss: 2.4289188385009766\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 160, batch train loss: 2.2201952934265137\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 161, batch train loss: 2.948354482650757\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 162, batch train loss: 2.9749984741210938\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 163, batch train loss: 2.1760926246643066\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 164, batch train loss: 2.4664387702941895\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 165, batch train loss: 2.233224630355835\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 166, batch train loss: 3.0331711769104004\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 167, batch train loss: 2.7549941539764404\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 168, batch train loss: 2.225898027420044\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 169, batch train loss: 2.9653820991516113\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 170, batch train loss: 2.696568727493286\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 171, batch train loss: 2.90698504447937\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 172, batch train loss: 2.439244508743286\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 173, batch train loss: 2.210507392883301\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 174, batch train loss: 2.751608371734619\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 175, batch train loss: 2.723764181137085\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 176, batch train loss: 2.94557523727417\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 177, batch train loss: 2.2423393726348877\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 178, batch train loss: 2.147653341293335\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 179, batch train loss: 2.1633660793304443\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 180, batch train loss: 2.385796308517456\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 181, batch train loss: 2.5615768432617188\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 182, batch train loss: 2.2346370220184326\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 183, batch train loss: 2.349461555480957\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 184, batch train loss: 1.9963271617889404\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 185, batch train loss: 2.386179208755493\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 186, batch train loss: 2.233834743499756\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 187, batch train loss: 2.307168483734131\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 188, batch train loss: 3.024904727935791\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 189, batch train loss: 2.4701595306396484\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 190, batch train loss: 2.3480236530303955\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 191, batch train loss: 2.8438117504119873\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 192, batch train loss: 2.648038387298584\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 193, batch train loss: 2.7811665534973145\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 194, batch train loss: 2.9145097732543945\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 195, batch train loss: 2.9081220626831055\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 196, batch train loss: 3.6987223625183105\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 197, batch train loss: 2.6553544998168945\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 198, batch train loss: 2.346139430999756\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 199, batch train loss: 2.223595380783081\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 200, batch train loss: 2.7303431034088135\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 201, batch train loss: 2.40197491645813\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 202, batch train loss: 2.733874559402466\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 203, batch train loss: 3.0065178871154785\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 204, batch train loss: 2.9680016040802\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 205, batch train loss: 2.978116273880005\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 206, batch train loss: 3.3077926635742188\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 207, batch train loss: 2.9161336421966553\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 208, batch train loss: 2.8431239128112793\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 209, batch train loss: 4.194098949432373\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 210, batch train loss: 4.542376518249512\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 211, batch train loss: 4.722202777862549\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 212, batch train loss: 3.546037197113037\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 213, batch train loss: 4.460259437561035\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 214, batch train loss: 4.542294979095459\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 215, batch train loss: 5.342860698699951\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 216, batch train loss: 4.720374584197998\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 217, batch train loss: 6.259899616241455\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 218, batch train loss: 6.4121012687683105\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 219, batch train loss: 6.781520843505859\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 220, batch train loss: 6.143314838409424\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 221, batch train loss: 5.292205333709717\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 222, batch train loss: 8.618188858032227\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 223, batch train loss: 7.076873302459717\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 224, batch train loss: 6.530018329620361\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 225, batch train loss: 6.193351745605469\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 226, batch train loss: 6.075980186462402\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 227, batch train loss: 6.930881500244141\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 228, batch train loss: 7.1425299644470215\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 229, batch train loss: 5.344326019287109\n",
      "\n",
      "\n",
      "Epoch: 94, batch_id: 230, batch train loss: 5.257791042327881\n",
      "\n",
      "\n",
      "Epoch: 94/ 100, Loss: 2.852252745110056\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:07<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94 Validation Loss: 7.09442777633667\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95, batch_id: 1, batch train loss: 7.277623653411865\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 2, batch train loss: 6.788712501525879\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 3, batch train loss: 6.197371959686279\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 4, batch train loss: 5.226370811462402\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 5, batch train loss: 4.7974700927734375\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 6, batch train loss: 4.918443202972412\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 7, batch train loss: 4.719984531402588\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 8, batch train loss: 4.536426067352295\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 9, batch train loss: 4.3105363845825195\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 10, batch train loss: 5.2427825927734375\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 11, batch train loss: 4.754298210144043\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 12, batch train loss: 5.5134172439575195\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 13, batch train loss: 5.51791524887085\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 14, batch train loss: 4.893792629241943\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 15, batch train loss: 4.796167850494385\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 16, batch train loss: 4.879462242126465\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 17, batch train loss: 4.871870040893555\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 18, batch train loss: 5.224069595336914\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 19, batch train loss: 4.865734577178955\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 20, batch train loss: 4.658491611480713\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 21, batch train loss: 4.712275505065918\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 22, batch train loss: 5.754886150360107\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 23, batch train loss: 5.484492778778076\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 24, batch train loss: 4.518747806549072\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 25, batch train loss: 5.230677127838135\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 26, batch train loss: 4.9108805656433105\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 27, batch train loss: 6.071825981140137\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 28, batch train loss: 5.678823471069336\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 29, batch train loss: 5.079596996307373\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 30, batch train loss: 4.613735198974609\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 31, batch train loss: 4.771663188934326\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 32, batch train loss: 4.533866882324219\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 33, batch train loss: 3.8433804512023926\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 34, batch train loss: 3.553553819656372\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 35, batch train loss: 3.8350448608398438\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 36, batch train loss: 3.703024387359619\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 37, batch train loss: 4.417952060699463\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 38, batch train loss: 4.141416072845459\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 39, batch train loss: 3.66373610496521\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 40, batch train loss: 3.1762843132019043\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 41, batch train loss: 3.8611185550689697\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 42, batch train loss: 3.6874043941497803\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 43, batch train loss: 3.59004282951355\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 44, batch train loss: 3.150209903717041\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 45, batch train loss: 3.1492178440093994\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 46, batch train loss: 2.727203845977783\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 47, batch train loss: 2.812389612197876\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 48, batch train loss: 3.3139641284942627\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 49, batch train loss: 3.1103458404541016\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 50, batch train loss: 3.369248390197754\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 51, batch train loss: 3.1789937019348145\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 52, batch train loss: 3.2533154487609863\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 53, batch train loss: 3.6896603107452393\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 54, batch train loss: 4.0617899894714355\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 55, batch train loss: 4.062562942504883\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 56, batch train loss: 3.8550240993499756\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 57, batch train loss: 3.4825031757354736\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 58, batch train loss: 4.063261032104492\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 59, batch train loss: 3.8695223331451416\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 60, batch train loss: 3.5648324489593506\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 61, batch train loss: 3.7957441806793213\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 62, batch train loss: 3.7667076587677\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 63, batch train loss: 3.721059560775757\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 64, batch train loss: 3.954540491104126\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 65, batch train loss: 3.2611916065216064\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 66, batch train loss: 2.9191646575927734\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 67, batch train loss: 3.8463191986083984\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 68, batch train loss: 4.403450012207031\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 69, batch train loss: 3.881056308746338\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 70, batch train loss: 3.8013339042663574\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 71, batch train loss: 2.583866834640503\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 72, batch train loss: 3.5648491382598877\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 73, batch train loss: 3.781219005584717\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 74, batch train loss: 3.6542439460754395\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 75, batch train loss: 3.1959455013275146\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 76, batch train loss: 4.144160270690918\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 77, batch train loss: 3.274428367614746\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 78, batch train loss: 3.1265628337860107\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 79, batch train loss: 4.203880786895752\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 80, batch train loss: 3.440664052963257\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 81, batch train loss: 2.912846565246582\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 82, batch train loss: 3.5653369426727295\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 83, batch train loss: 3.088131904602051\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 84, batch train loss: 2.9152393341064453\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 85, batch train loss: 2.835317611694336\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 86, batch train loss: 2.858231544494629\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 87, batch train loss: 3.5757734775543213\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 88, batch train loss: 3.046292781829834\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 89, batch train loss: 3.115525484085083\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 90, batch train loss: 3.5473194122314453\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 91, batch train loss: 3.5355453491210938\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 92, batch train loss: 3.2026023864746094\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 93, batch train loss: 3.0872268676757812\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 94, batch train loss: 4.24833869934082\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 95, batch train loss: 3.471306085586548\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 96, batch train loss: 3.1837587356567383\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 97, batch train loss: 3.195992946624756\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 98, batch train loss: 2.9778921604156494\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 99, batch train loss: 3.415299892425537\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 100, batch train loss: 2.921370029449463\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 101, batch train loss: 3.1550352573394775\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 102, batch train loss: 2.820962429046631\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 103, batch train loss: 3.0861241817474365\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 104, batch train loss: 2.7607808113098145\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 105, batch train loss: 2.788372755050659\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 106, batch train loss: 3.6514997482299805\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 107, batch train loss: 2.8643007278442383\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 108, batch train loss: 2.820071220397949\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 109, batch train loss: 2.755417585372925\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 110, batch train loss: 2.9857542514801025\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 111, batch train loss: 2.812321424484253\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 112, batch train loss: 2.724377393722534\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 113, batch train loss: 2.901686668395996\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 114, batch train loss: 3.630307674407959\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 115, batch train loss: 3.162494421005249\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 116, batch train loss: 3.262817859649658\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 117, batch train loss: 2.7828032970428467\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 118, batch train loss: 3.402890205383301\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 119, batch train loss: 3.1285812854766846\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 120, batch train loss: 3.4841134548187256\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 121, batch train loss: 3.683537483215332\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 122, batch train loss: 3.28417706489563\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 123, batch train loss: 3.147698163986206\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 124, batch train loss: 3.8348796367645264\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 125, batch train loss: 3.7117481231689453\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 126, batch train loss: 3.3468072414398193\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 127, batch train loss: 3.613891124725342\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 128, batch train loss: 3.9398396015167236\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 129, batch train loss: 5.03428840637207\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 130, batch train loss: 4.090324878692627\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95, batch_id: 131, batch train loss: 4.300889492034912\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 132, batch train loss: 4.279808521270752\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 133, batch train loss: 4.316207408905029\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 134, batch train loss: 3.550192356109619\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 135, batch train loss: 4.3425984382629395\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 136, batch train loss: 4.084392070770264\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 137, batch train loss: 5.7320075035095215\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 138, batch train loss: 4.150782585144043\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 139, batch train loss: 4.400842189788818\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 140, batch train loss: 4.452634334564209\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 141, batch train loss: 3.949532985687256\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 142, batch train loss: 3.9411556720733643\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 143, batch train loss: 3.8133671283721924\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 144, batch train loss: 3.8135368824005127\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 145, batch train loss: 3.843775987625122\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 146, batch train loss: 3.8447673320770264\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 147, batch train loss: 4.448182582855225\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 148, batch train loss: 4.453282356262207\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 149, batch train loss: 5.746028900146484\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 150, batch train loss: 4.365604400634766\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 151, batch train loss: 4.679548740386963\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 152, batch train loss: 5.711795330047607\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 153, batch train loss: 6.7223405838012695\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 154, batch train loss: 5.095177173614502\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 155, batch train loss: 6.445806980133057\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 156, batch train loss: 5.121264457702637\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 157, batch train loss: 4.841587543487549\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 158, batch train loss: 4.020116806030273\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 159, batch train loss: 4.480525970458984\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 160, batch train loss: 5.508603572845459\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 161, batch train loss: 4.965234279632568\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 162, batch train loss: 4.4312005043029785\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 163, batch train loss: 4.866327285766602\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 164, batch train loss: 4.103850841522217\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 165, batch train loss: 4.653820991516113\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 166, batch train loss: 4.475254535675049\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 167, batch train loss: 4.402044773101807\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 168, batch train loss: 3.8101806640625\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 169, batch train loss: 4.2006001472473145\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 170, batch train loss: 3.9639391899108887\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 171, batch train loss: 3.9789395332336426\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 172, batch train loss: 4.428978443145752\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 173, batch train loss: 3.964508533477783\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 174, batch train loss: 3.8584933280944824\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 175, batch train loss: 3.997464895248413\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 176, batch train loss: 3.390129804611206\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 177, batch train loss: 4.214570999145508\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 178, batch train loss: 4.472954273223877\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 179, batch train loss: 4.45956563949585\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 180, batch train loss: 4.480419158935547\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 181, batch train loss: 4.068099498748779\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 182, batch train loss: 3.9588589668273926\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 183, batch train loss: 4.696231842041016\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 184, batch train loss: 4.035314559936523\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 185, batch train loss: 4.680059432983398\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 186, batch train loss: 4.266434669494629\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 187, batch train loss: 3.8629565238952637\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 188, batch train loss: 4.182847023010254\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 189, batch train loss: 4.106192111968994\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 190, batch train loss: 4.338372707366943\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 191, batch train loss: 4.706782341003418\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 192, batch train loss: 3.7862024307250977\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 193, batch train loss: 3.95450758934021\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 194, batch train loss: 3.9317142963409424\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 195, batch train loss: 3.4637277126312256\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 196, batch train loss: 3.9238898754119873\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 197, batch train loss: 3.648528575897217\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 198, batch train loss: 4.225223064422607\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 199, batch train loss: 3.868330478668213\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 200, batch train loss: 5.038080215454102\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 201, batch train loss: 4.035152912139893\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 202, batch train loss: 4.676893711090088\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 203, batch train loss: 3.8681623935699463\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 204, batch train loss: 3.619070529937744\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 205, batch train loss: 3.7681336402893066\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 206, batch train loss: 4.1474432945251465\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 207, batch train loss: 3.918511152267456\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 208, batch train loss: 3.746112108230591\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 209, batch train loss: 3.530240774154663\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 210, batch train loss: 3.8598437309265137\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 211, batch train loss: 4.393158435821533\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 212, batch train loss: 3.890556573867798\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 213, batch train loss: 4.266611099243164\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 214, batch train loss: 3.992138624191284\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 215, batch train loss: 3.656567335128784\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 216, batch train loss: 3.3850440979003906\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 217, batch train loss: 3.477403163909912\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 218, batch train loss: 3.824207067489624\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 219, batch train loss: 3.9663443565368652\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 220, batch train loss: 3.701667070388794\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 221, batch train loss: 3.506265163421631\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 222, batch train loss: 3.453035831451416\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 223, batch train loss: 3.4520483016967773\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 224, batch train loss: 3.254465103149414\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 225, batch train loss: 2.9296376705169678\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 226, batch train loss: 3.8180484771728516\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 227, batch train loss: 3.5390877723693848\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 228, batch train loss: 4.507478713989258\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 229, batch train loss: 3.477013349533081\n",
      "\n",
      "\n",
      "Epoch: 95, batch_id: 230, batch train loss: 3.6159956455230713\n",
      "\n",
      "\n",
      "Epoch: 95/ 100, Loss: 4.003567750557609\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:08<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95 Validation Loss: 3.516635223229726\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96, batch_id: 1, batch train loss: 3.520740509033203\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 2, batch train loss: 3.5795905590057373\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 3, batch train loss: 3.319939136505127\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 4, batch train loss: 3.6879866123199463\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 5, batch train loss: 4.000633239746094\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 6, batch train loss: 3.66180419921875\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 7, batch train loss: 3.5643839836120605\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 8, batch train loss: 3.540959119796753\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 9, batch train loss: 3.2514889240264893\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 10, batch train loss: 3.2973392009735107\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 11, batch train loss: 3.8895061016082764\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 12, batch train loss: 3.38397216796875\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 13, batch train loss: 4.146033763885498\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 14, batch train loss: 3.620119571685791\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 15, batch train loss: 3.6282901763916016\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 16, batch train loss: 3.157480478286743\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 17, batch train loss: 3.433640241622925\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 18, batch train loss: 3.3308472633361816\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 19, batch train loss: 3.47052001953125\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 20, batch train loss: 3.7005786895751953\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 21, batch train loss: 4.1851654052734375\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 22, batch train loss: 3.68361496925354\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 23, batch train loss: 3.1100234985351562\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 24, batch train loss: 3.46148681640625\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 25, batch train loss: 3.7124149799346924\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 26, batch train loss: 3.1897778511047363\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 27, batch train loss: 5.93267822265625\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 28, batch train loss: 4.207952499389648\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 29, batch train loss: 4.77789306640625\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 30, batch train loss: 5.327428340911865\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 31, batch train loss: 3.712726593017578\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 32, batch train loss: 4.516203880310059\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 33, batch train loss: 3.984325408935547\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 34, batch train loss: 3.8155012130737305\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 35, batch train loss: 4.897051811218262\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 36, batch train loss: 4.7808637619018555\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 37, batch train loss: 4.131744384765625\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 38, batch train loss: 5.357448101043701\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 39, batch train loss: 4.326371192932129\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 40, batch train loss: 3.792837619781494\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 41, batch train loss: 4.781539440155029\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 42, batch train loss: 4.160173416137695\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 43, batch train loss: 4.576930522918701\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 44, batch train loss: 4.641674995422363\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 45, batch train loss: 3.807957649230957\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 46, batch train loss: 4.816097259521484\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 47, batch train loss: 4.3831281661987305\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 48, batch train loss: 3.6569461822509766\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 49, batch train loss: 4.754178047180176\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 50, batch train loss: 4.323230743408203\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 51, batch train loss: 3.3984649181365967\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 52, batch train loss: 4.096786022186279\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 53, batch train loss: 4.176113128662109\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 54, batch train loss: 3.17048716545105\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 55, batch train loss: 4.106690883636475\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 56, batch train loss: 2.948206663131714\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 57, batch train loss: 2.9332616329193115\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 58, batch train loss: 2.615771532058716\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 59, batch train loss: 2.397787570953369\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 60, batch train loss: 2.6296544075012207\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 61, batch train loss: 3.7359814643859863\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 62, batch train loss: 3.3656723499298096\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 63, batch train loss: 3.344346284866333\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 64, batch train loss: 2.921964406967163\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 65, batch train loss: 2.6922338008880615\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 66, batch train loss: 4.301961421966553\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 67, batch train loss: 3.0842247009277344\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 68, batch train loss: 2.7879438400268555\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 69, batch train loss: 2.614586114883423\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 70, batch train loss: 3.694114923477173\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 71, batch train loss: 3.935281991958618\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 72, batch train loss: 3.8333165645599365\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 73, batch train loss: 3.3519294261932373\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 74, batch train loss: 2.727341890335083\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 75, batch train loss: 2.7486732006073\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 76, batch train loss: 3.516958713531494\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 77, batch train loss: 3.6180431842803955\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 78, batch train loss: 2.875702381134033\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 79, batch train loss: 2.5017592906951904\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 80, batch train loss: 2.844515323638916\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 81, batch train loss: 2.839019536972046\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 82, batch train loss: 2.571448564529419\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 83, batch train loss: 2.4309704303741455\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 84, batch train loss: 2.304428815841675\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 85, batch train loss: 2.4483566284179688\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 86, batch train loss: 2.657663345336914\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 87, batch train loss: 2.481977939605713\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 88, batch train loss: 2.621946334838867\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 89, batch train loss: 2.7473292350769043\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 90, batch train loss: 2.4967880249023438\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 91, batch train loss: 2.5372977256774902\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 92, batch train loss: 2.137368679046631\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 93, batch train loss: 2.1598291397094727\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 94, batch train loss: 2.2892754077911377\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 95, batch train loss: 2.288153648376465\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 96, batch train loss: 3.2323925495147705\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 97, batch train loss: 4.000986576080322\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 98, batch train loss: 2.810370922088623\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 99, batch train loss: 2.262287139892578\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 100, batch train loss: 2.22871732711792\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 101, batch train loss: 2.2310216426849365\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 102, batch train loss: 2.452880382537842\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 103, batch train loss: 4.355724334716797\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 104, batch train loss: 3.909014940261841\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 105, batch train loss: 3.928060293197632\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 106, batch train loss: 4.109434604644775\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 107, batch train loss: 2.416198253631592\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 108, batch train loss: 2.624196767807007\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 109, batch train loss: 4.112733364105225\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 110, batch train loss: 2.6476497650146484\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 111, batch train loss: 4.058658599853516\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 112, batch train loss: 2.8031866550445557\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 113, batch train loss: 2.985055923461914\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 114, batch train loss: 3.6944308280944824\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 115, batch train loss: 3.4598543643951416\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 116, batch train loss: 2.3357300758361816\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 117, batch train loss: 3.5429928302764893\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 118, batch train loss: 2.8223772048950195\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 119, batch train loss: 3.1599225997924805\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 120, batch train loss: 3.3036298751831055\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 121, batch train loss: 4.919105052947998\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 122, batch train loss: 3.4351189136505127\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 123, batch train loss: 2.827974557876587\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 124, batch train loss: 2.2165184020996094\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 125, batch train loss: 5.209956169128418\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 126, batch train loss: 3.924309492111206\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 127, batch train loss: 3.993762969970703\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 128, batch train loss: 5.0692458152771\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 129, batch train loss: 3.3300671577453613\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 130, batch train loss: 3.7153337001800537\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96, batch_id: 131, batch train loss: 4.613304138183594\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 132, batch train loss: 3.1785900592803955\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 133, batch train loss: 3.157442569732666\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 134, batch train loss: 2.9302732944488525\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 135, batch train loss: 3.051306962966919\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 136, batch train loss: 2.646981716156006\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 137, batch train loss: 3.725627899169922\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 138, batch train loss: 4.046013355255127\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 139, batch train loss: 2.9305026531219482\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 140, batch train loss: 3.093146324157715\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 141, batch train loss: 3.5603408813476562\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 142, batch train loss: 2.8889036178588867\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 143, batch train loss: 3.2410624027252197\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 144, batch train loss: 3.025991916656494\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 145, batch train loss: 3.1758480072021484\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 146, batch train loss: 4.04852819442749\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 147, batch train loss: 3.528698682785034\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 148, batch train loss: 2.195298194885254\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 149, batch train loss: 3.8758480548858643\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 150, batch train loss: 3.2344260215759277\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 151, batch train loss: 3.5006327629089355\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 152, batch train loss: 3.4878833293914795\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 153, batch train loss: 3.094862461090088\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 154, batch train loss: 2.8448312282562256\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 155, batch train loss: 2.9804296493530273\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 156, batch train loss: 2.661694288253784\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 157, batch train loss: 4.135978698730469\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 158, batch train loss: 2.950483798980713\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 159, batch train loss: 2.8128669261932373\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 160, batch train loss: 2.906632423400879\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 161, batch train loss: 3.1232240200042725\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 162, batch train loss: 3.223984479904175\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 163, batch train loss: 3.2834632396698\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 164, batch train loss: 3.2947733402252197\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 165, batch train loss: 3.2426626682281494\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 166, batch train loss: 3.027339220046997\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 167, batch train loss: 3.272463798522949\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 168, batch train loss: 3.0316247940063477\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 169, batch train loss: 2.9816489219665527\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 170, batch train loss: 3.206416130065918\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 171, batch train loss: 2.8393452167510986\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 172, batch train loss: 2.667081594467163\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 173, batch train loss: 3.2076642513275146\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 174, batch train loss: 2.4252569675445557\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 175, batch train loss: 2.8961682319641113\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 176, batch train loss: 2.9351112842559814\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 177, batch train loss: 2.7098498344421387\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 178, batch train loss: 2.872389078140259\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 179, batch train loss: 3.396944284439087\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 180, batch train loss: 2.941051959991455\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 181, batch train loss: 2.8749396800994873\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 182, batch train loss: 3.0132975578308105\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 183, batch train loss: 2.5873217582702637\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 184, batch train loss: 2.643204689025879\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 185, batch train loss: 3.0195698738098145\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 186, batch train loss: 2.280867576599121\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 187, batch train loss: 3.018234968185425\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 188, batch train loss: 2.760540246963501\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 189, batch train loss: 3.504101037979126\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 190, batch train loss: 2.999993324279785\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 191, batch train loss: 3.4769349098205566\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 192, batch train loss: 4.050655841827393\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 193, batch train loss: 3.0813562870025635\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 194, batch train loss: 2.717695951461792\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 195, batch train loss: 2.8328981399536133\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 196, batch train loss: 3.275587320327759\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 197, batch train loss: 3.1397337913513184\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 198, batch train loss: 2.980466604232788\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 199, batch train loss: 3.137741804122925\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 200, batch train loss: 3.110887050628662\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 201, batch train loss: 2.603011131286621\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 202, batch train loss: 2.39328932762146\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 203, batch train loss: 2.3899707794189453\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 204, batch train loss: 2.2124404907226562\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 205, batch train loss: 2.8154077529907227\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 206, batch train loss: 2.31465220451355\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 207, batch train loss: 2.3727545738220215\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 208, batch train loss: 2.253770351409912\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 209, batch train loss: 2.6760454177856445\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 210, batch train loss: 2.6801021099090576\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 211, batch train loss: 2.542846202850342\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 212, batch train loss: 2.565044641494751\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 213, batch train loss: 2.2678451538085938\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 214, batch train loss: 3.370419502258301\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 215, batch train loss: 2.266376256942749\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 216, batch train loss: 1.9518872499465942\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 217, batch train loss: 2.651820659637451\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 218, batch train loss: 2.342977523803711\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 219, batch train loss: 2.599597930908203\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 220, batch train loss: 2.3596558570861816\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 221, batch train loss: 2.3853533267974854\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 222, batch train loss: 2.007071018218994\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 223, batch train loss: 3.150372266769409\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 224, batch train loss: 2.469632863998413\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 225, batch train loss: 2.410480499267578\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 226, batch train loss: 2.3777570724487305\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 227, batch train loss: 2.2520809173583984\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 228, batch train loss: 3.165985584259033\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 229, batch train loss: 3.1048882007598877\n",
      "\n",
      "\n",
      "Epoch: 96, batch_id: 230, batch train loss: 2.3664515018463135\n",
      "\n",
      "\n",
      "Epoch: 96/ 100, Loss: 3.2436115622520445\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:10<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96 Validation Loss: 2.9088425159454347\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97, batch_id: 1, batch train loss: 2.7467870712280273\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 2, batch train loss: 2.5576748847961426\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 3, batch train loss: 3.0469727516174316\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 4, batch train loss: 2.375845193862915\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 5, batch train loss: 2.3964617252349854\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 6, batch train loss: 2.897982358932495\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 7, batch train loss: 2.313430070877075\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 8, batch train loss: 2.4825849533081055\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 9, batch train loss: 2.312044143676758\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 10, batch train loss: 2.3262975215911865\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 11, batch train loss: 2.209810495376587\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 12, batch train loss: 2.557469367980957\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 13, batch train loss: 2.7021796703338623\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 14, batch train loss: 2.134829044342041\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 15, batch train loss: 2.784200668334961\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 16, batch train loss: 3.171546220779419\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 17, batch train loss: 2.6498095989227295\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 18, batch train loss: 2.226973295211792\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 19, batch train loss: 2.6991164684295654\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 20, batch train loss: 2.9401280879974365\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 21, batch train loss: 2.5285909175872803\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 22, batch train loss: 2.74375319480896\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 23, batch train loss: 2.3107800483703613\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 24, batch train loss: 2.739847421646118\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 25, batch train loss: 2.5026445388793945\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 26, batch train loss: 2.2348713874816895\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 27, batch train loss: 2.5135767459869385\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 28, batch train loss: 2.7321743965148926\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 29, batch train loss: 2.5494868755340576\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 30, batch train loss: 3.2016732692718506\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 31, batch train loss: 2.730405330657959\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 32, batch train loss: 3.89482045173645\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 33, batch train loss: 2.9124832153320312\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 34, batch train loss: 2.219602346420288\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 35, batch train loss: 2.5223488807678223\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 36, batch train loss: 2.421769618988037\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 37, batch train loss: 2.6631906032562256\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 38, batch train loss: 2.5094969272613525\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 39, batch train loss: 2.222411870956421\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 40, batch train loss: 2.5861551761627197\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 41, batch train loss: 2.3117377758026123\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 42, batch train loss: 2.278081178665161\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 43, batch train loss: 2.436551809310913\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 44, batch train loss: 2.787083625793457\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 45, batch train loss: 2.6436026096343994\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 46, batch train loss: 3.0818307399749756\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 47, batch train loss: 2.7758171558380127\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 48, batch train loss: 2.585273265838623\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 49, batch train loss: 2.686089277267456\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 50, batch train loss: 2.490384817123413\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 51, batch train loss: 2.679260492324829\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 52, batch train loss: 2.51693058013916\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 53, batch train loss: 2.708474636077881\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 54, batch train loss: 2.3337535858154297\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 55, batch train loss: 2.600111484527588\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 56, batch train loss: 2.967560052871704\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 57, batch train loss: 2.400235414505005\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 58, batch train loss: 2.3040571212768555\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 59, batch train loss: 2.3943159580230713\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 60, batch train loss: 2.5191731452941895\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 61, batch train loss: 2.4117534160614014\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 62, batch train loss: 2.8630120754241943\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 63, batch train loss: 2.1929681301116943\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 64, batch train loss: 2.9341704845428467\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 65, batch train loss: 2.868002414703369\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 66, batch train loss: 2.8214259147644043\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 67, batch train loss: 2.5941460132598877\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 68, batch train loss: 2.5502963066101074\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 69, batch train loss: 2.8248958587646484\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 70, batch train loss: 2.925849676132202\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 71, batch train loss: 2.625321388244629\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 72, batch train loss: 3.1573400497436523\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 73, batch train loss: 2.647590160369873\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 74, batch train loss: 2.3464717864990234\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 75, batch train loss: 2.6200954914093018\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 76, batch train loss: 2.5848941802978516\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 77, batch train loss: 2.572267770767212\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 78, batch train loss: 2.015594720840454\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 79, batch train loss: 2.639544725418091\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 80, batch train loss: 2.961458921432495\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 81, batch train loss: 2.6782968044281006\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 82, batch train loss: 2.2954635620117188\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 83, batch train loss: 2.792400598526001\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 84, batch train loss: 2.0212926864624023\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 85, batch train loss: 2.3591065406799316\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 86, batch train loss: 2.694575071334839\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 87, batch train loss: 2.396465301513672\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 88, batch train loss: 2.9608089923858643\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 89, batch train loss: 2.3430874347686768\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 90, batch train loss: 2.5583252906799316\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 91, batch train loss: 2.4773001670837402\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 92, batch train loss: 1.9627337455749512\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 93, batch train loss: 2.386460065841675\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 94, batch train loss: 2.0634765625\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 95, batch train loss: 2.736074924468994\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 96, batch train loss: 2.2943272590637207\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 97, batch train loss: 2.241596221923828\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 98, batch train loss: 2.512216567993164\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 99, batch train loss: 2.5426840782165527\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 100, batch train loss: 2.91113543510437\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 101, batch train loss: 2.3602404594421387\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 102, batch train loss: 2.4378859996795654\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 103, batch train loss: 2.995971918106079\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 104, batch train loss: 5.109609127044678\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 105, batch train loss: 3.2755274772644043\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 106, batch train loss: 3.083535671234131\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 107, batch train loss: 3.6855404376983643\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 108, batch train loss: 2.8794894218444824\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 109, batch train loss: 2.825580358505249\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 110, batch train loss: 3.6629638671875\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 111, batch train loss: 2.5707788467407227\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 112, batch train loss: 3.080153703689575\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 113, batch train loss: 2.445624589920044\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 114, batch train loss: 2.69258189201355\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 115, batch train loss: 2.483858108520508\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 116, batch train loss: 2.6224334239959717\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 117, batch train loss: 2.486619710922241\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 118, batch train loss: 3.234208106994629\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 119, batch train loss: 2.884774684906006\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 120, batch train loss: 2.638375997543335\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 121, batch train loss: 2.486828327178955\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 122, batch train loss: 2.242866277694702\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 123, batch train loss: 2.215144157409668\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 124, batch train loss: 2.2901344299316406\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 125, batch train loss: 2.5453526973724365\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 126, batch train loss: 2.770566463470459\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 127, batch train loss: 2.791247606277466\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 128, batch train loss: 2.610482931137085\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 129, batch train loss: 2.9409310817718506\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97, batch_id: 130, batch train loss: 2.8827261924743652\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 131, batch train loss: 2.687551736831665\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 132, batch train loss: 3.8511650562286377\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 133, batch train loss: 3.363067626953125\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 134, batch train loss: 3.0312623977661133\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 135, batch train loss: 2.5949201583862305\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 136, batch train loss: 2.7659108638763428\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 137, batch train loss: 2.902073621749878\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 138, batch train loss: 2.977674722671509\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 139, batch train loss: 3.031481981277466\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 140, batch train loss: 2.536938428878784\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 141, batch train loss: 2.9441604614257812\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 142, batch train loss: 2.407848596572876\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 143, batch train loss: 3.005352258682251\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 144, batch train loss: 3.1300950050354004\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 145, batch train loss: 3.588024377822876\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 146, batch train loss: 2.9277846813201904\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 147, batch train loss: 2.5502474308013916\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 148, batch train loss: 2.5191140174865723\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 149, batch train loss: 2.6479668617248535\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 150, batch train loss: 2.472705364227295\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 151, batch train loss: 2.3153696060180664\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 152, batch train loss: 2.539346218109131\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 153, batch train loss: 3.0414509773254395\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 154, batch train loss: 2.701676368713379\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 155, batch train loss: 2.6774325370788574\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 156, batch train loss: 2.7406351566314697\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 157, batch train loss: 2.1340630054473877\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 158, batch train loss: 2.765871524810791\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 159, batch train loss: 2.9885330200195312\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 160, batch train loss: 2.731461763381958\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 161, batch train loss: 2.5194637775421143\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 162, batch train loss: 2.7608189582824707\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 163, batch train loss: 3.0026259422302246\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 164, batch train loss: 3.140489101409912\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 165, batch train loss: 3.2713589668273926\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 166, batch train loss: 3.1925816535949707\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 167, batch train loss: 3.099168300628662\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 168, batch train loss: 2.9560139179229736\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 169, batch train loss: 3.04132342338562\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 170, batch train loss: 2.4600656032562256\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 171, batch train loss: 2.5398685932159424\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 172, batch train loss: 2.862169027328491\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 173, batch train loss: 3.2038705348968506\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 174, batch train loss: 3.7844743728637695\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 175, batch train loss: 3.4402904510498047\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 176, batch train loss: 2.8828048706054688\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 177, batch train loss: 2.5634984970092773\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 178, batch train loss: 2.604102373123169\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 179, batch train loss: 3.1218059062957764\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 180, batch train loss: 3.2970244884490967\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 181, batch train loss: 4.016772747039795\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 182, batch train loss: 3.2311758995056152\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 183, batch train loss: 3.217024087905884\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 184, batch train loss: 3.3956077098846436\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 185, batch train loss: 3.032588243484497\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 186, batch train loss: 3.7617809772491455\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 187, batch train loss: 3.4886369705200195\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 188, batch train loss: 3.1867058277130127\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 189, batch train loss: 3.305666923522949\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 190, batch train loss: 2.9142510890960693\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 191, batch train loss: 3.050123453140259\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 192, batch train loss: 3.142578125\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 193, batch train loss: 2.8323593139648438\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 194, batch train loss: 2.9912869930267334\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 195, batch train loss: 3.2057626247406006\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 196, batch train loss: 3.1665539741516113\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 197, batch train loss: 3.438957452774048\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 198, batch train loss: 3.0834438800811768\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 199, batch train loss: 2.928640842437744\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 200, batch train loss: 3.2960166931152344\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 201, batch train loss: 3.411928415298462\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 202, batch train loss: 3.742828845977783\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 203, batch train loss: 3.9982962608337402\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 204, batch train loss: 3.735445261001587\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 205, batch train loss: 3.3657546043395996\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 206, batch train loss: 3.4505627155303955\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 207, batch train loss: 3.5984489917755127\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 208, batch train loss: 4.0705461502075195\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 209, batch train loss: 3.9883780479431152\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 210, batch train loss: 4.512547016143799\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 211, batch train loss: 3.7282462120056152\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 212, batch train loss: 3.7908809185028076\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 213, batch train loss: 4.241154193878174\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 214, batch train loss: 3.7185134887695312\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 215, batch train loss: 3.751246452331543\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 216, batch train loss: 3.4397506713867188\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 217, batch train loss: 3.36159348487854\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 218, batch train loss: 3.283385753631592\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 219, batch train loss: 4.093240261077881\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 220, batch train loss: 3.4575634002685547\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 221, batch train loss: 3.5139904022216797\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 222, batch train loss: 3.4586117267608643\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 223, batch train loss: 3.406582832336426\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 224, batch train loss: 3.7607040405273438\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 225, batch train loss: 3.8657336235046387\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 226, batch train loss: 3.3899877071380615\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 227, batch train loss: 3.3076558113098145\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 228, batch train loss: 3.2557857036590576\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 229, batch train loss: 3.2688169479370117\n",
      "\n",
      "\n",
      "Epoch: 97, batch_id: 230, batch train loss: 2.895038604736328\n",
      "\n",
      "\n",
      "Epoch: 97/ 100, Loss: 2.8750159533127495\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:09<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97 Validation Loss: 3.357658064365387\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98, batch_id: 1, batch train loss: 3.1635704040527344\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 2, batch train loss: 3.104069948196411\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 3, batch train loss: 3.247270345687866\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 4, batch train loss: 2.923905372619629\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 5, batch train loss: 2.961555242538452\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 6, batch train loss: 2.8427181243896484\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 7, batch train loss: 2.7481586933135986\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 8, batch train loss: 2.8056654930114746\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 9, batch train loss: 2.7202558517456055\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 10, batch train loss: 2.8838467597961426\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 11, batch train loss: 3.2730627059936523\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 12, batch train loss: 3.2324447631835938\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 13, batch train loss: 3.1592347621917725\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 14, batch train loss: 3.5688650608062744\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 15, batch train loss: 3.4619555473327637\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 16, batch train loss: 3.9850943088531494\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 17, batch train loss: 4.559845447540283\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 18, batch train loss: 3.8925552368164062\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 19, batch train loss: 3.800278425216675\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 20, batch train loss: 3.4870450496673584\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 21, batch train loss: 3.3215043544769287\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 22, batch train loss: 3.3361992835998535\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 23, batch train loss: 3.1673924922943115\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 24, batch train loss: 3.4397785663604736\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 25, batch train loss: 3.740410089492798\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 26, batch train loss: 3.5437350273132324\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 27, batch train loss: 2.891366481781006\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 28, batch train loss: 3.0820436477661133\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 29, batch train loss: 3.5033931732177734\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 30, batch train loss: 3.3073222637176514\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 31, batch train loss: 2.9658193588256836\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 32, batch train loss: 3.2719883918762207\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 33, batch train loss: 3.1911280155181885\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 34, batch train loss: 3.4567952156066895\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 35, batch train loss: 3.5010921955108643\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 36, batch train loss: 3.5323855876922607\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 37, batch train loss: 3.3200387954711914\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 38, batch train loss: 3.130910634994507\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 39, batch train loss: 3.1801798343658447\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 40, batch train loss: 4.0759100914001465\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 41, batch train loss: 3.9861502647399902\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 42, batch train loss: 5.43548059463501\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 43, batch train loss: 5.796281814575195\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 44, batch train loss: 4.529162883758545\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 45, batch train loss: 4.961457252502441\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 46, batch train loss: 3.533278465270996\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 47, batch train loss: 3.383739471435547\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 48, batch train loss: 5.051745414733887\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 49, batch train loss: 4.412402629852295\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 50, batch train loss: 4.372308731079102\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 51, batch train loss: 3.619870662689209\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 52, batch train loss: 3.1709814071655273\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 53, batch train loss: 3.3668103218078613\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 54, batch train loss: 3.7464773654937744\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 55, batch train loss: 3.726013660430908\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 56, batch train loss: 4.02327299118042\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 57, batch train loss: 3.45924973487854\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 58, batch train loss: 3.619462013244629\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 59, batch train loss: 3.496439218521118\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 60, batch train loss: 3.3325741291046143\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 61, batch train loss: 3.582617998123169\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 62, batch train loss: 3.193189859390259\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 63, batch train loss: 4.768307209014893\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 64, batch train loss: 3.7656733989715576\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 65, batch train loss: 3.2679860591888428\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 66, batch train loss: 3.691131114959717\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 67, batch train loss: 3.6351852416992188\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 68, batch train loss: 3.3828837871551514\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 69, batch train loss: 3.4448623657226562\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 70, batch train loss: 3.803330183029175\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 71, batch train loss: 3.3721110820770264\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 72, batch train loss: 3.2719054222106934\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 73, batch train loss: 2.811231851577759\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 74, batch train loss: 3.16475248336792\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 75, batch train loss: 3.1527066230773926\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 76, batch train loss: 3.221897602081299\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 77, batch train loss: 2.55464243888855\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 78, batch train loss: 3.0873794555664062\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 79, batch train loss: 3.211322069168091\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 80, batch train loss: 3.058579444885254\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 81, batch train loss: 3.0467944145202637\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 82, batch train loss: 3.0027990341186523\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 83, batch train loss: 3.0339455604553223\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 84, batch train loss: 3.1004838943481445\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 85, batch train loss: 2.783764123916626\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 86, batch train loss: 2.822619915008545\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 87, batch train loss: 3.156816005706787\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 88, batch train loss: 3.45542311668396\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 89, batch train loss: 2.968160629272461\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 90, batch train loss: 2.835655450820923\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 91, batch train loss: 2.6634223461151123\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 92, batch train loss: 2.6627771854400635\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 93, batch train loss: 3.5907576084136963\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 94, batch train loss: 2.948626756668091\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 95, batch train loss: 2.951500654220581\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 96, batch train loss: 2.8320789337158203\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 97, batch train loss: 3.5104146003723145\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 98, batch train loss: 3.539245128631592\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 99, batch train loss: 3.6042187213897705\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 100, batch train loss: 3.556121349334717\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 101, batch train loss: 2.7914822101593018\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 102, batch train loss: 2.9669554233551025\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 103, batch train loss: 3.026693105697632\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 104, batch train loss: 2.7643818855285645\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 105, batch train loss: 2.7913122177124023\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 106, batch train loss: 3.259204626083374\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 107, batch train loss: 3.2760987281799316\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 108, batch train loss: 3.439974069595337\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 109, batch train loss: 2.9554288387298584\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 110, batch train loss: 4.178919792175293\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 111, batch train loss: 3.2735745906829834\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 112, batch train loss: 3.9178295135498047\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 113, batch train loss: 3.2856225967407227\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 114, batch train loss: 3.08559250831604\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 115, batch train loss: 2.8103435039520264\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 116, batch train loss: 2.8930461406707764\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 117, batch train loss: 2.8023407459259033\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 118, batch train loss: 2.8609609603881836\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 119, batch train loss: 2.864276885986328\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 120, batch train loss: 3.093021869659424\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 121, batch train loss: 2.5938308238983154\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 122, batch train loss: 3.1276869773864746\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 123, batch train loss: 3.369216203689575\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 124, batch train loss: 2.973059892654419\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 125, batch train loss: 2.782346248626709\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 126, batch train loss: 2.9934184551239014\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 127, batch train loss: 2.8295252323150635\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 128, batch train loss: 3.0695011615753174\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 129, batch train loss: 3.016953229904175\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98, batch_id: 130, batch train loss: 3.0043623447418213\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 131, batch train loss: 3.140092134475708\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 132, batch train loss: 2.982860565185547\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 133, batch train loss: 2.9123666286468506\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 134, batch train loss: 2.630514621734619\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 135, batch train loss: 2.6876964569091797\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 136, batch train loss: 2.982720136642456\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 137, batch train loss: 3.1319563388824463\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 138, batch train loss: 3.5990428924560547\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 139, batch train loss: 3.587534189224243\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 140, batch train loss: 3.3080992698669434\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 141, batch train loss: 3.326641798019409\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 142, batch train loss: 3.400345802307129\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 143, batch train loss: 3.1686861515045166\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 144, batch train loss: 3.253157377243042\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 145, batch train loss: 2.9076268672943115\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 146, batch train loss: 3.129133462905884\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 147, batch train loss: 3.3787600994110107\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 148, batch train loss: 3.9913322925567627\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 149, batch train loss: 3.406989336013794\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 150, batch train loss: 3.702737331390381\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 151, batch train loss: 3.683830499649048\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 152, batch train loss: 3.1665682792663574\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 153, batch train loss: 3.054159641265869\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 154, batch train loss: 2.9332990646362305\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 155, batch train loss: 3.6821835041046143\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 156, batch train loss: 3.047441244125366\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 157, batch train loss: 3.038944721221924\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 158, batch train loss: 2.656770706176758\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 159, batch train loss: 3.0098536014556885\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 160, batch train loss: 2.8958609104156494\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 161, batch train loss: 2.790060043334961\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 162, batch train loss: 2.781073570251465\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 163, batch train loss: 3.476452589035034\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 164, batch train loss: 3.281680107116699\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 165, batch train loss: 3.222198247909546\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 166, batch train loss: 3.127589464187622\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 167, batch train loss: 2.9413914680480957\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 168, batch train loss: 3.5597102642059326\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 169, batch train loss: 3.2345728874206543\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 170, batch train loss: 3.367616891860962\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 171, batch train loss: 2.911083698272705\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 172, batch train loss: 3.857694387435913\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 173, batch train loss: 3.5009350776672363\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 174, batch train loss: 2.979403495788574\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 175, batch train loss: 4.2502899169921875\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 176, batch train loss: 3.488696813583374\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 177, batch train loss: 4.228524684906006\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 178, batch train loss: 3.656411647796631\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 179, batch train loss: 3.8123624324798584\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 180, batch train loss: 5.683038234710693\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 181, batch train loss: 5.64381742477417\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 182, batch train loss: 4.47812032699585\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 183, batch train loss: 4.648105621337891\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 184, batch train loss: 3.3846850395202637\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 185, batch train loss: 3.457777500152588\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 186, batch train loss: 4.652507781982422\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 187, batch train loss: 5.137094497680664\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 188, batch train loss: 4.5734028816223145\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 189, batch train loss: 5.212217330932617\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 190, batch train loss: 4.516667366027832\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 191, batch train loss: 4.761600494384766\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 192, batch train loss: 4.495332717895508\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 193, batch train loss: 3.9064009189605713\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 194, batch train loss: 4.812294960021973\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 195, batch train loss: 4.140679836273193\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 196, batch train loss: 3.4032933712005615\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 197, batch train loss: 3.949150800704956\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 198, batch train loss: 2.9340784549713135\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 199, batch train loss: 3.145387887954712\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 200, batch train loss: 3.2365529537200928\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 201, batch train loss: 4.303703784942627\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 202, batch train loss: 3.1492857933044434\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 203, batch train loss: 3.761974334716797\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 204, batch train loss: 2.9960777759552\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 205, batch train loss: 3.992412567138672\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 206, batch train loss: 3.101219415664673\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 207, batch train loss: 3.2226057052612305\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 208, batch train loss: 2.875688076019287\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 209, batch train loss: 2.787147283554077\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 210, batch train loss: 3.2737181186676025\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 211, batch train loss: 2.8593080043792725\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 212, batch train loss: 2.7495734691619873\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 213, batch train loss: 2.331953763961792\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 214, batch train loss: 2.52571702003479\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 215, batch train loss: 2.396451711654663\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 216, batch train loss: 2.5047287940979004\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 217, batch train loss: 2.7610578536987305\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 218, batch train loss: 2.6328883171081543\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 219, batch train loss: 3.463423252105713\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 220, batch train loss: 3.2510526180267334\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 221, batch train loss: 2.981788396835327\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 222, batch train loss: 4.821594715118408\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 223, batch train loss: 2.601318359375\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 224, batch train loss: 3.0050833225250244\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 225, batch train loss: 3.4611103534698486\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 226, batch train loss: 3.588789463043213\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 227, batch train loss: 2.6279568672180176\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 228, batch train loss: 3.661358594894409\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 229, batch train loss: 2.2282655239105225\n",
      "\n",
      "\n",
      "Epoch: 98, batch_id: 230, batch train loss: 3.461688280105591\n",
      "\n",
      "\n",
      "Epoch: 98/ 100, Loss: 3.3879318848900173\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:10<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98 Validation Loss: 4.389088559150696\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99, batch_id: 1, batch train loss: 6.3272905349731445\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 2, batch train loss: 3.452686071395874\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 3, batch train loss: 4.536572456359863\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 4, batch train loss: 3.6258890628814697\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 5, batch train loss: 4.177096366882324\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 6, batch train loss: 3.260812759399414\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 7, batch train loss: 3.5458483695983887\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 8, batch train loss: 4.39798641204834\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 9, batch train loss: 3.275995969772339\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 10, batch train loss: 2.838124990463257\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 11, batch train loss: 2.7720260620117188\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 12, batch train loss: 2.5169167518615723\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 13, batch train loss: 3.1619277000427246\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 14, batch train loss: 3.380218029022217\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 15, batch train loss: 2.435403347015381\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 16, batch train loss: 2.559678077697754\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 17, batch train loss: 2.2301182746887207\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 18, batch train loss: 2.5752177238464355\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 19, batch train loss: 2.460019588470459\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 20, batch train loss: 2.3531389236450195\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 21, batch train loss: 2.4515812397003174\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 22, batch train loss: 2.535677194595337\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 23, batch train loss: 2.7067878246307373\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 24, batch train loss: 2.4512009620666504\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 25, batch train loss: 3.9592387676239014\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 26, batch train loss: 2.948969841003418\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 27, batch train loss: 2.636082649230957\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 28, batch train loss: 2.7463409900665283\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 29, batch train loss: 3.046889543533325\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 30, batch train loss: 3.0876996517181396\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 31, batch train loss: 4.261226654052734\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 32, batch train loss: 2.9848735332489014\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 33, batch train loss: 2.8073339462280273\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 34, batch train loss: 2.8706717491149902\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 35, batch train loss: 3.5628368854522705\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 36, batch train loss: 3.105959415435791\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 37, batch train loss: 4.370694637298584\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 38, batch train loss: 4.377534866333008\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 39, batch train loss: 3.784827947616577\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 40, batch train loss: 6.188405990600586\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 41, batch train loss: 4.232922554016113\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 42, batch train loss: 3.630262851715088\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 43, batch train loss: 4.143012046813965\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 44, batch train loss: 2.7753336429595947\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 45, batch train loss: 3.147235155105591\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 46, batch train loss: 3.5291435718536377\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 47, batch train loss: 4.685985088348389\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 48, batch train loss: 2.7430717945098877\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 49, batch train loss: 3.0819778442382812\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 50, batch train loss: 3.2230982780456543\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 51, batch train loss: 3.3415465354919434\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 52, batch train loss: 4.02620267868042\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 53, batch train loss: 2.8902695178985596\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 54, batch train loss: 3.12166166305542\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 55, batch train loss: 3.3448715209960938\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 56, batch train loss: 2.8585264682769775\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 57, batch train loss: 3.169833183288574\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 58, batch train loss: 3.504733085632324\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 59, batch train loss: 2.6804492473602295\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 60, batch train loss: 3.1416337490081787\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 61, batch train loss: 3.599095344543457\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 62, batch train loss: 3.3298258781433105\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 63, batch train loss: 3.4117038249969482\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 64, batch train loss: 3.1906943321228027\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 65, batch train loss: 2.745983123779297\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 66, batch train loss: 3.3006346225738525\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 67, batch train loss: 3.350311756134033\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 68, batch train loss: 3.3329849243164062\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 69, batch train loss: 3.281301975250244\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 70, batch train loss: 3.101839542388916\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 71, batch train loss: 2.5596327781677246\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 72, batch train loss: 3.541268825531006\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 73, batch train loss: 3.5560314655303955\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 74, batch train loss: 3.6410274505615234\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 75, batch train loss: 5.5042724609375\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 76, batch train loss: 4.177542686462402\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 77, batch train loss: 4.164147853851318\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 78, batch train loss: 4.609134197235107\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 79, batch train loss: 3.7454020977020264\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 80, batch train loss: 5.989353656768799\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 81, batch train loss: 7.028229236602783\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 82, batch train loss: 4.018203258514404\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 83, batch train loss: 4.6434197425842285\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 84, batch train loss: 4.356799125671387\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 85, batch train loss: 3.3708393573760986\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 86, batch train loss: 3.785372734069824\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 87, batch train loss: 4.190770149230957\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 88, batch train loss: 3.215195894241333\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 89, batch train loss: 3.476195812225342\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 90, batch train loss: 3.2248106002807617\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 91, batch train loss: 3.2171871662139893\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 92, batch train loss: 3.1279428005218506\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 93, batch train loss: 3.909534454345703\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 94, batch train loss: 3.8273723125457764\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 95, batch train loss: 4.619767665863037\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 96, batch train loss: 3.1725332736968994\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 97, batch train loss: 3.325080156326294\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 98, batch train loss: 3.481083869934082\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 99, batch train loss: 3.9932327270507812\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 100, batch train loss: 3.561763048171997\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 101, batch train loss: 3.1078238487243652\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 102, batch train loss: 3.7562999725341797\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 103, batch train loss: 3.1808977127075195\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 104, batch train loss: 3.1500494480133057\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 105, batch train loss: 3.176629066467285\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 106, batch train loss: 3.1587421894073486\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 107, batch train loss: 3.069843053817749\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 108, batch train loss: 3.2107319831848145\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 109, batch train loss: 3.0210037231445312\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 110, batch train loss: 3.8892269134521484\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 111, batch train loss: 3.8753793239593506\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 112, batch train loss: 4.111583709716797\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 113, batch train loss: 3.8857624530792236\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 114, batch train loss: 3.811490058898926\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 115, batch train loss: 4.103880405426025\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 116, batch train loss: 3.5737016201019287\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 117, batch train loss: 3.2151360511779785\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 118, batch train loss: 3.145935297012329\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 119, batch train loss: 4.650211811065674\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 120, batch train loss: 4.1207098960876465\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 121, batch train loss: 3.927407741546631\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 122, batch train loss: 3.4390029907226562\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 123, batch train loss: 3.808361053466797\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 124, batch train loss: 3.2765841484069824\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 125, batch train loss: 4.520680904388428\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 126, batch train loss: 3.642530918121338\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 127, batch train loss: 4.238382339477539\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 128, batch train loss: 3.723224639892578\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 129, batch train loss: 3.861436367034912\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99, batch_id: 130, batch train loss: 3.955618381500244\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 131, batch train loss: 3.61372447013855\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 132, batch train loss: 4.496552467346191\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 133, batch train loss: 3.6930603981018066\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 134, batch train loss: 4.082677841186523\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 135, batch train loss: 3.4693408012390137\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 136, batch train loss: 4.076777458190918\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 137, batch train loss: 4.057742595672607\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 138, batch train loss: 3.792851209640503\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 139, batch train loss: 3.932748556137085\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 140, batch train loss: 3.387941360473633\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 141, batch train loss: 4.364858150482178\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 142, batch train loss: 3.8548078536987305\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 143, batch train loss: 3.687077283859253\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 144, batch train loss: 4.2819504737854\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 145, batch train loss: 4.680431842803955\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 146, batch train loss: 4.253959655761719\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 147, batch train loss: 5.410275936126709\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 148, batch train loss: 4.0559916496276855\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 149, batch train loss: 4.003041744232178\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 150, batch train loss: 4.168873310089111\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 151, batch train loss: 4.269223690032959\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 152, batch train loss: 4.403726577758789\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 153, batch train loss: 4.700371265411377\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 154, batch train loss: 4.542433261871338\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 155, batch train loss: 4.972238063812256\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 156, batch train loss: 4.3541035652160645\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 157, batch train loss: 3.951317548751831\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 158, batch train loss: 4.800134181976318\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 159, batch train loss: 3.991133213043213\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 160, batch train loss: 5.044130325317383\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 161, batch train loss: 4.284569263458252\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 162, batch train loss: 4.671098232269287\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 163, batch train loss: 5.042057991027832\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 164, batch train loss: 5.549472808837891\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 165, batch train loss: 4.203352928161621\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 166, batch train loss: 3.7270491123199463\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 167, batch train loss: 4.031739711761475\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 168, batch train loss: 4.51016092300415\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 169, batch train loss: 4.161275863647461\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 170, batch train loss: 5.062582492828369\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 171, batch train loss: 4.570522308349609\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 172, batch train loss: 4.198110580444336\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 173, batch train loss: 4.6442952156066895\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 174, batch train loss: 4.117611408233643\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 175, batch train loss: 4.667484760284424\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 176, batch train loss: 5.09443473815918\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 177, batch train loss: 4.043715476989746\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 178, batch train loss: 4.073706150054932\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 179, batch train loss: 3.7816081047058105\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 180, batch train loss: 4.824078559875488\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 181, batch train loss: 4.285759449005127\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 182, batch train loss: 4.81768274307251\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 183, batch train loss: 4.364872455596924\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 184, batch train loss: 5.282617092132568\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 185, batch train loss: 3.9488444328308105\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 186, batch train loss: 3.5683157444000244\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 187, batch train loss: 4.064352035522461\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 188, batch train loss: 4.004802227020264\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 189, batch train loss: 3.559098243713379\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 190, batch train loss: 3.525714635848999\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 191, batch train loss: 3.230611562728882\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 192, batch train loss: 3.0608673095703125\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 193, batch train loss: 2.962359666824341\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 194, batch train loss: 3.2190744876861572\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 195, batch train loss: 2.955350637435913\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 196, batch train loss: 2.5579633712768555\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 197, batch train loss: 2.9095566272735596\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 198, batch train loss: 3.1626577377319336\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 199, batch train loss: 2.664217948913574\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 200, batch train loss: 2.738224744796753\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 201, batch train loss: 2.5856926441192627\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 202, batch train loss: 2.580691337585449\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 203, batch train loss: 2.668484687805176\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 204, batch train loss: 2.261720657348633\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 205, batch train loss: 2.289142370223999\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 206, batch train loss: 3.2165746688842773\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 207, batch train loss: 2.4413888454437256\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 208, batch train loss: 2.0588274002075195\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 209, batch train loss: 2.4550483226776123\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 210, batch train loss: 2.0071418285369873\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 211, batch train loss: 2.046377658843994\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 212, batch train loss: 2.2709383964538574\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 213, batch train loss: 2.2780795097351074\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 214, batch train loss: 2.870466947555542\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 215, batch train loss: 2.2305402755737305\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 216, batch train loss: 2.079031229019165\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 217, batch train loss: 2.1343531608581543\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 218, batch train loss: 2.767533540725708\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 219, batch train loss: 2.5069234371185303\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 220, batch train loss: 2.759787082672119\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 221, batch train loss: 2.4824719429016113\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 222, batch train loss: 2.755793809890747\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 223, batch train loss: 2.483304023742676\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 224, batch train loss: 3.415424108505249\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 225, batch train loss: 2.6890153884887695\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 226, batch train loss: 2.5055007934570312\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 227, batch train loss: 2.9054465293884277\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 228, batch train loss: 2.674236536026001\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 229, batch train loss: 2.3701887130737305\n",
      "\n",
      "\n",
      "Epoch: 99, batch_id: 230, batch train loss: 2.3000876903533936\n",
      "\n",
      "\n",
      "Epoch: 99/ 100, Loss: 3.578047576157943\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:07<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99 Validation Loss: 2.340448937813441\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, batch_id: 1, batch train loss: 2.624722957611084\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 2, batch train loss: 3.909438371658325\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 3, batch train loss: 4.090118408203125\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 4, batch train loss: 3.606179714202881\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 5, batch train loss: 3.782489776611328\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 6, batch train loss: 2.2279231548309326\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 7, batch train loss: 2.5242104530334473\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 8, batch train loss: 1.856605052947998\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 9, batch train loss: 2.3887782096862793\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 10, batch train loss: 2.194030523300171\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 11, batch train loss: 1.810876488685608\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 12, batch train loss: 2.1106598377227783\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 13, batch train loss: 2.214308977127075\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 14, batch train loss: 2.156686544418335\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 15, batch train loss: 2.5312883853912354\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 16, batch train loss: 2.5014219284057617\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 17, batch train loss: 2.1523194313049316\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 18, batch train loss: 1.9691084623336792\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 19, batch train loss: 2.121340751647949\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 20, batch train loss: 2.842804431915283\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 21, batch train loss: 2.4979565143585205\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 22, batch train loss: 2.2997195720672607\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 23, batch train loss: 2.063265323638916\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 24, batch train loss: 2.2773263454437256\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 25, batch train loss: 2.782594919204712\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 26, batch train loss: 2.966731548309326\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 27, batch train loss: 2.7361080646514893\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 28, batch train loss: 3.3175501823425293\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 29, batch train loss: 2.8260538578033447\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 30, batch train loss: 2.7527527809143066\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 31, batch train loss: 3.861818790435791\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 32, batch train loss: 2.608808994293213\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 33, batch train loss: 3.1770365238189697\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 34, batch train loss: 2.4830551147460938\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 35, batch train loss: 2.043558120727539\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 36, batch train loss: 2.4119138717651367\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 37, batch train loss: 2.6020047664642334\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 38, batch train loss: 2.7768590450286865\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 39, batch train loss: 2.3541600704193115\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 40, batch train loss: 2.1246161460876465\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 41, batch train loss: 2.2537126541137695\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 42, batch train loss: 1.8243823051452637\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 43, batch train loss: 2.5594565868377686\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 44, batch train loss: 2.4054043292999268\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 45, batch train loss: 2.07794451713562\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 46, batch train loss: 2.809844493865967\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 47, batch train loss: 2.3299546241760254\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 48, batch train loss: 1.9984478950500488\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 49, batch train loss: 2.7620174884796143\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 50, batch train loss: 2.505681276321411\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 51, batch train loss: 2.3881044387817383\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 52, batch train loss: 2.501883029937744\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 53, batch train loss: 1.9285626411437988\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 54, batch train loss: 4.275078296661377\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 55, batch train loss: 2.696704149246216\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 56, batch train loss: 2.1753225326538086\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 57, batch train loss: 2.722532033920288\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 58, batch train loss: 2.2830851078033447\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 59, batch train loss: 2.1354358196258545\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 60, batch train loss: 2.6000328063964844\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 61, batch train loss: 1.9062813520431519\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 62, batch train loss: 3.0966384410858154\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 63, batch train loss: 2.2582273483276367\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 64, batch train loss: 3.1372756958007812\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 65, batch train loss: 2.1078455448150635\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 66, batch train loss: 1.7859382629394531\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 67, batch train loss: 1.7646321058273315\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 68, batch train loss: 2.0606470108032227\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 69, batch train loss: 2.218430280685425\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 70, batch train loss: 1.8430438041687012\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 71, batch train loss: 2.0945844650268555\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 72, batch train loss: 2.154102087020874\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 73, batch train loss: 2.212324619293213\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 74, batch train loss: 2.5155980587005615\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 75, batch train loss: 3.0779905319213867\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 76, batch train loss: 1.9524096250534058\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 77, batch train loss: 2.224515438079834\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 78, batch train loss: 2.7482409477233887\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 79, batch train loss: 4.644834995269775\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 80, batch train loss: 3.119999885559082\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 81, batch train loss: 5.2984089851379395\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 82, batch train loss: 3.0234618186950684\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 83, batch train loss: 3.2528111934661865\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 84, batch train loss: 3.785475254058838\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 85, batch train loss: 3.94193434715271\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 86, batch train loss: 2.614560842514038\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 87, batch train loss: 2.9191622734069824\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 88, batch train loss: 2.0617854595184326\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 89, batch train loss: 1.9980028867721558\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 90, batch train loss: 1.8794434070587158\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 91, batch train loss: 4.899801731109619\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 92, batch train loss: 3.344728708267212\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 93, batch train loss: 2.697439432144165\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 94, batch train loss: 2.0526211261749268\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 95, batch train loss: 1.9039913415908813\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 96, batch train loss: 2.5905325412750244\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 97, batch train loss: 2.3486104011535645\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 98, batch train loss: 2.2815637588500977\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 99, batch train loss: 2.0936038494110107\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 100, batch train loss: 1.9078530073165894\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 101, batch train loss: 1.8797492980957031\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 102, batch train loss: 2.217508554458618\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 103, batch train loss: 1.8469047546386719\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 104, batch train loss: 2.5143489837646484\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 105, batch train loss: 1.9072121381759644\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 106, batch train loss: 3.2984371185302734\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 107, batch train loss: 2.6454813480377197\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 108, batch train loss: 2.6398918628692627\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 109, batch train loss: 4.342700481414795\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 110, batch train loss: 2.7728869915008545\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 111, batch train loss: 2.095820665359497\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 112, batch train loss: 3.868917226791382\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 113, batch train loss: 2.941119432449341\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 114, batch train loss: 2.5904479026794434\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 115, batch train loss: 4.037050724029541\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 116, batch train loss: 2.2202436923980713\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 117, batch train loss: 2.5213747024536133\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 118, batch train loss: 3.2717418670654297\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 119, batch train loss: 2.5949208736419678\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 120, batch train loss: 3.065558910369873\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 121, batch train loss: 2.7611782550811768\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 122, batch train loss: 1.6865718364715576\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 123, batch train loss: 1.8299731016159058\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 124, batch train loss: 2.154104709625244\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 125, batch train loss: 2.487764835357666\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 126, batch train loss: 2.682649850845337\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 127, batch train loss: 2.155611991882324\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, batch_id: 128, batch train loss: 2.799999475479126\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 129, batch train loss: 2.0409390926361084\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 130, batch train loss: 2.46977162361145\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 131, batch train loss: 3.497483015060425\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 132, batch train loss: 3.458470106124878\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 133, batch train loss: 2.568979024887085\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 134, batch train loss: 2.8875656127929688\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 135, batch train loss: 3.3805415630340576\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 136, batch train loss: 3.3657784461975098\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 137, batch train loss: 4.043323040008545\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 138, batch train loss: 2.4362025260925293\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 139, batch train loss: 2.444535732269287\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 140, batch train loss: 4.352662563323975\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 141, batch train loss: 2.774876594543457\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 142, batch train loss: 3.1545472145080566\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 143, batch train loss: 2.5355336666107178\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 144, batch train loss: 2.9240660667419434\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 145, batch train loss: 3.2697136402130127\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 146, batch train loss: 3.3083314895629883\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 147, batch train loss: 1.8300319910049438\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 148, batch train loss: 3.1781229972839355\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 149, batch train loss: 1.9732940196990967\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 150, batch train loss: 2.627812623977661\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 151, batch train loss: 2.1035537719726562\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 152, batch train loss: 2.5722427368164062\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 153, batch train loss: 2.741412878036499\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 154, batch train loss: 2.3486528396606445\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 155, batch train loss: 2.8717920780181885\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 156, batch train loss: 2.3478806018829346\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 157, batch train loss: 2.8335068225860596\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 158, batch train loss: 2.514155864715576\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 159, batch train loss: 2.5610315799713135\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 160, batch train loss: 2.4182913303375244\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 161, batch train loss: 2.953766107559204\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 162, batch train loss: 2.6292922496795654\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 163, batch train loss: 2.285954236984253\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 164, batch train loss: 2.251749277114868\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 165, batch train loss: 2.622905969619751\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 166, batch train loss: 2.4390480518341064\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 167, batch train loss: 2.7288854122161865\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 168, batch train loss: 2.2458226680755615\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 169, batch train loss: 2.2304582595825195\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 170, batch train loss: 2.5350780487060547\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 171, batch train loss: 2.775094509124756\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 172, batch train loss: 3.8581290245056152\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 173, batch train loss: 3.227245330810547\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 174, batch train loss: 2.684220314025879\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 175, batch train loss: 2.569371223449707\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 176, batch train loss: 3.1824963092803955\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 177, batch train loss: 3.0952494144439697\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 178, batch train loss: 3.023104190826416\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 179, batch train loss: 2.5195369720458984\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 180, batch train loss: 2.6699106693267822\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 181, batch train loss: 2.784189224243164\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 182, batch train loss: 2.648684024810791\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 183, batch train loss: 2.5928714275360107\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 184, batch train loss: 2.7360098361968994\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 185, batch train loss: 2.7297089099884033\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 186, batch train loss: 2.3351693153381348\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 187, batch train loss: 2.3875420093536377\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 188, batch train loss: 3.4212841987609863\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 189, batch train loss: 2.9138433933258057\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 190, batch train loss: 3.042750358581543\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 191, batch train loss: 2.875575065612793\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 192, batch train loss: 2.549130439758301\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 193, batch train loss: 2.7570295333862305\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 194, batch train loss: 2.627715587615967\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 195, batch train loss: 2.8781471252441406\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 196, batch train loss: 3.169323205947876\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 197, batch train loss: 2.945863962173462\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 198, batch train loss: 2.845860242843628\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 199, batch train loss: 2.752854347229004\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 200, batch train loss: 2.599113941192627\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 201, batch train loss: 3.465205192565918\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 202, batch train loss: 3.070159912109375\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 203, batch train loss: 2.8026533126831055\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 204, batch train loss: 2.7516708374023438\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 205, batch train loss: 2.483665943145752\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 206, batch train loss: 2.8683977127075195\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 207, batch train loss: 2.720172166824341\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 208, batch train loss: 2.7858200073242188\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 209, batch train loss: 2.820983409881592\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 210, batch train loss: 2.2681314945220947\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 211, batch train loss: 2.4679956436157227\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 212, batch train loss: 2.2147653102874756\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 213, batch train loss: 3.069624900817871\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 214, batch train loss: 2.4070122241973877\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 215, batch train loss: 2.543003559112549\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 216, batch train loss: 2.264085292816162\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 217, batch train loss: 2.589602470397949\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 218, batch train loss: 2.2897868156433105\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 219, batch train loss: 2.832970142364502\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 220, batch train loss: 2.5248351097106934\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 221, batch train loss: 2.9916861057281494\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 222, batch train loss: 2.9004573822021484\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 223, batch train loss: 2.577615261077881\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 224, batch train loss: 2.476008892059326\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 225, batch train loss: 2.3746724128723145\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 226, batch train loss: 3.265972852706909\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 227, batch train loss: 3.1869561672210693\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 228, batch train loss: 2.6828384399414062\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 229, batch train loss: 3.172438144683838\n",
      "\n",
      "\n",
      "Epoch: 100, batch_id: 230, batch train loss: 2.9056389331817627\n",
      "\n",
      "\n",
      "Epoch: 100/ 100, Loss: 2.67474881514259\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [01:07<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 Validation Loss: 2.7706087907155355\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    total_loss = 0; val_loss = 0\n",
    "    for batch_idx, (inp_vid, tar_img, tar_pls) in enumerate(train_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inp_vid, tar_img, tar_pls = inp_vid.to(device), tar_img.to(device), tar_pls.to(device)\n",
    "        \n",
    "        out_vid = net(inp_vid)\n",
    "        \n",
    "        out_img = out_vid.sum(dim=2, keepdim=True).squeeze(1).squeeze(1)\n",
    "        out_pls = out_vid.sum(dim=[3,4], keepdim=True).squeeze(1).squeeze(2).squeeze(2)\n",
    "        \n",
    "        loss_img = criterion(out_img, tar_img)\n",
    "        loss_pls = criterion(out_pls, tar_pls)\n",
    "        \n",
    "        #loss = loss_img# + 0.5 * loss_pls\n",
    "        loss = loss_pls\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1}, batch_id: {batch_idx+1}, batch train loss: {loss.item()}\")\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    train_losses.append(total_loss/len(train_loader))\n",
    "    print(f\"Epoch: {epoch + 1}/ {num_epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "    print(\"-\"*50)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for inp_vid, tar_img, tar_pls in tqdm(val_loader):\n",
    "            inp_vid, tar_img, tar_pls = inp_vid.to(device), tar_img.to(device), tar_pls.to(device)\n",
    "            out_vid = net(inp_vid)\n",
    "            out_img = out_vid.sum(dim=2, keepdim=True).squeeze(1).squeeze(1)\n",
    "            out_pls = out_vid.sum(dim=[3, 4], keepdim=True).squeeze(1).squeeze(2).squeeze(2)\n",
    "            loss_img = criterion(out_img, tar_img)\n",
    "            loss_pls = criterion(out_pls, tar_pls)\n",
    "            #loss = loss_img#+ 0.5*loss_pls\n",
    "            loss = loss_pls\n",
    "            val_loss += loss.item()\n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Epoch: {epoch + 1} Validation Loss: {val_loss}\")\n",
    "        print(\"-\"*50)\n",
    "        print(\"\\n\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epoch_path = f\"{save_path}/chck_epoch_{epoch+1}.pt\"\n",
    "            torch.save({'epoch': epoch + 1,\n",
    "                        'model_state_dict': net.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict()},\n",
    "                         epoch_path)\n",
    "            print(f\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6d96bf1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cebb3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(1,num_epochs+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "607a414e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and Validation Loss vs. Epoch for ViT-3D Translator \\n (Pulse-only)')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.plot(epochs[:60], train_losses[:60], label = 'training loss', marker = 'o')\n",
    "plt.plot(epochs[:60], val_losses[:60], label = 'validation loss', marker = \"*\")\n",
    "plt.legend(fontsize = 20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.xlabel(\"Epoch\", fontsize = 20)\n",
    "plt.ylabel(\"Loss\", fontsize = 20)\n",
    "plt.title(\"Training and Validation Loss vs. Epoch for ViT-3D Translator \\n (Pulse-only)\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7f3c83fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03302317339306076"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "656d20ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmin(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3c314c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/rishabhsharma/Desktop/UR_MSDS_Fall_2024/Capstone/LLE/ViT_AE_prototype/Results/first_pulse_only/val_losses.npy'\n",
    "np.save(path, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
